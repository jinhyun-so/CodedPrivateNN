{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2\n",
    "from models.Fed import FedAvg\n",
    "from models.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models.test import test_img\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "size of X: (60000, 784)\n",
      "size of Y: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2\n",
    "from models.Fed import FedAvg\n",
    "from models.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models.test import test_img\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "\n",
    "class my_argument:    \n",
    "    epochs = 200    #\"rounds of training\"\n",
    "    num_users = 15  # \"number of users: N\"\n",
    "    num_partition = 6 # \"number of users: K\"\n",
    "    frac = 0.5 #\"the fraction of clients: C\"\n",
    "    local_ep = 1 #\"the number of local epochs: E\"\n",
    "    local_bs = 200 #\"local batch size: B\"\n",
    "    bs=200 #\"test batch size\"\n",
    "    lr=0.01 #\"learning rate\"\n",
    "    momentum=0.5 # \"SGD momentum (default: 0.5)\"\n",
    "    split='user' # \"train-test split type, user or sample\"\n",
    "    opt='ADAM'\n",
    "    loss='Custom' # 'Custom' or 'Default'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num=9 #, help='number of each kind of kernel')\n",
    "    kernel_sizes='3,4,5' #  help='comma-separated kernel size to use for convolution')\n",
    "    norm='None' #, help=\"batch_norm, layer_norm, or None\")\n",
    "    num_filters=32 #, help=\"number of filters for conv nets\")\n",
    "    max_pool='True' #help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    dataset='mnist' #, help=\"name of dataset\")\n",
    "    iid=1\n",
    "    num_classes=10#, help=\"number of classes\")\n",
    "    num_channels=1#, help=\"number of channels of imges\")\n",
    "    gpu=1#, help=\"GPU ID, -1 for CPU\")\n",
    "    stopping_rounds=10#, help='rounds of early stopping')\n",
    "    verbose='False'#, help='verbose print')\n",
    "    seed=1#, help='random seed (default: 1)')\n",
    "    \n",
    "args = my_argument()\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "# load dataset and split users\n",
    "trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "\n",
    "dict_users = mnist_iid(dataset_train, args.num_partition)\n",
    "\n",
    "encoding_input_array_np = np.empty((len(dataset_train),28*28))\n",
    "encoding_label_array_np = np.empty((len(dataset_train),args.num_classes))\n",
    "print(\"size of X:\" ,encoding_input_array_np.shape)\n",
    "print(\"size of Y:\" ,encoding_label_array_np.shape)\n",
    "\n",
    "Size_submatrices = int(60000/args.num_partition)\n",
    "\n",
    "for i in range(args.num_partition):\n",
    "    \n",
    "    stt_pos = i*Size_submatrices\n",
    "    end_pos = (i+1)*Size_submatrices\n",
    "#     print(i,stt_pos,end_pos)\n",
    "    Temp_train = DataLoader(DatasetSplit(dataset_train, dict_users[i]), batch_size=Size_submatrices, shuffle=True)\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(Temp_train):\n",
    "        \n",
    "        images_np = images.detach().cpu().numpy()\n",
    "        encoding_input_array_np[stt_pos:end_pos,:] = np.reshape(images_np, (Size_submatrices,28*28))\n",
    "#         print(encoding_input_array_np[stt_pos:end_pos,:].shape)\n",
    "\n",
    "        onehot_labels = torch.nn.functional.one_hot(labels,num_classes=args.num_classes)\n",
    "        labels_np = onehot_labels.detach().cpu().numpy()\n",
    "#         print(labels_np.shape)\n",
    "        encoding_label_array_np[stt_pos:end_pos,:] = labels_np\n",
    "\n",
    "\n",
    "# print(labels_np[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Encoding MNIST (N=15, K=6, T=3, Sigma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_array:  [ 9.84807753e-01  8.66025404e-01  6.42787610e-01  3.42020143e-01\n",
      "  6.12323400e-17 -3.42020143e-01 -6.42787610e-01 -8.66025404e-01\n",
      " -9.84807753e-01] \n",
      "\n",
      "z_array:  [ 1.          0.9781476   0.91354546  0.80901699  0.66913061  0.5\n",
      "  0.30901699  0.10452846 -0.10452846 -0.30901699 -0.5        -0.66913061\n",
      " -0.80901699 -0.91354546 -0.9781476 ] \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "(15, 10000, 784)\n"
     ]
    }
   ],
   "source": [
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "N = args.num_users\n",
    "K = args.num_partition\n",
    "T = 3\n",
    "sigma = 0.01\n",
    "Noise_Alloc = [2,4,7] # np.random.choice(range(K+T), T, replace=False)\n",
    "\n",
    "\n",
    "j_array = np.array(range(K+T))\n",
    "# print(\"j: \",(2*j_array+1)*math.pi/2/K,'\\n')\n",
    "\n",
    "alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "print(\"alpha_array: \",alpha_array,'\\n')\n",
    "\n",
    "i_array = np.array(range(N))\n",
    "z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "print(\"z_array: \",z_array,'\\n')\n",
    "\n",
    "Noise_Alloc = [2,4,6]\n",
    "X_tilde,a,b = BACC_Enc_withNoise(encoding_input_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "y_tilde,a,b = BACC_Enc_withNoise(encoding_label_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "\n",
    "print(X_tilde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 5, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "Signal_Alloc = []\n",
    "for i in range(K+T):\n",
    "    if i not in Noise_Alloc:\n",
    "        Signal_Alloc.append(i)\n",
    "print(Signal_Alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of results: 15\n",
      "(m= 15 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2995 \n",
      "Accuracy: 1171/10000 (11.71%)\n",
      "\n",
      "Round   0, Average loss 2.299 Test accuracy 11.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5675 \n",
      "Accuracy: 7552/10000 (75.52%)\n",
      "\n",
      "Round   1, Average loss 1.568 Test accuracy 75.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0586 \n",
      "Accuracy: 7524/10000 (75.24%)\n",
      "\n",
      "Round   2, Average loss 4.059 Test accuracy 75.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.1901 \n",
      "Accuracy: 7005/10000 (70.05%)\n",
      "\n",
      "Round   3, Average loss 6.190 Test accuracy 70.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.1861 \n",
      "Accuracy: 7385/10000 (73.85%)\n",
      "\n",
      "Round   4, Average loss 5.186 Test accuracy 73.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.3346 \n",
      "Accuracy: 7322/10000 (73.22%)\n",
      "\n",
      "Round   5, Average loss 11.335 Test accuracy 73.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.4360 \n",
      "Accuracy: 7245/10000 (72.45%)\n",
      "\n",
      "Round   6, Average loss 4.436 Test accuracy 72.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.6258 \n",
      "Accuracy: 7101/10000 (71.01%)\n",
      "\n",
      "Round   7, Average loss 12.626 Test accuracy 71.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2432 \n",
      "Accuracy: 7325/10000 (73.25%)\n",
      "\n",
      "Round   8, Average loss 3.243 Test accuracy 73.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.4562 \n",
      "Accuracy: 7413/10000 (74.13%)\n",
      "\n",
      "Round   9, Average loss 9.456 Test accuracy 74.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.1399 \n",
      "Accuracy: 5741/10000 (57.41%)\n",
      "\n",
      "Round  10, Average loss 10.140 Test accuracy 57.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.9015 \n",
      "Accuracy: 7041/10000 (70.41%)\n",
      "\n",
      "Round  11, Average loss 7.902 Test accuracy 70.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.4090 \n",
      "Accuracy: 6634/10000 (66.34%)\n",
      "\n",
      "Round  12, Average loss 5.409 Test accuracy 66.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.3959 \n",
      "Accuracy: 6284/10000 (62.84%)\n",
      "\n",
      "Round  13, Average loss 11.396 Test accuracy 62.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9397 \n",
      "Accuracy: 6309/10000 (63.09%)\n",
      "\n",
      "Round  14, Average loss 6.940 Test accuracy 63.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.7071 \n",
      "Accuracy: 6155/10000 (61.55%)\n",
      "\n",
      "Round  15, Average loss 9.707 Test accuracy 61.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.3441 \n",
      "Accuracy: 6270/10000 (62.70%)\n",
      "\n",
      "Round  16, Average loss 5.344 Test accuracy 62.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.8436 \n",
      "Accuracy: 5802/10000 (58.02%)\n",
      "\n",
      "Round  17, Average loss 10.844 Test accuracy 58.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.3220 \n",
      "Accuracy: 5969/10000 (59.69%)\n",
      "\n",
      "Round  18, Average loss 7.322 Test accuracy 59.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.0854 \n",
      "Accuracy: 5936/10000 (59.36%)\n",
      "\n",
      "Round  19, Average loss 7.085 Test accuracy 59.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.7703 \n",
      "Accuracy: 5882/10000 (58.82%)\n",
      "\n",
      "Round  20, Average loss 8.770 Test accuracy 58.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.8717 \n",
      "Accuracy: 5697/10000 (56.97%)\n",
      "\n",
      "Round  21, Average loss 9.872 Test accuracy 56.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.0002 \n",
      "Accuracy: 5757/10000 (57.57%)\n",
      "\n",
      "Round  22, Average loss 8.000 Test accuracy 57.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.2024 \n",
      "Accuracy: 5802/10000 (58.02%)\n",
      "\n",
      "Round  23, Average loss 8.202 Test accuracy 58.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4111 \n",
      "Accuracy: 5735/10000 (57.35%)\n",
      "\n",
      "Round  24, Average loss 7.411 Test accuracy 57.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.5948 \n",
      "Accuracy: 5952/10000 (59.52%)\n",
      "\n",
      "Round  25, Average loss 8.595 Test accuracy 59.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.5073 \n",
      "Accuracy: 6012/10000 (60.12%)\n",
      "\n",
      "Round  26, Average loss 6.507 Test accuracy 60.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9077 \n",
      "Accuracy: 6555/10000 (65.55%)\n",
      "\n",
      "Round  27, Average loss 6.908 Test accuracy 65.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.2056 \n",
      "Accuracy: 6345/10000 (63.45%)\n",
      "\n",
      "Round  28, Average loss 6.206 Test accuracy 63.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.4105 \n",
      "Accuracy: 6299/10000 (62.99%)\n",
      "\n",
      "Round  29, Average loss 8.410 Test accuracy 62.990\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "# training\n",
    "loss_train_arr = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "net_best = None\n",
    "best_loss = None\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "# m_array = np.array(range(4,16)) # m is the number of received result @ master\n",
    "m_array = np.array([15]) # m is the number of received result @ master\n",
    "loss_test_arr = np.empty((len(m_array),N_trials,N_epochs))\n",
    "acc_test_arr  = np.empty((len(m_array),N_trials,N_epochs))\n",
    "\n",
    "for m_idx in range(len(m_array)):   \n",
    "    \n",
    "    m = m_array[m_idx] # m is the number of received result @ master\n",
    "    print('number of results:',m)\n",
    "    \n",
    "    for trial_idx in range(N_trials):\n",
    "        print('(m=',m,') ',trial_idx,'-th Trial!!')\n",
    "        \n",
    "        net_glob = CNNMnist2(args=args)\n",
    "        net_glob.cuda()\n",
    "        net_glob.train()\n",
    "\n",
    "        # copy weights\n",
    "        w_glob = net_glob.state_dict()\n",
    "        \n",
    "        y_hat = net_glob(X_tilde[idx,:,:])\n",
    "        for iter in range(N_epochs): #args.epochs\n",
    "            w_locals, loss_locals = [], []\n",
    "            idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "            idxs_users = np.sort(idxs_users)\n",
    "            print('selected users:',idxs_users)\n",
    "\n",
    "            dec_z_array = []\n",
    "            for idx in idxs_users: #for idx in range(N):\n",
    "        #         print(idx)\n",
    "                local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                w_locals.append(copy.deepcopy(w))\n",
    "                loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "            # update global weights\n",
    "            #w_glob = FedAvg(w_locals)\n",
    "            w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "            # copy weight to net_glob\n",
    "            net_glob.load_state_dict(w_glob)\n",
    "\n",
    "            # print loss\n",
    "        #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "        #     loss_train_arr.append(loss_train)\n",
    "\n",
    "            acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "            acc_test_arr[m_idx][trial_idx][iter] = acc_test\n",
    "            loss_test_arr[m_idx][trial_idx][iter] = loss_test\n",
    "            if iter % 1 ==0:\n",
    "                print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "            #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98480775  0.8660254   0.34202014 -0.34202014 -0.8660254  -0.98480775]\n"
     ]
    }
   ],
   "source": [
    "print(alpha_array[Signal_Alloc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Encoding MNIST (N=15, K=6, T=[0,1,2,3], Sigma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T= 0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2873 \n",
      "Accuracy: 5058/10000 (50.58%)\n",
      "\n",
      "Round   1, Average loss 2.287 Test accuracy 50.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0460 \n",
      "Accuracy: 9397/10000 (93.97%)\n",
      "\n",
      "Round   2, Average loss 1.046 Test accuracy 93.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5650 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round   3, Average loss 0.565 Test accuracy 95.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1770 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round   4, Average loss 0.177 Test accuracy 95.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1501 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round   5, Average loss 0.150 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1589 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round   6, Average loss 0.159 Test accuracy 95.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1460 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round   7, Average loss 0.146 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1400 \n",
      "Accuracy: 9615/10000 (96.15%)\n",
      "\n",
      "Round   8, Average loss 0.140 Test accuracy 96.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1461 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round   9, Average loss 0.146 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1426 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  10, Average loss 0.143 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1445 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  11, Average loss 0.145 Test accuracy 95.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1348 \n",
      "Accuracy: 9622/10000 (96.22%)\n",
      "\n",
      "Round  12, Average loss 0.135 Test accuracy 96.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1507 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  13, Average loss 0.151 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1487 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  14, Average loss 0.149 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1515 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  15, Average loss 0.152 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1534 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  16, Average loss 0.153 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1444 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round  17, Average loss 0.144 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1539 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  18, Average loss 0.154 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1515 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  19, Average loss 0.151 Test accuracy 95.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1543 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  20, Average loss 0.154 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1524 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  21, Average loss 0.152 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1650 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  22, Average loss 0.165 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1833 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round  23, Average loss 0.183 Test accuracy 95.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1625 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round  24, Average loss 0.163 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1864 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  25, Average loss 0.186 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1589 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  26, Average loss 0.159 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1450 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  27, Average loss 0.145 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1625 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  28, Average loss 0.163 Test accuracy 95.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1428 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round  29, Average loss 0.143 Test accuracy 95.970\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T= 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3012 \n",
      "Accuracy: 1877/10000 (18.77%)\n",
      "\n",
      "Round   0, Average loss 2.301 Test accuracy 18.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6965 \n",
      "Accuracy: 8598/10000 (85.98%)\n",
      "\n",
      "Round   1, Average loss 1.696 Test accuracy 85.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3992 \n",
      "Accuracy: 9234/10000 (92.34%)\n",
      "\n",
      "Round   2, Average loss 0.399 Test accuracy 92.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3696 \n",
      "Accuracy: 9093/10000 (90.93%)\n",
      "\n",
      "Round   3, Average loss 0.370 Test accuracy 90.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3405 \n",
      "Accuracy: 9015/10000 (90.15%)\n",
      "\n",
      "Round   4, Average loss 0.341 Test accuracy 90.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2772 \n",
      "Accuracy: 9205/10000 (92.05%)\n",
      "\n",
      "Round   5, Average loss 0.277 Test accuracy 92.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3855 \n",
      "Accuracy: 8708/10000 (87.08%)\n",
      "\n",
      "Round   6, Average loss 0.386 Test accuracy 87.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3377 \n",
      "Accuracy: 9139/10000 (91.39%)\n",
      "\n",
      "Round   7, Average loss 0.338 Test accuracy 91.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3112 \n",
      "Accuracy: 9037/10000 (90.37%)\n",
      "\n",
      "Round   8, Average loss 0.311 Test accuracy 90.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4544 \n",
      "Accuracy: 8662/10000 (86.62%)\n",
      "\n",
      "Round   9, Average loss 0.454 Test accuracy 86.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3024 \n",
      "Accuracy: 9076/10000 (90.76%)\n",
      "\n",
      "Round  10, Average loss 0.302 Test accuracy 90.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3607 \n",
      "Accuracy: 8939/10000 (89.39%)\n",
      "\n",
      "Round  11, Average loss 0.361 Test accuracy 89.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3849 \n",
      "Accuracy: 8749/10000 (87.49%)\n",
      "\n",
      "Round  12, Average loss 0.385 Test accuracy 87.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3405 \n",
      "Accuracy: 8983/10000 (89.83%)\n",
      "\n",
      "Round  13, Average loss 0.341 Test accuracy 89.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4577 \n",
      "Accuracy: 8456/10000 (84.56%)\n",
      "\n",
      "Round  14, Average loss 0.458 Test accuracy 84.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4637 \n",
      "Accuracy: 8674/10000 (86.74%)\n",
      "\n",
      "Round  15, Average loss 0.464 Test accuracy 86.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3429 \n",
      "Accuracy: 9006/10000 (90.06%)\n",
      "\n",
      "Round  16, Average loss 0.343 Test accuracy 90.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3565 \n",
      "Accuracy: 9016/10000 (90.16%)\n",
      "\n",
      "Round  17, Average loss 0.356 Test accuracy 90.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3964 \n",
      "Accuracy: 8785/10000 (87.85%)\n",
      "\n",
      "Round  18, Average loss 0.396 Test accuracy 87.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3589 \n",
      "Accuracy: 8937/10000 (89.37%)\n",
      "\n",
      "Round  19, Average loss 0.359 Test accuracy 89.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5362 \n",
      "Accuracy: 8196/10000 (81.96%)\n",
      "\n",
      "Round  20, Average loss 0.536 Test accuracy 81.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4073 \n",
      "Accuracy: 8821/10000 (88.21%)\n",
      "\n",
      "Round  21, Average loss 0.407 Test accuracy 88.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5913 \n",
      "Accuracy: 8062/10000 (80.62%)\n",
      "\n",
      "Round  22, Average loss 0.591 Test accuracy 80.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3574 \n",
      "Accuracy: 9041/10000 (90.41%)\n",
      "\n",
      "Round  23, Average loss 0.357 Test accuracy 90.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5942 \n",
      "Accuracy: 8244/10000 (82.44%)\n",
      "\n",
      "Round  24, Average loss 0.594 Test accuracy 82.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4029 \n",
      "Accuracy: 8746/10000 (87.46%)\n",
      "\n",
      "Round  25, Average loss 0.403 Test accuracy 87.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6472 \n",
      "Accuracy: 7862/10000 (78.62%)\n",
      "\n",
      "Round  26, Average loss 0.647 Test accuracy 78.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3911 \n",
      "Accuracy: 8910/10000 (89.10%)\n",
      "\n",
      "Round  27, Average loss 0.391 Test accuracy 89.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5319 \n",
      "Accuracy: 8326/10000 (83.26%)\n",
      "\n",
      "Round  28, Average loss 0.532 Test accuracy 83.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5246 \n",
      "Accuracy: 8475/10000 (84.75%)\n",
      "\n",
      "Round  29, Average loss 0.525 Test accuracy 84.750\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T= 2 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3687 \n",
      "Accuracy: 8195/10000 (81.95%)\n",
      "\n",
      "Round   1, Average loss 1.369 Test accuracy 81.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8730 \n",
      "Accuracy: 9091/10000 (90.91%)\n",
      "\n",
      "Round   2, Average loss 2.873 Test accuracy 90.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.7586 \n",
      "Accuracy: 9033/10000 (90.33%)\n",
      "\n",
      "Round   3, Average loss 5.759 Test accuracy 90.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.3782 \n",
      "Accuracy: 8902/10000 (89.02%)\n",
      "\n",
      "Round   4, Average loss 8.378 Test accuracy 89.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.3830 \n",
      "Accuracy: 8025/10000 (80.25%)\n",
      "\n",
      "Round   5, Average loss 20.383 Test accuracy 80.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.4319 \n",
      "Accuracy: 8112/10000 (81.12%)\n",
      "\n",
      "Round   6, Average loss 18.432 Test accuracy 81.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.2184 \n",
      "Accuracy: 7779/10000 (77.79%)\n",
      "\n",
      "Round   7, Average loss 27.218 Test accuracy 77.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.5827 \n",
      "Accuracy: 7887/10000 (78.87%)\n",
      "\n",
      "Round   8, Average loss 22.583 Test accuracy 78.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 34.0310 \n",
      "Accuracy: 7560/10000 (75.60%)\n",
      "\n",
      "Round   9, Average loss 34.031 Test accuracy 75.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.5621 \n",
      "Accuracy: 7837/10000 (78.37%)\n",
      "\n",
      "Round  10, Average loss 24.562 Test accuracy 78.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 49.2088 \n",
      "Accuracy: 6967/10000 (69.67%)\n",
      "\n",
      "Round  11, Average loss 49.209 Test accuracy 69.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.7804 \n",
      "Accuracy: 8451/10000 (84.51%)\n",
      "\n",
      "Round  12, Average loss 17.780 Test accuracy 84.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.0898 \n",
      "Accuracy: 7681/10000 (76.81%)\n",
      "\n",
      "Round  13, Average loss 32.090 Test accuracy 76.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.1472 \n",
      "Accuracy: 7698/10000 (76.98%)\n",
      "\n",
      "Round  14, Average loss 28.147 Test accuracy 76.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.1847 \n",
      "Accuracy: 7541/10000 (75.41%)\n",
      "\n",
      "Round  15, Average loss 35.185 Test accuracy 75.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.5507 \n",
      "Accuracy: 7751/10000 (77.51%)\n",
      "\n",
      "Round  16, Average loss 28.551 Test accuracy 77.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 46.0404 \n",
      "Accuracy: 7036/10000 (70.36%)\n",
      "\n",
      "Round  17, Average loss 46.040 Test accuracy 70.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.9306 \n",
      "Accuracy: 8061/10000 (80.61%)\n",
      "\n",
      "Round  18, Average loss 22.931 Test accuracy 80.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 33.1799 \n",
      "Accuracy: 7715/10000 (77.15%)\n",
      "\n",
      "Round  19, Average loss 33.180 Test accuracy 77.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.4774 \n",
      "Accuracy: 7719/10000 (77.19%)\n",
      "\n",
      "Round  20, Average loss 29.477 Test accuracy 77.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 34.2496 \n",
      "Accuracy: 7562/10000 (75.62%)\n",
      "\n",
      "Round  21, Average loss 34.250 Test accuracy 75.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.9070 \n",
      "Accuracy: 7660/10000 (76.60%)\n",
      "\n",
      "Round  22, Average loss 28.907 Test accuracy 76.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 54.6116 \n",
      "Accuracy: 6942/10000 (69.42%)\n",
      "\n",
      "Round  23, Average loss 54.612 Test accuracy 69.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.7062 \n",
      "Accuracy: 8096/10000 (80.96%)\n",
      "\n",
      "Round  24, Average loss 25.706 Test accuracy 80.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.5514 \n",
      "Accuracy: 8039/10000 (80.39%)\n",
      "\n",
      "Round  25, Average loss 25.551 Test accuracy 80.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 53.4150 \n",
      "Accuracy: 6989/10000 (69.89%)\n",
      "\n",
      "Round  26, Average loss 53.415 Test accuracy 69.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 30.3150 \n",
      "Accuracy: 7752/10000 (77.52%)\n",
      "\n",
      "Round  27, Average loss 30.315 Test accuracy 77.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.2995 \n",
      "Accuracy: 7532/10000 (75.32%)\n",
      "\n",
      "Round  28, Average loss 35.299 Test accuracy 75.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 40.1955 \n",
      "Accuracy: 7334/10000 (73.34%)\n",
      "\n",
      "Round  29, Average loss 40.195 Test accuracy 73.340\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T= 3 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1126/10000 (11.26%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2849 \n",
      "Accuracy: 7833/10000 (78.33%)\n",
      "\n",
      "Round   1, Average loss 1.285 Test accuracy 78.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2027 \n",
      "Accuracy: 8675/10000 (86.75%)\n",
      "\n",
      "Round   2, Average loss 5.203 Test accuracy 86.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.5499 \n",
      "Accuracy: 8666/10000 (86.66%)\n",
      "\n",
      "Round   3, Average loss 8.550 Test accuracy 86.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.3870 \n",
      "Accuracy: 8741/10000 (87.41%)\n",
      "\n",
      "Round   4, Average loss 10.387 Test accuracy 87.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.0639 \n",
      "Accuracy: 8446/10000 (84.46%)\n",
      "\n",
      "Round   5, Average loss 15.064 Test accuracy 84.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.8554 \n",
      "Accuracy: 8141/10000 (81.41%)\n",
      "\n",
      "Round   6, Average loss 18.855 Test accuracy 81.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.7610 \n",
      "Accuracy: 8051/10000 (80.51%)\n",
      "\n",
      "Round   7, Average loss 21.761 Test accuracy 80.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.5802 \n",
      "Accuracy: 8130/10000 (81.30%)\n",
      "\n",
      "Round   8, Average loss 20.580 Test accuracy 81.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.8239 \n",
      "Accuracy: 7918/10000 (79.18%)\n",
      "\n",
      "Round   9, Average loss 24.824 Test accuracy 79.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.7069 \n",
      "Accuracy: 7918/10000 (79.18%)\n",
      "\n",
      "Round  10, Average loss 25.707 Test accuracy 79.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.3377 \n",
      "Accuracy: 7896/10000 (78.96%)\n",
      "\n",
      "Round  11, Average loss 25.338 Test accuracy 78.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.4203 \n",
      "Accuracy: 8020/10000 (80.20%)\n",
      "\n",
      "Round  12, Average loss 23.420 Test accuracy 80.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.9946 \n",
      "Accuracy: 7833/10000 (78.33%)\n",
      "\n",
      "Round  13, Average loss 29.995 Test accuracy 78.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.6270 \n",
      "Accuracy: 7921/10000 (79.21%)\n",
      "\n",
      "Round  14, Average loss 23.627 Test accuracy 79.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.9914 \n",
      "Accuracy: 7483/10000 (74.83%)\n",
      "\n",
      "Round  15, Average loss 31.991 Test accuracy 74.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.9502 \n",
      "Accuracy: 7841/10000 (78.41%)\n",
      "\n",
      "Round  16, Average loss 24.950 Test accuracy 78.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 34.5039 \n",
      "Accuracy: 7628/10000 (76.28%)\n",
      "\n",
      "Round  17, Average loss 34.504 Test accuracy 76.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.4221 \n",
      "Accuracy: 7958/10000 (79.58%)\n",
      "\n",
      "Round  18, Average loss 24.422 Test accuracy 79.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 30.9409 \n",
      "Accuracy: 7752/10000 (77.52%)\n",
      "\n",
      "Round  19, Average loss 30.941 Test accuracy 77.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.9639 \n",
      "Accuracy: 7923/10000 (79.23%)\n",
      "\n",
      "Round  20, Average loss 24.964 Test accuracy 79.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.8102 \n",
      "Accuracy: 7622/10000 (76.22%)\n",
      "\n",
      "Round  21, Average loss 35.810 Test accuracy 76.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.5114 \n",
      "Accuracy: 7896/10000 (78.96%)\n",
      "\n",
      "Round  22, Average loss 23.511 Test accuracy 78.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 43.1047 \n",
      "Accuracy: 7241/10000 (72.41%)\n",
      "\n",
      "Round  23, Average loss 43.105 Test accuracy 72.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.4118 \n",
      "Accuracy: 7800/10000 (78.00%)\n",
      "\n",
      "Round  24, Average loss 24.412 Test accuracy 78.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 57.5473 \n",
      "Accuracy: 7040/10000 (70.40%)\n",
      "\n",
      "Round  25, Average loss 57.547 Test accuracy 70.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.4732 \n",
      "Accuracy: 7860/10000 (78.60%)\n",
      "\n",
      "Round  26, Average loss 24.473 Test accuracy 78.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 40.9563 \n",
      "Accuracy: 7195/10000 (71.95%)\n",
      "\n",
      "Round  27, Average loss 40.956 Test accuracy 71.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 47.1226 \n",
      "Accuracy: 7102/10000 (71.02%)\n",
      "\n",
      "Round  28, Average loss 47.123 Test accuracy 71.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 38.9664 \n",
      "Accuracy: 7360/10000 (73.60%)\n",
      "\n",
      "Round  29, Average loss 38.966 Test accuracy 73.600\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "N = args.num_users\n",
    "K = args.num_partition\n",
    "\n",
    "sigma = 0.1\n",
    "\n",
    "\n",
    "# training\n",
    "loss_train_arr = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "net_best = None\n",
    "best_loss = None\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "# m_array = np.array(range(4,16)) # m is the number of received result @ master\n",
    "T_array = np.array([0,1,2,3]) # m is the number of received result @ master\n",
    "\n",
    "\n",
    "loss_test_arr = np.empty((len(T_array),N_trials,N_epochs))\n",
    "acc_test_arr  = np.empty((len(T_array),N_trials,N_epochs))\n",
    "\n",
    "for T_idx in range(len(T_array)):\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    T = T_array[T_idx]\n",
    "    \n",
    "    if T == 0:\n",
    "        Noise_Alloc = []\n",
    "    elif T == 1:\n",
    "        Noise_Alloc = [3]\n",
    "    elif T == 2:\n",
    "        Noise_Alloc = [2,5]\n",
    "    else:\n",
    "        Noise_Alloc = [2,4,7] # np.random.choice(range(K+T), T, replace=False)\n",
    "        \n",
    "    Signal_Alloc = []\n",
    "    for i in range(K+T):\n",
    "        if i not in Noise_Alloc:\n",
    "            Signal_Alloc.append(i)\n",
    "\n",
    "    j_array = np.array(range(K+T))\n",
    "    # print(\"j: \",(2*j_array+1)*math.pi/2/K,'\\n')\n",
    "\n",
    "    alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "    i_array = np.array(range(N))\n",
    "    z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "\n",
    "    X_tilde,a,b = BACC_Enc_withNoise(encoding_input_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "    y_tilde,a,b = BACC_Enc_withNoise(encoding_label_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "    \n",
    "    m = N # m is the number of received result @ master\n",
    "#     print('number of results:',m)\n",
    "    \n",
    "    for trial_idx in range(N_trials):\n",
    "        print('(T=',T,') ',trial_idx,'-th Trial!!')\n",
    "        \n",
    "        net_glob = CNNMnist2(args=args)\n",
    "        net_glob.cuda()\n",
    "        net_glob.train()\n",
    "\n",
    "        # copy weights\n",
    "        w_glob = net_glob.state_dict()\n",
    "\n",
    "        for iter in range(N_epochs): #args.epochs\n",
    "            w_locals, loss_locals = [], []\n",
    "            idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "            idxs_users = np.sort(idxs_users)\n",
    "            print('selected users:',idxs_users)\n",
    "\n",
    "            dec_z_array = []\n",
    "            for idx in idxs_users: #for idx in range(N):\n",
    "        #         print(idx)\n",
    "                local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                w_locals.append(copy.deepcopy(w))\n",
    "                loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "            # update global weights\n",
    "            #w_glob = FedAvg(w_locals)\n",
    "            w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "            # copy weight to net_glob\n",
    "            net_glob.load_state_dict(w_glob)\n",
    "\n",
    "            # print loss\n",
    "        #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "        #     loss_train_arr.append(loss_train)\n",
    "\n",
    "            acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "            acc_test_arr[T_idx][trial_idx][iter] = acc_test\n",
    "            loss_test_arr[T_idx][trial_idx][iter] = loss_test\n",
    "            if iter % 1 ==0:\n",
    "                print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "            #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 30)\n",
      "(4, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_acc = np.mean(acc_test_arr, axis=1)\n",
    "print(acc_test_arr.shape)\n",
    "print(plot_acc.shape)\n",
    "\n",
    "plt.plot(plot_acc[0,:],label='T=0, sigma=0.1')\n",
    "plt.plot(plot_acc[1,:],label='T=1, sigma=0.1')\n",
    "plt.plot(plot_acc[2,:],label='T=2, sigma=0.1')\n",
    "plt.plot(plot_acc[3,:],label='T=3, sigma=0.1')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "\n",
    "filehandler = open(\"./plot/MNIST_LeNet_N15_K6_T_0_1_2_3_sigma0-1_test_acc\",\"wb\")\n",
    "pickle.dump(acc_test_arr,filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Encoding MNIST (N=15, K=6, T=[0,1,...,7], Sigma=[0, 0.1, 1, 10, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T, sigma)= 0 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2916 \n",
      "Accuracy: 5728/10000 (57.28%)\n",
      "\n",
      "Round   1, Average loss 2.292 Test accuracy 57.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3518 \n",
      "Accuracy: 9048/10000 (90.48%)\n",
      "\n",
      "Round   2, Average loss 1.352 Test accuracy 90.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8508 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round   3, Average loss 0.851 Test accuracy 94.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2926 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round   4, Average loss 0.293 Test accuracy 94.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2120 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round   5, Average loss 0.212 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1734 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round   6, Average loss 0.173 Test accuracy 95.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1694 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round   7, Average loss 0.169 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1894 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round   8, Average loss 0.189 Test accuracy 95.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1713 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round   9, Average loss 0.171 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1655 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  10, Average loss 0.165 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2015 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round  11, Average loss 0.202 Test accuracy 95.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1524 \n",
      "Accuracy: 9602/10000 (96.02%)\n",
      "\n",
      "Round  12, Average loss 0.152 Test accuracy 96.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1376 \n",
      "Accuracy: 9600/10000 (96.00%)\n",
      "\n",
      "Round  13, Average loss 0.138 Test accuracy 96.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1519 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  14, Average loss 0.152 Test accuracy 95.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1430 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  15, Average loss 0.143 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1403 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round  16, Average loss 0.140 Test accuracy 95.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1419 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  17, Average loss 0.142 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1445 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round  18, Average loss 0.145 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1450 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  19, Average loss 0.145 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1441 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round  20, Average loss 0.144 Test accuracy 95.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1423 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  21, Average loss 0.142 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1404 \n",
      "Accuracy: 9600/10000 (96.00%)\n",
      "\n",
      "Round  22, Average loss 0.140 Test accuracy 96.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1620 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  23, Average loss 0.162 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1655 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  24, Average loss 0.166 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1558 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  25, Average loss 0.156 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1546 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  26, Average loss 0.155 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1508 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  27, Average loss 0.151 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1447 \n",
      "Accuracy: 9610/10000 (96.10%)\n",
      "\n",
      "Round  28, Average loss 0.145 Test accuracy 96.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1506 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round  29, Average loss 0.151 Test accuracy 95.740\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T, sigma)= 0 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2851 \n",
      "Accuracy: 5423/10000 (54.23%)\n",
      "\n",
      "Round   1, Average loss 2.285 Test accuracy 54.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0484 \n",
      "Accuracy: 8858/10000 (88.58%)\n",
      "\n",
      "Round   2, Average loss 1.048 Test accuracy 88.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2918 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round   3, Average loss 0.292 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2164 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round   4, Average loss 0.216 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2317 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round   5, Average loss 0.232 Test accuracy 95.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1602 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round   6, Average loss 0.160 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1539 \n",
      "Accuracy: 9616/10000 (96.16%)\n",
      "\n",
      "Round   7, Average loss 0.154 Test accuracy 96.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1445 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round   8, Average loss 0.145 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1396 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round   9, Average loss 0.140 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1682 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round  10, Average loss 0.168 Test accuracy 95.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1359 \n",
      "Accuracy: 9627/10000 (96.27%)\n",
      "\n",
      "Round  11, Average loss 0.136 Test accuracy 96.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1553 \n",
      "Accuracy: 9587/10000 (95.87%)\n",
      "\n",
      "Round  12, Average loss 0.155 Test accuracy 95.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1391 \n",
      "Accuracy: 9602/10000 (96.02%)\n",
      "\n",
      "Round  13, Average loss 0.139 Test accuracy 96.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1386 \n",
      "Accuracy: 9617/10000 (96.17%)\n",
      "\n",
      "Round  14, Average loss 0.139 Test accuracy 96.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1463 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  15, Average loss 0.146 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1402 \n",
      "Accuracy: 9604/10000 (96.04%)\n",
      "\n",
      "Round  16, Average loss 0.140 Test accuracy 96.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1503 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  17, Average loss 0.150 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1577 \n",
      "Accuracy: 9599/10000 (95.99%)\n",
      "\n",
      "Round  18, Average loss 0.158 Test accuracy 95.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1851 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  19, Average loss 0.185 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1713 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  20, Average loss 0.171 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1550 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  21, Average loss 0.155 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1568 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round  22, Average loss 0.157 Test accuracy 95.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1658 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  23, Average loss 0.166 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1844 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round  24, Average loss 0.184 Test accuracy 95.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1938 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  25, Average loss 0.194 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1931 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  26, Average loss 0.193 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1910 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  27, Average loss 0.191 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1681 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  28, Average loss 0.168 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1522 \n",
      "Accuracy: 9607/10000 (96.07%)\n",
      "\n",
      "Round  29, Average loss 0.152 Test accuracy 96.070\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T, sigma)= 0 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3017 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1741 \n",
      "Accuracy: 7415/10000 (74.15%)\n",
      "\n",
      "Round   1, Average loss 2.174 Test accuracy 74.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2931 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round   2, Average loss 0.293 Test accuracy 95.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1683 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round   3, Average loss 0.168 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1576 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round   4, Average loss 0.158 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1431 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round   5, Average loss 0.143 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1593 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round   6, Average loss 0.159 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1674 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round   7, Average loss 0.167 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1683 \n",
      "Accuracy: 9600/10000 (96.00%)\n",
      "\n",
      "Round   8, Average loss 0.168 Test accuracy 96.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1638 \n",
      "Accuracy: 9615/10000 (96.15%)\n",
      "\n",
      "Round   9, Average loss 0.164 Test accuracy 96.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1518 \n",
      "Accuracy: 9601/10000 (96.01%)\n",
      "\n",
      "Round  10, Average loss 0.152 Test accuracy 96.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1750 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  11, Average loss 0.175 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1690 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  12, Average loss 0.169 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1518 \n",
      "Accuracy: 9605/10000 (96.05%)\n",
      "\n",
      "Round  13, Average loss 0.152 Test accuracy 96.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1779 \n",
      "Accuracy: 9608/10000 (96.08%)\n",
      "\n",
      "Round  14, Average loss 0.178 Test accuracy 96.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1589 \n",
      "Accuracy: 9599/10000 (95.99%)\n",
      "\n",
      "Round  15, Average loss 0.159 Test accuracy 95.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1761 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  16, Average loss 0.176 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2004 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  17, Average loss 0.200 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1851 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  18, Average loss 0.185 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1822 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  19, Average loss 0.182 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1976 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  20, Average loss 0.198 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1733 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round  21, Average loss 0.173 Test accuracy 95.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1650 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  22, Average loss 0.165 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1654 \n",
      "Accuracy: 9606/10000 (96.06%)\n",
      "\n",
      "Round  23, Average loss 0.165 Test accuracy 96.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2026 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  24, Average loss 0.203 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2002 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  25, Average loss 0.200 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1784 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  26, Average loss 0.178 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1956 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  27, Average loss 0.196 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1775 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  28, Average loss 0.178 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2111 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  29, Average loss 0.211 Test accuracy 95.650\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T, sigma)= 0 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3021 \n",
      "Accuracy: 1175/10000 (11.75%)\n",
      "\n",
      "Round   1, Average loss 2.302 Test accuracy 11.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0620 \n",
      "Accuracy: 8376/10000 (83.76%)\n",
      "\n",
      "Round   2, Average loss 2.062 Test accuracy 83.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4038 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round   3, Average loss 0.404 Test accuracy 94.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2734 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round   4, Average loss 0.273 Test accuracy 95.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1601 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round   5, Average loss 0.160 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1596 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round   6, Average loss 0.160 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1507 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round   7, Average loss 0.151 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1403 \n",
      "Accuracy: 9607/10000 (96.07%)\n",
      "\n",
      "Round   8, Average loss 0.140 Test accuracy 96.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1610 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round   9, Average loss 0.161 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1360 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  10, Average loss 0.136 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1428 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  11, Average loss 0.143 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1528 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  12, Average loss 0.153 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1503 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  13, Average loss 0.150 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1540 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round  14, Average loss 0.154 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1526 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  15, Average loss 0.153 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1581 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  16, Average loss 0.158 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1364 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round  17, Average loss 0.136 Test accuracy 95.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1661 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  18, Average loss 0.166 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1571 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  19, Average loss 0.157 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1530 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  20, Average loss 0.153 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1403 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  21, Average loss 0.140 Test accuracy 96.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1501 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  22, Average loss 0.150 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1439 \n",
      "Accuracy: 9599/10000 (95.99%)\n",
      "\n",
      "Round  23, Average loss 0.144 Test accuracy 95.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1511 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round  24, Average loss 0.151 Test accuracy 95.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1655 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  25, Average loss 0.166 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1490 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  26, Average loss 0.149 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1512 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  27, Average loss 0.151 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1507 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  28, Average loss 0.151 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1828 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  29, Average loss 0.183 Test accuracy 95.260\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T, sigma)= 0 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2770 \n",
      "Accuracy: 5201/10000 (52.01%)\n",
      "\n",
      "Round   1, Average loss 2.277 Test accuracy 52.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3596 \n",
      "Accuracy: 8902/10000 (89.02%)\n",
      "\n",
      "Round   2, Average loss 0.360 Test accuracy 89.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2103 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round   3, Average loss 0.210 Test accuracy 95.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1431 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round   4, Average loss 0.143 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1662 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round   5, Average loss 0.166 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1456 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round   6, Average loss 0.146 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1486 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round   7, Average loss 0.149 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1883 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round   8, Average loss 0.188 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1785 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round   9, Average loss 0.178 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1845 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  10, Average loss 0.185 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1746 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round  11, Average loss 0.175 Test accuracy 95.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1649 \n",
      "Accuracy: 9594/10000 (95.94%)\n",
      "\n",
      "Round  12, Average loss 0.165 Test accuracy 95.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2029 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  13, Average loss 0.203 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2142 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round  14, Average loss 0.214 Test accuracy 95.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1889 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  15, Average loss 0.189 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1809 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  16, Average loss 0.181 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1871 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  17, Average loss 0.187 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2031 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  18, Average loss 0.203 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1692 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  19, Average loss 0.169 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1932 \n",
      "Accuracy: 9594/10000 (95.94%)\n",
      "\n",
      "Round  20, Average loss 0.193 Test accuracy 95.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1898 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round  21, Average loss 0.190 Test accuracy 95.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1829 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  22, Average loss 0.183 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2390 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round  23, Average loss 0.239 Test accuracy 95.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1876 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  24, Average loss 0.188 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1922 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  25, Average loss 0.192 Test accuracy 95.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1988 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  26, Average loss 0.199 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2187 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  27, Average loss 0.219 Test accuracy 95.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2431 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round  28, Average loss 0.243 Test accuracy 95.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2102 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  29, Average loss 0.210 Test accuracy 95.470\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T, sigma)= 1 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5301 \n",
      "Accuracy: 8528/10000 (85.28%)\n",
      "\n",
      "Round   1, Average loss 1.530 Test accuracy 85.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4234 \n",
      "Accuracy: 9250/10000 (92.50%)\n",
      "\n",
      "Round   2, Average loss 0.423 Test accuracy 92.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4220 \n",
      "Accuracy: 9149/10000 (91.49%)\n",
      "\n",
      "Round   3, Average loss 0.422 Test accuracy 91.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3654 \n",
      "Accuracy: 9181/10000 (91.81%)\n",
      "\n",
      "Round   4, Average loss 0.365 Test accuracy 91.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2964 \n",
      "Accuracy: 9193/10000 (91.93%)\n",
      "\n",
      "Round   5, Average loss 0.296 Test accuracy 91.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3696 \n",
      "Accuracy: 8977/10000 (89.77%)\n",
      "\n",
      "Round   6, Average loss 0.370 Test accuracy 89.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3011 \n",
      "Accuracy: 9141/10000 (91.41%)\n",
      "\n",
      "Round   7, Average loss 0.301 Test accuracy 91.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3203 \n",
      "Accuracy: 8935/10000 (89.35%)\n",
      "\n",
      "Round   8, Average loss 0.320 Test accuracy 89.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3067 \n",
      "Accuracy: 9118/10000 (91.18%)\n",
      "\n",
      "Round   9, Average loss 0.307 Test accuracy 91.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3504 \n",
      "Accuracy: 8866/10000 (88.66%)\n",
      "\n",
      "Round  10, Average loss 0.350 Test accuracy 88.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4098 \n",
      "Accuracy: 8637/10000 (86.37%)\n",
      "\n",
      "Round  11, Average loss 0.410 Test accuracy 86.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3298 \n",
      "Accuracy: 8987/10000 (89.87%)\n",
      "\n",
      "Round  12, Average loss 0.330 Test accuracy 89.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3463 \n",
      "Accuracy: 8946/10000 (89.46%)\n",
      "\n",
      "Round  13, Average loss 0.346 Test accuracy 89.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3808 \n",
      "Accuracy: 8866/10000 (88.66%)\n",
      "\n",
      "Round  14, Average loss 0.381 Test accuracy 88.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3651 \n",
      "Accuracy: 8869/10000 (88.69%)\n",
      "\n",
      "Round  15, Average loss 0.365 Test accuracy 88.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5980 \n",
      "Accuracy: 8169/10000 (81.69%)\n",
      "\n",
      "Round  16, Average loss 0.598 Test accuracy 81.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3646 \n",
      "Accuracy: 8876/10000 (88.76%)\n",
      "\n",
      "Round  17, Average loss 0.365 Test accuracy 88.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5079 \n",
      "Accuracy: 8483/10000 (84.83%)\n",
      "\n",
      "Round  18, Average loss 0.508 Test accuracy 84.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3623 \n",
      "Accuracy: 8785/10000 (87.85%)\n",
      "\n",
      "Round  19, Average loss 0.362 Test accuracy 87.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4305 \n",
      "Accuracy: 8470/10000 (84.70%)\n",
      "\n",
      "Round  20, Average loss 0.431 Test accuracy 84.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4539 \n",
      "Accuracy: 8556/10000 (85.56%)\n",
      "\n",
      "Round  21, Average loss 0.454 Test accuracy 85.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5608 \n",
      "Accuracy: 8089/10000 (80.89%)\n",
      "\n",
      "Round  22, Average loss 0.561 Test accuracy 80.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3155 \n",
      "Accuracy: 9012/10000 (90.12%)\n",
      "\n",
      "Round  23, Average loss 0.315 Test accuracy 90.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5430 \n",
      "Accuracy: 8201/10000 (82.01%)\n",
      "\n",
      "Round  24, Average loss 0.543 Test accuracy 82.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3957 \n",
      "Accuracy: 8867/10000 (88.67%)\n",
      "\n",
      "Round  25, Average loss 0.396 Test accuracy 88.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4156 \n",
      "Accuracy: 8685/10000 (86.85%)\n",
      "\n",
      "Round  26, Average loss 0.416 Test accuracy 86.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3629 \n",
      "Accuracy: 8970/10000 (89.70%)\n",
      "\n",
      "Round  27, Average loss 0.363 Test accuracy 89.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4085 \n",
      "Accuracy: 8693/10000 (86.93%)\n",
      "\n",
      "Round  28, Average loss 0.408 Test accuracy 86.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4393 \n",
      "Accuracy: 8534/10000 (85.34%)\n",
      "\n",
      "Round  29, Average loss 0.439 Test accuracy 85.340\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T, sigma)= 1 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0442 \n",
      "Accuracy: 8311/10000 (83.11%)\n",
      "\n",
      "Round   1, Average loss 2.044 Test accuracy 83.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3808 \n",
      "Accuracy: 9179/10000 (91.79%)\n",
      "\n",
      "Round   2, Average loss 0.381 Test accuracy 91.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3092 \n",
      "Accuracy: 9050/10000 (90.50%)\n",
      "\n",
      "Round   3, Average loss 0.309 Test accuracy 90.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3410 \n",
      "Accuracy: 8897/10000 (88.97%)\n",
      "\n",
      "Round   4, Average loss 0.341 Test accuracy 88.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3267 \n",
      "Accuracy: 9065/10000 (90.65%)\n",
      "\n",
      "Round   5, Average loss 0.327 Test accuracy 90.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3290 \n",
      "Accuracy: 8954/10000 (89.54%)\n",
      "\n",
      "Round   6, Average loss 0.329 Test accuracy 89.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3530 \n",
      "Accuracy: 8891/10000 (88.91%)\n",
      "\n",
      "Round   7, Average loss 0.353 Test accuracy 88.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4230 \n",
      "Accuracy: 8649/10000 (86.49%)\n",
      "\n",
      "Round   8, Average loss 0.423 Test accuracy 86.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3166 \n",
      "Accuracy: 9046/10000 (90.46%)\n",
      "\n",
      "Round   9, Average loss 0.317 Test accuracy 90.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3793 \n",
      "Accuracy: 8788/10000 (87.88%)\n",
      "\n",
      "Round  10, Average loss 0.379 Test accuracy 87.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3390 \n",
      "Accuracy: 8969/10000 (89.69%)\n",
      "\n",
      "Round  11, Average loss 0.339 Test accuracy 89.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3634 \n",
      "Accuracy: 8817/10000 (88.17%)\n",
      "\n",
      "Round  12, Average loss 0.363 Test accuracy 88.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3264 \n",
      "Accuracy: 9025/10000 (90.25%)\n",
      "\n",
      "Round  13, Average loss 0.326 Test accuracy 90.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3885 \n",
      "Accuracy: 8759/10000 (87.59%)\n",
      "\n",
      "Round  14, Average loss 0.388 Test accuracy 87.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3416 \n",
      "Accuracy: 8948/10000 (89.48%)\n",
      "\n",
      "Round  15, Average loss 0.342 Test accuracy 89.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3834 \n",
      "Accuracy: 8811/10000 (88.11%)\n",
      "\n",
      "Round  16, Average loss 0.383 Test accuracy 88.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4720 \n",
      "Accuracy: 8389/10000 (83.89%)\n",
      "\n",
      "Round  17, Average loss 0.472 Test accuracy 83.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6007 \n",
      "Accuracy: 8219/10000 (82.19%)\n",
      "\n",
      "Round  18, Average loss 0.601 Test accuracy 82.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4089 \n",
      "Accuracy: 8654/10000 (86.54%)\n",
      "\n",
      "Round  19, Average loss 0.409 Test accuracy 86.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3883 \n",
      "Accuracy: 8780/10000 (87.80%)\n",
      "\n",
      "Round  20, Average loss 0.388 Test accuracy 87.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4991 \n",
      "Accuracy: 8281/10000 (82.81%)\n",
      "\n",
      "Round  21, Average loss 0.499 Test accuracy 82.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3324 \n",
      "Accuracy: 8962/10000 (89.62%)\n",
      "\n",
      "Round  22, Average loss 0.332 Test accuracy 89.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4394 \n",
      "Accuracy: 8566/10000 (85.66%)\n",
      "\n",
      "Round  23, Average loss 0.439 Test accuracy 85.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4531 \n",
      "Accuracy: 8496/10000 (84.96%)\n",
      "\n",
      "Round  24, Average loss 0.453 Test accuracy 84.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3543 \n",
      "Accuracy: 8944/10000 (89.44%)\n",
      "\n",
      "Round  25, Average loss 0.354 Test accuracy 89.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4250 \n",
      "Accuracy: 8608/10000 (86.08%)\n",
      "\n",
      "Round  26, Average loss 0.425 Test accuracy 86.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3746 \n",
      "Accuracy: 8872/10000 (88.72%)\n",
      "\n",
      "Round  27, Average loss 0.375 Test accuracy 88.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4338 \n",
      "Accuracy: 8604/10000 (86.04%)\n",
      "\n",
      "Round  28, Average loss 0.434 Test accuracy 86.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3189 \n",
      "Accuracy: 9023/10000 (90.23%)\n",
      "\n",
      "Round  29, Average loss 0.319 Test accuracy 90.230\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T, sigma)= 1 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2925 \n",
      "Accuracy: 5666/10000 (56.66%)\n",
      "\n",
      "Round   1, Average loss 2.293 Test accuracy 56.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2500 \n",
      "Accuracy: 8980/10000 (89.80%)\n",
      "\n",
      "Round   2, Average loss 1.250 Test accuracy 89.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6470 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round   3, Average loss 0.647 Test accuracy 93.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7063 \n",
      "Accuracy: 9315/10000 (93.15%)\n",
      "\n",
      "Round   4, Average loss 0.706 Test accuracy 93.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6462 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round   5, Average loss 0.646 Test accuracy 93.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6630 \n",
      "Accuracy: 9391/10000 (93.91%)\n",
      "\n",
      "Round   6, Average loss 0.663 Test accuracy 93.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7220 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round   7, Average loss 0.722 Test accuracy 93.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6048 \n",
      "Accuracy: 9332/10000 (93.32%)\n",
      "\n",
      "Round   8, Average loss 0.605 Test accuracy 93.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6872 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round   9, Average loss 0.687 Test accuracy 93.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6246 \n",
      "Accuracy: 9341/10000 (93.41%)\n",
      "\n",
      "Round  10, Average loss 0.625 Test accuracy 93.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6444 \n",
      "Accuracy: 9267/10000 (92.67%)\n",
      "\n",
      "Round  11, Average loss 0.644 Test accuracy 92.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5771 \n",
      "Accuracy: 9379/10000 (93.79%)\n",
      "\n",
      "Round  12, Average loss 0.577 Test accuracy 93.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6440 \n",
      "Accuracy: 9265/10000 (92.65%)\n",
      "\n",
      "Round  13, Average loss 0.644 Test accuracy 92.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5560 \n",
      "Accuracy: 9345/10000 (93.45%)\n",
      "\n",
      "Round  14, Average loss 0.556 Test accuracy 93.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6294 \n",
      "Accuracy: 9336/10000 (93.36%)\n",
      "\n",
      "Round  15, Average loss 0.629 Test accuracy 93.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5495 \n",
      "Accuracy: 9298/10000 (92.98%)\n",
      "\n",
      "Round  16, Average loss 0.549 Test accuracy 92.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7823 \n",
      "Accuracy: 9260/10000 (92.60%)\n",
      "\n",
      "Round  17, Average loss 0.782 Test accuracy 92.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5153 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round  18, Average loss 0.515 Test accuracy 93.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7243 \n",
      "Accuracy: 9286/10000 (92.86%)\n",
      "\n",
      "Round  19, Average loss 0.724 Test accuracy 92.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5526 \n",
      "Accuracy: 9252/10000 (92.52%)\n",
      "\n",
      "Round  20, Average loss 0.553 Test accuracy 92.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6286 \n",
      "Accuracy: 9308/10000 (93.08%)\n",
      "\n",
      "Round  21, Average loss 0.629 Test accuracy 93.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5784 \n",
      "Accuracy: 9254/10000 (92.54%)\n",
      "\n",
      "Round  22, Average loss 0.578 Test accuracy 92.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6936 \n",
      "Accuracy: 9215/10000 (92.15%)\n",
      "\n",
      "Round  23, Average loss 0.694 Test accuracy 92.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5056 \n",
      "Accuracy: 9321/10000 (93.21%)\n",
      "\n",
      "Round  24, Average loss 0.506 Test accuracy 93.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6321 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round  25, Average loss 0.632 Test accuracy 92.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5931 \n",
      "Accuracy: 9263/10000 (92.63%)\n",
      "\n",
      "Round  26, Average loss 0.593 Test accuracy 92.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6314 \n",
      "Accuracy: 9262/10000 (92.62%)\n",
      "\n",
      "Round  27, Average loss 0.631 Test accuracy 92.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5434 \n",
      "Accuracy: 9323/10000 (93.23%)\n",
      "\n",
      "Round  28, Average loss 0.543 Test accuracy 93.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5930 \n",
      "Accuracy: 9252/10000 (92.52%)\n",
      "\n",
      "Round  29, Average loss 0.593 Test accuracy 92.520\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T, sigma)= 1 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3019 \n",
      "Accuracy: 1453/10000 (14.53%)\n",
      "\n",
      "Round   1, Average loss 2.302 Test accuracy 14.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2747 \n",
      "Accuracy: 7471/10000 (74.71%)\n",
      "\n",
      "Round   2, Average loss 2.275 Test accuracy 74.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1828 \n",
      "Accuracy: 9030/10000 (90.30%)\n",
      "\n",
      "Round   3, Average loss 2.183 Test accuracy 90.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1451 \n",
      "Accuracy: 9114/10000 (91.14%)\n",
      "\n",
      "Round   4, Average loss 2.145 Test accuracy 91.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0940 \n",
      "Accuracy: 9294/10000 (92.94%)\n",
      "\n",
      "Round   5, Average loss 2.094 Test accuracy 92.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1152 \n",
      "Accuracy: 9365/10000 (93.65%)\n",
      "\n",
      "Round   6, Average loss 2.115 Test accuracy 93.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0779 \n",
      "Accuracy: 9421/10000 (94.21%)\n",
      "\n",
      "Round   7, Average loss 2.078 Test accuracy 94.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0981 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round   8, Average loss 2.098 Test accuracy 93.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0631 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round   9, Average loss 2.063 Test accuracy 93.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1118 \n",
      "Accuracy: 9415/10000 (94.15%)\n",
      "\n",
      "Round  10, Average loss 2.112 Test accuracy 94.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0968 \n",
      "Accuracy: 9368/10000 (93.68%)\n",
      "\n",
      "Round  11, Average loss 2.097 Test accuracy 93.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1156 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  12, Average loss 2.116 Test accuracy 93.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0969 \n",
      "Accuracy: 9242/10000 (92.42%)\n",
      "\n",
      "Round  13, Average loss 2.097 Test accuracy 92.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0989 \n",
      "Accuracy: 9215/10000 (92.15%)\n",
      "\n",
      "Round  14, Average loss 2.099 Test accuracy 92.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1229 \n",
      "Accuracy: 9192/10000 (91.92%)\n",
      "\n",
      "Round  15, Average loss 2.123 Test accuracy 91.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1032 \n",
      "Accuracy: 9460/10000 (94.60%)\n",
      "\n",
      "Round  16, Average loss 2.103 Test accuracy 94.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1228 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  17, Average loss 2.123 Test accuracy 94.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0966 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  18, Average loss 2.097 Test accuracy 94.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1000 \n",
      "Accuracy: 9052/10000 (90.52%)\n",
      "\n",
      "Round  19, Average loss 2.100 Test accuracy 90.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0843 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  20, Average loss 2.084 Test accuracy 94.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0971 \n",
      "Accuracy: 9413/10000 (94.13%)\n",
      "\n",
      "Round  21, Average loss 2.097 Test accuracy 94.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1181 \n",
      "Accuracy: 9429/10000 (94.29%)\n",
      "\n",
      "Round  22, Average loss 2.118 Test accuracy 94.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1080 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  23, Average loss 2.108 Test accuracy 94.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1292 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round  24, Average loss 2.129 Test accuracy 94.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0810 \n",
      "Accuracy: 9469/10000 (94.69%)\n",
      "\n",
      "Round  25, Average loss 2.081 Test accuracy 94.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0993 \n",
      "Accuracy: 9389/10000 (93.89%)\n",
      "\n",
      "Round  26, Average loss 2.099 Test accuracy 93.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1278 \n",
      "Accuracy: 9431/10000 (94.31%)\n",
      "\n",
      "Round  27, Average loss 2.128 Test accuracy 94.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1313 \n",
      "Accuracy: 9341/10000 (93.41%)\n",
      "\n",
      "Round  28, Average loss 2.131 Test accuracy 93.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0985 \n",
      "Accuracy: 9414/10000 (94.14%)\n",
      "\n",
      "Round  29, Average loss 2.099 Test accuracy 94.140\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T, sigma)= 1 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3022 \n",
      "Accuracy: 2877/10000 (28.77%)\n",
      "\n",
      "Round   2, Average loss 2.302 Test accuracy 28.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3013 \n",
      "Accuracy: 1973/10000 (19.73%)\n",
      "\n",
      "Round   3, Average loss 2.301 Test accuracy 19.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3003 \n",
      "Accuracy: 2598/10000 (25.98%)\n",
      "\n",
      "Round   4, Average loss 2.300 Test accuracy 25.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2985 \n",
      "Accuracy: 3823/10000 (38.23%)\n",
      "\n",
      "Round   5, Average loss 2.298 Test accuracy 38.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2994 \n",
      "Accuracy: 1118/10000 (11.18%)\n",
      "\n",
      "Round   6, Average loss 2.299 Test accuracy 11.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2983 \n",
      "Accuracy: 1687/10000 (16.87%)\n",
      "\n",
      "Round   7, Average loss 2.298 Test accuracy 16.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3000 \n",
      "Accuracy: 1294/10000 (12.94%)\n",
      "\n",
      "Round   8, Average loss 2.300 Test accuracy 12.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2989 \n",
      "Accuracy: 1772/10000 (17.72%)\n",
      "\n",
      "Round   9, Average loss 2.299 Test accuracy 17.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2971 \n",
      "Accuracy: 1800/10000 (18.00%)\n",
      "\n",
      "Round  10, Average loss 2.297 Test accuracy 18.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2991 \n",
      "Accuracy: 974/10000 (9.74%)\n",
      "\n",
      "Round  11, Average loss 2.299 Test accuracy 9.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3009 \n",
      "Accuracy: 977/10000 (9.77%)\n",
      "\n",
      "Round  12, Average loss 2.301 Test accuracy 9.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3015 \n",
      "Accuracy: 1485/10000 (14.85%)\n",
      "\n",
      "Round  13, Average loss 2.301 Test accuracy 14.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3010 \n",
      "Accuracy: 1191/10000 (11.91%)\n",
      "\n",
      "Round  14, Average loss 2.301 Test accuracy 11.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3015 \n",
      "Accuracy: 1400/10000 (14.00%)\n",
      "\n",
      "Round  15, Average loss 2.302 Test accuracy 14.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2997 \n",
      "Accuracy: 1620/10000 (16.20%)\n",
      "\n",
      "Round  16, Average loss 2.300 Test accuracy 16.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3006 \n",
      "Accuracy: 1163/10000 (11.63%)\n",
      "\n",
      "Round  17, Average loss 2.301 Test accuracy 11.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2993 \n",
      "Accuracy: 1442/10000 (14.42%)\n",
      "\n",
      "Round  18, Average loss 2.299 Test accuracy 14.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3010 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  19, Average loss 2.301 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2996 \n",
      "Accuracy: 1478/10000 (14.78%)\n",
      "\n",
      "Round  20, Average loss 2.300 Test accuracy 14.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3000 \n",
      "Accuracy: 2262/10000 (22.62%)\n",
      "\n",
      "Round  21, Average loss 2.300 Test accuracy 22.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2994 \n",
      "Accuracy: 1352/10000 (13.52%)\n",
      "\n",
      "Round  22, Average loss 2.299 Test accuracy 13.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2977 \n",
      "Accuracy: 2959/10000 (29.59%)\n",
      "\n",
      "Round  23, Average loss 2.298 Test accuracy 29.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2980 \n",
      "Accuracy: 1235/10000 (12.35%)\n",
      "\n",
      "Round  24, Average loss 2.298 Test accuracy 12.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3006 \n",
      "Accuracy: 1005/10000 (10.05%)\n",
      "\n",
      "Round  25, Average loss 2.301 Test accuracy 10.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2970 \n",
      "Accuracy: 2964/10000 (29.64%)\n",
      "\n",
      "Round  26, Average loss 2.297 Test accuracy 29.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2952 \n",
      "Accuracy: 2062/10000 (20.62%)\n",
      "\n",
      "Round  27, Average loss 2.295 Test accuracy 20.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2993 \n",
      "Accuracy: 960/10000 (9.60%)\n",
      "\n",
      "Round  28, Average loss 2.299 Test accuracy 9.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2972 \n",
      "Accuracy: 1144/10000 (11.44%)\n",
      "\n",
      "Round  29, Average loss 2.297 Test accuracy 11.440\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T, sigma)= 2 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3368 \n",
      "Accuracy: 7450/10000 (74.50%)\n",
      "\n",
      "Round   1, Average loss 1.337 Test accuracy 74.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4115 \n",
      "Accuracy: 8639/10000 (86.39%)\n",
      "\n",
      "Round   2, Average loss 2.412 Test accuracy 86.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.6015 \n",
      "Accuracy: 8465/10000 (84.65%)\n",
      "\n",
      "Round   3, Average loss 5.601 Test accuracy 84.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.4349 \n",
      "Accuracy: 7695/10000 (76.95%)\n",
      "\n",
      "Round   4, Average loss 15.435 Test accuracy 76.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.6086 \n",
      "Accuracy: 8465/10000 (84.65%)\n",
      "\n",
      "Round   5, Average loss 8.609 Test accuracy 84.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.7973 \n",
      "Accuracy: 7590/10000 (75.90%)\n",
      "\n",
      "Round   6, Average loss 21.797 Test accuracy 75.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.6085 \n",
      "Accuracy: 8107/10000 (81.07%)\n",
      "\n",
      "Round   7, Average loss 12.609 Test accuracy 81.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.4972 \n",
      "Accuracy: 7396/10000 (73.96%)\n",
      "\n",
      "Round   8, Average loss 27.497 Test accuracy 73.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.0695 \n",
      "Accuracy: 8306/10000 (83.06%)\n",
      "\n",
      "Round   9, Average loss 12.069 Test accuracy 83.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.2017 \n",
      "Accuracy: 7401/10000 (74.01%)\n",
      "\n",
      "Round  10, Average loss 28.202 Test accuracy 74.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.5630 \n",
      "Accuracy: 7785/10000 (77.85%)\n",
      "\n",
      "Round  11, Average loss 17.563 Test accuracy 77.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 33.6675 \n",
      "Accuracy: 7268/10000 (72.68%)\n",
      "\n",
      "Round  12, Average loss 33.668 Test accuracy 72.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.0218 \n",
      "Accuracy: 8225/10000 (82.25%)\n",
      "\n",
      "Round  13, Average loss 15.022 Test accuracy 82.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.2320 \n",
      "Accuracy: 7407/10000 (74.07%)\n",
      "\n",
      "Round  14, Average loss 25.232 Test accuracy 74.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 27.1252 \n",
      "Accuracy: 7475/10000 (74.75%)\n",
      "\n",
      "Round  15, Average loss 27.125 Test accuracy 74.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.3044 \n",
      "Accuracy: 7200/10000 (72.00%)\n",
      "\n",
      "Round  16, Average loss 35.304 Test accuracy 72.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.7483 \n",
      "Accuracy: 8117/10000 (81.17%)\n",
      "\n",
      "Round  17, Average loss 16.748 Test accuracy 81.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.2332 \n",
      "Accuracy: 7456/10000 (74.56%)\n",
      "\n",
      "Round  18, Average loss 24.233 Test accuracy 74.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.9509 \n",
      "Accuracy: 7449/10000 (74.49%)\n",
      "\n",
      "Round  19, Average loss 27.951 Test accuracy 74.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.4181 \n",
      "Accuracy: 7434/10000 (74.34%)\n",
      "\n",
      "Round  20, Average loss 26.418 Test accuracy 74.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.3288 \n",
      "Accuracy: 7632/10000 (76.32%)\n",
      "\n",
      "Round  21, Average loss 22.329 Test accuracy 76.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.5619 \n",
      "Accuracy: 7154/10000 (71.54%)\n",
      "\n",
      "Round  22, Average loss 35.562 Test accuracy 71.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.3439 \n",
      "Accuracy: 8071/10000 (80.71%)\n",
      "\n",
      "Round  23, Average loss 19.344 Test accuracy 80.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.6921 \n",
      "Accuracy: 8202/10000 (82.02%)\n",
      "\n",
      "Round  24, Average loss 16.692 Test accuracy 82.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 40.0716 \n",
      "Accuracy: 7089/10000 (70.89%)\n",
      "\n",
      "Round  25, Average loss 40.072 Test accuracy 70.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.3182 \n",
      "Accuracy: 8161/10000 (81.61%)\n",
      "\n",
      "Round  26, Average loss 17.318 Test accuracy 81.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.9886 \n",
      "Accuracy: 7737/10000 (77.37%)\n",
      "\n",
      "Round  27, Average loss 21.989 Test accuracy 77.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.9472 \n",
      "Accuracy: 7412/10000 (74.12%)\n",
      "\n",
      "Round  28, Average loss 32.947 Test accuracy 74.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.1079 \n",
      "Accuracy: 7709/10000 (77.09%)\n",
      "\n",
      "Round  29, Average loss 21.108 Test accuracy 77.090\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T, sigma)= 2 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6818 \n",
      "Accuracy: 8287/10000 (82.87%)\n",
      "\n",
      "Round   1, Average loss 0.682 Test accuracy 82.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9881 \n",
      "Accuracy: 8740/10000 (87.40%)\n",
      "\n",
      "Round   2, Average loss 2.988 Test accuracy 87.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.0627 \n",
      "Accuracy: 8312/10000 (83.12%)\n",
      "\n",
      "Round   3, Average loss 7.063 Test accuracy 83.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.3862 \n",
      "Accuracy: 8375/10000 (83.75%)\n",
      "\n",
      "Round   4, Average loss 9.386 Test accuracy 83.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.8162 \n",
      "Accuracy: 8150/10000 (81.50%)\n",
      "\n",
      "Round   5, Average loss 12.816 Test accuracy 81.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.6451 \n",
      "Accuracy: 8239/10000 (82.39%)\n",
      "\n",
      "Round   6, Average loss 12.645 Test accuracy 82.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.2999 \n",
      "Accuracy: 8118/10000 (81.18%)\n",
      "\n",
      "Round   7, Average loss 16.300 Test accuracy 81.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.3273 \n",
      "Accuracy: 8137/10000 (81.37%)\n",
      "\n",
      "Round   8, Average loss 15.327 Test accuracy 81.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.0946 \n",
      "Accuracy: 7958/10000 (79.58%)\n",
      "\n",
      "Round   9, Average loss 21.095 Test accuracy 79.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.4000 \n",
      "Accuracy: 8152/10000 (81.52%)\n",
      "\n",
      "Round  10, Average loss 16.400 Test accuracy 81.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.7498 \n",
      "Accuracy: 8062/10000 (80.62%)\n",
      "\n",
      "Round  11, Average loss 17.750 Test accuracy 80.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.5456 \n",
      "Accuracy: 8036/10000 (80.36%)\n",
      "\n",
      "Round  12, Average loss 17.546 Test accuracy 80.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.2359 \n",
      "Accuracy: 7979/10000 (79.79%)\n",
      "\n",
      "Round  13, Average loss 18.236 Test accuracy 79.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.7276 \n",
      "Accuracy: 7863/10000 (78.63%)\n",
      "\n",
      "Round  14, Average loss 18.728 Test accuracy 78.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.3386 \n",
      "Accuracy: 7828/10000 (78.28%)\n",
      "\n",
      "Round  15, Average loss 21.339 Test accuracy 78.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.0040 \n",
      "Accuracy: 7879/10000 (78.79%)\n",
      "\n",
      "Round  16, Average loss 19.004 Test accuracy 78.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.1008 \n",
      "Accuracy: 7804/10000 (78.04%)\n",
      "\n",
      "Round  17, Average loss 22.101 Test accuracy 78.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.9004 \n",
      "Accuracy: 8410/10000 (84.10%)\n",
      "\n",
      "Round  18, Average loss 13.900 Test accuracy 84.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.7667 \n",
      "Accuracy: 7608/10000 (76.08%)\n",
      "\n",
      "Round  19, Average loss 25.767 Test accuracy 76.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.4340 \n",
      "Accuracy: 8349/10000 (83.49%)\n",
      "\n",
      "Round  20, Average loss 14.434 Test accuracy 83.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.6298 \n",
      "Accuracy: 7752/10000 (77.52%)\n",
      "\n",
      "Round  21, Average loss 22.630 Test accuracy 77.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.5424 \n",
      "Accuracy: 7898/10000 (78.98%)\n",
      "\n",
      "Round  22, Average loss 20.542 Test accuracy 78.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.4178 \n",
      "Accuracy: 7873/10000 (78.73%)\n",
      "\n",
      "Round  23, Average loss 21.418 Test accuracy 78.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.1533 \n",
      "Accuracy: 7782/10000 (77.82%)\n",
      "\n",
      "Round  24, Average loss 21.153 Test accuracy 77.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.0721 \n",
      "Accuracy: 7855/10000 (78.55%)\n",
      "\n",
      "Round  25, Average loss 21.072 Test accuracy 78.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.8921 \n",
      "Accuracy: 7893/10000 (78.93%)\n",
      "\n",
      "Round  26, Average loss 19.892 Test accuracy 78.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.5570 \n",
      "Accuracy: 7827/10000 (78.27%)\n",
      "\n",
      "Round  27, Average loss 24.557 Test accuracy 78.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.8105 \n",
      "Accuracy: 8120/10000 (81.20%)\n",
      "\n",
      "Round  28, Average loss 17.810 Test accuracy 81.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 30.5877 \n",
      "Accuracy: 7521/10000 (75.21%)\n",
      "\n",
      "Round  29, Average loss 30.588 Test accuracy 75.210\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T, sigma)= 2 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1491/10000 (14.91%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 14.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8664 \n",
      "Accuracy: 8078/10000 (80.78%)\n",
      "\n",
      "Round   1, Average loss 0.866 Test accuracy 80.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3513 \n",
      "Accuracy: 9012/10000 (90.12%)\n",
      "\n",
      "Round   2, Average loss 1.351 Test accuracy 90.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2285 \n",
      "Accuracy: 8892/10000 (88.92%)\n",
      "\n",
      "Round   3, Average loss 3.229 Test accuracy 88.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.0852 \n",
      "Accuracy: 8430/10000 (84.30%)\n",
      "\n",
      "Round   4, Average loss 5.085 Test accuracy 84.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2209 \n",
      "Accuracy: 8744/10000 (87.44%)\n",
      "\n",
      "Round   5, Average loss 4.221 Test accuracy 87.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.7401 \n",
      "Accuracy: 8441/10000 (84.41%)\n",
      "\n",
      "Round   6, Average loss 5.740 Test accuracy 84.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.6732 \n",
      "Accuracy: 8424/10000 (84.24%)\n",
      "\n",
      "Round   7, Average loss 6.673 Test accuracy 84.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8553 \n",
      "Accuracy: 8527/10000 (85.27%)\n",
      "\n",
      "Round   8, Average loss 5.855 Test accuracy 85.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.8396 \n",
      "Accuracy: 8268/10000 (82.68%)\n",
      "\n",
      "Round   9, Average loss 7.840 Test accuracy 82.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2966 \n",
      "Accuracy: 8637/10000 (86.37%)\n",
      "\n",
      "Round  10, Average loss 5.297 Test accuracy 86.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.6433 \n",
      "Accuracy: 8225/10000 (82.25%)\n",
      "\n",
      "Round  11, Average loss 7.643 Test accuracy 82.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.4276 \n",
      "Accuracy: 8473/10000 (84.73%)\n",
      "\n",
      "Round  12, Average loss 6.428 Test accuracy 84.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.6658 \n",
      "Accuracy: 8345/10000 (83.45%)\n",
      "\n",
      "Round  13, Average loss 7.666 Test accuracy 83.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.3628 \n",
      "Accuracy: 8186/10000 (81.86%)\n",
      "\n",
      "Round  14, Average loss 8.363 Test accuracy 81.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.8855 \n",
      "Accuracy: 8407/10000 (84.07%)\n",
      "\n",
      "Round  15, Average loss 6.886 Test accuracy 84.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.6998 \n",
      "Accuracy: 8428/10000 (84.28%)\n",
      "\n",
      "Round  16, Average loss 6.700 Test accuracy 84.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.3451 \n",
      "Accuracy: 8128/10000 (81.28%)\n",
      "\n",
      "Round  17, Average loss 9.345 Test accuracy 81.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.8710 \n",
      "Accuracy: 8234/10000 (82.34%)\n",
      "\n",
      "Round  18, Average loss 7.871 Test accuracy 82.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.4082 \n",
      "Accuracy: 8159/10000 (81.59%)\n",
      "\n",
      "Round  19, Average loss 9.408 Test accuracy 81.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.4425 \n",
      "Accuracy: 7866/10000 (78.66%)\n",
      "\n",
      "Round  20, Average loss 10.442 Test accuracy 78.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.3356 \n",
      "Accuracy: 8263/10000 (82.63%)\n",
      "\n",
      "Round  21, Average loss 8.336 Test accuracy 82.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.3308 \n",
      "Accuracy: 7965/10000 (79.65%)\n",
      "\n",
      "Round  22, Average loss 10.331 Test accuracy 79.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.2358 \n",
      "Accuracy: 8172/10000 (81.72%)\n",
      "\n",
      "Round  23, Average loss 8.236 Test accuracy 81.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.7986 \n",
      "Accuracy: 8040/10000 (80.40%)\n",
      "\n",
      "Round  24, Average loss 10.799 Test accuracy 80.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.8387 \n",
      "Accuracy: 8359/10000 (83.59%)\n",
      "\n",
      "Round  25, Average loss 7.839 Test accuracy 83.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.7563 \n",
      "Accuracy: 7661/10000 (76.61%)\n",
      "\n",
      "Round  26, Average loss 16.756 Test accuracy 76.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8251 \n",
      "Accuracy: 8778/10000 (87.78%)\n",
      "\n",
      "Round  27, Average loss 5.825 Test accuracy 87.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.8084 \n",
      "Accuracy: 8137/10000 (81.37%)\n",
      "\n",
      "Round  28, Average loss 8.808 Test accuracy 81.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.9963 \n",
      "Accuracy: 7910/10000 (79.10%)\n",
      "\n",
      "Round  29, Average loss 11.996 Test accuracy 79.100\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T, sigma)= 2 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3022 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   2, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   3, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   4, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   5, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   6, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  10, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  13, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  14, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  15, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  16, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  17, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  19, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  20, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  23, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  24, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  26, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  27, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  28, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  29, Average loss 2.302 Test accuracy 11.350\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T, sigma)= 2 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 974/10000 (9.74%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 974/10000 (9.74%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 10.280\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T, sigma)= 3 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1248/10000 (12.48%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 12.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0264 \n",
      "Accuracy: 7856/10000 (78.56%)\n",
      "\n",
      "Round   1, Average loss 1.026 Test accuracy 78.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.5720 \n",
      "Accuracy: 7607/10000 (76.07%)\n",
      "\n",
      "Round   2, Average loss 13.572 Test accuracy 76.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.7369 \n",
      "Accuracy: 8783/10000 (87.83%)\n",
      "\n",
      "Round   3, Average loss 8.737 Test accuracy 87.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.6107 \n",
      "Accuracy: 8721/10000 (87.21%)\n",
      "\n",
      "Round   4, Average loss 10.611 Test accuracy 87.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.4663 \n",
      "Accuracy: 8416/10000 (84.16%)\n",
      "\n",
      "Round   5, Average loss 13.466 Test accuracy 84.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.3679 \n",
      "Accuracy: 8431/10000 (84.31%)\n",
      "\n",
      "Round   6, Average loss 14.368 Test accuracy 84.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.6022 \n",
      "Accuracy: 8115/10000 (81.15%)\n",
      "\n",
      "Round   7, Average loss 19.602 Test accuracy 81.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.5652 \n",
      "Accuracy: 7987/10000 (79.87%)\n",
      "\n",
      "Round   8, Average loss 24.565 Test accuracy 79.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.6834 \n",
      "Accuracy: 8222/10000 (82.22%)\n",
      "\n",
      "Round   9, Average loss 18.683 Test accuracy 82.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.6643 \n",
      "Accuracy: 7599/10000 (75.99%)\n",
      "\n",
      "Round  10, Average loss 26.664 Test accuracy 75.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.1498 \n",
      "Accuracy: 7964/10000 (79.64%)\n",
      "\n",
      "Round  11, Average loss 20.150 Test accuracy 79.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.8377 \n",
      "Accuracy: 7503/10000 (75.03%)\n",
      "\n",
      "Round  12, Average loss 29.838 Test accuracy 75.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.6863 \n",
      "Accuracy: 7372/10000 (73.72%)\n",
      "\n",
      "Round  13, Average loss 27.686 Test accuracy 73.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 36.2789 \n",
      "Accuracy: 7154/10000 (71.54%)\n",
      "\n",
      "Round  14, Average loss 36.279 Test accuracy 71.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.1289 \n",
      "Accuracy: 8359/10000 (83.59%)\n",
      "\n",
      "Round  15, Average loss 17.129 Test accuracy 83.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.3663 \n",
      "Accuracy: 7818/10000 (78.18%)\n",
      "\n",
      "Round  16, Average loss 21.366 Test accuracy 78.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 51.3365 \n",
      "Accuracy: 6772/10000 (67.72%)\n",
      "\n",
      "Round  17, Average loss 51.336 Test accuracy 67.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.9761 \n",
      "Accuracy: 7654/10000 (76.54%)\n",
      "\n",
      "Round  18, Average loss 26.976 Test accuracy 76.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.2817 \n",
      "Accuracy: 7737/10000 (77.37%)\n",
      "\n",
      "Round  19, Average loss 26.282 Test accuracy 77.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.6347 \n",
      "Accuracy: 7473/10000 (74.73%)\n",
      "\n",
      "Round  20, Average loss 32.635 Test accuracy 74.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.7113 \n",
      "Accuracy: 7679/10000 (76.79%)\n",
      "\n",
      "Round  21, Average loss 22.711 Test accuracy 76.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 45.7951 \n",
      "Accuracy: 6991/10000 (69.91%)\n",
      "\n",
      "Round  22, Average loss 45.795 Test accuracy 69.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.6406 \n",
      "Accuracy: 7365/10000 (73.65%)\n",
      "\n",
      "Round  23, Average loss 27.641 Test accuracy 73.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 38.3911 \n",
      "Accuracy: 7149/10000 (71.49%)\n",
      "\n",
      "Round  24, Average loss 38.391 Test accuracy 71.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.4533 \n",
      "Accuracy: 7859/10000 (78.59%)\n",
      "\n",
      "Round  25, Average loss 22.453 Test accuracy 78.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 30.9897 \n",
      "Accuracy: 7524/10000 (75.24%)\n",
      "\n",
      "Round  26, Average loss 30.990 Test accuracy 75.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 46.9737 \n",
      "Accuracy: 6737/10000 (67.37%)\n",
      "\n",
      "Round  27, Average loss 46.974 Test accuracy 67.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 40.4249 \n",
      "Accuracy: 7177/10000 (71.77%)\n",
      "\n",
      "Round  28, Average loss 40.425 Test accuracy 71.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.0890 \n",
      "Accuracy: 7503/10000 (75.03%)\n",
      "\n",
      "Round  29, Average loss 27.089 Test accuracy 75.030\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T, sigma)= 3 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3013 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.301 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0746 \n",
      "Accuracy: 8250/10000 (82.50%)\n",
      "\n",
      "Round   1, Average loss 1.075 Test accuracy 82.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2835 \n",
      "Accuracy: 8864/10000 (88.64%)\n",
      "\n",
      "Round   2, Average loss 3.283 Test accuracy 88.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.2256 \n",
      "Accuracy: 8459/10000 (84.59%)\n",
      "\n",
      "Round   3, Average loss 7.226 Test accuracy 84.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.5288 \n",
      "Accuracy: 7657/10000 (76.57%)\n",
      "\n",
      "Round   4, Average loss 18.529 Test accuracy 76.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.9944 \n",
      "Accuracy: 7915/10000 (79.15%)\n",
      "\n",
      "Round   5, Average loss 17.994 Test accuracy 79.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.3195 \n",
      "Accuracy: 7844/10000 (78.44%)\n",
      "\n",
      "Round   6, Average loss 22.319 Test accuracy 78.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.6854 \n",
      "Accuracy: 7703/10000 (77.03%)\n",
      "\n",
      "Round   7, Average loss 24.685 Test accuracy 77.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.0518 \n",
      "Accuracy: 7680/10000 (76.80%)\n",
      "\n",
      "Round   8, Average loss 27.052 Test accuracy 76.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.8948 \n",
      "Accuracy: 7603/10000 (76.03%)\n",
      "\n",
      "Round   9, Average loss 27.895 Test accuracy 76.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.6503 \n",
      "Accuracy: 7926/10000 (79.26%)\n",
      "\n",
      "Round  10, Average loss 22.650 Test accuracy 79.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.9391 \n",
      "Accuracy: 7684/10000 (76.84%)\n",
      "\n",
      "Round  11, Average loss 26.939 Test accuracy 76.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.1570 \n",
      "Accuracy: 7774/10000 (77.74%)\n",
      "\n",
      "Round  12, Average loss 27.157 Test accuracy 77.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.9993 \n",
      "Accuracy: 7791/10000 (77.91%)\n",
      "\n",
      "Round  13, Average loss 25.999 Test accuracy 77.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 29.7720 \n",
      "Accuracy: 7704/10000 (77.04%)\n",
      "\n",
      "Round  14, Average loss 29.772 Test accuracy 77.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.7535 \n",
      "Accuracy: 7801/10000 (78.01%)\n",
      "\n",
      "Round  15, Average loss 26.754 Test accuracy 78.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 33.7727 \n",
      "Accuracy: 7545/10000 (75.45%)\n",
      "\n",
      "Round  16, Average loss 33.773 Test accuracy 75.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.7901 \n",
      "Accuracy: 7887/10000 (78.87%)\n",
      "\n",
      "Round  17, Average loss 23.790 Test accuracy 78.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 34.6341 \n",
      "Accuracy: 7558/10000 (75.58%)\n",
      "\n",
      "Round  18, Average loss 34.634 Test accuracy 75.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.6365 \n",
      "Accuracy: 7679/10000 (76.79%)\n",
      "\n",
      "Round  19, Average loss 29.636 Test accuracy 76.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.0003 \n",
      "Accuracy: 7585/10000 (75.85%)\n",
      "\n",
      "Round  20, Average loss 32.000 Test accuracy 75.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.2734 \n",
      "Accuracy: 7897/10000 (78.97%)\n",
      "\n",
      "Round  21, Average loss 24.273 Test accuracy 78.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 34.7370 \n",
      "Accuracy: 7405/10000 (74.05%)\n",
      "\n",
      "Round  22, Average loss 34.737 Test accuracy 74.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.8703 \n",
      "Accuracy: 7880/10000 (78.80%)\n",
      "\n",
      "Round  23, Average loss 24.870 Test accuracy 78.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.5404 \n",
      "Accuracy: 7927/10000 (79.27%)\n",
      "\n",
      "Round  24, Average loss 23.540 Test accuracy 79.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.0841 \n",
      "Accuracy: 7750/10000 (77.50%)\n",
      "\n",
      "Round  25, Average loss 28.084 Test accuracy 77.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.2142 \n",
      "Accuracy: 7825/10000 (78.25%)\n",
      "\n",
      "Round  26, Average loss 26.214 Test accuracy 78.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.2636 \n",
      "Accuracy: 7749/10000 (77.49%)\n",
      "\n",
      "Round  27, Average loss 27.264 Test accuracy 77.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.6844 \n",
      "Accuracy: 7897/10000 (78.97%)\n",
      "\n",
      "Round  28, Average loss 24.684 Test accuracy 78.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 37.7525 \n",
      "Accuracy: 7325/10000 (73.25%)\n",
      "\n",
      "Round  29, Average loss 37.753 Test accuracy 73.250\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T, sigma)= 3 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1025/10000 (10.25%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 10.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6576 \n",
      "Accuracy: 8574/10000 (85.74%)\n",
      "\n",
      "Round   1, Average loss 0.658 Test accuracy 85.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0654 \n",
      "Accuracy: 8969/10000 (89.69%)\n",
      "\n",
      "Round   2, Average loss 2.065 Test accuracy 89.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6206 \n",
      "Accuracy: 8805/10000 (88.05%)\n",
      "\n",
      "Round   3, Average loss 3.621 Test accuracy 88.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0613 \n",
      "Accuracy: 8852/10000 (88.52%)\n",
      "\n",
      "Round   4, Average loss 4.061 Test accuracy 88.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2883 \n",
      "Accuracy: 8708/10000 (87.08%)\n",
      "\n",
      "Round   5, Average loss 5.288 Test accuracy 87.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9523 \n",
      "Accuracy: 8804/10000 (88.04%)\n",
      "\n",
      "Round   6, Average loss 4.952 Test accuracy 88.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.6959 \n",
      "Accuracy: 8732/10000 (87.32%)\n",
      "\n",
      "Round   7, Average loss 5.696 Test accuracy 87.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.5857 \n",
      "Accuracy: 8841/10000 (88.41%)\n",
      "\n",
      "Round   8, Average loss 5.586 Test accuracy 88.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.1861 \n",
      "Accuracy: 8685/10000 (86.85%)\n",
      "\n",
      "Round   9, Average loss 6.186 Test accuracy 86.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.4855 \n",
      "Accuracy: 8741/10000 (87.41%)\n",
      "\n",
      "Round  10, Average loss 6.485 Test accuracy 87.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.7550 \n",
      "Accuracy: 8549/10000 (85.49%)\n",
      "\n",
      "Round  11, Average loss 6.755 Test accuracy 85.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.4980 \n",
      "Accuracy: 8089/10000 (80.89%)\n",
      "\n",
      "Round  12, Average loss 10.498 Test accuracy 80.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.3524 \n",
      "Accuracy: 8350/10000 (83.50%)\n",
      "\n",
      "Round  13, Average loss 8.352 Test accuracy 83.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.4258 \n",
      "Accuracy: 8078/10000 (80.78%)\n",
      "\n",
      "Round  14, Average loss 10.426 Test accuracy 80.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.9601 \n",
      "Accuracy: 8115/10000 (81.15%)\n",
      "\n",
      "Round  15, Average loss 9.960 Test accuracy 81.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.1581 \n",
      "Accuracy: 7934/10000 (79.34%)\n",
      "\n",
      "Round  16, Average loss 13.158 Test accuracy 79.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.3007 \n",
      "Accuracy: 8367/10000 (83.67%)\n",
      "\n",
      "Round  17, Average loss 9.301 Test accuracy 83.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.8515 \n",
      "Accuracy: 7812/10000 (78.12%)\n",
      "\n",
      "Round  18, Average loss 14.851 Test accuracy 78.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.8807 \n",
      "Accuracy: 8270/10000 (82.70%)\n",
      "\n",
      "Round  19, Average loss 9.881 Test accuracy 82.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.1842 \n",
      "Accuracy: 7794/10000 (77.94%)\n",
      "\n",
      "Round  20, Average loss 14.184 Test accuracy 77.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.5512 \n",
      "Accuracy: 7852/10000 (78.52%)\n",
      "\n",
      "Round  21, Average loss 13.551 Test accuracy 78.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.5425 \n",
      "Accuracy: 8059/10000 (80.59%)\n",
      "\n",
      "Round  22, Average loss 11.542 Test accuracy 80.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.6634 \n",
      "Accuracy: 8028/10000 (80.28%)\n",
      "\n",
      "Round  23, Average loss 11.663 Test accuracy 80.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.0431 \n",
      "Accuracy: 7990/10000 (79.90%)\n",
      "\n",
      "Round  24, Average loss 13.043 Test accuracy 79.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.0979 \n",
      "Accuracy: 8086/10000 (80.86%)\n",
      "\n",
      "Round  25, Average loss 11.098 Test accuracy 80.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.2700 \n",
      "Accuracy: 8021/10000 (80.21%)\n",
      "\n",
      "Round  26, Average loss 12.270 Test accuracy 80.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.0687 \n",
      "Accuracy: 7832/10000 (78.32%)\n",
      "\n",
      "Round  27, Average loss 13.069 Test accuracy 78.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.4661 \n",
      "Accuracy: 8078/10000 (80.78%)\n",
      "\n",
      "Round  28, Average loss 11.466 Test accuracy 80.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 15.3082 \n",
      "Accuracy: 7875/10000 (78.75%)\n",
      "\n",
      "Round  29, Average loss 15.308 Test accuracy 78.750\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T, sigma)= 3 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   4, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   6, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   9, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  14, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  15, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  22, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  27, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 10.280\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T, sigma)= 3 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "N = args.num_users\n",
    "K = args.num_partition\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training\n",
    "loss_train_arr = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "net_best = None\n",
    "best_loss = None\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "# m_array = np.array(range(4,16)) # m is the number of received result @ master\n",
    "T_array = np.array([0,1,2,3]) # m is the number of received result @ master\n",
    "sigma_array = np.array([0, 0.1, 1, 10, 100])\n",
    "\n",
    "\n",
    "loss_test_arr = np.empty((len(T_array),len(sigma_array),N_trials,N_epochs))\n",
    "acc_test_arr  = np.empty((len(T_array),len(sigma_array),N_trials,N_epochs))\n",
    "\n",
    "for T_idx in range(len(T_array)):\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    T = T_array[T_idx]\n",
    "    \n",
    "    if T == 0:\n",
    "        Noise_Alloc = []\n",
    "    elif T == 1:\n",
    "        Noise_Alloc = [3]\n",
    "    elif T == 2:\n",
    "        Noise_Alloc = [2,5]\n",
    "    else:\n",
    "        Noise_Alloc = [2,4,7] # np.random.choice(range(K+T), T, replace=False)\n",
    "        \n",
    "    Signal_Alloc = []\n",
    "    for i in range(K+T):\n",
    "        if i not in Noise_Alloc:\n",
    "            Signal_Alloc.append(i)\n",
    "\n",
    "    j_array = np.array(range(K+T))\n",
    "    # print(\"j: \",(2*j_array+1)*math.pi/2/K,'\\n')\n",
    "\n",
    "    alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "    i_array = np.array(range(N))\n",
    "    z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "    \n",
    "    for sigma_idx in range(len(sigma_array)):\n",
    "        \n",
    "        sigma = sigma_array[sigma_idx]\n",
    "\n",
    "        X_tilde,a,b = BACC_Enc_withNoise(encoding_input_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "        y_tilde,a,b = BACC_Enc_withNoise(encoding_label_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "\n",
    "        m = N # m is the number of received result @ master\n",
    "    #     print('number of results:',m)\n",
    "\n",
    "        for trial_idx in range(N_trials):\n",
    "            print('(T, sigma)=',T,sigma,') ',trial_idx,'-th Trial!!')\n",
    "\n",
    "            net_glob = CNNMnist2(args=args)\n",
    "            net_glob.cuda()\n",
    "            net_glob.train()\n",
    "\n",
    "            # copy weights\n",
    "            w_glob = net_glob.state_dict()\n",
    "\n",
    "            for iter in range(N_epochs): #args.epochs\n",
    "                w_locals, loss_locals = [], []\n",
    "                idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "                idxs_users = np.sort(idxs_users)\n",
    "                print('selected users:',idxs_users)\n",
    "\n",
    "                dec_z_array = []\n",
    "                for idx in idxs_users: #for idx in range(N):\n",
    "            #         print(idx)\n",
    "                    local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                    w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                    w_locals.append(copy.deepcopy(w))\n",
    "                    loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                    dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "                # update global weights\n",
    "                #w_glob = FedAvg(w_locals)\n",
    "                w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "                # copy weight to net_glob\n",
    "                net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                # print loss\n",
    "            #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "            #     loss_train_arr.append(loss_train)\n",
    "\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                acc_test_arr[T_idx][sigma_idx][trial_idx][iter] = acc_test\n",
    "                loss_test_arr[T_idx][sigma_idx][trial_idx][iter] = loss_test\n",
    "                if iter % 1 ==0:\n",
    "                    print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "                #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(\"./plot/MNIST_LeNet_N15_K6_T_0_to_3_sigma_0_to_100_test_acc\",\"wb\")\n",
    "pickle.dump(acc_test_arr,filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 1, 30)\n",
      "(4, 5, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc = np.mean(acc_test_arr, axis=2)\n",
    "print(acc_test_arr.shape)\n",
    "print(plot_acc.shape)\n",
    "\n",
    "T_sel = 3\n",
    "\n",
    "plt.plot(plot_acc[T_sel,0,:],label='T=1, sigma=  0')\n",
    "plt.plot(plot_acc[T_sel,1,:],label='T=1, sigma=0.1')\n",
    "plt.plot(plot_acc[T_sel,2,:],label='T=1, sigma=  1')\n",
    "plt.plot(plot_acc[T_sel,3,:],label='T=1, sigma= 10')\n",
    "plt.plot(plot_acc[T_sel,4,:],label='T=1, sigma=100')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma_sel = 1\n",
    "\n",
    "title_name = 'Sigma ='+str(sigma_array[sigma_sel])\n",
    "plt.plot(plot_acc[0,sigma_sel,:],label='T=0')\n",
    "plt.plot(plot_acc[1,sigma_sel,:],label='T=1')\n",
    "plt.plot(plot_acc[2,sigma_sel,:],label='T=2')\n",
    "plt.plot(plot_acc[3,sigma_sel,:],label='T=3')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.9965 \n",
      "Accuracy: 1581/10000 (15.81%)\n",
      "\n",
      "Round   0, Average loss 14.996 Test accuracy 15.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8523 \n",
      "Accuracy: 3446/10000 (34.46%)\n",
      "\n",
      "Round   1, Average loss 1.852 Test accuracy 34.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.0250 \n",
      "Accuracy: 1232/10000 (12.32%)\n",
      "\n",
      "Round   2, Average loss 27.025 Test accuracy 12.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.5783 \n",
      "Accuracy: 4790/10000 (47.90%)\n",
      "\n",
      "Round   3, Average loss 8.578 Test accuracy 47.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.9562 \n",
      "Accuracy: 4113/10000 (41.13%)\n",
      "\n",
      "Round   4, Average loss 12.956 Test accuracy 41.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.9174 \n",
      "Accuracy: 4863/10000 (48.63%)\n",
      "\n",
      "Round   5, Average loss 10.917 Test accuracy 48.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.4324 \n",
      "Accuracy: 2654/10000 (26.54%)\n",
      "\n",
      "Round   6, Average loss 31.432 Test accuracy 26.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.0505 \n",
      "Accuracy: 6041/10000 (60.41%)\n",
      "\n",
      "Round   7, Average loss 8.051 Test accuracy 60.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.2046 \n",
      "Accuracy: 2373/10000 (23.73%)\n",
      "\n",
      "Round   8, Average loss 28.205 Test accuracy 23.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2622 \n",
      "Accuracy: 6788/10000 (67.88%)\n",
      "\n",
      "Round   9, Average loss 5.262 Test accuracy 67.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 38.5651 \n",
      "Accuracy: 1586/10000 (15.86%)\n",
      "\n",
      "Round  10, Average loss 38.565 Test accuracy 15.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8742 \n",
      "Accuracy: 6463/10000 (64.63%)\n",
      "\n",
      "Round  11, Average loss 4.874 Test accuracy 64.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.9825 \n",
      "Accuracy: 2001/10000 (20.01%)\n",
      "\n",
      "Round  12, Average loss 16.982 Test accuracy 20.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8741 \n",
      "Accuracy: 6663/10000 (66.63%)\n",
      "\n",
      "Round  13, Average loss 4.874 Test accuracy 66.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.8914 \n",
      "Accuracy: 1519/10000 (15.19%)\n",
      "\n",
      "Round  14, Average loss 32.891 Test accuracy 15.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.1510 \n",
      "Accuracy: 6529/10000 (65.29%)\n",
      "\n",
      "Round  15, Average loss 5.151 Test accuracy 65.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 34.1152 \n",
      "Accuracy: 1567/10000 (15.67%)\n",
      "\n",
      "Round  16, Average loss 34.115 Test accuracy 15.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.0372 \n",
      "Accuracy: 6116/10000 (61.16%)\n",
      "\n",
      "Round  17, Average loss 7.037 Test accuracy 61.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.0452 \n",
      "Accuracy: 1762/10000 (17.62%)\n",
      "\n",
      "Round  18, Average loss 22.045 Test accuracy 17.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.2119 \n",
      "Accuracy: 6314/10000 (63.14%)\n",
      "\n",
      "Round  19, Average loss 6.212 Test accuracy 63.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 36.8745 \n",
      "Accuracy: 1495/10000 (14.95%)\n",
      "\n",
      "Round  20, Average loss 36.875 Test accuracy 14.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.5458 \n",
      "Accuracy: 6139/10000 (61.39%)\n",
      "\n",
      "Round  21, Average loss 6.546 Test accuracy 61.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.0249 \n",
      "Accuracy: 1732/10000 (17.32%)\n",
      "\n",
      "Round  22, Average loss 20.025 Test accuracy 17.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.1508 \n",
      "Accuracy: 6249/10000 (62.49%)\n",
      "\n",
      "Round  23, Average loss 6.151 Test accuracy 62.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.2614 \n",
      "Accuracy: 1695/10000 (16.95%)\n",
      "\n",
      "Round  24, Average loss 26.261 Test accuracy 16.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9937 \n",
      "Accuracy: 6089/10000 (60.89%)\n",
      "\n",
      "Round  25, Average loss 6.994 Test accuracy 60.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.9532 \n",
      "Accuracy: 1641/10000 (16.41%)\n",
      "\n",
      "Round  26, Average loss 27.953 Test accuracy 16.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.9073 \n",
      "Accuracy: 6300/10000 (63.00%)\n",
      "\n",
      "Round  27, Average loss 5.907 Test accuracy 63.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.9209 \n",
      "Accuracy: 1479/10000 (14.79%)\n",
      "\n",
      "Round  28, Average loss 32.921 Test accuracy 14.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8911 \n",
      "Accuracy: 6526/10000 (65.26%)\n",
      "\n",
      "Round  29, Average loss 4.891 Test accuracy 65.260\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.6928 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 14.693 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1867 \n",
      "Accuracy: 2584/10000 (25.84%)\n",
      "\n",
      "Round   1, Average loss 2.187 Test accuracy 25.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 76.1670 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   2, Average loss 76.167 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.8279 \n",
      "Accuracy: 1352/10000 (13.52%)\n",
      "\n",
      "Round   3, Average loss 20.828 Test accuracy 13.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.6227 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round   4, Average loss 12.623 Test accuracy 36.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.8772 \n",
      "Accuracy: 3231/10000 (32.31%)\n",
      "\n",
      "Round   5, Average loss 26.877 Test accuracy 32.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.9869 \n",
      "Accuracy: 4453/10000 (44.53%)\n",
      "\n",
      "Round   6, Average loss 23.987 Test accuracy 44.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 30.3443 \n",
      "Accuracy: 3735/10000 (37.35%)\n",
      "\n",
      "Round   7, Average loss 30.344 Test accuracy 37.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.6974 \n",
      "Accuracy: 5098/10000 (50.98%)\n",
      "\n",
      "Round   8, Average loss 21.697 Test accuracy 50.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.7364 \n",
      "Accuracy: 4027/10000 (40.27%)\n",
      "\n",
      "Round   9, Average loss 29.736 Test accuracy 40.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.7005 \n",
      "Accuracy: 5022/10000 (50.22%)\n",
      "\n",
      "Round  10, Average loss 24.701 Test accuracy 50.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.9756 \n",
      "Accuracy: 3686/10000 (36.86%)\n",
      "\n",
      "Round  11, Average loss 29.976 Test accuracy 36.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.4762 \n",
      "Accuracy: 5063/10000 (50.63%)\n",
      "\n",
      "Round  12, Average loss 19.476 Test accuracy 50.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.3862 \n",
      "Accuracy: 3952/10000 (39.52%)\n",
      "\n",
      "Round  13, Average loss 23.386 Test accuracy 39.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 17.5357 \n",
      "Accuracy: 5122/10000 (51.22%)\n",
      "\n",
      "Round  14, Average loss 17.536 Test accuracy 51.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.1068 \n",
      "Accuracy: 3511/10000 (35.11%)\n",
      "\n",
      "Round  15, Average loss 28.107 Test accuracy 35.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.6928 \n",
      "Accuracy: 5475/10000 (54.75%)\n",
      "\n",
      "Round  16, Average loss 14.693 Test accuracy 54.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.1987 \n",
      "Accuracy: 3136/10000 (31.36%)\n",
      "\n",
      "Round  17, Average loss 31.199 Test accuracy 31.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.7532 \n",
      "Accuracy: 5822/10000 (58.22%)\n",
      "\n",
      "Round  18, Average loss 11.753 Test accuracy 58.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 37.5537 \n",
      "Accuracy: 2537/10000 (25.37%)\n",
      "\n",
      "Round  19, Average loss 37.554 Test accuracy 25.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.6658 \n",
      "Accuracy: 6145/10000 (61.45%)\n",
      "\n",
      "Round  20, Average loss 8.666 Test accuracy 61.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 39.4528 \n",
      "Accuracy: 2512/10000 (25.12%)\n",
      "\n",
      "Round  21, Average loss 39.453 Test accuracy 25.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2977 \n",
      "Accuracy: 6837/10000 (68.37%)\n",
      "\n",
      "Round  22, Average loss 5.298 Test accuracy 68.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 47.5600 \n",
      "Accuracy: 1827/10000 (18.27%)\n",
      "\n",
      "Round  23, Average loss 47.560 Test accuracy 18.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.0117 \n",
      "Accuracy: 6682/10000 (66.82%)\n",
      "\n",
      "Round  24, Average loss 5.012 Test accuracy 66.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.6541 \n",
      "Accuracy: 2402/10000 (24.02%)\n",
      "\n",
      "Round  25, Average loss 29.654 Test accuracy 24.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9400 \n",
      "Accuracy: 6556/10000 (65.56%)\n",
      "\n",
      "Round  26, Average loss 6.940 Test accuracy 65.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 47.1188 \n",
      "Accuracy: 1867/10000 (18.67%)\n",
      "\n",
      "Round  27, Average loss 47.119 Test accuracy 18.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.6964 \n",
      "Accuracy: 6455/10000 (64.55%)\n",
      "\n",
      "Round  28, Average loss 5.696 Test accuracy 64.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.0676 \n",
      "Accuracy: 1913/10000 (19.13%)\n",
      "\n",
      "Round  29, Average loss 31.068 Test accuracy 19.130\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2523 \n",
      "Accuracy: 1440/10000 (14.40%)\n",
      "\n",
      "Round   1, Average loss 2.252 Test accuracy 14.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3532 \n",
      "Accuracy: 5389/10000 (53.89%)\n",
      "\n",
      "Round   2, Average loss 1.353 Test accuracy 53.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7184 \n",
      "Accuracy: 8019/10000 (80.19%)\n",
      "\n",
      "Round   3, Average loss 0.718 Test accuracy 80.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8456 \n",
      "Accuracy: 7987/10000 (79.87%)\n",
      "\n",
      "Round   4, Average loss 0.846 Test accuracy 79.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0268 \n",
      "Accuracy: 7644/10000 (76.44%)\n",
      "\n",
      "Round   5, Average loss 1.027 Test accuracy 76.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3335 \n",
      "Accuracy: 7004/10000 (70.04%)\n",
      "\n",
      "Round   6, Average loss 1.334 Test accuracy 70.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9230 \n",
      "Accuracy: 7840/10000 (78.40%)\n",
      "\n",
      "Round   7, Average loss 0.923 Test accuracy 78.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0563 \n",
      "Accuracy: 7838/10000 (78.38%)\n",
      "\n",
      "Round   8, Average loss 1.056 Test accuracy 78.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8012 \n",
      "Accuracy: 8086/10000 (80.86%)\n",
      "\n",
      "Round   9, Average loss 0.801 Test accuracy 80.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7853 \n",
      "Accuracy: 6931/10000 (69.31%)\n",
      "\n",
      "Round  10, Average loss 1.785 Test accuracy 69.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9313 \n",
      "Accuracy: 7953/10000 (79.53%)\n",
      "\n",
      "Round  11, Average loss 0.931 Test accuracy 79.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5579 \n",
      "Accuracy: 7684/10000 (76.84%)\n",
      "\n",
      "Round  12, Average loss 1.558 Test accuracy 76.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2782 \n",
      "Accuracy: 7513/10000 (75.13%)\n",
      "\n",
      "Round  13, Average loss 1.278 Test accuracy 75.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0952 \n",
      "Accuracy: 7837/10000 (78.37%)\n",
      "\n",
      "Round  14, Average loss 1.095 Test accuracy 78.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2474 \n",
      "Accuracy: 7471/10000 (74.71%)\n",
      "\n",
      "Round  15, Average loss 1.247 Test accuracy 74.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8584 \n",
      "Accuracy: 8085/10000 (80.85%)\n",
      "\n",
      "Round  16, Average loss 0.858 Test accuracy 80.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9642 \n",
      "Accuracy: 7809/10000 (78.09%)\n",
      "\n",
      "Round  17, Average loss 0.964 Test accuracy 78.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0660 \n",
      "Accuracy: 7750/10000 (77.50%)\n",
      "\n",
      "Round  18, Average loss 1.066 Test accuracy 77.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9366 \n",
      "Accuracy: 7815/10000 (78.15%)\n",
      "\n",
      "Round  19, Average loss 0.937 Test accuracy 78.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3462 \n",
      "Accuracy: 7410/10000 (74.10%)\n",
      "\n",
      "Round  20, Average loss 1.346 Test accuracy 74.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1647 \n",
      "Accuracy: 7488/10000 (74.88%)\n",
      "\n",
      "Round  21, Average loss 1.165 Test accuracy 74.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2397 \n",
      "Accuracy: 7428/10000 (74.28%)\n",
      "\n",
      "Round  22, Average loss 1.240 Test accuracy 74.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7888 \n",
      "Accuracy: 8339/10000 (83.39%)\n",
      "\n",
      "Round  23, Average loss 0.789 Test accuracy 83.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1576 \n",
      "Accuracy: 7914/10000 (79.14%)\n",
      "\n",
      "Round  24, Average loss 1.158 Test accuracy 79.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4171 \n",
      "Accuracy: 7466/10000 (74.66%)\n",
      "\n",
      "Round  25, Average loss 1.417 Test accuracy 74.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1215 \n",
      "Accuracy: 7676/10000 (76.76%)\n",
      "\n",
      "Round  26, Average loss 1.121 Test accuracy 76.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0568 \n",
      "Accuracy: 7254/10000 (72.54%)\n",
      "\n",
      "Round  27, Average loss 1.057 Test accuracy 72.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0489 \n",
      "Accuracy: 7855/10000 (78.55%)\n",
      "\n",
      "Round  28, Average loss 1.049 Test accuracy 78.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9296 \n",
      "Accuracy: 7558/10000 (75.58%)\n",
      "\n",
      "Round  29, Average loss 0.930 Test accuracy 75.580\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3031 \n",
      "Accuracy: 873/10000 (8.73%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 8.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3034 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3027 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.302 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3027 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3035 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 879/10000 (8.79%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 8.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 2024/10000 (20.24%)\n",
      "\n",
      "Round  10, Average loss 2.302 Test accuracy 20.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3032 \n",
      "Accuracy: 1128/10000 (11.28%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 11.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3057 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  12, Average loss 2.306 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  14, Average loss 2.302 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3038 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  15, Average loss 2.304 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3067 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  16, Average loss 2.307 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 461/10000 (4.61%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 4.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 923/10000 (9.23%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3043 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  20, Average loss 2.304 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3027 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3022 \n",
      "Accuracy: 974/10000 (9.74%)\n",
      "\n",
      "Round  24, Average loss 2.302 Test accuracy 9.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3207 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  25, Average loss 2.321 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3063 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  27, Average loss 2.306 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3041 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  29, Average loss 2.304 Test accuracy 11.350\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "(T, sigma)= 5 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 941/10000 (9.41%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0272 \n",
      "Accuracy: 7296/10000 (72.96%)\n",
      "\n",
      "Round   1, Average loss 1.027 Test accuracy 72.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3456 \n",
      "Accuracy: 9061/10000 (90.61%)\n",
      "\n",
      "Round   2, Average loss 0.346 Test accuracy 90.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4075 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round   3, Average loss 0.407 Test accuracy 93.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5957 \n",
      "Accuracy: 9284/10000 (92.84%)\n",
      "\n",
      "Round   4, Average loss 0.596 Test accuracy 92.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6683 \n",
      "Accuracy: 9485/10000 (94.85%)\n",
      "\n",
      "Round   5, Average loss 0.668 Test accuracy 94.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7188 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round   6, Average loss 0.719 Test accuracy 93.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7847 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round   7, Average loss 0.785 Test accuracy 93.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2389 \n",
      "Accuracy: 9315/10000 (93.15%)\n",
      "\n",
      "Round   8, Average loss 1.239 Test accuracy 93.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3019 \n",
      "Accuracy: 9263/10000 (92.63%)\n",
      "\n",
      "Round   9, Average loss 1.302 Test accuracy 92.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2724 \n",
      "Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Round  10, Average loss 1.272 Test accuracy 92.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2869 \n",
      "Accuracy: 9275/10000 (92.75%)\n",
      "\n",
      "Round  11, Average loss 1.287 Test accuracy 92.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4695 \n",
      "Accuracy: 9241/10000 (92.41%)\n",
      "\n",
      "Round  12, Average loss 1.469 Test accuracy 92.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2958 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round  13, Average loss 1.296 Test accuracy 92.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4299 \n",
      "Accuracy: 9208/10000 (92.08%)\n",
      "\n",
      "Round  14, Average loss 1.430 Test accuracy 92.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4511 \n",
      "Accuracy: 9179/10000 (91.79%)\n",
      "\n",
      "Round  15, Average loss 1.451 Test accuracy 91.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6480 \n",
      "Accuracy: 9125/10000 (91.25%)\n",
      "\n",
      "Round  16, Average loss 1.648 Test accuracy 91.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3470 \n",
      "Accuracy: 9160/10000 (91.60%)\n",
      "\n",
      "Round  17, Average loss 1.347 Test accuracy 91.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5216 \n",
      "Accuracy: 9057/10000 (90.57%)\n",
      "\n",
      "Round  18, Average loss 1.522 Test accuracy 90.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5243 \n",
      "Accuracy: 9124/10000 (91.24%)\n",
      "\n",
      "Round  19, Average loss 1.524 Test accuracy 91.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9773 \n",
      "Accuracy: 8999/10000 (89.99%)\n",
      "\n",
      "Round  20, Average loss 1.977 Test accuracy 89.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3539 \n",
      "Accuracy: 9149/10000 (91.49%)\n",
      "\n",
      "Round  21, Average loss 1.354 Test accuracy 91.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6719 \n",
      "Accuracy: 9078/10000 (90.78%)\n",
      "\n",
      "Round  22, Average loss 1.672 Test accuracy 90.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4019 \n",
      "Accuracy: 9164/10000 (91.64%)\n",
      "\n",
      "Round  23, Average loss 1.402 Test accuracy 91.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6336 \n",
      "Accuracy: 9116/10000 (91.16%)\n",
      "\n",
      "Round  24, Average loss 1.634 Test accuracy 91.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5686 \n",
      "Accuracy: 9132/10000 (91.32%)\n",
      "\n",
      "Round  25, Average loss 1.569 Test accuracy 91.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8916 \n",
      "Accuracy: 9075/10000 (90.75%)\n",
      "\n",
      "Round  26, Average loss 1.892 Test accuracy 90.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6267 \n",
      "Accuracy: 9113/10000 (91.13%)\n",
      "\n",
      "Round  27, Average loss 1.627 Test accuracy 91.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6484 \n",
      "Accuracy: 9006/10000 (90.06%)\n",
      "\n",
      "Round  28, Average loss 1.648 Test accuracy 90.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2678 \n",
      "Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Round  29, Average loss 1.268 Test accuracy 91.980\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "(T, sigma)= 5 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4387 \n",
      "Accuracy: 9104/10000 (91.04%)\n",
      "\n",
      "Round   1, Average loss 0.439 Test accuracy 91.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8369 \n",
      "Accuracy: 9300/10000 (93.00%)\n",
      "\n",
      "Round   2, Average loss 1.837 Test accuracy 93.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7551 \n",
      "Accuracy: 9253/10000 (92.53%)\n",
      "\n",
      "Round   3, Average loss 3.755 Test accuracy 92.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7320 \n",
      "Accuracy: 9237/10000 (92.37%)\n",
      "\n",
      "Round   4, Average loss 4.732 Test accuracy 92.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.5165 \n",
      "Accuracy: 9200/10000 (92.00%)\n",
      "\n",
      "Round   5, Average loss 5.517 Test accuracy 92.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.3534 \n",
      "Accuracy: 9277/10000 (92.77%)\n",
      "\n",
      "Round   6, Average loss 5.353 Test accuracy 92.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2079 \n",
      "Accuracy: 9278/10000 (92.78%)\n",
      "\n",
      "Round   7, Average loss 5.208 Test accuracy 92.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.3686 \n",
      "Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Round   8, Average loss 6.369 Test accuracy 91.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.4064 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round   9, Average loss 6.406 Test accuracy 92.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.4223 \n",
      "Accuracy: 9220/10000 (92.20%)\n",
      "\n",
      "Round  10, Average loss 6.422 Test accuracy 92.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9484 \n",
      "Accuracy: 9133/10000 (91.33%)\n",
      "\n",
      "Round  11, Average loss 6.948 Test accuracy 91.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.0885 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round  12, Average loss 6.088 Test accuracy 92.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8982 \n",
      "Accuracy: 9223/10000 (92.23%)\n",
      "\n",
      "Round  13, Average loss 5.898 Test accuracy 92.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.3450 \n",
      "Accuracy: 9101/10000 (91.01%)\n",
      "\n",
      "Round  14, Average loss 7.345 Test accuracy 91.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.0311 \n",
      "Accuracy: 9148/10000 (91.48%)\n",
      "\n",
      "Round  15, Average loss 7.031 Test accuracy 91.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.2975 \n",
      "Accuracy: 9151/10000 (91.51%)\n",
      "\n",
      "Round  16, Average loss 7.297 Test accuracy 91.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.4982 \n",
      "Accuracy: 9185/10000 (91.85%)\n",
      "\n",
      "Round  17, Average loss 6.498 Test accuracy 91.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4075 \n",
      "Accuracy: 9074/10000 (90.74%)\n",
      "\n",
      "Round  18, Average loss 7.407 Test accuracy 90.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.5982 \n",
      "Accuracy: 9095/10000 (90.95%)\n",
      "\n",
      "Round  19, Average loss 7.598 Test accuracy 90.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.5912 \n",
      "Accuracy: 9117/10000 (91.17%)\n",
      "\n",
      "Round  20, Average loss 7.591 Test accuracy 91.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.8550 \n",
      "Accuracy: 9141/10000 (91.41%)\n",
      "\n",
      "Round  21, Average loss 6.855 Test accuracy 91.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.1986 \n",
      "Accuracy: 9103/10000 (91.03%)\n",
      "\n",
      "Round  22, Average loss 7.199 Test accuracy 91.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.8711 \n",
      "Accuracy: 9079/10000 (90.79%)\n",
      "\n",
      "Round  23, Average loss 7.871 Test accuracy 90.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9451 \n",
      "Accuracy: 9136/10000 (91.36%)\n",
      "\n",
      "Round  24, Average loss 6.945 Test accuracy 91.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4934 \n",
      "Accuracy: 9099/10000 (90.99%)\n",
      "\n",
      "Round  25, Average loss 7.493 Test accuracy 90.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.0946 \n",
      "Accuracy: 9075/10000 (90.75%)\n",
      "\n",
      "Round  26, Average loss 8.095 Test accuracy 90.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.3976 \n",
      "Accuracy: 9026/10000 (90.26%)\n",
      "\n",
      "Round  27, Average loss 8.398 Test accuracy 90.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.2041 \n",
      "Accuracy: 9096/10000 (90.96%)\n",
      "\n",
      "Round  28, Average loss 8.204 Test accuracy 90.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.0110 \n",
      "Accuracy: 9165/10000 (91.65%)\n",
      "\n",
      "Round  29, Average loss 7.011 Test accuracy 91.650\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "(T, sigma)= 5 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1244 \n",
      "Accuracy: 7336/10000 (73.36%)\n",
      "\n",
      "Round   1, Average loss 2.124 Test accuracy 73.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2408 \n",
      "Accuracy: 9278/10000 (92.78%)\n",
      "\n",
      "Round   2, Average loss 0.241 Test accuracy 92.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2425 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round   3, Average loss 0.243 Test accuracy 93.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2578 \n",
      "Accuracy: 9290/10000 (92.90%)\n",
      "\n",
      "Round   4, Average loss 0.258 Test accuracy 92.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2538 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round   5, Average loss 0.254 Test accuracy 93.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2447 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round   6, Average loss 0.245 Test accuracy 93.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2604 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round   7, Average loss 0.260 Test accuracy 93.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2730 \n",
      "Accuracy: 9346/10000 (93.46%)\n",
      "\n",
      "Round   8, Average loss 0.273 Test accuracy 93.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3121 \n",
      "Accuracy: 9317/10000 (93.17%)\n",
      "\n",
      "Round   9, Average loss 0.312 Test accuracy 93.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2653 \n",
      "Accuracy: 9300/10000 (93.00%)\n",
      "\n",
      "Round  10, Average loss 0.265 Test accuracy 93.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2536 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round  11, Average loss 0.254 Test accuracy 93.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2917 \n",
      "Accuracy: 9325/10000 (93.25%)\n",
      "\n",
      "Round  12, Average loss 0.292 Test accuracy 93.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3221 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round  13, Average loss 0.322 Test accuracy 93.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2758 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round  14, Average loss 0.276 Test accuracy 93.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2764 \n",
      "Accuracy: 9303/10000 (93.03%)\n",
      "\n",
      "Round  15, Average loss 0.276 Test accuracy 93.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2863 \n",
      "Accuracy: 9320/10000 (93.20%)\n",
      "\n",
      "Round  16, Average loss 0.286 Test accuracy 93.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2655 \n",
      "Accuracy: 9355/10000 (93.55%)\n",
      "\n",
      "Round  17, Average loss 0.266 Test accuracy 93.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3169 \n",
      "Accuracy: 9292/10000 (92.92%)\n",
      "\n",
      "Round  18, Average loss 0.317 Test accuracy 92.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2812 \n",
      "Accuracy: 9322/10000 (93.22%)\n",
      "\n",
      "Round  19, Average loss 0.281 Test accuracy 93.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2721 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round  20, Average loss 0.272 Test accuracy 93.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3237 \n",
      "Accuracy: 9304/10000 (93.04%)\n",
      "\n",
      "Round  21, Average loss 0.324 Test accuracy 93.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2742 \n",
      "Accuracy: 9344/10000 (93.44%)\n",
      "\n",
      "Round  22, Average loss 0.274 Test accuracy 93.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2945 \n",
      "Accuracy: 9317/10000 (93.17%)\n",
      "\n",
      "Round  23, Average loss 0.295 Test accuracy 93.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3219 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round  24, Average loss 0.322 Test accuracy 92.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3136 \n",
      "Accuracy: 9316/10000 (93.16%)\n",
      "\n",
      "Round  25, Average loss 0.314 Test accuracy 93.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3237 \n",
      "Accuracy: 9327/10000 (93.27%)\n",
      "\n",
      "Round  26, Average loss 0.324 Test accuracy 93.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2906 \n",
      "Accuracy: 9348/10000 (93.48%)\n",
      "\n",
      "Round  27, Average loss 0.291 Test accuracy 93.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3200 \n",
      "Accuracy: 9224/10000 (92.24%)\n",
      "\n",
      "Round  28, Average loss 0.320 Test accuracy 92.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2795 \n",
      "Accuracy: 9347/10000 (93.47%)\n",
      "\n",
      "Round  29, Average loss 0.279 Test accuracy 93.470\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "(T, sigma)= 5 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 10.280\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "(T, sigma)= 5 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3111 \n",
      "Accuracy: 903/10000 (9.03%)\n",
      "\n",
      "Round   0, Average loss 2.311 Test accuracy 9.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 974/10000 (9.74%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1045/10000 (10.45%)\n",
      "\n",
      "Round   9, Average loss 2.302 Test accuracy 10.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 975/10000 (9.75%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3029 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3027 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3016 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round  27, Average loss 2.302 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 10.280\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "(T, sigma)= 6 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1036 \n",
      "Accuracy: 5343/10000 (53.43%)\n",
      "\n",
      "Round   1, Average loss 2.104 Test accuracy 53.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5258 \n",
      "Accuracy: 8667/10000 (86.67%)\n",
      "\n",
      "Round   2, Average loss 1.526 Test accuracy 86.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6995 \n",
      "Accuracy: 8353/10000 (83.53%)\n",
      "\n",
      "Round   3, Average loss 3.699 Test accuracy 83.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4192 \n",
      "Accuracy: 7609/10000 (76.09%)\n",
      "\n",
      "Round   4, Average loss 7.419 Test accuracy 76.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4514 \n",
      "Accuracy: 7358/10000 (73.58%)\n",
      "\n",
      "Round   5, Average loss 7.451 Test accuracy 73.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.7420 \n",
      "Accuracy: 6711/10000 (67.11%)\n",
      "\n",
      "Round   6, Average loss 10.742 Test accuracy 67.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.7371 \n",
      "Accuracy: 7937/10000 (79.37%)\n",
      "\n",
      "Round   7, Average loss 8.737 Test accuracy 79.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.8457 \n",
      "Accuracy: 6384/10000 (63.84%)\n",
      "\n",
      "Round   8, Average loss 10.846 Test accuracy 63.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.9904 \n",
      "Accuracy: 8014/10000 (80.14%)\n",
      "\n",
      "Round   9, Average loss 12.990 Test accuracy 80.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.3709 \n",
      "Accuracy: 5570/10000 (55.70%)\n",
      "\n",
      "Round  10, Average loss 19.371 Test accuracy 55.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.7380 \n",
      "Accuracy: 8090/10000 (80.90%)\n",
      "\n",
      "Round  11, Average loss 14.738 Test accuracy 80.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.1458 \n",
      "Accuracy: 5166/10000 (51.66%)\n",
      "\n",
      "Round  12, Average loss 24.146 Test accuracy 51.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.4666 \n",
      "Accuracy: 7468/10000 (74.68%)\n",
      "\n",
      "Round  13, Average loss 15.467 Test accuracy 74.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.7799 \n",
      "Accuracy: 5283/10000 (52.83%)\n",
      "\n",
      "Round  14, Average loss 18.780 Test accuracy 52.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 16.2418 \n",
      "Accuracy: 7893/10000 (78.93%)\n",
      "\n",
      "Round  15, Average loss 16.242 Test accuracy 78.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.7175 \n",
      "Accuracy: 5155/10000 (51.55%)\n",
      "\n",
      "Round  16, Average loss 19.717 Test accuracy 51.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.6559 \n",
      "Accuracy: 7804/10000 (78.04%)\n",
      "\n",
      "Round  17, Average loss 15.656 Test accuracy 78.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.6766 \n",
      "Accuracy: 5043/10000 (50.43%)\n",
      "\n",
      "Round  18, Average loss 20.677 Test accuracy 50.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.7279 \n",
      "Accuracy: 7452/10000 (74.52%)\n",
      "\n",
      "Round  19, Average loss 17.728 Test accuracy 74.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.9455 \n",
      "Accuracy: 4936/10000 (49.36%)\n",
      "\n",
      "Round  20, Average loss 20.945 Test accuracy 49.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.0526 \n",
      "Accuracy: 7382/10000 (73.82%)\n",
      "\n",
      "Round  21, Average loss 16.053 Test accuracy 73.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.2112 \n",
      "Accuracy: 5418/10000 (54.18%)\n",
      "\n",
      "Round  22, Average loss 19.211 Test accuracy 54.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.9572 \n",
      "Accuracy: 7479/10000 (74.79%)\n",
      "\n",
      "Round  23, Average loss 14.957 Test accuracy 74.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.8111 \n",
      "Accuracy: 5385/10000 (53.85%)\n",
      "\n",
      "Round  24, Average loss 19.811 Test accuracy 53.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.1295 \n",
      "Accuracy: 7669/10000 (76.69%)\n",
      "\n",
      "Round  25, Average loss 15.129 Test accuracy 76.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.7044 \n",
      "Accuracy: 5678/10000 (56.78%)\n",
      "\n",
      "Round  26, Average loss 19.704 Test accuracy 56.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.2085 \n",
      "Accuracy: 7424/10000 (74.24%)\n",
      "\n",
      "Round  27, Average loss 16.209 Test accuracy 74.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.5604 \n",
      "Accuracy: 5639/10000 (56.39%)\n",
      "\n",
      "Round  28, Average loss 16.560 Test accuracy 56.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.3757 \n",
      "Accuracy: 7944/10000 (79.44%)\n",
      "\n",
      "Round  29, Average loss 15.376 Test accuracy 79.440\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "(T, sigma)= 6 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2585 \n",
      "Accuracy: 7479/10000 (74.79%)\n",
      "\n",
      "Round   1, Average loss 1.258 Test accuracy 74.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1310 \n",
      "Accuracy: 8815/10000 (88.15%)\n",
      "\n",
      "Round   2, Average loss 1.131 Test accuracy 88.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7055 \n",
      "Accuracy: 8571/10000 (85.71%)\n",
      "\n",
      "Round   3, Average loss 2.705 Test accuracy 85.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3069 \n",
      "Accuracy: 8780/10000 (87.80%)\n",
      "\n",
      "Round   4, Average loss 2.307 Test accuracy 87.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2720 \n",
      "Accuracy: 8319/10000 (83.19%)\n",
      "\n",
      "Round   5, Average loss 4.272 Test accuracy 83.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7207 \n",
      "Accuracy: 8856/10000 (88.56%)\n",
      "\n",
      "Round   6, Average loss 2.721 Test accuracy 88.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.5236 \n",
      "Accuracy: 7776/10000 (77.76%)\n",
      "\n",
      "Round   7, Average loss 5.524 Test accuracy 77.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0019 \n",
      "Accuracy: 8920/10000 (89.20%)\n",
      "\n",
      "Round   8, Average loss 3.002 Test accuracy 89.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.1141 \n",
      "Accuracy: 7960/10000 (79.60%)\n",
      "\n",
      "Round   9, Average loss 7.114 Test accuracy 79.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.7344 \n",
      "Accuracy: 8047/10000 (80.47%)\n",
      "\n",
      "Round  10, Average loss 5.734 Test accuracy 80.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.7426 \n",
      "Accuracy: 7760/10000 (77.60%)\n",
      "\n",
      "Round  11, Average loss 10.743 Test accuracy 77.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.1613 \n",
      "Accuracy: 6891/10000 (68.91%)\n",
      "\n",
      "Round  12, Average loss 12.161 Test accuracy 68.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.1514 \n",
      "Accuracy: 7666/10000 (76.66%)\n",
      "\n",
      "Round  13, Average loss 15.151 Test accuracy 76.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.9826 \n",
      "Accuracy: 6035/10000 (60.35%)\n",
      "\n",
      "Round  14, Average loss 17.983 Test accuracy 60.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.1177 \n",
      "Accuracy: 7922/10000 (79.22%)\n",
      "\n",
      "Round  15, Average loss 15.118 Test accuracy 79.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.3545 \n",
      "Accuracy: 6445/10000 (64.45%)\n",
      "\n",
      "Round  16, Average loss 15.355 Test accuracy 64.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.3334 \n",
      "Accuracy: 7861/10000 (78.61%)\n",
      "\n",
      "Round  17, Average loss 16.333 Test accuracy 78.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.5576 \n",
      "Accuracy: 6106/10000 (61.06%)\n",
      "\n",
      "Round  18, Average loss 18.558 Test accuracy 61.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.3981 \n",
      "Accuracy: 7739/10000 (77.39%)\n",
      "\n",
      "Round  19, Average loss 16.398 Test accuracy 77.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.2741 \n",
      "Accuracy: 6128/10000 (61.28%)\n",
      "\n",
      "Round  20, Average loss 22.274 Test accuracy 61.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.6632 \n",
      "Accuracy: 7763/10000 (77.63%)\n",
      "\n",
      "Round  21, Average loss 14.663 Test accuracy 77.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.9720 \n",
      "Accuracy: 6388/10000 (63.88%)\n",
      "\n",
      "Round  22, Average loss 15.972 Test accuracy 63.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.4284 \n",
      "Accuracy: 7600/10000 (76.00%)\n",
      "\n",
      "Round  23, Average loss 16.428 Test accuracy 76.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.4527 \n",
      "Accuracy: 5996/10000 (59.96%)\n",
      "\n",
      "Round  24, Average loss 18.453 Test accuracy 59.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.9281 \n",
      "Accuracy: 7778/10000 (77.78%)\n",
      "\n",
      "Round  25, Average loss 15.928 Test accuracy 77.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.8310 \n",
      "Accuracy: 6073/10000 (60.73%)\n",
      "\n",
      "Round  26, Average loss 20.831 Test accuracy 60.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.4369 \n",
      "Accuracy: 7684/10000 (76.84%)\n",
      "\n",
      "Round  27, Average loss 15.437 Test accuracy 76.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.4181 \n",
      "Accuracy: 6845/10000 (68.45%)\n",
      "\n",
      "Round  28, Average loss 13.418 Test accuracy 68.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.7789 \n",
      "Accuracy: 8017/10000 (80.17%)\n",
      "\n",
      "Round  29, Average loss 17.779 Test accuracy 80.170\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "(T, sigma)= 6 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7282 \n",
      "Accuracy: 7932/10000 (79.32%)\n",
      "\n",
      "Round   1, Average loss 1.728 Test accuracy 79.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5758 \n",
      "Accuracy: 8942/10000 (89.42%)\n",
      "\n",
      "Round   2, Average loss 0.576 Test accuracy 89.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9030 \n",
      "Accuracy: 9086/10000 (90.86%)\n",
      "\n",
      "Round   3, Average loss 0.903 Test accuracy 90.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1458 \n",
      "Accuracy: 9037/10000 (90.37%)\n",
      "\n",
      "Round   4, Average loss 1.146 Test accuracy 90.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9297 \n",
      "Accuracy: 9119/10000 (91.19%)\n",
      "\n",
      "Round   5, Average loss 0.930 Test accuracy 91.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0255 \n",
      "Accuracy: 9088/10000 (90.88%)\n",
      "\n",
      "Round   6, Average loss 1.025 Test accuracy 90.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0388 \n",
      "Accuracy: 9165/10000 (91.65%)\n",
      "\n",
      "Round   7, Average loss 1.039 Test accuracy 91.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3817 \n",
      "Accuracy: 8887/10000 (88.87%)\n",
      "\n",
      "Round   8, Average loss 1.382 Test accuracy 88.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2044 \n",
      "Accuracy: 9045/10000 (90.45%)\n",
      "\n",
      "Round   9, Average loss 1.204 Test accuracy 90.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2793 \n",
      "Accuracy: 9024/10000 (90.24%)\n",
      "\n",
      "Round  10, Average loss 1.279 Test accuracy 90.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1989 \n",
      "Accuracy: 9054/10000 (90.54%)\n",
      "\n",
      "Round  11, Average loss 1.199 Test accuracy 90.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2577 \n",
      "Accuracy: 9122/10000 (91.22%)\n",
      "\n",
      "Round  12, Average loss 1.258 Test accuracy 91.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5275 \n",
      "Accuracy: 8897/10000 (88.97%)\n",
      "\n",
      "Round  13, Average loss 1.527 Test accuracy 88.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4046 \n",
      "Accuracy: 8951/10000 (89.51%)\n",
      "\n",
      "Round  14, Average loss 1.405 Test accuracy 89.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3760 \n",
      "Accuracy: 9014/10000 (90.14%)\n",
      "\n",
      "Round  15, Average loss 1.376 Test accuracy 90.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4652 \n",
      "Accuracy: 9012/10000 (90.12%)\n",
      "\n",
      "Round  16, Average loss 1.465 Test accuracy 90.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3738 \n",
      "Accuracy: 8976/10000 (89.76%)\n",
      "\n",
      "Round  17, Average loss 1.374 Test accuracy 89.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3929 \n",
      "Accuracy: 9023/10000 (90.23%)\n",
      "\n",
      "Round  18, Average loss 1.393 Test accuracy 90.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4846 \n",
      "Accuracy: 9043/10000 (90.43%)\n",
      "\n",
      "Round  19, Average loss 1.485 Test accuracy 90.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6261 \n",
      "Accuracy: 8933/10000 (89.33%)\n",
      "\n",
      "Round  20, Average loss 1.626 Test accuracy 89.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6099 \n",
      "Accuracy: 8860/10000 (88.60%)\n",
      "\n",
      "Round  21, Average loss 1.610 Test accuracy 88.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4939 \n",
      "Accuracy: 8938/10000 (89.38%)\n",
      "\n",
      "Round  22, Average loss 1.494 Test accuracy 89.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5391 \n",
      "Accuracy: 8988/10000 (89.88%)\n",
      "\n",
      "Round  23, Average loss 1.539 Test accuracy 89.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6590 \n",
      "Accuracy: 8753/10000 (87.53%)\n",
      "\n",
      "Round  24, Average loss 1.659 Test accuracy 87.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4627 \n",
      "Accuracy: 9037/10000 (90.37%)\n",
      "\n",
      "Round  25, Average loss 1.463 Test accuracy 90.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5307 \n",
      "Accuracy: 8954/10000 (89.54%)\n",
      "\n",
      "Round  26, Average loss 1.531 Test accuracy 89.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8218 \n",
      "Accuracy: 8876/10000 (88.76%)\n",
      "\n",
      "Round  27, Average loss 1.822 Test accuracy 88.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6725 \n",
      "Accuracy: 8774/10000 (87.74%)\n",
      "\n",
      "Round  28, Average loss 1.673 Test accuracy 87.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8097 \n",
      "Accuracy: 8775/10000 (87.75%)\n",
      "\n",
      "Round  29, Average loss 1.810 Test accuracy 87.750\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "(T, sigma)= 6 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  10, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  12, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "(T, sigma)= 6 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 859/10000 (8.59%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 8.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3029 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 532/10000 (5.32%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 5.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "(T, sigma)= 7 0.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2936 \n",
      "Accuracy: 1699/10000 (16.99%)\n",
      "\n",
      "Round   0, Average loss 2.294 Test accuracy 16.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6331 \n",
      "Accuracy: 8346/10000 (83.46%)\n",
      "\n",
      "Round   1, Average loss 0.633 Test accuracy 83.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6112 \n",
      "Accuracy: 8963/10000 (89.63%)\n",
      "\n",
      "Round   2, Average loss 0.611 Test accuracy 89.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3674 \n",
      "Accuracy: 8662/10000 (86.62%)\n",
      "\n",
      "Round   3, Average loss 1.367 Test accuracy 86.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1592 \n",
      "Accuracy: 8813/10000 (88.13%)\n",
      "\n",
      "Round   4, Average loss 1.159 Test accuracy 88.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7288 \n",
      "Accuracy: 8711/10000 (87.11%)\n",
      "\n",
      "Round   5, Average loss 1.729 Test accuracy 87.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6648 \n",
      "Accuracy: 8546/10000 (85.46%)\n",
      "\n",
      "Round   6, Average loss 1.665 Test accuracy 85.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6451 \n",
      "Accuracy: 8757/10000 (87.57%)\n",
      "\n",
      "Round   7, Average loss 1.645 Test accuracy 87.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3192 \n",
      "Accuracy: 8957/10000 (89.57%)\n",
      "\n",
      "Round   8, Average loss 1.319 Test accuracy 89.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0403 \n",
      "Accuracy: 8663/10000 (86.63%)\n",
      "\n",
      "Round   9, Average loss 2.040 Test accuracy 86.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.4313 \n",
      "Accuracy: 7910/10000 (79.10%)\n",
      "\n",
      "Round  10, Average loss 3.431 Test accuracy 79.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1004 \n",
      "Accuracy: 8437/10000 (84.37%)\n",
      "\n",
      "Round  11, Average loss 2.100 Test accuracy 84.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9198 \n",
      "Accuracy: 8057/10000 (80.57%)\n",
      "\n",
      "Round  12, Average loss 2.920 Test accuracy 80.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2157 \n",
      "Accuracy: 7857/10000 (78.57%)\n",
      "\n",
      "Round  13, Average loss 3.216 Test accuracy 78.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3347 \n",
      "Accuracy: 7858/10000 (78.58%)\n",
      "\n",
      "Round  14, Average loss 3.335 Test accuracy 78.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.6505 \n",
      "Accuracy: 7866/10000 (78.66%)\n",
      "\n",
      "Round  15, Average loss 4.650 Test accuracy 78.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7091 \n",
      "Accuracy: 7609/10000 (76.09%)\n",
      "\n",
      "Round  16, Average loss 3.709 Test accuracy 76.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5714 \n",
      "Accuracy: 8353/10000 (83.53%)\n",
      "\n",
      "Round  17, Average loss 2.571 Test accuracy 83.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6774 \n",
      "Accuracy: 8327/10000 (83.27%)\n",
      "\n",
      "Round  18, Average loss 2.677 Test accuracy 83.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8884 \n",
      "Accuracy: 8028/10000 (80.28%)\n",
      "\n",
      "Round  19, Average loss 3.888 Test accuracy 80.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5538 \n",
      "Accuracy: 8189/10000 (81.89%)\n",
      "\n",
      "Round  20, Average loss 2.554 Test accuracy 81.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7612 \n",
      "Accuracy: 8195/10000 (81.95%)\n",
      "\n",
      "Round  21, Average loss 3.761 Test accuracy 81.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2408 \n",
      "Accuracy: 8657/10000 (86.57%)\n",
      "\n",
      "Round  22, Average loss 2.241 Test accuracy 86.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3040 \n",
      "Accuracy: 7953/10000 (79.53%)\n",
      "\n",
      "Round  23, Average loss 3.304 Test accuracy 79.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0330 \n",
      "Accuracy: 8751/10000 (87.51%)\n",
      "\n",
      "Round  24, Average loss 2.033 Test accuracy 87.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1427 \n",
      "Accuracy: 8641/10000 (86.41%)\n",
      "\n",
      "Round  25, Average loss 2.143 Test accuracy 86.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0908 \n",
      "Accuracy: 8248/10000 (82.48%)\n",
      "\n",
      "Round  26, Average loss 3.091 Test accuracy 82.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6093 \n",
      "Accuracy: 8258/10000 (82.58%)\n",
      "\n",
      "Round  27, Average loss 2.609 Test accuracy 82.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5184 \n",
      "Accuracy: 8343/10000 (83.43%)\n",
      "\n",
      "Round  28, Average loss 2.518 Test accuracy 83.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1085 \n",
      "Accuracy: 8513/10000 (85.13%)\n",
      "\n",
      "Round  29, Average loss 2.108 Test accuracy 85.130\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "(T, sigma)= 7 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2881 \n",
      "Accuracy: 3204/10000 (32.04%)\n",
      "\n",
      "Round   0, Average loss 2.288 Test accuracy 32.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1479 \n",
      "Accuracy: 7860/10000 (78.60%)\n",
      "\n",
      "Round   1, Average loss 1.148 Test accuracy 78.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9387 \n",
      "Accuracy: 8814/10000 (88.14%)\n",
      "\n",
      "Round   2, Average loss 0.939 Test accuracy 88.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9605 \n",
      "Accuracy: 8354/10000 (83.54%)\n",
      "\n",
      "Round   3, Average loss 1.960 Test accuracy 83.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6549 \n",
      "Accuracy: 8349/10000 (83.49%)\n",
      "\n",
      "Round   4, Average loss 2.655 Test accuracy 83.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7128 \n",
      "Accuracy: 8288/10000 (82.88%)\n",
      "\n",
      "Round   5, Average loss 2.713 Test accuracy 82.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5648 \n",
      "Accuracy: 8416/10000 (84.16%)\n",
      "\n",
      "Round   6, Average loss 2.565 Test accuracy 84.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0135 \n",
      "Accuracy: 8029/10000 (80.29%)\n",
      "\n",
      "Round   7, Average loss 3.013 Test accuracy 80.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1011 \n",
      "Accuracy: 8333/10000 (83.33%)\n",
      "\n",
      "Round   8, Average loss 3.101 Test accuracy 83.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9852 \n",
      "Accuracy: 7976/10000 (79.76%)\n",
      "\n",
      "Round   9, Average loss 3.985 Test accuracy 79.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4175 \n",
      "Accuracy: 8810/10000 (88.10%)\n",
      "\n",
      "Round  10, Average loss 2.418 Test accuracy 88.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8034 \n",
      "Accuracy: 8501/10000 (85.01%)\n",
      "\n",
      "Round  11, Average loss 2.803 Test accuracy 85.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6072 \n",
      "Accuracy: 8426/10000 (84.26%)\n",
      "\n",
      "Round  12, Average loss 3.607 Test accuracy 84.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9893 \n",
      "Accuracy: 7973/10000 (79.73%)\n",
      "\n",
      "Round  13, Average loss 3.989 Test accuracy 79.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.9036 \n",
      "Accuracy: 8702/10000 (87.02%)\n",
      "\n",
      "Round  14, Average loss 2.904 Test accuracy 87.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4263 \n",
      "Accuracy: 7517/10000 (75.17%)\n",
      "\n",
      "Round  15, Average loss 7.426 Test accuracy 75.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1837 \n",
      "Accuracy: 8666/10000 (86.66%)\n",
      "\n",
      "Round  16, Average loss 3.184 Test accuracy 86.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6444 \n",
      "Accuracy: 8572/10000 (85.72%)\n",
      "\n",
      "Round  17, Average loss 2.644 Test accuracy 85.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.5372 \n",
      "Accuracy: 8037/10000 (80.37%)\n",
      "\n",
      "Round  18, Average loss 6.537 Test accuracy 80.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9011 \n",
      "Accuracy: 8056/10000 (80.56%)\n",
      "\n",
      "Round  19, Average loss 3.901 Test accuracy 80.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.4202 \n",
      "Accuracy: 7969/10000 (79.69%)\n",
      "\n",
      "Round  20, Average loss 4.420 Test accuracy 79.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7375 \n",
      "Accuracy: 8309/10000 (83.09%)\n",
      "\n",
      "Round  21, Average loss 3.737 Test accuracy 83.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3840 \n",
      "Accuracy: 7858/10000 (78.58%)\n",
      "\n",
      "Round  22, Average loss 4.384 Test accuracy 78.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.7452 \n",
      "Accuracy: 7692/10000 (76.92%)\n",
      "\n",
      "Round  23, Average loss 5.745 Test accuracy 76.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.9332 \n",
      "Accuracy: 7773/10000 (77.73%)\n",
      "\n",
      "Round  24, Average loss 7.933 Test accuracy 77.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.6279 \n",
      "Accuracy: 5930/10000 (59.30%)\n",
      "\n",
      "Round  25, Average loss 13.628 Test accuracy 59.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.7626 \n",
      "Accuracy: 7264/10000 (72.64%)\n",
      "\n",
      "Round  26, Average loss 9.763 Test accuracy 72.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.2644 \n",
      "Accuracy: 6452/10000 (64.52%)\n",
      "\n",
      "Round  27, Average loss 8.264 Test accuracy 64.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.4446 \n",
      "Accuracy: 7372/10000 (73.72%)\n",
      "\n",
      "Round  28, Average loss 11.445 Test accuracy 73.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.7192 \n",
      "Accuracy: 6153/10000 (61.53%)\n",
      "\n",
      "Round  29, Average loss 9.719 Test accuracy 61.530\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "(T, sigma)= 7 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2573 \n",
      "Accuracy: 7408/10000 (74.08%)\n",
      "\n",
      "Round   1, Average loss 2.257 Test accuracy 74.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3722 \n",
      "Accuracy: 8848/10000 (88.48%)\n",
      "\n",
      "Round   2, Average loss 0.372 Test accuracy 88.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3416 \n",
      "Accuracy: 8855/10000 (88.55%)\n",
      "\n",
      "Round   3, Average loss 0.342 Test accuracy 88.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3005 \n",
      "Accuracy: 9056/10000 (90.56%)\n",
      "\n",
      "Round   4, Average loss 0.300 Test accuracy 90.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2607 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round   5, Average loss 0.261 Test accuracy 92.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2552 \n",
      "Accuracy: 9263/10000 (92.63%)\n",
      "\n",
      "Round   6, Average loss 0.255 Test accuracy 92.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2512 \n",
      "Accuracy: 9257/10000 (92.57%)\n",
      "\n",
      "Round   7, Average loss 0.251 Test accuracy 92.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2505 \n",
      "Accuracy: 9273/10000 (92.73%)\n",
      "\n",
      "Round   8, Average loss 0.251 Test accuracy 92.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2520 \n",
      "Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Round   9, Average loss 0.252 Test accuracy 92.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2714 \n",
      "Accuracy: 9194/10000 (91.94%)\n",
      "\n",
      "Round  10, Average loss 0.271 Test accuracy 91.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2686 \n",
      "Accuracy: 9216/10000 (92.16%)\n",
      "\n",
      "Round  11, Average loss 0.269 Test accuracy 92.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2720 \n",
      "Accuracy: 9183/10000 (91.83%)\n",
      "\n",
      "Round  12, Average loss 0.272 Test accuracy 91.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2522 \n",
      "Accuracy: 9279/10000 (92.79%)\n",
      "\n",
      "Round  13, Average loss 0.252 Test accuracy 92.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2650 \n",
      "Accuracy: 9259/10000 (92.59%)\n",
      "\n",
      "Round  14, Average loss 0.265 Test accuracy 92.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2339 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round  15, Average loss 0.234 Test accuracy 93.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2985 \n",
      "Accuracy: 9104/10000 (91.04%)\n",
      "\n",
      "Round  16, Average loss 0.299 Test accuracy 91.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3197 \n",
      "Accuracy: 9085/10000 (90.85%)\n",
      "\n",
      "Round  17, Average loss 0.320 Test accuracy 90.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2670 \n",
      "Accuracy: 9222/10000 (92.22%)\n",
      "\n",
      "Round  18, Average loss 0.267 Test accuracy 92.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2793 \n",
      "Accuracy: 9190/10000 (91.90%)\n",
      "\n",
      "Round  19, Average loss 0.279 Test accuracy 91.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2602 \n",
      "Accuracy: 9236/10000 (92.36%)\n",
      "\n",
      "Round  20, Average loss 0.260 Test accuracy 92.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2564 \n",
      "Accuracy: 9271/10000 (92.71%)\n",
      "\n",
      "Round  21, Average loss 0.256 Test accuracy 92.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2857 \n",
      "Accuracy: 9206/10000 (92.06%)\n",
      "\n",
      "Round  22, Average loss 0.286 Test accuracy 92.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2701 \n",
      "Accuracy: 9205/10000 (92.05%)\n",
      "\n",
      "Round  23, Average loss 0.270 Test accuracy 92.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2768 \n",
      "Accuracy: 9197/10000 (91.97%)\n",
      "\n",
      "Round  24, Average loss 0.277 Test accuracy 91.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2912 \n",
      "Accuracy: 9159/10000 (91.59%)\n",
      "\n",
      "Round  25, Average loss 0.291 Test accuracy 91.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2744 \n",
      "Accuracy: 9211/10000 (92.11%)\n",
      "\n",
      "Round  26, Average loss 0.274 Test accuracy 92.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2635 \n",
      "Accuracy: 9214/10000 (92.14%)\n",
      "\n",
      "Round  27, Average loss 0.264 Test accuracy 92.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2978 \n",
      "Accuracy: 9138/10000 (91.38%)\n",
      "\n",
      "Round  28, Average loss 0.298 Test accuracy 91.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3213 \n",
      "Accuracy: 9066/10000 (90.66%)\n",
      "\n",
      "Round  29, Average loss 0.321 Test accuracy 90.660\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "(T, sigma)= 7 10.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 10.090\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "(T, sigma)= 7 100.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 713/10000 (7.13%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 7.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 958/10000 (9.58%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   3, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1327/10000 (13.27%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 13.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1008/10000 (10.08%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 10.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 974/10000 (9.74%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3053 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  16, Average loss 2.305 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 468/10000 (4.68%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 4.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.302 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 8.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 892/10000 (8.92%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 8.920\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "N = args.num_users\n",
    "K = args.num_partition\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "# m_array = np.array(range(4,16)) # m is the number of received result @ master\n",
    "T_array = np.array([4,5,6,7]) # m is the number of received result @ master\n",
    "sigma_array = np.array([0, 0.1, 1, 10, 100])\n",
    "\n",
    "\n",
    "loss_test_arr_v2 = np.empty((len(T_array),len(sigma_array),N_trials,N_epochs))\n",
    "acc_test_arr_v2  = np.empty((len(T_array),len(sigma_array),N_trials,N_epochs))\n",
    "\n",
    "for T_idx in range(len(T_array)):\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    T = T_array[T_idx]\n",
    "    \n",
    "    if T == 0:\n",
    "        Noise_Alloc = []\n",
    "    elif T == 1:\n",
    "        Noise_Alloc = [3]\n",
    "    elif T == 2:\n",
    "        Noise_Alloc = [2,5]\n",
    "    elif T == 3:\n",
    "        Noise_Alloc = [2,4,7]\n",
    "    elif T == 4:\n",
    "        Noise_Alloc = [1,3,5,8]\n",
    "    elif T == 5:\n",
    "        Noise_Alloc = [1,3,5,7,9]\n",
    "    elif T == 6:\n",
    "        Noise_Alloc = [2,4,5,7,9,10]\n",
    "    elif T == 7:\n",
    "        Noise_Alloc = [1,3,5,7,9,10,12] # np.random.choice(range(K+T), T, replace=False)\n",
    "    else:\n",
    "        Noise_Alloc = np.random.choice(range(K+T), T, replace=False)\n",
    "        \n",
    "    Signal_Alloc = []\n",
    "    for i in range(K+T):\n",
    "        if i not in Noise_Alloc:\n",
    "            Signal_Alloc.append(i)\n",
    "\n",
    "    j_array = np.array(range(K+T))\n",
    "    # print(\"j: \",(2*j_array+1)*math.pi/2/K,'\\n')\n",
    "\n",
    "    alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "    i_array = np.array(range(N))\n",
    "    z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "    \n",
    "    for sigma_idx in range(len(sigma_array)):\n",
    "        \n",
    "        sigma = sigma_array[sigma_idx]\n",
    "\n",
    "        X_tilde,a,b = BACC_Enc_withNoise(encoding_input_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "        y_tilde,a,b = BACC_Enc_withNoise(encoding_label_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "\n",
    "        m = N # m is the number of received result @ master\n",
    "    #     print('number of results:',m)\n",
    "\n",
    "        for trial_idx in range(N_trials):\n",
    "            print('(T, sigma)=',T,sigma,') ',trial_idx,'-th Trial!!')\n",
    "\n",
    "            net_glob = CNNMnist2(args=args)\n",
    "            net_glob.cuda()\n",
    "            net_glob.train()\n",
    "\n",
    "            # copy weights\n",
    "            w_glob = net_glob.state_dict()\n",
    "\n",
    "            for iter in range(N_epochs): #args.epochs\n",
    "                w_locals, loss_locals = [], []\n",
    "                idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "                idxs_users = np.sort(idxs_users)\n",
    "                print('selected users:',idxs_users)\n",
    "\n",
    "                dec_z_array = []\n",
    "                for idx in idxs_users: #for idx in range(N):\n",
    "            #         print(idx)\n",
    "                    local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                    w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                    w_locals.append(copy.deepcopy(w))\n",
    "                    loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                    dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "                # update global weights\n",
    "                #w_glob = FedAvg(w_locals)\n",
    "                w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "                # copy weight to net_glob\n",
    "                net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                # print loss\n",
    "            #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "            #     loss_train_arr.append(loss_train)\n",
    "\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                acc_test_arr_v2[T_idx][sigma_idx][trial_idx][iter] = acc_test\n",
    "                loss_test_arr_v2[T_idx][sigma_idx][trial_idx][iter] = loss_test\n",
    "                if iter % 1 ==0:\n",
    "                    print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "                #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 30)\n"
     ]
    }
   ],
   "source": [
    "plot_acc_v2 = np.mean(acc_test_arr_v2, axis=2)\n",
    "# print(acc_test_arr.shape)\n",
    "print(plot_acc_v2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3hUVd6A3zN9kslMZtIbJKH3XkQ6qKAoYEWRoruWLe6uu+7qftvcdZvd1c/uqogodhEsNAWp0kILoYSWhPSe6e1+f5xJSCAJSWh+OO/z3Oe2c889Z+be8zu/cs4ViqIQJkyYMGHC1KO62AUIEyZMmDDfL8KCIUyYMGHCNCEsGMKECRMmTBPCgiFMmDBhwjQhLBjChAkTJkwTwoIhTJgwYcI0ISwYwvxgEELMFkKsuNjlCBPm+05YMIS5pBBCjBZCbBRC1AghKoUQG4QQwwAURVmkKMqVF7uM7UEIMUkIsV8I4RRCfCOE6NxK2keEEHuEEH4hxMMXsJhhLjHCgiHMJYMQwgwsA54DbEAK8FfAczHL1VGEELHAx8CfkPXZBrzXyiW5wO+Az89/6cJcyoQFQ5hLie4AiqK8qyhKQFEUl6IoKxRF2Q0ghJgvhFhfn1gIcaUQ4kBIu3hBCLFWCPHjRmk3CCGeFkJUCyGOCCFGhY7nCyFKhRDzGuV1jRAiSwhRGzr/8Dmoz/VAtqIoHyiK4gYeBgYIIXo2l1hRlAWKonwJ1J2De4f5ARMWDGEuJQ4CASHEAiHEVCGEtaWEod74h8DvgRjgADDqlGQjgN2h8+8Ai4FhQFfgduB/hRCmUFoHMBeIBq4BfiKEmNHCvTuFhE1Ly22hpH2AXfXXKYriAA6HjocJc94IC4YwlwyKotQCowEFeBUoE0J8JoRIaCb51cje+MeKoviBZ4HiU9IcVRTlDUVRAkgTThrwN0VRPIqirAC8SCGBoihrFEXZoyhKMKShvAuMa6GceYqiRLeyvBNKagJqTrm8Bohq3y8TJkz7CAuGMJcUiqLkKIoyX1GUVKAvkAw800zSZCC/0XUKUHBKmpJG265QulOPmQCEECNCzuEyIUQNcC8Qe5bVsQPmU46ZCZuKwpxnwoIhzCWLoij7gTeRAuJUioDU+h0hhGi83wHeAT4D0hRFsQAvAaK5hCFTkr2VZXYoaTYwoNF1kUCX0PEwYc4bYcEQ5pJBCNFTCPEbIURqaD8NuBXY3Ezyz4F+QogZQggN8DMg8SxuHwVUKoriFkIMB25rKWHIlGRqZVkUSvoJ0FcIcYMQwgD8GdgdEninIYTQhtKpAI0QwiCEUJ9FncL8QAkLhjCXEnVIh/F3QggHUiDsBX5zakJFUcqBm4DHgAqgNzIctKOhrT8F/iaEqEM24O93MJ/GZSwDbgD+AVQh6zar/rwQ4iUhxEuNLnkVad66FfhDaHvO2ZYjzA8PEf5QT5gwIIRQIX0MsxVF+eZilydMmItJWGMI84NFCHGVECJaCKEH/gfpE2jO7BQmzA+KsGAI80PmMuS4gHLgWmCGoiiui1ukMGEuPmFTUpgwYcKEacJ50xiEEK+Hpg3Y2+iYTQixUghxKLS2ho4LIcSzQohcIcRuIcTg81WuMGHChAnTOudNYxBCjEUO0HlLUZS+oWOPIUP6/i2EeAiwKoryoBDiauA+5GjUEcB/FEUZcaZ7xMbGKunp6R0qn8PhIDIyskPXfl+51Op0qdUHLr06XWr1gUuvTs3VZ/v27eWKosS1eJGiKOdtAdKBvY32DwBJoe0k4EBo+2Xg1ubStbYMGTJE6SjffPNNh6/9vnKp1elSq4+iXHp1utTqoyiXXp2aqw+wTWmlbT2vPgYhRDqwTDmpMVQrihLd6HyVoihWIcQy4N+KoqwPHV8NPKgoyrZm8rwbuBsgISFhyOLFiztUNrvdjslkOnPC/0dcanW61OoDl16dLrX6wKVXp+bqM2HChO2Kogxt6RrNeS9V22hu6oBmJZaiKK8ArwAMHTpUGT9+fIduuGbNGjp67feVS61Ol1p94NKr06VWH7j06tSR+lzocNUSIUQSQGhdGjpegJy5sp5UoPACly1MmDBhwnDhBcNnQP3HTeYBSxodnxuKThoJ1CiKUnSByxYmTJgwYTiPpiQhxLvAeCBWCFEA/AX4N/C+EOJHQB5yrhqAL5ARSbmAE7jjfJUrTJgwYcK0znkTDIqi3NrCqUnNpFWQs1uGCRMmTJiLTHhKjDBhwoQJ04TvS1RSmO8ZDo+fQ6V2VAKsETpskToidGrk92y+H5TbPew9UcP+4jo0KkGMSUdMpJ5Yk55Ykw5rpA6t+uz6Poqi4A0E8fiDuH0BPL4gHn8At08e8/gCqFSClGgjSRYDmrO8X5gwbcHlDQBg1J2fz22EBcMPHEVRKKvzkF1Uy77CWvYV1ZJTWMvRCgenDnHRaVTYQkLCFikbXluEFmukDpNeQ1BRCAQhEAzKtaI0bAcVBX9AIagoWIxakiwGEiwGkiwGEs0GLEZti0JHURRK6zzsKahhb2ENe0/Ukl1YQ1GN+4z1s0ZoiTHpiYnUEWvSY9JrQg19feMuG3u3v77RDwkAf+icP3ja79ASapUgOdpAmjVCLjYjabYIUq0RpFmNxEXp8QcVCqtdlNS6Ka3zUFrrpqTWQ2mdXJfUuimr81Dn9qPXqNBrVeg16oa1QatCr1Fh0KrleY2aoKLgCwTxB6QQq9/2BYL4GtZBAAxaNZF6DRE6NUatWq51cl8uGoxaFUEFmZc/iDcQxNt47Zf5eQNBSkrdfFqchUGrlmVqVE6DRh06LsvrDyoN13tDv23jfD2hxR8IElRCg2+Rz07DvlK/L7fVKtFk0agEapUqtA7tqwVqIbdVKrldf6zxtarQ/qECH6Xb8lEJgUqASgiEABHaF8i1Rq3CpNdg0muI1KsxGeS2UdvxDpTXH6TMLp+D0lo3xTVuSurq9+W6uNZNndvPv6/vx6zhnTp0nzMRFgwXgQ255RworiMYanFOPviEHviT+0IQenlDL7G26Utcv23UqXH6FCrsnobGwBN6gesXr18er3J62RcSBDlFtZTbvQ1lS7MZ6Z1kZvrAFHomRaESgiqHl0qnV64dXqqccn2i2kWF3UOt299iXdWqpi+gEGD3+E9rbPUalRQWZgOJFrmcyPfy5tEt7D1RS7ldfj9HCOgSZ2JEho2+KRb6JFvonSw/i1xh91Dh8FJe56Hc4aXC7qHc7qHC7qXC7iWnqBa7x3+yUW3UiJmN2lMa3EbbjdaGU9Z6jQp/QKGgykl+lZP8Shf5VU5W7y9tKHM9Oo0Krz8IK74+7TeKNelIMBtItUYwuLMVs0GL199YYDUVZFUOb8O+SiXQqlRoNQKtWoVWJetmMmjQqFToNAKNSmoyLl8Ap9eP3eOnrM6D0xvA6Q3g8vpx+gLNCkEhQKdWoQv9LtrQtk6twukMUpZXjdsXkEuosW8PQsj/X95DjVYtGhrj+sZZnLqP3A8qCv6gQqDRUr/vDwSb7gfbMZh37+521aExKgGRDQJDLigKvoCCPxgS2vXrxsdC7+ypaNWC+CgD8WY9XeJMXN41lniznv6p0c3c/dwQFgwXmI255cx+7bvzd4PVq9qUTKsWdE+IYkKPeHonm+mdZKZnkhmLUdvuW/oCQZzeQEMPrb7nVf9Cn4rXHwz1kN0U13goqpE96KIaeWxHXhUlNR78wSDdE9yM7xFHvxQLfVPM9Ew0yxetGSxGLZktz/5ywXF5A00ERmG1i5LCfEb070mCWd/wssdE6lGrLr6JTlEU3L4gLl8AtRBoNQKdWtWqeay5wVPBoNRcpLAIrf0BNCqBTq1uEDC60KJRiQtmogwGlZAmG1oUhWBIaNSf27hxE8NHjERRQEF20uo1lPpOW72WZvf4cXgC2D0+7J4ADo8fh8dPnVuuHV4/dk8AgXznNCoVGrUU4BqVQKNWNRzXqgUROg0JZj0JZkNo0WON0KG6wM9HWDBcQOrcPn774W4yYiN5756RGLRqBPW9oHp1NaS6ho4HFQWnL4Ar1LNzePyhXl+ol+cN4AhtHzl8hF49ujX06LRq+WJr1Sq0oX29RoVJryUjNhKd5tzYw7VqFRZj2/PSaVSkWqWJpSUURWH1N2uYPHHsuSjiRcGoU9MtIYpuCVENx9asKWH8eVL/zxYhBMaQ9nk2qFQCg0qakb5vqFQCFYLWihZjVJFma/nZ/CEQFgwXkH98nkNRjYsP7h1FfJShTdeoEJjVKsyGM/fk1wTzGT8q/SxL+f1AhGzCYcKEufCEQyguEN8cKGXx1nzuGpvJkM7Wi12cMGHChGmRsGA4hyjB5p1uNU4fD320m+4JJu6f3P0ClypMmDBh2kfYlHSWBPx+Dm3ZSNZXyyg8mIMxyozJasNki8FktRFpjeHLww4iS/z8ZdYoAo5agmYzKtWFtb96nA7K8/OoKMijrqIckGFPJ6NQ5EbDNOyhdVRMHLGdOhOblo7hEpqKOEyYMC0TFgwdxFlTze5VX7Fr5RfYqyqJTkhi6LSZeJ1O7FUV2KsqKT16GEd1NVYUrgE2P/MFmwGhUqEzGNHodKFFf/q2Vm5rDQaMUWaMZjMRZgvGKEvDtsEUhVrT9C/0OJ1UFOSFluMNwsBeWdG0AqEoEIFomPT8ZGSIdIQrikIwEGi4xGSLIbZTOrFpneXSKZ2YlDQ0Ol2TrJVgELfDjrOmBmdtNc6a0FJbg6u2BhBo9Hq0er2sY+O1Xo9WJ9euqgqCgQAq9dkJUZ/XQ8nhQxQe3E91SRFqjTb0G2vR6PSoQ2uNVos69D9otTpiO2dgstrO6t5hwvx/JCwY2klx7kGyvlrKgU3rCPj9pA8YzBV330dG376I8gOQ0AfU0lFcYfcw5elvSDMEeOa6Lnhqq3BUVmKvqsDrcuH3evD7fHLt9eL3evG6nDhrquW+z4vP5cLtsLdYHn1kpBQSkVGUFxey/cUnGs5ptDpsKWmk9elPTGonYtM6EZPaGUtcPEJ1ZiuioijUVZRTkX+csrxjcp1/nPzs3QR8PgCEUBGdlEyULQZXXW1D499YoNQjhApDlIzQ8Xs8+LwezjR67OBHi4jt1Jm49Ezi07sQn55BXKcMtIaWnff2qkoKD+ZQeGAfhQf2U3L0MMGAHGsRYYkm6Pc3/O5nIia1E537DaRTv4Gk9e6LznjxolUCfh9uux1XXS3uujpc9lo8DgfRiUkkdul+moAOc+kiB/sFz5vlISwY2kDA7+Pg5g1kfbWUokMH0BqM9Js0hUFTpmFLTpWJvvgdbHkZ9BbIHIfSdTJP7Ymn2q2w8K4xdEo0d/j+wUAAV10trtqaUOPbeLumYTsqKZXeQ4YRk9qJmLROWOITzurBEUJgjo3DHBtHxqCTH3sKBgJUFRdSnnec8vzjlOcdw1FThTkunsQu3YiwRMvFbDm5jrZiMJmalEdRFAI+Hz6vRwoKjxufx9MgNLZv2kiMUU/Z8SMc2ryBPauX1xcMa1IK8Z0ziM/oQmxaZ2rLy6QgOJhDTWkJAGqtlsQu3RgybQbJ3XuR3L0nEWZL0/v7/QR83gbB7Pd5Cfh8eF1Oig4d4Pienexe9RU7vvwMlVpNYtcedO43gE79BpLUtcdpGls9fq8XR3Ul9spK7FWV2CsrcFRXkn/0KF8fPXDy87dKECWooKDItRIEBfw+L257nRQC9jpcdXX43K4W/yu1VktS1x6k9upDSq++JHfvic5g7PB/3xECfh8epxOf24XX5cLjcuJzufC65aIzGDFGWYgwmzGaLRijzGetDbaGoii46mqpLS3B43JijApp3WYzak37x+tcDHweN9XFRVQWnqCq6ARVhQVUFRVSWVTAhHl302fcaXOSnhPO66c9zzdDhw5Vtm077eufbaKtXzXa8eVnbPn0AxzVVViTkhl41TT6jJuMPqJRz7HqGDw3FLpOAlM85K6G2hMAVER0IWbAVOg6GTpdBtq2hal2hEv5y1NSeymj9OgRSo8doey4XNeWlTakj7BEk9KjN8k9epHcvRcJmV3OSQPg93opPLifvL07Ob5nJyWHc1GUIFqDkbTefYlJ64yzphpHSADYqypx2+tOy0et0YBKjUarQQiVNN0JObhLqJruqzUajCYzhqgojKYoDFFmDCZTo2NyrTdGUJ5/nIKcvRTkZFN69DCKEkSoVCRkdiW1V18pLHr0aeIjCvj9UhC73XjdLvweD163q2Hf53bLBr5hP3Qu1NDXp6utqkKFgs/lJOBveQR8swiBwRRFRJQUFPWNtjHKgs5oRGeMkGtDo+3QWm+MQKPT4aqrpaashNqyUmpK5bq2rITa8jJqykrwe5rXCnXGiEb3a3T/KDPHCgroN2CgvJfBiC4itA7dX61tefqWjhAMBqgrL2to/BuEQNEJ6srLmqQ1xcRiS0rBmpRCrzETSOnR64z5N9cuCCFa/bRnWDC0gqIoPDN7BrFp6Yy+dS7p/Qc1b4L5+B7Y9yn8IgvMyZTWuPjJM+8wLWIf8+JzUeVthIAXtBGQPkYKiR5TIPocDHQKBiFvI+xbwrGSGtLH3Qapw0AXefZ5nw+q8yAyDrRn7s225T9y2+2U5x/DZIvFEp9wQUbQuu128vft5vieXeTt2Ul1SRGR0daGYIPGwQcmq43I0LbBFMXatWvPq/D2upwUHsihYP8+CnL2Upx7QDbYQmCy2vB7vfjcrnY14mqNBq3BiNZgkA1kaFtrMFJVU0NaesZpjWfDOnRMqzfgc7tw1tbirK3GVVvToPnK/ZPar9tul5pTBzBEmjDHJWCOi8cSHy+3Y+PRGSNw22sbadmNtuu18dqaNv0uKrUancGIwRQl/+fQEtWwHdvw/zfWiDxOB5WFBVQVhhr/wgIqQwKg3jQLUmjZklOwJqdiTUrGlpyKNSkFa2LySRNq/Xw5baAjgiFsSmoFv9dDMBCgx6gxZAwc0nyikmzY/R6Mug/MySiKwu8/2cteXzKPzb8FVZwJvA44tl5qErmr4NBy+PK3kDIE+syE3tPbLyTKD8GuxbD7fajJA42Rzn4PvPUeqDSQNBA6j4LOl0OnEWD8Hoyd2L4Alt0PUUkw+WHoewO0wdfRGgaTidRefc9J8QD5wh1dCzvfhdShMOQOUDd9TQwmE92Gj6Lb8FGhS5TvzayzOmME6QOHkB56Xv1eL8W5BynI2Ut1aTFavQGdwYBWbwg19nq0BmOjY3KtMxobjremdZ0PLVVRlAYN5qRpyonH5cLncp487vFgjDI3EQBNNPkO3NfndrFm9WqGDByI1+3E63TJtUuWoV5j8rqcuOrqsFdWUJR7AHtlRZPGHQAhiIy2EmGJxlFVibOm+uQplYrohESsSSl07j8IW3IKtqRUrMkpRFiiW3+enJXwwXyY9Gf5jJ4HwoKhFTxOJ0DrDsev/w56M4y+H4APtxewen8pf5rWmy5xIdVdFwndr5ILQMVhyPkMsj+BFX+US8oQ6D0D+sxoWUg4K2HvR1IgnNgGQgWZE+QD0vNq1n+7ljGddXB8AxzfCJtfhI3PAgIS+oYExWWQOhzMyW3ucZw1wSB8/QisfwoyxoK7Bj7+MWx+Aa76pyxTR3FWwoEvwZIqhaC6g490wCf/j43PQvEeqd3tXgxb/wtT/w2Z41u89PsiFJpDo9OR2rsvqb3PofA8n3jqELVFaOO6ozUYiIy+cB0aIYTUckxRxKSmnfmCRtT7M6QpsQJ7RQV1lRXYKytw1lSRkNEFa1KK7P0npxCdkNgxM2dNASy8XpqvHWVnTN5RwoKhFbwuKRha7IXkfQcHvoCJf4QIG4XVLv62dB/DM2zc0drUFDFdpCAZfT9UHoF9S2SjtPJPcmksJEwJcHC51EoOLoegD+L7wJV/h343QVRiQ7YBTQR0Gw/dJssDPhcUbJNCIm8jZC2UDnIAjRFsGWDNCK3TT+5Hd2qIrGoLQbcff7kLXWrU6Sd9bvj0J5D9MQyZD1c/AUIt67P6r/DGFKkxTf6rvH9bUBQp/LYvkL9dIGRHjoiFXtfK363z6LYJCXct7FgghWjtCYjtAdc9B/1uhtyVsPwP8NZ06DlN/uZtLWNjKg7Dttdhz4cMFlEgbpadhMT+F044/38gGIR3ZslndepjMPyuC3v/8lz49F7SdL0gOLZd2qwQQgZZmC3Ep2een/KV7oe3rwdPHcz5BNIvPz/3ISwYWsXjdAAtaAyKAqv/BpHxMOInKIrCQx/sJKAoPHHjgLbPhmjLbF1IaCPB55ACYsQ9MGAWJPZrW95aI2SMkQvIXnHRLijMgsqjUHVU3vPw1+BvFPEi1LIHbsuUpq6Bs1ttZGu+PIpjSzEJvx6CNq7Rb+WogMW3Qf5m2fBf/suTDeHAW6H3dbDxf2HDM7LXP+IeGPMAGFuYTtheBrvegR1vQUWujAAbPFfmVVMA2Z9K09r2NyAiRjbmfWZA+tjTy19TAN+9JIWLp1b6fqY9DV2vONkg9LpW7m/6X1j3FDw/Akb9HEb/GvRnGOwX8EuT4dbX5O+r0kC3q1CKcuGbf8I3/4Co5JAmOQUyx7XJ73JJs+UVOL4e4nrBFw/IXvEVf4MLMRi07AAsuBZc1XQJbIW382DmKxCVcPZ5Vx2XHTiNvuN55G+Fd24CtQ7u+KLtbUAHCQuGVvA6ZWPZrMZweLV8iKc+DnoTG/78KD/75H2Kf/VHOsV00M7ZnJCoPAq9rpOmjI6aSepRa3GUpOHKMRIz+0eI+tlVg0Gwl8h7Vh09KTRKsmHpL6R5ZcIfpBZzSi8q6PHjzCoDBerWFmC7MTTlR8VhWHQj1JyAG9+AvtefXh5dJIx/UDbuX/9dComsRTD+9zD0jpNlO/K1FAb7v5AaU6fLpADpPR10od86ZYjc9zqlH2ffEml227EAjDboNU2ej4iR2sHej6Rw7zMDLvs5pAxu/jfTGmDsAzDwNlj1V1j3pCzjFX+VWsWpvcq6YlnW7W9KDSQqWf52g+dCVCJZa9YwfmhvOLQSDn4Jez6QgkxjlMKh+xQpLMzJHfuP/79SngurHoZuV8Ksd2H5/0iBXHUMrn/15P98PijJhgXXSQF0z7fsX72Qnof/Cy9dDjNfksEiHaE8F1b8AQ5+Jd/tq/4l/9v2aomHVsL7c2XncM4nHdNa20lYMLRCvSnpNI0hGJSNRHQnGDIf+/oNeHJy2XXdzYxatopqm4romdPP7ua2TJRRv0LxBFAZz83f5D5QSdVHByEIrr3lRAyMlydUKjAnyaWxeqoosif/9SPw4R2Q+DRM+osMyw093M6dZSjeALrOZpxZpZgnd0ZTmwXv3irzmLdUOr9bw5wEM56HEXdL082Xv+XA+k857OtLr21/IMG+VzbuI+6RDWxcj5bz0kVITaT3ddKUlrtaRozt/Vg22CC1sOF3w4h7wdq5bT+eORmufxmG/Qi+fBA+uUdqA1MelULl2Hq5v38ZBP3QZaI0h3SfcrpAN8XDoNly8XvktQeXS0Fx8CuZJn0M3Pi6TPt9xe9B7XecfT7BACz5KWh0cO2z8ve6+jHZmH71ELx5Ddy6+Nz03k+laBe8NQM0BvmsxnalOOkKek6aI5/5t2+AUb+AiX+S5WsL7hpY+xh897LUEi7/Fez/HN69RWqgU/4Fsd3altfu96UpNr433P7RBXsewoKhFepNSfqIU0I/930Kxbth5sv4KqopePBBsiZMwa5xsap/KlO/ceA58i5xv7oFVQe+ARz0BnBuL6Fu/QmCtV5i5vbG0O3snHC+YgcV7+xHmxBJ0BvAvrHwpGBoCSGg59Wyl7PnQ2n+WHSDdPJO+gt0GoFjSzHaxAhss3pQ/Pg27J+sIbpgjjRFzf5A+lPaStIAmLcUb/Yyln20njrFyCtMYnzf2xl13XzUunaaWrRGqSn0miZ9HYdXyx593+s7HqWVNhx+vFo6plc9DK9NBEsnGRlmiJbCZuidba+3Ri8FbddJMPVRKNsvG5F1T8LrV8keojW9Y2U91ygKlB+UprHDX8Ox9VwWFNB3+dmZNjY9D/nfSdONOenk8ZH3ys7XRz+C1ybD7Pch/sxx+23mxHZYOFMGj8z7TAqieuJ7wl1fy47Kxmel8L7x9dZ768GA7Hx8/XdwVkjBP/HPUqBN+IM0la19FF4YKZ+TcQ+CoZWBr5tegOW/l52EWe+0nvYcE55dtRUaNIbGpqSAT/7xcb1Qes2k8IEHOB6fjF3jR63z4dH6+TL6GBXlMRT+8UtcOeW0daxIwO6lZuVxiv+9heolh1FHaFHbDJQv2Ic7t6rD9QjUeSl/IxuhVxMzvw+my5Lx5tXhLTh9EFazqNQw4Bb4+TbpPK7IhdevxPvaz/GdsBM5PAlNtJ6I5FIcB1QEEsbAj1e1TyjUIwSbKy3UKUb698ykR+++rN5bwusL3qas7CyiMLQG6HmN7PGfbeiuSiVNS/dtxzXyfgpM/WDGi/Cb/XDVPzpWb5CCOL6XNF3NXSIjrv57lTR1XCyclVLbWvIzeLoPPD9c9uIrj8DA2fg1BhklU3mkY/mXHZDvU49roP/Np5/vebW0qQc88rc4suasqtNA/hapKRiiYf7nTYVCPVojTHsKbl4IlYfhpTGyg9Qcx9bDy+Ng2a+kNnD3NzD9+ZNajkYn/VP3bYcBt0ph+NwQyHpbWiAaoyiy07H899LPNfvDCyoUICwYWqUhXLXx1AI7F8mHZNKfKX/pZRxbt5LVvzfWYCR74gv4Kn45LoOfL/TfUe2so2JBDmUv78KTV9vifXxlTqo+OUTRv7dStzoPXWczcff2J+6nA4i7qx/aWAMVC/bhzq1uMY+WCHoDlC/IJuj0ETuvDxqLnsihCQidCvvGwvZlptHJSJFfZMGkv+DIi0PgISLvEVjyM6JK/4iCHnvqoxDRscnn7HY769evp2fPntgSO3HTTTdx4403UllZyUsvvcTGjRsJtjC9+YVG0Zn4oDST14t6Utfl2nPmPC4vL+fbo24OTnwdu2KAN6ZC3uZzknebOLEDVj8Cr0yAxzKlSSVnqfTjXPsf+OVu2cBd8wS7+/9Vms4WzpTaWHsI+OGTe6Wv6dpnWra9Jw+SHQ1zsjTtZL19dvU7vlGWNzJWCp0zmRN7Xwf3roeE3lJ7WfIzORTxoEIAACAASURBVDYJpA/kvTnS3OWulv60O76UZW4OUzxM/1+pjVjTZV7/nSyjB0H+Jp/9HNY/LcfQ3LTgvM6W0BJhU1IreFxONHr9yflwfC5Y8yikDsdRYaH8xZfYOL4XbgHpgUSm9prBHt+LrGAFV5RdwfK4XCZt30BMYBplL9Rh6BOD5ap0tPFSA/Ecq6Hu2xO4cypALYgcnIBpTEqTyB61SUfsj/tR9uoeKhZkEzOvD4aubfsIuBJUqHrvAL4TdmLm9EaXIiNpVAYNEYMTcGwrxnJ1BmpTOydf00USHPYLnCu+w5hUgOrwp+Bzoh3/W4xFcdi/KyVqQnqHfCNr167F5/MxefJk9u7dixCCvn370rlzZ5YtW8aKFSvIyclhxowZxMTEtDv/c8nu3bs5ckT2lHft2sXo0aPPSb7Lly/n0KFDob2ZmFVOkt94geT++0jpP46kpCQizmIgV6tseVVGBAm1HDw1/iHoMkk2dM0EPzgj02SPdsG1stGe/3nLUWWnsvE/ULijbb6U6E7wo+Xw/jzZmFYelWHi7XXkHv0W3rkFzCnSp9DYdHWm+8//Atb8S5r58rdIR/mWV6VGPeEPcpBrWzsHKYPhzuWw531Y+Rd4bZLUJNy1cOBzGPs7mPA/Fy2cOSwYWsHrdKBv7Hje8irUFeIb/zgF9/2O0ngDB1IzSPIa2e1P4MpYC3O6PcbftH9jZfZKJpdNZvXwZMZ9/m9iMiYitBMo2VdBxMB4/BUuvHl1qCI0RE1Iw3RZMuqo5htotUlH3F2NhMP8Phi6nPnlq/nqGK7sCizTMjH2btqImi5LwrG5CMfWYswT2j81h3NXGYovSOTMqWAdL6OYOo0kqtCOa0859k2FmCe2L9/y8nK2bdvG0KFDiY2NbXIuKiqKWbNmsXv3br788ktefPFFJk+ezPDhw1Gd5ejpjuBwOFi+fDmpqakIIcjKyuLyyy8/68Fu1dXVHDp0iMsuu4yePXty4sQJCvOOUngI9u/Kg10LAbBarSQnJ5OSksLAgQPPjaBY/7Q0YXSfCjNfbLvJLXUIzFoEi26Cd2fB7R+fOYqoJBu++ZeMdOt7Q9vuY7BIv9Xnv4Z1T8je+oT/gejObYvYy10tw6etGdKn0F5HrloDk/4kB2l+fLeMmup/ixzF35EoMpVKhp/3vEYKm03PS1P11MdlIMZFJCwYWsHjcqGrdzy7a2D9UygZE8l/5j08ddW8fHsy3V1RDAik8wf8/NgWgUal4a+j/opZZ+bTrE+ZVDqJtddOYcKKFZiOrcF25z9w7i5DbdETfV0XIoYmoGrDx9ebCIc3zywc7FuKsH9bQOTIJEyXn/7QahMi0XeNxrG5iKixaQh12xs0RVFwfFeENjESXVoUCHODLVWXbMLQw4p9wwlMo1PaVLd6Vq1ahVarZdy4cc2eF0IwYMAAMjIyWLp0KV999RU5OTlMnz4dm+3Cfjdh5cqVuN1urr32WgoLC1myZAl5eXl07tzGKKcWyMrKAmDEiBFER0fL/EaNAve1uBbNoSj/MIXd53NCnUhBQQHZ2dlkZ2czb948dB2ddltRZOTZuieh740yRLMdAxwB6DIBbnhNTtXwwXwpKFrKI+CTJiSDBa55sn33UWtl5JI1Qw6Q3PshqLTSRxDbDWK6htbd5LrepHlwBbx3O8R2h7mfSjNSR8kcBz/dBPZS6aQ+W/RRUrgMnidHM6cNP/s8z5Kwj6EVpMYQUg03PgeuKgoLuuPZuo3/XqViqHkqJmHEGplGiVBItcpekhCC3wz9DfNGzuPr+K+p8TlYM2UKTmsk5c/ci3mch8QHhmIaldyuhrNeOKitBirezMZzpHmfg/tQFdWf5mLoYSX62i4t9mJNlyURqPHi2lfR7PmW8BXY8RU6iByR2GzeURPSCDr8OLa03eZ8/Phx9u/fz+jRozGd4UtxZrOZ2267jenTp1NcXMyLL77IBx98wJo1a8jOzqa0tBR/e2f6bAdHjx5l586djBo1ioSEBPr06YNOp2PHjh1nlW8gEGDHjh107dqV6OhThL7BjHHue2T2HMDog49wS9wh7v/Vr7jllls4ceIEn3zyScd8L8GgdCave1I2TNe/0n6hUE+fGdJZe2i5NPe0VJ51T8qovmuf6VgDLQSM+TX8ZKN08F72MykEyg/KXveSn8HrV8JjGfBoBvz3SqkpxPeSmsLZCIV6ImznRig0xpbxvRAKENYYWsXjckqNwV4Km16gzDCOmgWfsa6finE3/5XdX+zmMl939to0JKuM6DQn5awQgrv634VZZ+b5b59nXMk4vh47lit27uTEL+8j5aknMU+d2u4yndQcdlP+Rjaxd/RBn3myEfGVOKh4OwdtfAS2W3u2qgkYesWgjtbL0NV+bX9ZHFuKEVoVEYOaV8X16RZ0GRbs3xZgGpl0ciBdCyiKwooVK4iKimLkyJFtKoMQgkGDBpGZmcmqVasaes/1qFQqbDYbcXFxDUtsbCyxsbFotR2fitvn87F06VKsVmuDZqPT6ejbty979uxh6tSpGFr5iFBrHDp0iLq6Oq6++urmE2gN0hm57Ffw7ePgKKfXNU9y1VVXsXz5clavXs0VV1zR9hsGA/DZL2Dn23KQ35V/P3ub9tA7Zajm13+Xgwmv+mfTPAt3yrL3u1lG3JwNCX3k0piAH6qPy0kmKw6F1rnQY6qc6qSt/o8fOGHB0ApepxNTtA3WPUmlw8exFUeosQl6/uNJ8r4rI0JroIcnmcX4SLM173S6pectmHQmHl/9OGOKx7Bi0ECuBIr//g8ix4xB3YHvKKujdMTd1Z+yV+qFQ1/0mRbUHmRYqk5FzPw+qAwn/1673c7hw4fJzc3F5/MxdepULBYLpsuSqPnyGN4iB7qkM0/VHXT7ce4qxTggrkn+p2KekEb563tx7CjBNLx1B192djYnTpxg+vTp7TaHWCwWbrhB2qi9Xi8VFRWUlZU1LKWlpezfv78hZDgyMpI5c+aQmJjYWrYtsm7dOiorK5kzZ04TATN48GB27NjB3r17GTq0YzNebt++HZPJRPfu3VtOpNbIBi4iRk4l4qpi5IwXqaysZMOGDdhsNoYMOX0m4K3FW9lesp17+t8jtTy/Fz6+S47JGfeQdDKfK0fnmAdkmOvmF2Q5xz4gj/s98OlP5ZxWUx89N/c6FbVGhgvHdAGmnJ97/AAIC4ZW8Lic6DRBqra+zsYdiaS6/Rif/jPpkf345vCrjND1JDLDxt6yUib0iGsxn2syryFKF8XDXz3MqKJRLO/Xlx5V1RQ+9xyWKVNAgN1np9JdSaWnkgp3BRXuCsrcZQRUAab2msp1fa/D0ChsTR2lI+7ukHB4cy8xt/cmaYeKoNNH3D39waTh6NGjDcKguFiadSIiIvD7/bz66qvceuutJA5NpGZlHo5NheiuP/NoTOfOUhRvENOI1ht7fbdotKkm6tYWEDkksUXNxe/3s3r1auLj4xkwYMAZ798aOp2OpKQkkpKals3v91NRUUFpaSkrV65kwYIFzJ0797R0Z6K0tJT169fTv39/unRpOlYhJSWF+Ph4srKyOiQYqquryc3NZcyYMajP9FUzIeSUHJGxsOKPiMPfMKXPTKpSu7Ns2TKio6OblC+/Lp9ffv1L6nx1dI3uyuTky2V0z6HlUksYdV+7ywvg9rsp95U3X74r/xHSHB6RZpehd8rBXaXZcOt7HQ5nDnNhCAuGVvA6HShlu1lUGMOkY37qfjOXy8fcyrvvvotBb6BHTQLq8TGUfZZPJ1vrURhjU8fy2LTH+J8v/odhJ4axfdhQ8HhgyZJm0+vRk4r8bOi+g/vIXpKNLlJHSlwKNpsNq9WK1WrFcm0sgc8KKXt9Dx7honSkjm/XLePo0aN4vV5UKhVpaWlMnDiRrl27kpiYSHl5Oe+88w5vvPEGM2fOJGlgHM6sUixT0lFFtGxmkU7nYrRJkWhTpabj8XhYvXo1eXl5TJ8+vaGxFUJgHp9Gxds5uPaUtTjKeuvWrVRVVXH77beft+gijUZDQkICCQkJpKSksGDBggbhkJzctmiSYDDI0qVL0ev1XHXVVaedrzdtLV++nJKSEhIS2jd9Q1ZWFoqiMGhQC/HvzTHqPjm2YPsC1Hve5yafj9fVc3j/nYXceetMEroOwBvw8sDaB0BAujmdJ7Y+zhj70+iPbYBpz5yck6qdKIrC/WvuZ3PhZnqW96Rv7CnTeqtU0v7vqkZZ9muOHD9B8p7nMQ6cLT9SFeZ7TVgwtIASDOJ1udhWUcH1mwSeySMZ9uOHKCkp4cCBA4xMGYCuTktZkhQInWLObIYZmjiUZ6Y/wy9X/hJduYM/LPRQ3DWGQ3dPIikiicSIRBKMCcQaY1GhQlEUPB4Pm49sZkPuBpy1TipKKrAWWQl4Ak3y1hjV+JUAZEF0dHRDrzYjI+M0m3d8fDx33XUXixcv5oMPPmDs0Mvp5tPj2FZC1NjUFsvvK7DjK3IQPaMrQgiOHDnCZ599RnV1NUajkddee41p06Y1NG6G3jFo4iOo/SYfY/84xCkzzrpcLr799lsyMzPp2rVrm/6Xs8VmszF//vwG4TBnzhxSU1uucz07duwgPz+f6dOnExnZ/H/dv39/Vq5cyY4dO5jaDv9RY6ez1drOUdmdR8nF8wT6fZ9x2/YPebWgC++8vYAfpx7h2UQL+yr28eyEZzEE/dy99te8XVXDj65/Ffrf1L57NWLF8RWsP7EeDRp+s+Y3vDftPaINp9jv1Vpc015iyUsPs39PgATVLOaOfYjv6bcFwzQiLBhawBv68Hr3XAVXrJ7Bj/4vQgjWrVuHTqejR3kc+q7R5Li8AGfUGOrpHdObr27+CpVQUaF5Gesz/+Eq/Xgih7U80VxGRgazJs5iQ+EGXtr1EivLVpKoT2RWp1kMswzDUeugurqaiooKpkyZQkxMTJNooRpPDfsr97O/cj/7KvZR461hSPwQhl4zFMsGC99u20BRdBpjN+kwjU45rQGvx/5dEUKnQt3LzNKlS9m+fTs2m40777yTmJgYPvzwQ5YsWUJ+fj5Tp05Fq9USNSGNqvcO4N5fedpYivXr1+Nyubjyyivb9NudK6xWK/Pnz+fNN99k4cKF3H777aSltfxhlrq6OlauXEl6ejoDBw5sMV1kZCQ9e/Zk9+7dXHHFFWg0bXu9cnNzW3c6twV9FAyajWXQbG47sJ033lvKS8Wd+ED9LfMcTiZsWwwlexmPm1di45jebQIdjc2xe+08uuVRetl6MVU3lWdLn+X363/P85OeRyVOan35+fl8+OGH1HliGR5jZ0d1DAsWf8LcuXPPGHkW5uISDldtgfrpMKyOINXDUlBFRlJRUUF2djaDevRHW6MQMSCOvEqZrq2CAUCtUiOEwDZ/PtrkZEr+/W+UQKDVa4QQjE4ZzcKpC3n1yldJiU7hmUPPcN/e+zgQdYBxk8fJnm8krDuxjld2v8L939zPlI+mMHrxaH684sc8se0JdpTuoMRRwrNZzzJ3+VyedD+JM93JIXc+Sx2bKN+Z3+z9g24/rl1llGUGeOn1V9ixYwejRo3iJz/5CZ06dWpw6o4ePZodO3bw+uuvU1VVRUT/ONQ2A7Xf5DeZM6q6uprNmzczYMCADjuCz4bo6GjuuOMOIiIiWLhwIXl5eS2m/eqrr/D7/UybNu2MA9gGDx6My+Vi//79bS7Ltm3bzux0bgfJPYYwdtok7H4rk6vH84u0q+UsuZVHeGDMI3gJ8uyOZzuc/3NZz1HuKudPI/9Ehj6DB4c9yPoT63l196uANLtt2LCBN954AyEEd955J1ff9xi3zb6dyspKFixYQF1dG+fpCnNRCGsMLVA/gZ4mEEQVJb9Mtn79etRqNf1FOoq6GmOfGPJXlGPSa7C2YptvCZXBQPxvH+DE/b+m+qOPsN7czCRipyCEYGTSSEYmjWRr8VZe3v0yT25/ktf2vobiV6g9fnJOpk5Rnegb25ebut9EL1svesb0xGaQTr9KdyVbirewuXAz3xV9h4iDy0pH8tpnC6grcTGi2whGJI3ArDPj8ruoWZ/Pd0o2B44VEhkdyeBrBxO0BVl2bBnugJsITQQTO01k8uTJpKam8sknn/DKK69w/fXXkzQulepPcvEcrsbQVZpKvv76a4QQTJw48bQ6FtQV8P6B99lYspHvtnxH75je9LL1IsOSgfocfrTFYrFwxx138Oabb/L2228ze/bs0waoHTx4kOzsbCZMmHDaaOzmyMzMxGKxkJWVRd++Z/6cZr3TefTo0Wd2OrcRt9/N0wVPY4g30L20O2uMo7jygcfBa6dzZCyzXQW8te8tZvWcRe+Y3u3KO7s8m3f3v8stPW6hX1w/1rCGW3rcQlZpFs/vfJ6epp7kb8onNzeXXr16cd1112EMjQXKzMzk9ttvZ9GiRbz55pvMmzcPs/nCTg73fSeoBJtoXReLiyIYhBD3Az8GFGAPcAeQBCwGbMAOYI6iKN6LUT44qTFogkE0FivV1dXs2rWLIUOGIHY60PewoTJoOF7hoJMtosNTIURNmYLx7UWUPfMfzFOnoo5q5vOYLTAscRjDEoexs3Qni3IWUVFWwYTeE+hl60UPWw+idC3nZTPYmJI+hSnp0hFYUFfA3o83sevIIdRb1Dx37Dn+GPFHABIcCUwqGY9H4+eA5QD7LPsI7jl98JJhs4Er06/khm43cPfdd/P++++zaNEixo8dRzeTkbpv8jF0tVJYWMju3bsZPXo0FosFkM7MTUWbeDfnXdYWrEUlVCRpkvjw4Ie4A26Zv9pAD1sPetl6SWER04su0V3Qqjo+LsFsNjf4HOqFQ3p6OiDDXz///HPi4uK4/PK2fUZRpVIxcOBA1q5dS3V19ekD1U6h3uk8eHALHwrqAP/a8i8OVR3iheteoG53HRs3bsRmszVES90z4B6WHlnKo1se5c0pb7b52Q0EA/x101+JMcbwi8G/aDguhOAvl/2FE8dP8NW7XxGhRHD11VczbNiw0/JOT08/TTjUPwM/ZA5XH+Zvm/5GmauMRVcvwmq4cN+6bo4LLhiEECnAL4DeiqK4hBDvA7OAq4GnFUVZLIR4CfgR8OKFLl89jTUGgzWOjRs3AjA0rR++dceJGCDDU/MqnXSLb3tjfipCCBJ+/3uO3XQT5S+9RMJvf9vuPAbGD2Rg/EDWrFnD+N7jO1SO1KhUkm6YTvq/vmWVOZsxpWOI6R+Dq8aFo9SBUdEzuE8fJo6aiEFtwKgxYtQYMWjkdqG9kI9zP+bLo1/y2eHPSDenM/OymfQ41IM1367leEwqlx/OJOp4DSvXrCQiIoLRo0dj99pZcngJi/cv5ljtMWwGGz/rcS/XmqaQvz+PwTMv53jtcXIqc9hXsY99Ffv47PBnLD6wGACtSks3azfiI+IxaU1y0ZmabEfpoojURmLSmrDoLcQZ45poHo2Fw6JFi7jtttvIyMjgm2++oaamhjvuuKPN/gKAQYMGsXbtWrKyspgwYUKL6c7K6dwCS3KX8PGhj7mr312MSR1DIClAVVUVn3/+OXq9HqvVitfrZW7cXD7M+ZC3V71Nd3N3fD4fXq8Xn8+H3+8nOjqaxMREEhMTG5ztiw8sJqcyh8fHPt6k0xEMBtmyYQvdjnSjTlPH0R5HGTR0UIsCp3PnzsyZM4e33367QTicSYBeqngDXl7b8xqv7nmVSG0kTp+T36/7PS9MfuGiag4Xy5SkAYxCCB8QARQBE4HbQucXAA9zEQVD/Ud6NIEgKnM8O3bsYMCAAegOe/BrVRh62QgGFfKrXEzqdXZfljL27YNl5kwq31qI9eab0Z3lfDsdRW3SEd8/jWnZOjb1KODAroMIIRga24f+pUmkTh+JSt/8IxNjjKFfXD9+O/S3rDi+go8PfczTu55Gg4Yru13JscMnKDNU0P/TKo5WHWX4+OE8mfUkm/avI8Ueyw3qiQxjANbCSIJZXoKcIAU11VU5dJ7Rla5dunJtFzlSNqgEyavNI6cyh5yKHHIqcyiyF2H32eXitRNQWvbZaISGxMhEUkwpJJuSSTIlkWJKYdDVg9j2+TYWLVrEpEmT2Lx5M0OGDGn3/EfR0dFkZmayc+dOxo0b12IY7jlxOjfiUNUh/r757wxLHMZPB/4UALVazY033sjrr7/ORx991CT9CEZwuOwwhznccEyr1aJWq3G73Q3HzGYz1jgrq6tWMzF+IsMtw1EUBSEEHo+Ht956i2PHjtG/f3/0/fQ8tPEhntr2FA8Of7DFsqalpTUIhzfeeIP58+efM+H4/4Ws0iwe3vgwR2qOcE3mNfxu2O9YdXwVj2x+hFd2v8K9A+5t9jrFH6T89b2YxqZi7Hl+xoOItn5E5pzeVIhfAv8AXMAK4JfAZkVRuobOpwFfKopympFWCHE3cDdAQkLCkMWLF3eoDHa7vdXIiLJ9u8lbu4IJ+46xdd6tFNl9DB82nD6bTThjFEoGKlS5g9y/xsXc3jomduq4OQNAVVNDzJ//grdnT2p+0vwDcSbOVKe2oK+BtE1qSnsG2K8rxGKMot9WC3XJCmV92/esFPuK2WTfxBb7FrROLZOKJ6AoAq1Q058kunnSMAWl015BwRcJHrOCxwyeKIVglZfk4wZEEKoyFaoylTaFSyiKgk/x4Qq6cCku3EF3w2IP2qn0V1Lhr6AqUEWFv4LawEm/jC6gY2zRWCw+C36NH10fHd1N3UnQJLTLXFhaWsq+ffvo379/kwn+Gv9He/bsoa6ujpEjR571GA5P0MPjRY/jDDp5MOlBLJqm5hmfz0d1dTUqlQq1Wo1KpSLPl8fCqoVMip7EJOskVCpVQx19Ph92ux273U5dXR0FNQVoPVoE8rxarcZkMuFwOAgGg3Tv3r0hiODDyg9ZW7eWO2PvZFBk6+My6urq2LVrF2q1moEDBzb4Iy4m5+I9ag1X0MVnVZ+x3r4em9rGLTG30NsofT2KorCwYiHbHNv4afxP6Wk8fT6myGJI2qmmcEgAZ8vjahtorj4TJkzYrihKiyMxL4YpyQpMBzKAauADoLmg72ZbIUVRXgFeARg6dKgyfvz4DpVjzZo1tHbt1rpK8oCgWkO5W6Fv375M7DqS8nXZpF/Rh159YthytBLWbGLSyIGM696Gf+gMlBeXUPb003Q3GIhs45xBIB8m5+bN7MrJYdiMGWgSm5/crq2UFOwkudzPoF/fimNzEdXBw3SbOZg+Ke1/WWYxC1/Ax5qCNXyxaxkDt3Wnuz+ZKGsk0b2TMaXFoE2ORJsY2WRCQcfGjeSs/5SE+36H47saVLvLSagxYp3ZDX3mubVJewIeiuxFFDoKKbQXUlBRQPmOcvZH7OdA7QGohVhjLMMShjEsaRjDEobR2dy51d/Y7/dz9OhRAoFAw3Pm2FHCDncOY8aPp6amhrVr1zJ69OhmHfDtQVEUHlr3EGWBMl694lWGJ7V9IrZDXx9iVdEq7r/sfuIimn+Gvy34lhdXv8jP+/+cafHTKCoqori4uGE0/e23305c3MlrLw9czh3L72Bx1WJmjJ5BhqX1j9cPHTqUt956i3379jFv3rw2OfmbQ1EUgjU1+EpL8ZeW4S8txV9agr+0FKHTY7nuWgy9z+xsP1PbcDaszlvNE5ufoNxdzpzec/j5wJ8ToW0a0TjCN4LZX8zmnZp3eH/s+yRGNo3aK/vvHvwWF8NuGNZiaHljOlKfi2FKmgwcVRSlDEAI8TEwCogWQmgURfEDqUA7Py92bpE+BoUjXbvi8/sZM2YMzm/LEQY1hh5S5T1eIc1NndsRqtoatvnzqH7/fUr++S8yPvkY0YYoFdfu3ZT869+4srKwArn/eRYREYEuvTP6jEx0GRnoMzPQZWSgS09H1YYemWlUMlXvHcCTW439uyK0KaaGj/x0BK1ayxWdr+CKzldQM6maCF1kixPZBd1uSp96iqq3FhIJHFuzFtvts7HedAu1q4ooe2U3EUMTsEzNQB15dlpaPXq1nnRLOumW9JMHL5MNTUFdAVuKt7CleAtbi7fy5bEvAYg3xjcIiX5x/YgxxGDRW9Co5Cul0Wjo378/27Ztw+FwoPeqqXr/ILY0+SLv2LGjwens9rspdZZS7CimxFlCsaMYb9BLhjmDLtFdSLeko1frTyu3r6SU0qefY283FV9ovuDnA3/eLqEA8MDQB7huyXU8m/Usj1z+yGnnXX4X//zun2RaMrmz/51o1VpSUlIazq9Zs6aJUAD5fz8x7gluXnozv17za1413EXNU89inT0b29w5p90jMTGRSTdM4ov3v+Dpl59mfdJ6iKTBL9Sw1sl1hDaCKGEkc9luYgsdmGq8KOWV+EtLUTye0/JXWSwoTieVb76Jvncvoq+/Acu101A34/QOKkEcAQdHa45S6a6kyl3VsK7yVFHpktPWVLmrCCpB0qLS6GzuTCdzJzpHyXV8RPxp/oFSZyn/+u5frMpbRXdrd/4z8T8No8W9x49Tu2IFdStXIYQg7b+v8dT4p5i1bBYPrH2AN6a80RBg4a9048mtJmpipzYJhY5yMQRDHjBSCBGBNCVNArYB3wA3IiOT5gHNzxVxgfA4HQgUDnftSvfu3YmPiaNw72GMfWMbZgvNr3SiEpAcfW7UX5VeT/xvf/t/7L13fFxnlf//fu60O1Wj3otluduJYzuBBEicQgohhCRAspTly8Iuy7KQhVACC7sktFCWFFj4LSwllN1Qd1kIpJDgJE6cONWx3G1JlmXJqjOafqfc5/fHnRm1GWlmJNtJmPfr5ZdVZp77zEi65znnfM45HP+nf8L/y19RecP1eR+bGBxk5Bu3E/j97zHV1NBw6y3s9flZW+Eh3tuL1tNL9IUXCPzhD0a//TSWpiZsK1fi2noBrgsvwlI/t1WFY0MNk/f24P/tYZLjMbzXLl1VcoUzf5Ixtn8/gx//ONqhw1S+850c6lxG5/MvMP79H+D7+S+oes97az7ZFwAAIABJREFUsa+5kNCTw8T2jVNxZSeOs+oWPRwnH0IIWj2ttHpauW7ldUgpORo4ys4TO3nmxDM8Ofgk9/bcO+M5bqsbr81Lpa2SqmQV1alq7rj3DjbaujiTJswn4nz+8c8T3xEn4olw9f1X49PmzvMWCGTaaVaEQrOrmeUVy+n0drLcu5zl+4OYb/s+jrM/wfJf/g+fq6vm6uvePmedhWj1tPKuNe/iR3t+xA2rb2Bd9cxupf+x6z84HjrODy/7IZYi2nE3OBv4yqZ/YdenP8xo900oLhfDX/oSitOB9zrjvewe6+ah/od4qP8h+gJ9uGvdXDRyERcevxBRJ9DqNYL2IKFkiOHIMKHJEOFEmEgsyN//b4ymfZLBSjjoFmhVdsyrm/A0tVPbtpr2zo14Wzox19aiqCopv5/Je+/F/+tfM/yFLzDy1a8iL3gVQ1vXsm+ZmZ5ALz2TPfQH+onrcRiY+5rcFjeVaiX1eNjoc2LRUux1HuFxsZ24TGQfp5pUWtwthsFwt2G32PnJnp+gpTRu3HQjf732r9EP9zF6z78TfOABtIMHjeetXUv0wAEGb76Zjrvu4pbX3MLHH/k4tz97O584+xMAhJ8dBsC5ZXF5zYU45YZBSvmUEOJXGJLUJPA8RmjoXuAeIcQX0l/7/qne23TikSiKItBUlfb2dmIHfEgtlVUjgaFIaqyY2W57sbgvuxTHli2M3nknnivfMEe+mgqFGf/e95j40Y8AqP7A31P93vdhcjlJbNtG5SyXUY/FiB89SrynB623l3hPL9Fduwht2wafuwV1wwbcF12I66KLsa1cgRACYVZwntNA8OFjCJsJx5lFTroqEqnrTPzwR4zecQeKt4LW730P1+tey/5t22h++9upft/7GL3jDsbuugNT9U+o+n8fIqWtxPeLg0SeHcZ7zQosNQsbZz0WIzE4iB6NImMx9Fgs//9aHEtTI+rq1dhWrUKx2xFCZD2Lt616G1JKeid7OeA7gF/zG/9i/uzHI3IEu9WKZY/E7hdgb8KZUBl6to+6eCv6cp3Xt72eemc99Y56GpwN1DvqqXfWYxImjgaOcmTyCD3+HnomezjiP8ITA49x3bY4K3ZIfGtfjdPqxLduC2v/uJ2+a99C89e/hv2MM4p6///ujL/jt0d+y1d2foW7L787a2gP+w5z9567uXr51WxpKK4xYGj749R85oucPwK/eo1g9Ydv5JxvbmPws5/lf4ce4Kf1RxiODGMWZs5uOJt3rX0XF7ZeiClm4vHHH2fPnj3IIUmbs40NGzZwxuYzjD5cUjL0qU8xue//cH7kH3BctYW+tFpt38Q+jgW3Q3I7HITG442GrNm7Bq/NS//KQXr+oZ74Pj/rnxzmtY89RuODj2GqgMSWSqxb13Fp20WM+MfZsuFsqjQL3hMhHAMTWI6eINnbh3bkCMkTPdnXeTWguN2IZcuIttYwVm/nWLVkvz3CPn8Pjw48SkJPcHb9Fj7j/StcD+zm2MfeRPzoURAC++ZN1H/qZtyvfz2WpiYmfvxjhr/0Zca+8x0u/+AHeWHkBX6y9yecVXcWl7ReQuSZE9hWVGKuPLlzoE+LKklK+a/Av876cg/w0phSQVqVlA7luFwuIi+OojjN2JZPuZ/9E5GiKp4LQQhB/ac/Re91b2Hs29+h/pPGSUEmk/h//RtG77qL1Pg4njddRd1HPoJlgQ6hiqqirlqFumpV9mtSSuKHDxN86GGCDz/M6J13MXrnXVhaWnBddCHuiy7CuXkDwUcGcJxVh2JbuqKy2SSGhhi8+VNEnnoK1yUX0/j5z2OepU5RV62k9TvfJvLc84zefjuj//Y5LM3NVLz1JuLHTQzf8SzVb18zo+WGHg4T27+f2J69xPbuJbZnD1pPDyxQYZ7FZJp6rKJg7ehAXbMGdc1qbGvWoK5di7mykk5vJ53eTgBSoRCx7m6i+3cT2/0i0ReH2e8K8+zZW6gQLaSCR1GcLWwaaMdXYeIz131tXhnsisoVrKic6nibGBpi4KabiD33POErzsPacS0MQYN9NVU/+hGDN3+Svre/g9oPfYjq9723oFAkgMvq4kNnfYhbdtzC/Ufv5yLza1BqVT7/5OdxWV3ctOWmwt4zjPd9+Gtfw3/Pz7EuX077Pf/N8Invsvm3cf5tU5IL+ySbv/0oYx/czKrLb+T8lvOpsE0L6Tjgqquu4oorruDQoUPs2rWLnTt38uSTT1JTU0PnyAh1D/6Jjhs/TM37P0AbcG7Tuca1dZ1jI8d4oecFegZ6GB8eJ3EowaA2yGHzYba1b6PD28GyM7egnr+MCXsrnudP0H7fduoeegrx+G6cl72DyIltiK9+mdS4McAqAgi7HVtnJ85XnYN1eRe25Z0oDgdaTw/xI0fQDh2GHd00TUzQBLwKUJxOrMtXIBtrSb24B23oRjSzGec551D1nvfgvvgizLPCcJXvehexPXsZ++a3UNes4aYLbmL36G4++/hnWbm6FdNknIo3zuzsezIoVz7nIR6NINOus1N1Ets7jGNTHcI05R30T0S4ePXSu3Tq2rVUXHctEz/9KZXXv434wHFGvvIVtEOHsG/eTP3/9x3sGzaUvL4QAtuKFdhWrKDm799PYmSE0J+3EXr4Yfz3/Bzfj3+C4vHgPP8NJI7VMv6j7ShOJyanE+FwYHI6UWb9E6padEhn8t57OXHLrchkksYvfoGKa6+ddw3HprNo+/HdhLc/zujttzN2x0exrj4D++Z/wPervYSbD6PtM4xAvK8vG0Iz1dSgrluL65KLsXUaf9BCVVFUNfv/9I+FqoKikDg+iLZ/H7G9+4jt30/kuecI3DsVOjLX16OuXo3JW0G0ew/xnp7sNS3tbTjOOYct69ayq/8Yh1wxVl76Bnoeeobj6Kx+oZuBv3439Z/8BPYC2o0H//xnhm7+FDKRoOlrX8N96eUMfv5JzDUqybEo5pqVdP7v/zL0r//K6O23E96+naavfmXBg0OGa7qu4Z799/DDJ77H+t1Ojm+M8FzsOW4979aCi60iTz/N4Kf/mcTAAFXveQ+1N34YRVX5nOlTxCK9uGMeEndeh/3T/8kb/3Mvbee24FieW0hgNptZs2YNa9asIRKJsGfPHp699w/sVBR401W0qyrrn36aVCrF8PAwIyMjjIyMkEhMhXRqK2up66gjKZMcOXiE3136OxrqZ7VfWQlc/z7iA8eZ+NmfSfpMWFzLULdegG15F7au5diWL8fc2IjIoRxznnvujM+TExNohw8bxuLwEePj3ftRV6/B/eEbcV+4FdM8NRtCCBpu+Rza4cMMfvwTdPzyF0a+5vdvo/tPO9joXI19zclvWV42DHnQIhFEOpFoHUkhE/qMMFJYSzIWitNWvbQeQ4a6G28k+Mf76Lvhr0j5/VhaW2m+807cl75+yWPqlro6Kq9/G5XXvw09HCb0+OOEHv4zoUcfIPj7iYLWEKqKtXMZtq4ubF0rjP9XdGFpbp7zB5UKBjlx6+cJ/O532M88k6avfRVrW1th1xEC1+tei/O1ryF4/wOM3nknoQfvwnHeP+H/1dPI2H7UtWvxvPFK1LVrUdeuy5lHmQ+pSwL392E/oxb3JZfgvuSS7PeSPh/a/v3E9u0ntm9f2nDsRV23Ds+Vb8C+4QzsG9bP+ONf/YN7OHD0EKLFwd5KP9IHZ19+DfEffpu+62/A84YrqP3oR7Hm6PIq43FGbr+DiR/+ENuaNTR/49+wLVtGZNcoJCUVb1jG+E/2Ejvip6KzneZvfIPJ153PiS98gZ43X0PjrbfiuWz+JoVSSpK9fXxmYBOjO3qhGaofG+Wzk14uMIWJRnZhW70axTY3AQ5GiG70jjuZuPtuLC0ttP/kxzimzaQw9xkNDJaNN9DU+Wr075/L0Xe8k2N///e0/+THM7zZXNjtdtq2bcN1zz2Y//pdHD/vPHbv3s29aSNtt9upr69n06ZN1NXVUV9fT21tLbb0fn0+H3cevJP+o/1zDUMaa0sz1uXnkHxmGHPFMho/9y6EpfgQsbmqCvM55+A8xwh+pMIJTnz1aSresGzBGSYZFFWl5VvfpPe6tzDwwX+k4xc/56ubvkzjC0me7zxEk6lwxWKplA1DHuLRCDKtBDAdjiI8VqwdU6ebY77im+cVg7m2ltqPfISxb32Luk98gsp3vgOl1GHvRaA4nXguvRRPuuOpTCTQIxH0cHjq/3CYVPr/zNdSY2Noh48QeWongf/7XXa9jAueMRSm6hpGv3kXyeERaj70j9S8//2IIqqKs+sKgefyy3BfcjHBP28j/Dw4zn0nDZ981aJDX+FnThDcNkAqEKfqbTNvWubKSsznnjvnpDgfq61tdIv9HJjopS8yRIteRW3X63Dc9yYmfvB9xn/wQ4IP/onKv34XNe9/P6Z0/6D4wHGO3/RRYrtepPLtf0XdJz+ZvTlHu8dQXBbU1VVYml1oh/3wekNC6732GhybzuL4xz/B8RtvJPSW62j49KdRHFO/q4nhYcI7dhDZsYPwjidJjoxgAzpe8wEAVFc7Z7yoMvyFL6ZfuBnbihXY169HXb8e+4b12FaswNzXR+9Xv0a8pwfvX91A/cc+hjKrLXnsoA/FY0UPGPPFnZvrafvB9+l7xzvpf+/76PjpT7Cm25DkYuyb32Li+z/A+1c30PCpT7FCCC644AJGBk5g9zhxe9zzHpa8Xi8VFRX09fVxzjn5o9XaET+KwwyRJFp/AHX54quxtYNGbjJwfx+OBaYeTsfS2EjLnXdw9D1/w+DHP8G66z9FgKP8Oz8mftjFtSuuXfTe5qNsGPIQj0bAbEXRU+iHg7hf3TRDHtY/fnINA0DVO99B1TvfcdLWLwRhsWCqqMgp7ctHKhBIu9GHDFf68GHCTzzBZHookaW9jY7/+llBIZQF92c243n9JdhWBhj9zi5Cjx/Hc1Fh3kcu9EiCwH19gHFDk7pctCywesSK1+ziwT89iBbXWFdxBtG947gvaKH2wx/G+7a3GSfuH/yQyV//hpoPfhBzbS1D//IvoOs033E7nsunhtvIRIrYgQlDkaUI1C4vwUePo2uprFG0dnTQ8V8/Y/Sb32L8e98j+syzVP/d3xHr7ib85JNG2AswVVbiPPfVOF79ahyvejUjP+inRzlGZ7SF1tt/grVJEt29m1j3HmLd3QQeeAD/L38JgLBaqUom0evqaP3+f+LK0U8q6ddIDkeoeMMyQk8MEt09hnNzPZbmZtp+8H2OvuOd9P/Ne2n/r59hydFld+w/vsvYt79NxXXX0vDZz2YNgB6Mk/xuD8obOxGvmr8RnxCCjo4ODh06lK3YnrPPiRgpn4bnsg4mH+hFO+RfEsMQOzCBsJrQI0mC2waouLyj4Oc6zj6b+k/dzPDnv4BSfR3WjlpaOzr54pNfZG31WlZXzS1+WyrKhiEPWiQM7lpsUiBSYD9zZpKolHbbfymYPB4cm87CsWlm1WtqcpJ4fz+2rq6C6imKwdbuQV1TRfDRAVyvbpx3Et18TD5wFD2axPW6ZkKPHScxFF5UDUcqnCA1EmX9mtVs730Gq9XK6jPWEv7zAKlgHJPbiqWhgabbvkzVX7+L4a9+jeEvGqd0df16mm//BtZZsyJiB33IuI59vVEIZlvuJbhtAK13ckaLBGGxUPfRj+B8zWsY/MQnGPr0pxEOB44tm/G+5S04zzsX28qV2VCf1jeJ0CRnXH8+kXuPETvox7l5NZbGxikPUkoSx45ljcWx48c56wufz3o5s9EOGlJcdVUlqWCc0BOD6NEkit2MrbOT1u99j/53v5v+976P9p/+ZIbwYOLuuxm9/XY8b3wjjbfeOiMkGX5uBJnQiXaPFRSiaW9vZ9euXYyOjlJXNze0qB3xA2BfW8Xwzl6sh31U0LHguvMhdUnskA/7OkMUEdx+HOerGzF7c4fkclH59rcT7R5CpmwojjFuO/823vq7t/LRbR/lnjfeg8d6crrTnv7+ri9BUskkyXiclMWGEzumShvW1pmy0f6JCG6bGW+JN6C/REwVFdg3bFhyo5Ch4rIOw21/JIcIvQDigyHCTw3hOrcpO8kudnBujUFRa/YZ7TbOOnsTZrOZxsZGnBvqQEJs38z8jbp2LW0//AEt/993qPvYTbT/18/mGAWAaPc4wm7OVoDbOjxgFkY4KQfOV51D5+9/R8cvf8mqJ3fQ9t3vUv0370FdvXrGzTZ20AcKeFbXo66sRDtkeEzTEUJgbWuj4sorqf/kJwhde01eo2CsOYGpwoq5zoF9Qw2kJNG949nv29evo+U73yYxMMCx9/0tqVAIAN9//zfDX74N96WX0nTbl2corKSURJ4x9PxazyS6trDSLNMxt6+vL/c+j/hRXBbMdQ4i1ZLE8RCpcCLnYwslcTyEHk6irqrEc2k7SEngwaNFrSGEQN3wBmRKY/yuf8Y5MMG/XfBvDIWG+PXBXy+8QImUDUMOMp1Vk1YrLtzY11TPcT/7JyK0VZfebrvM0mNpcOLYWEfo8UFSk3MrYOdDSon/t0dQHGY8l7QZJ/kmJ7GDhSXf86H1ToJZULWygQ996EO0t7djaXBgqrTNuEFmEELg3rqV6ve9L2dOSSZ1ovvGsa+tzirkhMWErc2TPfXmwuR2Y9+wHjFPnip20Ie11YNiN6OuqkSPJIkfK32gjkzpxA75sa2oNAxKqxuT10Z099iMxznPOYfmO24nduAAAx/4B3z33MOJW27FtXUrzV//2pwcVLw/SHIsin1jLaTkvK87Q2VlJR6PJ6dhkNJYw7bcixCCaLUESUHrzkfswAQIsnUHrtc0EXlumPhQuOA19EiC6F6foYhULQx88B/ZoHbysyt/xv9b9/8Wtb/5KBuGHGQMQ8Kq4pAqpoq5rt/JqGEos3g8l7SBLgk8nH8iWy4iL4wSPxqg4vJl2TCUurKK+NEgeixZ8n603kmsrR6EWaGioiLbqM6+tprYYV9Bp93pxI74kbEU9vUzx6TaurwkhsKkQqWNMEmF4iQGQqgrjVCOuqISRPrmViLxY0Gklsq2kBFCYN9QQ+yQDz068z11X3ghTV/+MpFnnuHE527Bed55NN95R05DFnlmGGFR8F61HGFVCvLqMnmGo0ePMrtxaHI0ih5MZHMKsQoQqimvB1YosQM+rC3ubOsWz9ZWhGpm8o+9Ba8ReWEUkjru8ztpuetO4oODHP/Yx1jjXXVSD6Vlw5ADLRJBCoWUxYxD2gylwjR0XTIwES0bhpcg5mo7zlc1EH56mORYtKDn6LEkk3/owdLiwrF5qi5FXVUJuiz5BqHHkiQGQ9iWzQ212NdVQ1IWHaqK7h5D2EzGjXsati7jpqb1TJa0V+2Q8RozN3HFYcHa6l5UKC0TmspM7QNwnFE7J5yUoeKqN9L4pS9Rcc01tPz7t3LKY/V4isiLo9g31GByWrAt9xI7MDHnZp+Ljo4OwuEwY2MzPZaMZ5AtXlXA1ukldshX0Lq5SIUTxAeC2fcTjPfUc2Er2kEfsUNz39ft27dz9913Z68ppSS880S2V5lj0yYa/vnThB99jNG7vlnSvgqlbBhyEI9EkGbDyjuwothnGobhYIx4Sqe1bBheknguakOYBJMFxnMDD/ejBxNUXt01Q4FkbXMjbKaSb47a0QBIsC2bq+iytlegOMzEctwg8yFTktjecdTVVdl+Xdn1mo29lmrEYgd9KE4zlqapRLu6qorEQKhkL2R6aCqDpcWVM5yUwXvNm2n68pfy5qGi3WNILZXtFaSuqiLl00iOLnwIyJdn0A77MXltmKqm2kyoK7ykfBqp8RiloB3ygTT2Nx3XuU2YvDYm/9g7I38TDod55JFH6O3t5dgxY+564niIxIkwzrOn1Fre66/H+9a3Mv4f/0HgvvtL2lshlA1DDrRoGD1jGHJ4DEfTUtX2k1TcVmZxmNxWXK9pJrprlPhgaN7HJkYihLYP4thSP0dgIEwKapfX6JNVwskx3jsJisDaPtdjECaBurqK6P4JZGrumNRcaL2T6JFkVo00ez1bZwWxEuLiUjc8F3VF5QzDmDntlmIYZ4emsvucJ5xUCJFnhjFVqVjTxja7xwJCXrnyDFKXxHoms/mFDBkPLHY492sfHx/nwIEDea8VO5A2tLMUbcKiUHF5B4nBMNFdo9mvP/HEEyQSCcxmMy+88AIA4Z0nEBYFx8YpRaQQgvrPfgbPG67A0jq3IHKpKBuGHMzwGKRtjvSxLFV96eM+vxmhmgnc35f3MVJK/P93BGFV8urLbasqSU1qJEciRe9B6w1gbXHNmDMxHfvaamQ0idYbyPn92US7xxAWZUZ4YsZel3tJjcdI+oo75SYGQ+jhBLZZp1tLkwvFZSF2oHjDMDs0NZ35wknzkZyIofVM4tw8NTTJXKlirnMUtMdMnqGvry9r6BNDYWQ0mTUEGcw1dkxeG7FDuQ3tfffdxz333JOdSTGdfIY2g/2MWizNLibv70MmdMLhMDt37mT9+vWsX7+e7u5utFCMyAtGyGx2UZxitdL8jW9gX7duztpLRdkw5ECbYRjmhpKWut12maVHcVhwb20hdsCH1pc77h7bM4522E/F69sxuXKrdTIn3mJPzXo8RXwgmD3Z5sK2shLMSkHhJKlLonvGUVdW5jU0aibPUGQ4KfPa1BUzb45CEagrcstWC1lzdmgqQzac9OJojmfmJ/zsMAhwbJ5Zh6CuqjS8qQJlq9PzDJn8gjpr+JMQAluXF+2IH5ma+dojkQhHjhxBSsn9998/x5s0ZKqJOWGk7NqKoOKKZaT8GqEdg+zYsYNEIsEFF1zAxo0bicfj7PrTTmQ8hfOc3C08TjZlw5ADLWoYBkWX2LDMCSX1T0Ro8tqxmMpv30sZ13lNKG4rk/f1zfnj1eMp/L/vwdLgwPnqprxrmL3pE2mRhiHeH4SUzJlfyKBYTagrvET3ji8Yqor3B9CDcaMWIN9e6x3GCb/IcFLsoA9LsyuncczKVgcKl60udGIWQmA/o4bYYT96pLBaAalLIs8OY1vuxeyd2XJaXVVVsGw1M787E07Sjvgx19pzKg/VFZXIWIr48Zmvfd++fei6zsaNG+nt7eVgep5ChqxMdWX+5oNqlxd1VSUjDx/hqaeeYv369dTW1tLW1kZlZSUv7tmNudaeMwx5Kijf2XIQjxg5BjUFwmxCWGae0MpS1ZcHitWE5+JW4n2BOaGG4CMDpPwa3jctR5jml/2pKyuNQqp44dJSrXfSuDl0zP+HbV9bTcqvkVhA2x7tHod0XiIfQghsy9On3AJzIno0Sbw/MCcXkMGWla0Wbhjzhaam49iQCScVJofVeiZJ+bWcA2psHR6E1VRQnqGqqgq3222Ek1I6Wm8AW57WF7YuL4ipsFiG7u5uqqqquOqqq6iuruaBBx4gNa2de+ygD8s0mWo+Kq5YxovJnqy3AKAoChu61jIQHyW13nna6qTmNQxCiEYhxD8JIX4thNghhHhYCHGXEOIy8Qqu7NKiUTBbUHVljrcARp+kcuL55YFzSwOmKpXA/X3ZcEhyPErwkWPYz6zF1rlwPxx1VaVxIi1CChrvncTS6FywaZq6pgoERPfkDydJKYl2j6GuqFx4vS4vejBRcE4kdtgPeu5cAIDJWbxsNV9oajpT6qTCwkmRZ4cRqinbXmI6wqxgK1AkML2eQTsWRMZTM2asTMfktGBpcs2QlgaDQXp7e1m/fj0mk4lLL72U8fFxnn76aSAtUz0WzGtopxN3w17rcTr1eipNU8KH5bF6EHBQGVpwjZNFXsMghPge8NP0Y+4E3gN8FNgOvBl4XAjx2lOxyVNNPBJGmi3YdfOc/EJISzIejpelqi8ThFmh4tJ2EkPhbEzb//sehCLwvmH+IfUZbB0VCIuS7fuzEDKpo/UH5w0jZTC5rFjbPfPmGRLHQ6T82pyitpx7zRRpFZhn0A76EKoJa2t+z0ZdWUliIFiwbHW+0FSGYsJJeixJtHsMx5m1c7z37B5XVZLyFy5bDYVCnNhjFEHOdzhQu7zE+4PomqGg2rNnDwDr1xvzmleuXElnZyfbtm0jEolMk6kubBh27NhBQk9ylt6ZbZUhkzqWPWFa7HW8uHd3yXUUi2U+j+FbUsqLpZTfkFI+KqXcL6V8QUr5CynlB4CLgJFTtM9TihaNoJst2JkrVT1WViS97LCfUYulwcnkg0eJ7h0ntm8C90VtOePKuRAWxZCCFmgY4gNBSOoFGQYwwkmJoTDJidxqomj3uFEotmZhw2CuUjFVqQUloKVM5wK6vPOG09RVVUaLiDwKnenosflDU9MpNJwUfXHMmIeyOf9QrKxsdf/C4aRMPUPvoR4sjc55Qz62FV6jyDHtLXZ3d1NfX59txCeE4NJLL0XTNB599FFDpuowY21x510TmKFEanvtKiLPjxA/HiK6Zxw9kmTjxo34fD6OHi2ut9JSkdcwSCl3zf6aEKJdCLEm/f2YlPLg3Ge+/ImlVUlOYS9LVV8BCEXguayd1HiM8f/aj7nGjvu1zUWtoa6sJDkWJTm+8Ik0Iz+1LpBfyK6dHkmaS76ZCSPZOr0Lxqyz63V50Xom56hpZpMciZCa1FBXzj8RzNLsQnGaC4rha5nQVAGGwdLiMnpGLRBOCj87jLnOPqfOZDpmr4q5vjCRQFVVFW6Xm2MTg3nzCxls7RVgVtAO+fH5fAwMDGS9hQwNDQ2cddZZ7Ny5kxMHB4zeUAu0at+xYwfxeJzzzz8f99YWFIfRKiP89AlMXhsbLtiM1WrN1jScagpOPgshPgl8HficEOJHJ21HLwEiMePk5hSOOaGkUzGHoczSo66uMhQeSR3vVZ1zKocXIpNILeTGo/VOYq5zzBtKmY6lxm7c1HIYhuRwxGgYl6OoLe9el3uRWorEAsV9mdcyn3oGpmSrsQJkq7GDPoTNhLVt/hMzZIrdaokdyh9OSoxGiB8N4NzcsGAitlDZqhCm3uR+AAAgAElEQVSC1pomhoQPa+cCsxwsCrZlHmKH/dkw0roc9QMXXXQRZpOJJ+P7FgwjRSIRdu7cybp166irq0NRzbgvbkM77Ec77Md5dgM21ca6devYs2cPmlZcQ8ilYL4cwweEENO/v0lK+VYp5fXAppO/tdNHNGMYcOf0GDyqGa/j5E9TK7N0CCGoumEVVTesyqsvnw9ztRGiWcgwyJQkfjSQbYldKPa11Wh9k3NaPUe7x0CQM+maj0wydaE8Q+ygD3O9o6D5AOqqKvRwksTx/MZGSknsQCY0VZjhdWyoAX2q2G3wkI9n/jDVZC7y7DAo4Ni08HjWYmSrTaZqoiJO2Luw0kxdUUlyJEL3i7tpbm6mqmru74/L5eKc5jPoN40xpM4vUsh4CxklEoDrVY2YqtV0nYYRMtu4cSOJRIJ9+/YtuMelZr6fXhS4TwhxRfrzh9KqpD8DD538rZ0+tLjxx+nEkbOG4WTNeS5zcjFXqjg2Fjf/OYMQwpCtHvEjk/lbWCSGQkgtlbNx3nzY11aDPjdGHu0ew9ruweQu/CBiclmxNDjnvUHq8RRaz2RBIR9IexULdFvNhKZsBSReM0yFk4yCs307TrDz94aCTOqS8HMjqCurCnr9tvbCZat1fmP86NHBYwuv2+XFL8KcGBmeE0aaztpIM27FzoOPPISu5/4diUQiPPXUU1lvIYMwK1TfsJrK61ZkDXVbWxtVVVWnJZw0X47hRxjqo1cLIf4HeAK4GniLlPIjp2Z7px4pJYm0EiBf1XM5jPSXibqyEhnX0fryt7DQeo3TYqGJ5wyWZheKxzojnJQYi5I4ESkqjJTB1uVF6wsgE7lvUFrPJKRkwYbB5LRgaXHPW8+QlakWuCbMDSeF/ZpRIBdJGP2UAvGctQs51ypQtqprKexDOk6LPe/gnulYGpz02g3DlSuMBMbcBP1YmNd1ncPw8HDem3kubyGDtdWNc8tUpbMQgo0bN9LX18fExOLmghTLQv5eK3A38I/ATcBXgcVNWn+Jk0zE0U0WkBI71hkeQ0qXDPiiZanqXyi25V4wiXmH92i9ASPs5Cl8fCMYcXz72mpjbGfCCG9Eu42bUamGgaRudHjNtc+DPiN+3lG4AVNXVhIfCOadbBY76MNc55hTmbwQ08NJYb8RT48E4kSeGUZxmuct6puzx4xsdVodRyqpo01r2Bfvm0To0N7UOqNvUl4E9JhHaKQStzt37iR2yA8SzjhvEy0tLTz00ENzcgP5vIX5ODM9F33XrjlaoJPKfDmG7wO3ALcD/yilfA/wfeCHQohPnaL9nXLiEUOqakukEAgU+1SO4UTAaLdd9hj+MlFsJmwdnrynZqlL4n2T8/ZHmg/72mpkQs/mBqLdY1hb3UXNCM5gW+YBReQNJ8UO+rB1GvUZhaKuqkzLVue+fj2eQustPDQ1nenhpJAvbRhGI0T3juPYWFeUUCCTP5r+M3r2j3384ktPZz+PHZkEk2DZ2hWEQqEFT+PDw8P44gGWJepInMhdOBg7MIHiMGNr83D55ZcTDofZvn37jMdMVyIVSkVFBZ2dnezatStveOpkMN87vkVKeYOU8mrgcgAp5TNSyiuBV6RMFaYa6NnSp7bpHkNGkdRe5Twteytz+lFXVhlKoRyjQ5MjEfRIsugwUgZbZwXCZiK6Z5ykL0ZiIFSStwCg2MxYW9056xmS41GSY9Gib+LWFrcxQyKHYdR6JyFZeGhqOtPDSTI9LS+xdwJSct7ahVyYvTZD4TUtzzAxFCEwGiWZbmmiHfFjbXOzbLlR4LhQOKm7uxshBMtSdTmNYqY3VEam2tLSwoYNG9ixYwd+v/H+T/cW6uuLe00bN27E7/ef0pqG+QzDn9LJ5u3Az6d/Q0p58qZQn2bi6QZ69rTnOd0wlIvbymSkiLmqoEvNL2QQZqOldmz/RDYZW0i1cz5syyuID8wdTZqVqRapzhKKwLay0gh3zZKtagfSoakSX7vjDCOc1GgxJKlKzySWJifWHN1ZF0JdVYXWF8hWK0cChhEP+TX0SILEYAh1uZfq6mpcLte8hkFKSXd3N52dnbhrK7LeXDyaJJCeEJgYCqOHEjOM4sUXXwzAn/70J6A0byHDmjVrsNlspzQJPV/y+SbgLcCVUsrbTtmOTjNaph1G0nhrpoeS+icimBRBY5Ex1DKvHMz1DiNJnMcwmCpsmCqLD/1ksK+rRg8lCD5yDEujE3N16a3d1S6vEfqZ1eMpdtCHqUrFXF3877EhW03Mka2WEpqajqXZBS4LTRYFjwLmYBxnkd7C1B7Tva0OG687EjBaeYT9mmG8JdnBPLPnM8zm+PHj+P1+1q9fj7qiknjvJDKhs/P3vfzm688BU0qt6YbB6/Vy7rnn0t3dzcGDB3nqqadYu3Zt0d4CgMViYf369ezdu/eU1TTMl2O4AfBJKXOKcoUQHUKI807azk4TsXDIqHrWTaAIhHXqLTLabavldtt/wWRkq7FDvhmVxVIabRNsyzyL6oiprqoCk0AP557UVgzWNo/R42laOEkmdbQjftSVlSXtU13hnSNbzYSmFiqUmw8hBPFGF7VmQZdqQhdgL1FabOvwGCNZ03uMTBqGIeTT0I5MIixKtoq6o6ODYDCYN8/Q3d2NyWRi9erV2Lq8yISR0PePRAj7NZKJFLED6d5QsyS1r33ta3G5XNxzzz15lUiFkqlpyBTZnWzmu8M1A88LIb4rhHi/EOJaIcTbhRD/IoR4GLgDKG4E08uASb9hB+26oUia/sdztCxVLUNathpLET82pfhJjkXRQ4mSE88ZFNWcLY6bb/ZCIQizgrXDM2M+g9YXQMb1knIBkK6RaHbN8Jgy3UdLXTNDyGNFEYJWq8KkzVxwC5DZCNOUbFWLJkikK6HDfo3YET/WDk82oZ1vDjSArut0d3fT1dWF3W43CgcVgXbYl02Sh4cjRm+oHLUbNpuNiy66CF3XC/IWXvzzAL/7Zu5wUUtLC9XV1acsnDRfKOnfgC3A/2DIVq8EzsMwBu+VUr5ZSpl/6OnLlGDQ+GN3KHNHeho1DOXE81866opKUGa2x4in+yMVW/GcC/fWVlznt2CpW/whRO3ykhyOkAoap+bYQR+YxII9guZdc1UV8WNTstXYgXRoqmZxEw39SUkkHdIZXNRKadnqpEZ4Ws1JdDRCcjgy47XPl2fo7+8nFApli9oUmxlrm5vYIT/hjGHYN5Huppo7X7Nx40auvPJKrrjiipzfn87gQR/H9uVuO5Kpaejv72d8/OSfx+eNiUgpk8AOKeVnpJTvlVL+o5Ty36WUvfM97+VMKGTETu1iZtVzMJZgIhwvewxlUOxmrK2eGYZB651EcVkWfXMEUJd7C24JvhCZm2BGtqodnMDW4UGxlV6ONEO2qoN2ZLLk0NR0wpNxhi1mNJuJoUhy4SfMu0fjRh3dNxUiEsOGeESdZhjmyzN0d3djsVhYtWrV1LpdXhKDIVLp3k6JI36E3Zy3wZ+iKJx99tl56x+mE56MGyNcQ7nrRM4880yEEKekpqGQYPmzQoj/FkJcetJ38xIgHDF+eZwm14yq52MThgKhbBjKQGZGQSg7o0DrncS2rOK0TdzKh6XJhbCbiR32k5rUSJyILNhNdSGmy1btPpDx1KLDSGCohny1dsY2NxAJJdGLnDM9HXOFDUuDg1TaY7B7rNgmNYRqmjOHur29fU6eIZVKsXfvXlauXInVOpU7sK0wjGKt2fg5i6Ew6grvgt1UCyGclkBnivxm4/F4WL58OS+88MJJr2koxDCsAH4M/K0Q4pAQ4lYhxPKTuqvTSDQaAylxmCpmhJL6J4zRi2XDUAamyVYP+Un6YqT82oJjPE8HQhGonRVoh/1TLSuK6GWUb03bCkO26hgT6dDU4kNoYb+G02vD7rYatQF5Ts6FYltVhRiNYAbq2ty44ynDeM+aPZHJM0yvE+jp6SESiczpjWRtcYNVodasUGECRUuV1JRxNlLKbJI8nKNGJsPGjRsJBAL09p7coM2ChkFKqUsp/yilfCvwt8B7gReEEA8JIc45qbs7DUTjcUQygdU802PIzmEoN9Arg3ESV5xmYgd92foFawFjQk8Hti4vKb9G6MkhFI8Vc/0S5C5WVaKHE3iOCWztHhTb/CNHF0JP6UQCcZxeGw6PcUKPBgubGJcP+6pKhIRaq0JdrYoDsObIAdXU1OB0OmfkGbq7u7HZbHR1dc14rDAJktV26iyCurQ0dym8JS2SJJVuzpgxELlYtWoVqqqe9CT0goZBCOEVQnxQCPEUcDPwEaAK+GdmFb69EtCSScyJBIoyc3pb/0SECruFCntpSokyryyyMwoO+tB6JhGqGcsS3HBPBrYuw2AljoeWJBcAUzdDU1IsSqaaIRJIIHWJa5phmO8GWQjWdg8pRdBkN+FNS4tl/VzxyOw8QyqVYv/+/axevRqLZe7fe9hpwaEIOlUTEYtSVOfbfEwPH83nMWRqGvbt20cslnvi31JQSCjpaaAOeJuU8vL0aM+ElPJJ4HsnbWeniXhKx5IwEl8zDUO0HEYqMwNbutgrumvUqF9YgjjzycBcY8eUvtkuxekWDNmqni7kW4o1MzdGZ6U6ZRgW6TEIk0LQZqJWATWgoemSiDn3z6ijo4NAIIDP52NiYgJN09iwYUPOx06m65hUYIyl+ZlPN4L5cgwZzjrrLJLJ5EmtaSjE/1slpcyZ6ZBSfqmUiwohvMB/AusBCfwNcADDA+kA+jAMUWFDdpeQhJQ4kjrYZlY9H5uIsLbxpRdDLnP6UFcYJ3GZKHy+8+lACIGty0vk+RGjGnqJGLaYsCZ16kqooJ5N5ma4lB4DwJiELgkMBBlLSmpmrZlIJBgYGMBut3PZZZdx7Ngx2tvbaW1tJR6P5xySo65LMrHKhQBssCSDdBLxFGe/05h5YbZoC6755je/GYvFsuDjVFUtyUMsxDD8QQhxg5TSDyCEqAR+mm6mVyp3AvdJKd8ihLACDuDTwENSytuEEDdjhK0+uYhrFI2u6+jChD1puJ0Zj8Fotx3hsnUN8z29zF8YmWKvxPHQS9owAHgubcd+Ru2c2pzF0J+EE6EUrRMaVY2LyzGEMh6D14ZFNWGyKIv2GACGokm6BJCUjCYlqm/maXxgYAC32017ezsjIyNYrVZisRgOhwOvN7cRnRgKo0qJScJkUqe2zb0EUl2NsF/DYjMhJVQ1Lr5eSkrJ+Pg4TmfxaxUSSmrIGIX0xXxAU9FXSiOE8ADnY7TwRkoZT69/NcbsB9L/v7nUa5RKOBwGIXBk+yQZv+xDk1ESKUl7OfFcZhaOM2oweaxzJJAvNcxeFXsRcw0KIThuSLgzzeQWQ9ivoZgEdpcFIQQOjzXb/K5UpC7xBZPE0we8CSnnhGlisRjV1dUoipI1CgB2e/56lFRSJ2UzobsMI6unSpfVZtBTEqEITBYFPbU0UlQhBNXV1ZhMxdesFGLmU0KIFinlQPpibUVfZSadwCjGXIczgWeBG4F6KeUQgJRySAiRs1GKEOLvgL8DqK+vZ9u2bSVtIhQKzXluIJCuek4Zb+TOF58leRj2jRsl9b5jh9gW6SnpeqeCXK/p5czL4vVI4NVw4LFHCnr4y+I1FYCekoQnjRvic0/upm98cSfmgQM6Jhs88qjxPibROd4XY9u20ZLXTMaM8aBDdo06q0IsIek50E9820D2MRUVFdmi1kyBmxACTdOIx+d6LFJKpA6JVILMtOhQMISSJ3dRKPGYBAHJZAI9ZdyLlqomRkpZ9O9cIYbhX4DH0/2RAC4EPlDc1uZccxPwISnlU0KIOzHCRgUhpfwu8F2ALVu2yK1bt5a0iW3btjH7uXu7d/Pcc8/hTBkngfMuei2Kamb46X54ejdXXXjuS3p6W67X9HLmlfZ64JXzmnwnwuz75VMANFS1ct7WrgWeMT//+/xz2Bt0tm7dAkBk34sExqJs3fqqktccPx7iwP/upP6itXRtrmP3159FCMHWrZuyj9m3b1+2KjmRSDA6OorZbMbjyZ1PTCZSxHxh7A4Vs8VEPBRGtdmxLTJE5wuHUUwC1WEmGIvhdLgwFTGgaD6M17y1qOcsaBiklPem6xXOBQTwSSnlSEk7NBgABqSUT6U//xWGYRgWQjSmvYVGYDHXKAlfuvLRJW0gJCLdNiDbbrui3G67TBmA4PiUVDIwvhShpDjVzVPhOLvHyomenI2dC18zLft0VBjJbJfXxsjRYN7Hm81mvF4viUT+wrpM2MhkUlDShXKLCSWNj49z8cUXk0zojI4OYzabqfRWY7IoPP30zhlV17OZmJjg+uuvp6+vj46ODn7xi19QWbk0qrNCTVIM6AeGga7FtNuWUp4AjgkhMg1ILgb2Av8HvDv9tXcDvy31GqUSSE9bcksVoZqyrtzR8QjNXjvmcrvtMi9TAmNRep4vPSwzZ720YbBVzDQSpSClJOTXcE0bYerwWImFEotqi5GZw5BROTm9NkJ+Le/sBSEEDocDRcn/d65nhClmsSSGobq6mueff56H/7id977nb/nwh2/k4T9uZ+eOp+c1CgC33XYbF198MYcOHeLiiy/mttuWbmzOgh6DEOJvgJsw2nDvBs4GngS2LuK6HwJ+llYk9QDvwTBSvxBCvBfDCL11EeuXRCAQTFc9V2FyTv1Qjk1EyonnMi9rnr3vKPueGOL9d12wJCGK4HgUxSxwVEsCI4szDPFYiqSWwjndMLitSGlUPzsrSht8lJG7ZgyDq1IlldDRIknUHC29b/ndHvYOBkilUnkTtnpKJ5WUWNLRhISWQjGJvO/p2iYP/3rVunn3KXUJ0iiazNTCFGJsfvvb32ZzB+9+97vZunUrX/nKVxZ8XiEUkmP4CEb77R1SytcJIdYBn1nMRaWUL6TXnM3Fi1l3sYRChmFQLPZZfZIiXLGh8TTurEyZxTExGELqkuB4DO8SVGgHxmK4q1Qs7hi+ngTxWBKrWppkNdPC2lk5dRjLhH8WZRgCccw2U3ZfGcMT8mk5DUMhzHY2hJj7tWLJGAEhjH8AqZTkda97HcHg3NDX17/+dS655BKGh4dpbDTuS42NjYyMLF30vZCfZExKGRVCIISwSin3CCFWL9kOXkJEotG0YXBmDUMglsAXSZSrnsu8bJFSMjFoNIGcHI0ujWEYj+GpsSOdhrcQHI/NyBEUQ8hvrOGa5TFA+tTfUtoeI4F41luAKcMQ9mvUtMzda+ZkHwwG87bJ9o9E0JOSqiajNsA/HEHX5aLqDrKGQREIYYSo9JTOY489VvKai6UQwzCUrlT+HXC/EGICI9fwiiMSjaUNgyNbw3As0zyvbBjKvEwJ+TTiMUNcOTm6+EQxGKGkmtZaomrm89INQ7YdxrRZ6vYlaIsRmdRwVkwZBldlxmMoPfSlp+QMaapiEiQTi6s7SKXrFjLegmJS0AvwGOrr6xkaGqKxsZGhoSHq6kobhZqLQlRJb0p/+FkhxMVABXDvku3gJYKu68QScSzJBCb71JCe/vGyYSjz8ibjLQBMjkYWvV48liQaTOCpVrNa/sUok6YMw7RQ0hK0xYgE4tmTPaTDU2LhXkTzoSd1zNap22bmdC+lLLnuYLrHMLWmXNBjeNOb3sTdd9/NzTffzN13383VV19d0vVzMW8WSghhEkJkxwVJKR+SUv5GSrm4ksSXINFoFClBJJOYTPasx1But13m5c74oFHA5aq0LYnHEJwwTtyeajsmG5gtSlalVAohfxzVacFsmUr4WlUzZuvi2mIYoaSp8JTJpOBwW7PtN4pF6hJdl5imqROV9MeLUU9lqp4zhiVjbBbi5ptv5sEHH2TFihU8+OCD3HxzweVgCzKvxyClTAkh9gohmqWUx5fsqi9BMi6bLZXpk2TkGPonIngdFjxqud12mZcnE4NhnBVW6jo8M7yHUgmOGUbAXaMiwgJ3tZr9WilkBvTMxuGxluwxJBMptEhyRo4BjDxDqR5DKjUlVc0wXbJaQueJ9HN1FJPgc5/7HGC8H3pKLuiFVFdX89BDD5V20QUoRLdWA+wTQtwvhPhN5t9J2c1pJGMY7Im01XZMeQzlMFKZU8nEYJi9jw8u6XpVzS4qau0ExqOLOt3CVA2Dp9roJ+SpsS86lJTPMJQ6rCdbw1Ax0zC4Km2EfKUZhswpfqbHsPhaBj0ls57HUq25WApJPi9d1cRLmEy/FHdqZgO9/okI65tf2p0zy7yyeO7+oxx46gRdm+qw2hfXtVTXJb6hMOsuaKai1o6elIR8sexNvRQC41HMVgW72/Ci3dXqoqqUQ74Yta1zE9cOjw3/SGk5kdk1DBmcXhuDh/y5nrIg04vbMmRDSYtofJdKSay23IbBtLgff8kUknw+Ob7KS4yMx+BKGW+J4rCg65JBf5Qr1pdrGMqcOoaOGDeusYEgTSsW1+IgMBYlmdCpanTiSc9NmByNLsowBMdiuKvt2TCHu1pFiyTRoklsRRqyVFInGkzgrJzbbsbusTJ4uLSbeMZjmF0D4aq0oUWSJOIpLNbiYj8Z9dD0071pkad7KWU6lDQ9oT3d2JQYn1okhYz2DAohAul/ESGEJoQInIrNnUpCoRBCT2HH+AVVHGYmInESKUmDp7QCmzJliiXk0wik4/Xz9fUplExOobrJRUWdERKdHFlcAjowHs0aGZgKKQVLCCdl+hm58oSSYuFE9oZcDLPbYWTI1jKUEE7KJImVaZP6MtXKJRuGdNVzrlBS6jSGkhY0DFJKt5TSI6X0AC7gHRiDdl5RBINBlFQSm5I2DHYzJyaNP9CGcvO8MqeIjLcgFMHosaUzDJWNDlxeGyazQmCRyqTgeGymYagxPg6UkIAO+9Mn+zyGAQmxYP6mdvmITGogQHXPFI24phW5FYue1LM37ekUqiLKuWYmoW3KldBemrkMpVBU0xQppS6l/BXw+pO0n9NGMBhEJOPYFBWJRKhmRoLGL3qdp2wYypwaho5MYraZaF1TyWh/aNHrTQyG8NSoWFUzQhF4atRFSVa1SAItksQ9LRTlThuJUprphadNbptNtpYhUHwCOhKIY3dZZiSKp1+nFMlqKiXnrAdTdQelkMswGNXPSjancTooJJT0pmn/3iyE+AIs0QTslxChUAiRiGNV7GDWEYrgRNrNbSgbhjKniBNHJmlY5qGuw4P/RJiEllr4SfMwPhie0a6hota+qCK3rCKpZupvQnVasNhMJSmTMlXI+UJJUJphCE/OrGHI4FyMx5DScw7kURSlZMMwMjLKRVe8lrNftYWGhgaam5vZuHEjF152HrHo/Hv85S9/ybp161AUhWeeeaak6+ejkEzR9C6nSaAPYwznKwYppRFKSiSwmO0I1bCXw4EYQkCtu5xjKHPyiceSjB0LsvkNHdS1uZESxgZCNC4vTRWXSun4hyN0bKjJfq2i1sHAfl/JlbrZGoZpoSQh0rUMJXoMJrOCzTn3VmR3L85jmC1VBaNwzmo3Fy1ZlbpM1yrMPUubTAKtgLqDXFR6q3j4j9upaXVz66234HK5+NjHPpbtyTQf69ev5ze/+Q3vf//7i7pmIRSiSnrXkl/1JUY0GiWVSmFOJrCY7JhchiEYDsSodtqwlOcwlMnD5GiUkaMBVmypX/Rawz0BpISm5V4qG41E8Wh/sGTDMDkcRU/JGW0hKursJBM6kcl4zvDNQmS8Ak/NTFWTp1otMceg4ay05byhTnkMxZ/uIwGNyobc9Ud5i9z+eDOc2I09lWSOTlRKvPGU0V571v3AntKxJnWwmZgTTGnYAFfkV/znSmiDUSuR0ObPraxZs2be7y+GQkJJ30830ct8XimE+N5J29FpIFPDIJJxzCY7ZrfxCzUciFFfViQtyIEnh/j5F3eSjC8u7HGy0VM6sXDxicz5ePxXh3jgP/dk1TWLYfCIHyGgvtOD02vD7rYsKgGdaYVR3TwzlASlN9MLjMewqCZsjpk3TneNneB4NO8QnHzMHtAzHYvNhMVmIhoo7mcmpZzTWXU6RpFbcUYs87JyGbDsl0qIJmWqnmejmARXXXcZGzdunPPvT3/6U/EXKpJCQkmbpJRZMbGU0ieE2HwS93TKydQwiGQCk8OBku7VfiKg0VRWJC3I7keOM3YsxMGnh1n7mqYlWTOV1EmElzb59swf+njxzwO864vnFa23z0V4UqNv9zgAx/ZOsPrcxdW7DB2epKbVnZ0fUNvmZrS/dMMwMRhGCGa02a6oyxiGCE0rvPmemhdDkWSfc4P0VKvEY6m8Q3DyEfZr1C/L7xE5PNaiPQYtkkRPyryGwem1MXE8R2I/fbKP5mi7HQ8nCIxFqWp0osyqf0jGkviHI3jrHEUXJM6ues6gmAX/98v7qG5eutnPxVDIFRUhRPYnJ4SoBF5RjYMyHoOSmNlyeyQQKyuSFiAwFmW41yhr2b1toOgTYz6e+M1hDv9RLtkJX0rJgadOoEWSHHhyaEnW3L9jCKlLrKqJo3vGF7VWKqUz3Ds5I2xU2+rGNxgmmSjNE5sYDFNR55jRnM5VpSIUUXItQ2AsOiPxnKEUZZKUkrB//pCWw2MtupFepuo534Afl9dGJBAvSg6aSqaL23LcpBfTwsJQOuXyGBTe9NbL2bT5rJesx3AHsEMI8XMMZ+kG4KsndVenmIzHoCSTmM0OFIcFLZliPBwvK5IW4PBzxtSoTZe189z9Rxk6PFnSSXQ60VCcvY8Noiehd9coa85bvBcy2h8kMBZDMQu6HznOhq0tJbdJBiMZuXf7IM0rvbirVHpfHEuHBUo73Y0PhEjGdRq7pt672jY3ui4ZPx6mvsNT9JoTQ2Gqm2YOkDGZFNzVpUlWpTQmwLWsnluNnSlyC4xHqW3LPeRmNrFwglRSzxtKAsMwTAwV1/gv42HM5zFIWVxSO18uAKaK04otxMtV9Ty1puExeGrsJU+bWwyFFLj9EMMYTAJB4Hop5Y9O8r5OKcFgELPJhFUYP/YuYDsAACAASURBVADFYWY0aPxylXMM83Pk2RHq2t1subIDm8PMi38+tug1d287TjKhY7LBoWeWZlzhkedGUBTBuW9eju9EhOMHS2u1kOH4QR+BsRhrXtNE2/pqtEiS4b7Swz5Dh41eQzM8hvQNtpRwUjKeYnIkQmXT3Mli3lp7SYYhFk6Q0FI522lkPIZiEtDz1TBksJfiMeRpoJdhamBP4SGqfMVtkBnJWXwtQ66q5wyFtNr4n//5H1paWtixYwdXXnkll112WVHXn48FPQYhxNnAPinli+nP3UKILVLKpRXOnkZCoRA2i9moYcDokzQcyBiGsseQD0ORE+Tca5djsZpY+5omXnjoGMEJYx5wKSTiKXb/eYCOM2oIJcYY2O+bN5FYCFJKDj87QsvqStZf0Mwzf+yj+5EBWlaV3odo7+ND2Bxmlm+qJRnXEQL694yXrCAaOuzHU6POuEm6q1VsDnNJCWjfiQhSGq0wZlNRa+dEb6BoeWUgh1Q1g+q0YLWbiwolZW7MmRt1LhweK1o4SSqpFxxrz9cOI8OMWoYCW0blK24Dpo3jLM4wzC5uy7TdhqmhPfOFu6655hquueaaoq5ZKIW8098FplfEhIH/OCm7OU0Eg0FsZhNW01Q7jOGA8QteNgz5OZIOI3VtNkYKrr+gGaSk+9HSR3fsf2KIWDjBWZe2UdEukLqk5/nFeQ2ZMNLyzXWYLSbWnNdEzwtjJfflj4USHHl+hJWvasBsMaE6LdQvq6C/xDyDlJLBI5M0Lp8ZghNCGAnoEnomZcIvVTk8hoo6B/Fosuj8TTBb3Jb7bmrUMhTuiRTiMWRu7sW03w5PxjGZlbyJ4JI8hjzFbRlKaYuRylH1nCFb/Xya+iUVlHyWUmZfcfrjV1TyORgMYhECq5hqoDdlGMqhpHwcemaY+mWeGX35l51Zy97HBkuSruopnecf7Kehs4KmLi+2CqhscCw6nJQJI3WeWQvA+vObjBxBiTMPDjx1Aj0pZyiw2tdXMXI0WFIx1uRolGggTmPXXG+jttXN+GAom/wslInBEIpZZFVI0/FkJKtFJqADY+kahhweQ+brxUxyC/uNfkb5Qj5QWvVzJKDhqLDm9YZUpwWTWSn4YGDkAvJ7DEBJN3E926019z4X02pjsRRiGHqFEB9Ij/lUhBAfxKh+fkUgpeT/b+/No+M66zzvz3Nrl6q0l2RbtmQ7tuM1sR3HScdx4pCNZNIQODRh6R5e6GHptzmnh2ad7s47ge4MDQdozkx6GtJDIA0ZAk2gSUOgIYuzQBIvieJ4S+x4kWztpaUW1V7P+8etWypJtdxaZG3P5xwdS+Wqp56rW7q/+9u+v2AwiJaMUyN0I6C5rPT7I9gsgqba8kMYi5mxgQmGe4IZb8Fg200riYTivHlwoOQ133pliIAvwo7bOgD9rmn91W30nh4re7hKdhjJ6dbvZ+q9NXRsaeLYcxfLShge/10vravraFk5Gabp2NIMQM/x0r2GyfzCzKS9t8NDKiFLTsD6ekM0ttXkvJiV28sQ8EVw1Frz3onXNbvw+yKmK9OCY1FcHnvBC66rHMMwXjj0KISgtsH8iM9MyKeox1BuKCn38Vssoixl2WpgxjB8HLgZGEh/3Qh8dDY3dSmJRqPE43GIhnAahqHGxqA/SqvHWVHlymLGqEa6bOdUw9C+oYGmFbUll65KKXnlN+dpaKthzRWTEg7rrmoFORm2KpXsMFI2W29cSWg8xrkjwyWtN3DWz0hviM17pvYseFd5cHlsnD82UvIe+98aw1FjzdmpW24CeuRiiKYc+QVI6xyJ0g2DLredPyjvaXaSiCZNh6hCBZrbDGrKkMUwk5MqZcRnplS1oMcgdM+ihOl4hSqdjPebtx6DlHJASvkeKWWLlNIrpXyvlLL028F5itHDkAqHcBrJZ6cuua3ktvNz+vAgy9bWzUgyCyG44qaVDPcEM3fCZrhwcpThniA7buvIJN4AGpfV0rLKzalD5X3kpoeRDDq3NuNucnD02dLyIcdf6MXqsLD+6qkSGEITdGxppvu4r+TRmX1v6f0LIscFot7rwua0lGQYYpEEgZFIzvwCgNVmwd3oKFlMzz8cyRtGgtIrk/KN9MymvFBSjJo8PQwG7kZnyR5Drn4Dg3KksvN1PWfWtOo5NlnhKNZyMCOJ4RBCfFwI8T+FEA8aX5dic5cCo4dBhoPYhZOUiCMsgoGAksPIx2h/CN+FIOuuyq0PtOGaZSWXrr76m/PU1Nm5fPeyGf+3flcbA2f9mRi3WXKFkQw0TbBlbzsXTo4y2m8uTBMLJzh1aID1u1oz3cnZdG5pJhpKMHjO/ByrcCDGaP/ElP6FbIQm8K4qrQPaCDtN72HIpt7rKinHIKXUq83yJJ5hMilttjKpkByGgdVuwe60EDZpGJKJFJFg3JzHYDI8mSrQ3GYwOXWtNI+hmBcCczOwx0wo6V+A1cBdwMvAZUDpalnzFMMwpCITOCxOpE1Pmg6MR1RFUh5OH84dRjIwSlfPdA0TGCn+URnqDtBzYpQrb16FxTbzI2nkMUr1GvKFkQw271mBZhEce85cEvrUoQESsRSbr8/dcLdqUxNCUFIXdN9bM/sXpuNd5cF3IWj6btQYzpPPYwA9z1JKKGnCHyMZT5nzGExUJiViSaKhhCkhv5p6h2mPwaheqi2Q0Aa9+zmZSJm6G08m9bLefCEfKG/EZzIpGR8fyXQ0Z8tub9++nUQykV4z93n/7Gc/y8aNG7niiit417vexdhYZb052ZgxDBuklP8NCEopvwO8HdhatR3MMZOhpAh2zYlwCILRBKFYUhmGPJw+PMjydfUF689LKV199bfd2JwWtuzNfcGta3GxbG1dydVJ+cJIBjV1di7b2cqJF/tMzT04/kIvTStq83YhO902WlfX0X20NMNgsWq0dubvbPZ2ekjEU4wOmAv9jFwMYbVpBfMB9V4XkWCcaDhhak3DC8jVw2DgcFlx1Fgz0tyFMEQHzRgGl8dm2jAU62EwMN7XTNivWKkqlC6LYXQ9t3hb6Orqoquri0984hN86lOfyvzscjkKrnnrrbdy9OhRjhw5woYNG/jyl79s6r3NYEYSw8gkjQkhNqEnoDurtoM5JhAIYLVaScZi2Ny65HZmpOciNAzJRIoJf6zsBrSR3hAjvSH23rO+4POyS1evvnM11jyD1/3DYU4fHuTKm1fhqMlfBb1uVxsv/PgUI31TB8/ko1AYKZutN7Rz6uAApw4VFgAcvhBg8HyA69+7vmBBQufWZg784izhQCwzT6AQfafHaF3tyekpGXhXTSagczWsTWekL0jTitqcOQsDo4zVP2ROwmKyVLVwR1hdi8tUyWqmuc2Mx1DnwJdL9C4Hhk5SriE92Rg3Ndkew1cOfIWTIydJJpNYLJOfV730WmC1F76PjkeSaFYxpRFvY9NGPr/78zOeW6jr2aCYsbntttsy31977bX85Cc/Kbi/UjDjMXwnLZz334H/AN4Evl61HcwxgbSSokxKbBYXtjo3g35jpOfiyzEc/OVZfvD/vZiRZC6V068MgsgfRsrmChOlq11P9SAEXPm2VQXXWndVKwg4bTKcVCyMZLB8Xb2pKqrjL/RhsWpcfs3MHEg2HVuaQUL38eLVSYlY0tS8hYZlNVhtmuk8g683VDCMBHooCWBs0JwXYlzsPTkE9LIx2+RmprnNoKbObrrBrZgchoHxvmZCSVJmSWsXQmBaejvXSM/p3LjvRt525/Vcu+fqoiJ6Dz30EHfccYe5NzeBmUE9RpfzM0BH1d55nhAMBqmtrWUcgdVag7XBzUBgcXoMqZTk5O/7SCUkz3z/JO/+7FUF46a5OH14kBXrGvIqV2azIl26euSZC2y6bvmMO+1wMMaJF3rZcM2ygmEp0JUy2zc0cOrQIFfftaZoGXGxMJKBEIJtN7bz7A/fZOCcn2U5JKATsSRvHuhn7Q5vUUGz1o502epRX1EjMnjeTyopc/YvZKNpgpZVblOGIRKMMzEeo2l5Yc/CUEg1m2cIDIdx1dmx5fH8DDzNTrqP+orKbRgVQcXOO6RlMSYSJOOpgp4VTIaoaop4azX1dhCQygrfG3f2gSzZbSklQ90BauodRb2bkb4QmiamyJzno1DXs8Hzzz/P8MUgdoclb7c5wP3334/VauWDH/xg0fc1y5IfTRYIBKh16b90i9WFpdaWmfW82CS3e06MEBqPcdlOLwNn/SWXavouBhntC81oasuHUbrqu5C7dNUQy9txi7n7jfW72vTGuguFvR2zYSSDDdcsw+awcCzP7+OtV4eITiTyJp2zEZpg1eYmeo6PFI1f96Z/J8tM6Ct5O+oY7gkWvcMd6dN/N03thT0Gu9NKTZ0dv0nD4PcVLlU1qGvWJ8SFA4V7GUJjUWwOi6n5BZmSVRNew4Q/hqPWWtSAWCwaNXX2or9PM6Wqk2uab0gr1vUMsHfvXm66/Tr27Lsmr8fw8MMP84tf/IJHHnmkqj1XS94wBINBXA4HNs2BEBqay8aAP4LbYcXtqHyYy3zi5It9OGtt3PrhLaza3MRL//aWqaohg9OHBxEC1u4ofBeeTb7S1WyxvGJhD4O1O7xomigaTjIbRjKwO61cfu0yTh0aJBKceUE7/kIvdV4X7SblxDu3NBMJxRk8X7hste/0OE0rak3JKns73MSjyaKhH6MiqVCpqkF9q3mVVfOGwehlKLyumR4Gg1J6GfTmNnPruhscRY13oTkM0ymlIa1Y1zPoHsMLz7zE/t/8PpOQ7urq4pZbbgHg17/+NV/5yld4/PHHqakp7qWUgpk+hhlXx1yPLURisRjRaDStrDpVJ2mx9TBEQnHOdg2zfncbFpvGvg9cjpSS5374hqkOZeMufMUGc2EkA5vdwubrZ5auZovlmcXltrNyUxOnDg4W3HMmjLTdvAHbekM7yUSKE7+fOsRnbGCC3lNjbN6zvGAyN5tVm5tAULA6KZWS9J8ZN63GmumALqK06usNYXdZTV109V6G4jmGVEoSHIngKZJ4BvMDe4Kj5g1DKbIYxeQwsqltcFTVY9As5hvSinU9T66pkUrkXu+Tn/wkgUCAW2+9le3bt/OJT3yi6PuaxYzHcMDkYwsOo4fBbrFMSm67DMOwuMJIpw8NkEyk2JQeP1nX4uKad6zl3Ou+TF9CIXwXQ4wNTORtaivE9NLVVDJF15PdLFtbV7JM9fpdrQRGIpmpcdOZEkYqYcBJc7ub5evqOfrchSl/2Md/14vQREljO11uO22r6wrKY4z0hoiFE3kb26bTuLwWi1VjqLtwGG2kV6/aMhNWqPfWEBqPES8ieBgai5JKypyT26ZjtpfBjByGQUZh1ZTHEDVtGMx4DGZCPgaZKiKzJbDT1rzvvvv4zGc+M2PNfFIbp0+fpqenJ+NJfOtb3yr6vmbJaxiEEK1CiCsBlxBimxDiivTX9UB1/ZY5wuhhsGlMSm7XWBnwRxdd4vnEi/00t+vyEgZX3LSS1k4Pz//ozaL6NqcPDyAEXFZCGMmgrnmq6upbrw7hH46w47bOkuOia7Z70awib7NbqWGkbLbduBL/cITuE/oFPZlMcfLFPlZvay7JSwK9OmnwvD9vNU3/W3ozklnDaLFoNLfXMtSdPzwlpcTXGyyaXzAwxPSK5RmMKqNCPQwGdqcVp9tWsGRVpiQT4zFqTSSeIVsvqXCnspTpdYtUJBnUNjpAFr6QJxN6Et2Mt1iKLEYxtdZy1qwmhXb2n4AHgJXAP2Z9/RVw7+xvbfYxPAarlDjSHgNOK4OBxTXreaQ3xOA5Pxv/YGplkGbRuOlPNhIJJfjdY6fzvl5KyelDg7Rf3miqNj8X2aWrr/6me4ZYnlkcLiudW5o5fXgw5x90OWEkg7U7vLg8tkxS/tyRYcKBuKmk83Q6i5St9p4ep7bebupia+Dt8DDUHcwbRpvwx4iGEqbyCzDZy1Asz2BoHxXrYTCoa3YWDCVNBGKkUtK0x2CxaThqrEz4C9+8xCNJEvFUSTkGKHzRNZrbzNzAlCKLkUxKU16IpQypjWqQ1zBIKb8rpdwL/KmU8gYp5d70151Syn+t9I3TMt6vCiF+kf55jRDiZSHEKSHEj4QQs653bXgMWiKRyTH4kcSTkmWLKMdw8qU+NE2wIYcOUctKDztu6+Dk7/voOZn7IjbcE2R8KGy6GikXKzY00Nxey+9/epqh7gA7bu0wHbOfzvqr25gYj9F3aqoEQLlhJAOLVWPznhWcf30Yvy/M8Rf6qG1wZCS1S6G104PTbcs7vKfvrTGWr2soyWPydniIhRN5ReompTCKN8HBpLZRMc0kvy8CAtNNkZ5mV0HDUEoPg0FNnb2ox2C2h8GgtlE/nkIX3WTC3J09mNc2mpz1XIoXMk8MQxatQog6ACHEt4QQB4QQN1fhvf8COJH181eAf5BSrgdGgT+twnsUJBAIYLFYiAV92C36H8lgXL8rWSw5hlQyxRsv9dOxtTlv7PXqO1dT73Wx/5E3csabTx8eRGiCy3aUbxj00tVVREMJXSyvSI1/IVZva8Fq12aEkyoJIxlsTstyvPz4GbqP+9h03fKSez0grba6uYnu4yMzkpGBkQjBkWjOwTyFKCbBnTEMJjrDQR9Y46y1FVVZDQyHqa13FC0BNdAH9oTzJmHLMQwuj71o8tkwHKXkGGBSJC8XKZN39mD+Im6m63nmmvMnlGTwMSmlXwhxG3pY6c+Ar1bypkKIleihqv+T/lkAbwOMnu6HgbsreQ8zBAIB3G43QV8fDuEgRYyBkP7ha1skktvdx0eY8McySedcWO0W9v3xRvxDYQ7+4uyU/9PvwgdYZbInoBDrd7fR0FbDrjtXm77I5MLmsLDmihbeemVoSt14JWEkg7pmF53bWnjzZd3obLrOfNJ5Oh1bmokE4wxOG83Zl8kvmEs8GzSvcKNpIq9h8PUGcXlsJc3HrvMWL1n1+yKmEs+ZNVucpBIy74W8FDkMg5r64oYhNG5OJ8nAMEz57vAzd/YmZ01Pzn4ufBE30/WcWVPTw1j5KpNmCzNlp8aO7gC+K6U8LISotP/hm8DnAEOkpRkYk1Iail4XgPZcLxRCfAz4GEBbWxv79+8vawPBYJCenh6klPSdO8MmcTVxIjx38AgAZ4+9iv/MwmrzCAaDM34fPb9LYbHDuZGjdO8v/EFsWKsL2o2LHlyN+nPDIxL/sMS9Nlr27zqb9pvAx2n278+f0zDIdTwGEackEpI88eNn8SzXKzdOvSCpaYWXDv6uoj3KRv0jX9sGrxx9uex1ElF9nWd/eZjWrfrvMxgMcujQcTQrHD19CHGmNG/EXid547XzRBtnSpqfO5lCc1HSeYrKFKM9hV8zdDFFjTf3c3Kdo0Bv+rif/D01LTOPb+BICgQceOX3psOJI/4UgdHC+/S9ob/vq0cPYj1lbt0aWz2RcJSUNml0kskkgUAAmb6Ax+NRAiYlOSSSWDROIJBfnDAZ09eNRMPEUyb6iIQkGo0hizQN5t2TlCX/7ZoxDK8JIZ4ANgB/LYRwY1oRZCZCiLuAwbSB2Wc8nOOpOd9DSvkg8CDArl275L59+3I9rSj79+/HarXS1tZGou917BYnwp6iflknHDvFO27bh81kbHG+sH//frJ/H5FQnBM/eYGte9vZe/OGoq+PXB3n/37xZQInHNz++avQLBq/f+w0mtbDHfdcX1bcvhKmH082yXiKhw6/QE2shX37NjN43s/x0CGuf/fGgmJ4ZpApyfPaKTbsbsspkVEKo68eQoRg375dgH5MwUgN7ett3PS2HSWvl+o+wdkjw9x44/VT8hNSSt782XNsvG45N+wrfq4NXg6c4fAT59i754acXlwymeL4j/azfstqrtm3dsb/5zpHI30hup97mctWbcoZMnzq3HEiDaPc9LY9pvd5OHKOl948w/XX7c0ryPji6FsMWrq5+dZ9pg3OoRe7sGpWPJ7JQktDEiMeTRAZn6Cm1lVQ4DGbZHiCVFLi8eQP54WDMWLBCG5PLeP+MW6+WY/M9/f3Y7FY8Hp1j/fAgQPY7XYSIT1EOH3Ne++9l5///OdomkZrayvf+973WLFi5mdfCJH37ygfZq58HwbuA3ZLKScAJ5XF//cA7xBCnAMeRQ8hfRNoyGqcWwmUN6m9BIwPQHRiAkdacnswEKHFbV9wRiEXpw4OkEpI0zX4zlobN9yzgaHuAK89dWEymbup6ZIbhWJYbBprt7dw5tUhkvFUVcJIBkIT3HDPhoqNAkDnliYGzvkJB/U7zmRM4rsYNN2/MB1vh4dIMD5jBnZgJEI8mjSdXzBo8LqQMn/fQXAkipTmSlUN6oo0uQVL6Ho2cJkY8Wn0MJRS1CA0kTeUlEyHbywmQ0lAiaEkjebm5ryy23a7PfO8XHmLz372sxw5coSuri7uuusuvvSlL5neZzHMiOglhRBrgVuB+wEXFUhppGc7/DeAtMfwGSnlB4UQ/wq8B91YfAj4ebnvYYZkMkkkEsHtdpOIRLF7XGi1Ngb80UWTeD75Yh/NK92mZJUNLtvpZc2VLRz49zO4Gx0ERiLs/sM1s7jL8lm/q42TL/Zz/pivomqk2aRjazMHf3mOnuMjbNi9jAkfIM33L0wnOwGdXSVUihRGNvWt+p3y+FCYxmUzX2sYjEIibtOx2i246ux5VVZDY1EaSzRg2XpJ+fZiZtbzdDRt8kLe/z/+B9ETJ0kkk4xYLCSTKZIJyYTDkjOkkYtkIkUyKQmmX+PYtJFlf/VXU55jtus5s0eLyGkY6uomZ3iEQqFLq5UkhHgAuAn4Y2MPQPVa7Cb5PPCXQojT6DmH78zCe2SIxfQ7D4/HQyKeSEtu19K/SCa3+XqDDJ4PFEw650IIwQ3vuxxhETz53eNoFsGaK0vvN7gUtKcT4i8/fqbiaqTZorWzDmetje50F/TEkH5RaCvTG2le6UaImZVJZqa25SJTsponAW3c9ZvRSZqybrMzb5NbKTpJBhnDMJ7fYwiVIIdhIDT9opurN8SEUkyOBdMX5wKvNVuqunfvXrZv386eG6/hprfvySmi99d//desWrWKRx555NJ6DMB1UsqdQohXAaSUI9XqMZBS7gf2p78/A+yuxrpmyDYMyYTEanXhaGpksLeXK1dVHkKYa06+2I+miRlD683gbnRw3bsu49kfvsnqbc2m46uXGotF47KdrRx77mLVwkjVRkurrXYf9+kdv0PgXeXG5igsX50Pm91C4/LaGZpJI70h3I2Oks+Vy2PD5rTkNQz+4TBCE6bksbOpa3YycH5m9VQskiAWSZZUkQRZshgFksAT/lje6Xr50NK3xqmkzNzZGyHm8aEwiViS5nZzfSEA0Yl4xvvKd47Ndj0///zzgC6l7veFaVpRi9U2dc3777+f+++/ny9/+cs88MADfPGLXzS910KYCQnF01VIEkAI0Qxc2qLaWcAwDG63G5GyoQkLWr2H4WBs3ngM/uEwh399LqPwaJZUMsUbL/fTuS1/70IxtuxtZ+ftnVx15+qyXn+pWL9L9xLmYxjJoHNrM+FAXM81jFB2fsHAu8ozw2Pw9QZLzi+A7iHqYnr5PQZ3o8NUzX02nmYXwZHIjO70cnoYoHiOIZWSRALleQyQu08glUyVlF8Ac30HZrueDY/hmj27eNsd13PVrp15B/V84AMf4LHHHitpr4XI6zEIIazp8tF/BB4DvEKILwLvBapjluaQaDRdS+12Y003t4XSH5L5Yhhee6qHI89coP+tcd7+sW2ma/+7j48Q9sdKEn6bjtAEf/Cuy8p+/aVi+boGNuxuY2MF/QazTUdabfXQr84hk+XnFwy8HR7eeLmf0HiU2npdCG60f4KVlzeWtV69t4bhC7l7I/zD5uS2p+NpdpJKSkJj0Sm5kMyAnhINg8Wq4ai15jUM4UAMKc33MBgYhiGZkNimbSmZkNidpRqGwhIWk13PxYM1hseQiCcZ6Q1R1+ya0kt06tQp1q/XR+w+/vjjbNy4saS9FqLQ7g4AO6WU/yKEOAzcgl5W+kdSyqNV28EcEYvFEEJgt04qq45J3crPFwG9oZ4Ajlor51738cS3XueOT2yd4Urm4uSLfTjdNjq3li7lsNDQNMGtH9ky19soiMtjp7XDw/nXdXkMM4N5CpGdgK7d5sA/FCYZT5mWwphOvdfF2deG0hesqRdCvy9cliSI0RAX8EWmGIZyPQbQ5zjnMwylymEYaBmPYeqFfLK5rbQJA/nWy6xbQtdzZs30c6cPAfrCF77AG2+8gaZpdHZ2VlVdtdBRZ3wdKeUx4FjV3nUeEIvFcLvdxMPhjICeL6HLQcyHWc+plGSoJ8im65bT0u7mmUdO8sQ/vc6dn9iWt44b9Hjk2SPDbLthZclusGL20NVWA9jdlKzUOh1DIXeoO8DqbS2TFUkmVVWnU9/qIpWUBEejUyp+EvEkE+OxsjwGQ3DP7wuzImvAUcYwlJizAKips+WV3p7IdD2Xtq7QBIiZJaaTcxhK+xsSmsgktHNRqOv5vvvuy/kazeh+nrZmNUNH0ylkGLxCiL/M959Sym/Mwn4uGdFoNNPDYOgkDcT1bsX54DGMD06QiCbxrvLo85I1ePr7J/nl/z7Cnf/vFXln775p9C5cV74WkaL6dG5t5tAT56ipQn7c7rTS0FaTyTP4enUxyFzlpmYw5LfHB8NTDEO5FUkA7ibHlDUMgqNRHDXWorOjc1FT52DgXG7ZcUMnyazkdjYWi8j0LBiUModhOoV6GczMes6/5qWTxShkDi2AG122ItfXgsbwGGLhiYyyal80js0iaKyZdWHXohj6Oq2d+q9603UruOVDm7j4xii/fOA14tHcw1VOvthHyyo3LSsX/ClaVLSurmPDNW00rKlOrbkuwa1/RkZ6Q9S1OMuudKr3Gr0MU8X0jIu6mclt07HaLNTW22eUrJZTqmpQ47Hn9xjSj7vKKLbIdSE3DIVZ9eOZVQAAHWRJREFUnaRsLBYtb9NcuQbHTONcNSnkMfRJKatXGDvPiMViaY8hlDEMPeEYrR5nWWqa1WaoJ4DFptG4bLJV//Jr9fGST373OP/+v7q465NXYndOnsLImGSoO8D1f7R+LrasKICmCW798Bb27x+qynreVR5OHRwgHIgx0hcqO78A+l221aYxNq1k1biolyKgl42n2UVg2uznUia3Taem3k48miQeTc4wghPjMexOS1meiGbRSExTFS5lpOfM9QSJeO6LuJlZz2b3OJsU2t3cXx1niWQySTwe1w1DKIjd4iIpY/QGo/Nm1vNwd4CWle4ZH6ANu5dx659uof+Mn1/8r9eIhSfFusbOyvTchdJ7FxQLC2+HbggGzvoZ658oueM5G6EJ6ryuGZPc/MNhNIsoOyfiydHkVo4chkGhktXQeIyaMvdpseqyGNlNbslEyvTktukYd/e5muZK7XrO7NGSvxFvNihkGKoxc2FeYgzocbvdBEf6sGtOkjLMgD/Csnkgty1T+p2/d1XucND6XW3c/l+2MHDWz+P/s4toOEEymWL8PHRuay57yppi4dCS/my8eXCAVEqW3PE8nfoc8ttGRVG5A5XqWpwER6OZEEgqmSLsj5UfSqrP3+RWyqzn6WgWDaScMj/CmMNQjsyEcTOXax6F2a7nGWtadQXhfDMuqk2hCW75J5kvcIyRnh6PB/9AD3bNSUqLMeCP0uqZe8MwPhwmFkkW1Di6bGcrt39sK0PdAR7/5qucPjhAIlLZ/ADFwsFZa6OuxcnZLj00VUkoCSYNQ/aFxz8cLjuMBHplkkzJjODfhF/vNagkxwC5ZTEm/LGSS1UNck1eK2UOQ771ciWLzXY9z1zz0o74XJL1jIbH4PF4CI0MYre4SFkTBKOJeeExGEnFYuJ3a7d7efvHtzF8MciTD5/A4tBF2xRLA2+Hh0Q8hdAEjW01xV9QgPrWGpLxFKHxSdXWwEikrMSzgadlqspqOQN6sskW0ptOOQJ6BhZr+kKepTCgj/Qsz1MqNOIzmZja9ezz+TIaSMuWLaO9vT3zs6HOkL1mLsPwta99DSEEw8PDZe035zFUbaUFhOExuN1uJsbHcAgnSZv+oZgPOYah7gCaVZgKD6y5ooU7Pr4Ni0WjcW3pddeKhYtx49DQ6qpoIh5klaymw0mxSIJwIF6hx5Ceo542DJU0twE4PTYQMDE+VXI8Hk0SjyQrCyUxedEtZSZz7vVyy2JIKUmlpq5rRnY7e83pTW49PT389re/paOjo6y95qO0tr5FgsViweVyUVtbm04+OwnbEhCGtnkQShrqDtC8wm26QW31thY+9PfX8dKByiaXKRYWRg6q0vwCTDUM7RsaCYwYparl/z24G50gJqW7M3IYZTS3gX7T46y1MTFtktnkrOfy1jUuui/+21uMD4ZJJhOkEroMR6nVQwbxaALNqtG2uo6979UHJ5XT9Ty5x9yhpE996lN89atf5Z3vfGdZ+8zHkjQMO3fuxO/3Y7FYiIUj2OtcjNr1D9dcz3qWUk88X7azNAlpl7u0ASWKhY+304MQVKVnRRfKExkxvcCw0dxWfijJYtVwNzgyoaTQWBTNKiqaHV5TZ5/hMWS6nsvMMRizmo38Sqbwp6L5BmKG9HYps55BF9EzohsAiXgKTRN84x++zi233MLjjz9Oe3s7V155ZQX7zM2SNAzZpKISi2YlYHcByTkX0Av4IkQnEiUN11EsTVxuO+/+7FVV8Rg0i0ZdiyvT5FbOgJ5ceJqdUwxDbb2jooEyNXX2GVVJRvlqOV3PBppF46q3r6ahrYYxn59YEBqX15bVFwHguxjEardkPDEovevZENHLrNkbxGrTqPfWMDExwf33389vfvObsvZXjCVvGLSU/mEasrpxO0K4HXP7KzGbeFYoAJatrd7skOySVb8vgtWm4fJUJmVe1+zi4pujgJ58LjfxbFBTZ6f/zPiUxzICehXkBy0WQSKdfE5raZadfIbcncqldj1P9xgM+f1/+OY3aGtr4+zZsxlv4cKFC+zcuZMDBw6wbFnlcjhL3jBYpe4hDEjbvBDPG+oOoGmibEE0haJc6rwuek+PIaUkMBzB0+yseFykp8VJ6ECUZCJFaCxa8Q2Pq84+o8Ftwh9DCCoKUWlWjVRaZkamgDKb2zLrFeimNptjmO4x+IfDxKJJWtKDgwYHBzP/t3r1ag4dOkRLS3WmLS75Ehar0F293mh8XojnDXUHaMwxqUmhmG3qvS7ikSThgD4xrJJSVYO6ZidSQnA0UpFOkkFNnZ1ELEUsMtnxHxqP4vLYK5KyMXIMqZREpnRvoRKjqOXoVC6363nqmrk7qquN8hjSktvd4RjLShjhNxtIKRnqCdC5bX7OWFYsbrIrkwK+SFXCVIZxGeoOkoinyq5IMsj0MvhjGZ2wSprbDCyZqp9UxjBUgmZJdyrLyRx2sRLYfLLbk2tqIPXqJjFtnXPnzlW03xnvVdXVFhipVBK7RW8MOheKznniOTQWJRyI06ryC4o5oKFV/1sY6vYTnUhUVKpqYPQy9L+l5wUq9hjS3c/ZKqsT47GK8gugS04ApBJpj6HCWSbZhsag3K7nzB4LNLlVmyVtGGLhcEZZdSSVmvPmNkNqWyWeFXOBnlOAnhN6sriSUlUDd6MDoQn63hoDqmAY6mcK6VXDY8huIJOp8uYw5Fov+yI+veu5/D0qwzCrGLMYUqk4UeZ+QM9QTwAhoHnl3Ia0FEsTi1XD3eTMVBFV0vVsoFn0XoahnrRwZYWGYbrCqkxJwhXIYWTvEyARS1cOVegxTDcMubqey93jpZjLsKQNgzG9LZ7SS/Ra59owdAcqqp1WKCrFSEBDdTwG0A2M0TxW6VhTl8eOEJOGIRKKk0rJyg1DeiSnMQCrGjkGmLyIV9L1bGBRoaRLQyQQwK45SUjdMMy1gF4hqW2F4lJQn84z2JwWHLXVqU0xchUuj61iTSdN0zunDSG9yR6GyqXmNYvIlJhWcgGHrFnS6UlwpXY951tTaJNrziZL2jAEhrqxa05iUu/M9LrnLscQGo8yMR5T+QXFnGJUJtVVoYfBwKhMqjS/YFBT58jIYBj/VuqJwFQBSkNxtVyEEPos6bRBKHfW83Qu1YjPJW0YxvvP49BcxESU5lo79hxxxTNdQ/injSecDVTHs2I+YBiGavQwGBi5iuoZBltGFmNSQK8KHkOWMaiG7phmEaRSk0OKjMeyMSu7bZA9T/q+++6b8vwnnnii4j0bLOk+hsBwP82WTsaJ5yxVDQdj/Orbr7PuqlZu/y9bZ3UvQ90BENCySiWeFXNHtsdQLYy1qukxjA3oVU6hCgX0sjE8BqFRFW8pe/Zzvq5nQ3Yb9Au92+3mM5/5jKk1QVdXLfT8clnShmFidBi75iIoc5eqdh8bAQnnj/pIxlMVx0cLMdQdoKG1JtO0o1DMBfWtLmrq7VXVYDK8j0orkgxcdXYmAjGklEz4Y1jtGjZH5QUbv//Xhxg4cwYEVVkvGU/RsKyDOz/5yYq7ng0uVffzkg4lxQIhrJoNn5Q5E8/dx3wAxCNJek7O7qTToe6ACiMp5hyrzcKHv3I9669uq9qa7kYH1969lg27Kxd3Az1slIyniEeSmclt1bjDr1ZOJWtBZLpTuZzBP3v37s2EiYyv6268hmdfeIZUusrrgQce4IorruAjH/kIo6OjVdv6kr49TYVTUAt90jpj1rNMSbqPj3DZzla6j/s42zXE6lmSqggHYgRHKxcYUyjmI0IIrnr76qqtly2LMeGPViXxDHDjf/4oo30hrE5oaqureL1wMEbAFyGZlGV1PU8X0QO9PNc/HCaVlPzZn/0Z9957L0II7r33Xj796U/z0EMPVbxvWOKGQcQsUAv9wsXOaR7D4PkAkWCctdtbEBqcPTLMjSlZsSuYC5V4VijMU5PV5DYxHqNpeXWUiC1WLT20pzphmuyGtGRCYneWZhimy26D3ij3N5/7Eu9493+irW3Sq/voRz/KXXfdVfmm0yxpw6Al9Q/YBeHhjmk5hvNHh0HAqs1NCE1w+tAg/W+Ns2J9Q9X3MWgYBpV4ViiKki2LMeGPsfLyxqqsq2mC5pVugsFA8SebWS+rIU3vei7tcpvLY0gmUvguBkklU/T19bF8+XIAfvazn7F1a/UKZJa0YbBK3RgMW5wzqpLOHxuhbXUdLredzi3NaFbBma6hWTEMw90B6rwuHDWVDUVRKJYChiyGMe2wGhVJBppWmdz2lLXShiERT1Xc9ZxZU5sU+/vc5z5HV1cXQghWr17Nt7/97YrXN1jShsGCbgz8yCmGIRyIMXjez+671gBgd1lZtamJM11D7HnPuqonqYZ6Ang7Ko9pKhRLAafbhtAEwxf1O/tKlVVnC+MiPtlNXfi6UUx2G7K6n5OS73//+xXvMR9LuirJJvT2/7AGTTWTdx3dx/Uy1Y4tzZnH1m73EvBFGL4QrOoe9GRShNZOlV9QKMygaQKX24Yv/bdYTY+hmuj5Cs20YTCL3uQ2u93PS9swWFykZBKPxzklqXz+qA+XxzZlLsKaK1oQAs68OlTVPQz1GPkFZRgUCrPU1NsZ7ZvQv69C1/NsYUxy07+vzuU2e83Z4pIbBiHEKiHEM0KIE0KIY0KIv0g/3iSE+K0Q4lT63+pklApgs7iIJ8O0ZZW7pVKSnuMjdGxuntIW7/LYWb6ugTNdVTYMagaDQlEyNR57ppZ/voaSYKqXUKlia/aas62XNBceQwL4tJRyE3At8OdCiM3AF4CnpJTrgafSP88aqWQSm1ZDPDkxJb8weN5PJBSnY2vTjNes3e5lpDfE2OBE1fYx1BPA0+SsaJC5QrHUyPYSXHXz92/HMAxGbqAqa1pnzpOuNpfcMEgp+6SUr6S/DwAngHbgncDD6ac9DNw9m/tIxaLYLU5iqamGofuoDyGgY1PzjNesuVJvcKum1zDUHcCr8gsKRUm40obB6bZVNC5ztjH2Vq38gr6W0R+xiAxDNkKI1cAO4GWgTUrZB7rxAFpn873jkZCurCojUwzD+aM+2tbU5byDr2tx0bLKzdkqGYZoOMH4YFjlFxSKEjE8htp5mng2MAxCNY3XpRjYI2ZbjCnvGwvhBp4F7pdS/lQIMSalbMj6/1Ep5Yw8gxDiY8DHANra2q569NFHy3r/wZOHufL05QxHz7D/2k3sabeRiEje+DeJd6ugdWtuCz90TDL4umTDOwU2V2V3AaFBybmnJR03CDwrKr+jCAaDuN2Lp0lusR0PLL5jmqvjGTsnufiSpLYNVt9U/kW3vr6edevWTXksmUxisVRnimIyJokFwWIHu3vm37jP5+Md73gHAAMDA1gsFlpa9MjEM888g90+0/ClEpKoH+xu+OeHvs2DDz6I1Wrl9ttv52//9m9nPP/UqVP4/f4pj910002HpZS78u17TvoYhBA24DHgESnlT9MPDwghlksp+4QQy4HBXK+VUj4IPAiwa9cuuW/fvrL28JPXnsKuOQnLKDdds4Pr1rXwxsv9vMFx9v3hVbR25u4r8G0I8ujrB1heu4GtN7SX9d4GXU92c47T3HzXnqpUVuzfv59yfx/zkcV2PLD4jmmujqfn5AgXX+pi5epl7Nu3uex1Tpw4gccz1WMPBAIzHiuXeDRJLBjC4bTj9swU6vR4PBw5cgQwJ7sNevdz1B/kpZde4j/+4z84evQoDoeDwcHBnPsWQpR8ji65YRB6d9h3gBNSym9k/dfjwIeAv0//+/PZ3EfSP4ZNcxASCVanQ0lGmWqh0E7T8lrqW12c6Rqq2DAMdQeobXDM63I7hWI+YvzNVPNvZ+zf3yLWGyKZTBAuUb4iH9blNXBlK1qOIWDlolkEdc0uvvPdf+YLX/gCDodeldXaWr3o+1zkGPYAfwK8TQjRlf66E90g3CqEOAXcmv559gjp4zz9IsmyeieplKT7uI+OLc0FqweEEKzd7uXiyVGiE/GKtqCkthWK8nA3OPQLpLd6k+ZmA00IGtpqcNaWXjmVS3Z7+/btPPXUUzjdNk6dPsXzzz/PNddcw4033sjBgwertu9L7jFIKV8A8l15b75U+9AiEpwwbrHidljpPzNONJSgc8vMaqTprN3u5dXfdHPudR+XX1OexnwskmB0YIJ1u6qne69QLBUcNTbu+Zvd1LdUzzA0/OFlQHVDSZWQS0Qvm0QiwejoKC+99BIHDx7kve99L2fOnKmKZM+S1UqyxDRwQqhGzyWcP6aXqa7aPLN/YTptq+uoqbdzpmuobMPguxAEyZTuaoVCYZ5qyW3PV3LJbgN87Wtf45ZbbmHlypW8+93vRgjB7t270TSN4eFhvF5vxe+9dA1DUnftInW6h9BtlKmacPmEJlh7pZeTL/WRiCWx2kuvYBhUMxgUCkUBinkMd999N08//TT79u3jzTffJBaLZSqaKmX+dobMMlaZrhDwtjPhjzF4PkDn1uJhJIO1270kYildcK8MhrsDuOrs81YATKFQzG8+8pGPcObMGbZu3cr73vc+Hn744aopPy9Zj8Galtyu9TbSc1yf7dxhIr9gsOLyBhw1Vs52DbF2e+mu22B3gNYOT/XnzCoUigWJGdntbOx2Oz/4wQ9mZS9L1mOwCRdSpmhudHH+2EjRMtXpWCwaq7e1cPb14ZIFreKxJKN9IRVGUigU85IlbBhqiCcjtHqcpspUc7F2u5doKEHvqbGSXue7EERKlV9QKBTzk6VrGCwu4qkJaoNJvUy1hPyCwaotTVhtGme6hkt63ZBKPCsUinnM0jUMWg2x5ATxixN6meqm4mWqM9awW1i1uYmzrw2VJIE71BPAWWvD3Th/deQVCsXSZekaBouLeCrMyGk/bWvqy+pMBFi7w0twNMrg+Zn1xrmQUjJ4TpfaVolnhUIxH1mShkFKid3iIpaKMtxdWpnqdFZva0FoouiMhlQyxamDA/zo7w7iuxikfUNDwecrFArFXLEky1WjoSB2zUk0rcxRiWFw1tpo39DAmVeH+IO7L5vx/4l4kpMv9vPqb7vxD4VpXFbDzR/axIbdSgpDoVjq+Hw+br5ZVwLq7+/HYrFkOpcPHDiQU3bb4J577uGNN94AYGxsjIaGBrq6uqqyryVpGEbOn9Cnt2HDVWenZWVlevJrt3t57tE3GekLZdr0Y5EEx57rpeupbibGY7R2etjz8W2subKlaiP+FArFwqa5uTlzMTcru23wox/9KPP9pz/9aerr66u2ryVpGMbPncXDCqLU0Lm5qeIL9ZordcNwpmsIl8fGkacv8Pr+C0QnEqzc2MgtH97MyssbVU5BoZjH/OpXv6K/v7+qg3qWLVvGHXfcUZW18iGl5Mc//jFPP/101dZckobB39uLhxXEpZXLKwgjGbgbHbStqePI0z0c/tU5ErEUa7d72Xl7J21rcg/8USgUikIUE9EzeP7552lra2P9+vVVe+8laRiCQ/qYu7gUZZWp5uLya5bxwo9PsWF3Gztu71z0yo8KxWLDuLNfKLLbBj/84Q95//vfX9X3XpKGIR7Qh/RIR7zsMtXpbL2xnU3XLS9LaVWhUCimY8ZjSCQS/PSnP+Xw4cNVfe8laRjkhBVc4Git3uELIZRRUCgUVcOMx/Dkk0+yceNGVq5cWdX3XpJ9DCKhx/3bryhvyI5CoVDMBx599NGqh5FgiXoMcWeS3onzbLn+zrneikKhUACly24DfO9736v6PmCJegx/+PUvMPHuldQ2VCfxrFAoFIuJJWkYFAqFQpEfZRgUCsWSphRl5IVGucemDINCoViyOJ1OfD7fojQOUkp8Ph/JZLLk1y7J5LNCoVAArFy5kgsXLjA0NKmOHIlEcDqdc7ir6uF0OgmFQiW/ThkGhUKxZLHZbKxZs2bKY/v372fHjh1ztKPqc/78+ZJfo0JJCoVCoZiCMgwKhUKhmIIyDAqFQqGYgljI2XghxBBQegBNpwUYruJ25gOL7ZgW2/HA4jumxXY8sPiOKdfxdEopvflesKANQyUIIQ5JKXfN9T6qyWI7psV2PLD4jmmxHQ8svmMq53hUKEmhUCgUU1CGQaFQKBRTWMqG4cG53sAssNiOabEdDyy+Y1psxwOL75hKPp4lm2NQKBQKRW6WssegUCgUihwow6BQKBSKKSxJwyCEeLsQ4g0hxGkhxBfmej+VIoQ4J4R4XQjRJYQ4NNf7KQchxENCiEEhxNGsx5qEEL8VQpxK/9s4l3sshTzHc58Q4mL6PHUJIRbUCEEhxCohxDNCiBNCiGNCiL9IP74gz1OB41mw50kI4RRCHBBCvJY+pi+mH18jhHg5fY5+JISwF1xnqeUYhBAW4E3gVuACcBB4v5Ty+JxurAKEEOeAXVLKBduUI4S4AQgC/yKl3Jp+7KvAiJTy79MGvFFK+fm53KdZ8hzPfUBQSvm1udxbuQghlgPLpZSvCCE8wGHgbuD/YQGepwLH814W6HkSQgigVkoZFELYgBeAvwD+EviplPJRIcS3gNeklP+Ub52l6DHsBk5LKc9IKWPAo8A753hPSx4p5XPAyLSH3wk8nP7+YfQ/2gVBnuNZ0Egp+6SUr6S/DwAngHYW6HkqcDwLFqkTTP9oS39J4G3AT9KPFz1HS9EwtAM9WT9fYIF/GNBP/G+EEIeFEB+b681UkTYpZR/of8RA6xzvpxp8UghxJB1qWhAhl1wIIVYDO4CXWQTnadrxwAI+T0IIixCiCxgEfgu8BYxJKRPppxS95i1FwyByPLbQ42l7pJQ7gTuAP0+HMRTzj38CLgO2A33A1+d2O+UhhHADjwH/VUrpn+v9VEqO41nQ50lKmZRSbgdWokdINuV6WqE1lqJhuACsyvp5JdA7R3upClLK3vS/g8DP0D8Mi4GBdBzYiAcPzvF+KkJKOZD+o00B/8wCPE/puPVjwCNSyp+mH16w5ynX8SyG8wQgpRwD9gPXAg1CCGMwW9Fr3lI0DAeB9eksvR14H/D4HO+pbIQQtenEGUKIWuA24GjhVy0YHgc+lP7+Q8DP53AvFWNcPNO8iwV2ntKJze8AJ6SU38j6rwV5nvIdz0I+T0IIrxCiIf29C7gFPXfyDPCe9NOKnqMlV5UEkC4/+yZgAR6SUt4/x1sqGyHEWnQvAfRRrf93IR6PEOKHwD50ieAB4L8D/wb8GOgAuoE/klIuiIRunuPZhx6ekMA54ONGbH4hIIS4HngeeB1IpR/+K/S4/II7TwWO5/0s0PMkhLgCPblsQb/x/7GU8kvp68SjQBPwKvDHUspo3nWWomFQKBQKRX6WYihJoVAoFAVQhkGhUCgUU1CGQaFQKBRTUIZBoVAoFFNQhkGhUCgUU1CGQaG4hAgh9gkhfjHX+1AoCqEMg0KhUCimoAyDQpEDIcQfp3Xtu4QQ304LkwWFEF8XQrwihHhKCOFNP3e7EOKltOjazwzRNSHEOiHEk2lt/FeEEJell3cLIX4ihDgphHgk3YGLEOLvhRDH0+ssOMlnxeJBGQaFYhpCiE3APejihNuBJPBBoBZ4JS1Y+Cx6NzPAvwCfl1Jegd5Fazz+CPCPUsorgevQBdlAV/H8r8BmYC2wRwjRhC6/sCW9zt/N7lEqFPlRhkGhmMnNwFXAwbR88c3oF/AU8KP0c34AXC+EqAcapJTPph9/GLghrV/VLqX8GYCUMiKlnEg/54CU8kJapK0LWA34gQjwf4QQ7waM5yoUlxxlGBSKmQjgYSnl9vTX5VLK+3I8r5CeTC55d4NsjZokYE1r5e9GV/q8G/h1iXtWKKqGMgwKxUyeAt4jhGiFzEzjTvS/F0Oh8gPAC1LKcWBUCLE3/fifAM+mdf0vCCHuTq/hEELU5HvD9EyAeinlE+hhpu2zcWAKhRmsxZ+iUCwtpJTHhRB/gz4VTwPiwJ8DIWCLEOIwMI6ehwBdxvhb6Qv/GeDD6cf/BPi2EOJL6TX+qMDbeoCfCyGc6N7Gp6p8WAqFaZS6qkJhEiFEUErpnut9KBSzjQolKRQKhWIKymNQKBQKxRSUx6BQKBSKKSjDoFAoFIopKMOgUCgUiikow6BQKBSKKSjDoFAoFIop/P9Z78tw7DbyxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma_sel = 0\n",
    "\n",
    "title_name = 'Sigma ='+str(sigma_array[sigma_sel])\n",
    "plt.plot(plot_acc[0,sigma_sel,:],label='T=0')\n",
    "plt.plot(plot_acc[1,sigma_sel,:],label='T=1')\n",
    "plt.plot(plot_acc[2,sigma_sel,:],label='T=2')\n",
    "plt.plot(plot_acc[3,sigma_sel,:],label='T=3')\n",
    "plt.plot(plot_acc_v2[0,sigma_sel,:],label='T=4')\n",
    "plt.plot(plot_acc_v2[1,sigma_sel,:],label='T=5')\n",
    "plt.plot(plot_acc_v2[2,sigma_sel,:],label='T=6')\n",
    "plt.plot(plot_acc_v2[3,sigma_sel,:],label='T=7')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()\n",
    "\n",
    "sigma_sel = 1\n",
    "\n",
    "title_name = 'Sigma ='+str(sigma_array[sigma_sel])\n",
    "plt.plot(plot_acc[0,sigma_sel,:],label='T=0')\n",
    "plt.plot(plot_acc[1,sigma_sel,:],label='T=1')\n",
    "plt.plot(plot_acc[2,sigma_sel,:],label='T=2')\n",
    "plt.plot(plot_acc[3,sigma_sel,:],label='T=3')\n",
    "plt.plot(plot_acc_v2[0,sigma_sel,:],label='T=4')\n",
    "plt.plot(plot_acc_v2[1,sigma_sel,:],label='T=5')\n",
    "plt.plot(plot_acc_v2[2,sigma_sel,:],label='T=6')\n",
    "plt.plot(plot_acc_v2[3,sigma_sel,:],label='T=7')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()\n",
    "\n",
    "sigma_sel = 2\n",
    "\n",
    "title_name = 'Sigma ='+str(sigma_array[sigma_sel])\n",
    "plt.plot(plot_acc[0,sigma_sel,:],label='T=0')\n",
    "# plt.plot(plot_acc[1,sigma_sel,:],label='T=1')\n",
    "plt.plot(plot_acc[2,sigma_sel,:],label='T=2')\n",
    "plt.plot(plot_acc[3,sigma_sel,:],label='T=3')\n",
    "plt.plot(plot_acc_v2[0,sigma_sel,:],label='T=4')\n",
    "# plt.plot(plot_acc_v2[1,sigma_sel,:],label='T=5')\n",
    "# plt.plot(plot_acc_v2[2,sigma_sel,:],label='T=6')\n",
    "plt.plot(plot_acc_v2[3,sigma_sel,:],label='T=7')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T, sigma)= 0 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2580 \n",
      "Accuracy: 5752/10000 (57.52%)\n",
      "\n",
      "Round   1, Average loss 2.258 Test accuracy 57.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2482 \n",
      "Accuracy: 9458/10000 (94.58%)\n",
      "\n",
      "Round   2, Average loss 0.248 Test accuracy 94.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1686 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round   3, Average loss 0.169 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1489 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round   4, Average loss 0.149 Test accuracy 95.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1441 \n",
      "Accuracy: 9601/10000 (96.01%)\n",
      "\n",
      "Round   5, Average loss 0.144 Test accuracy 96.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1750 \n",
      "Accuracy: 9587/10000 (95.87%)\n",
      "\n",
      "Round   6, Average loss 0.175 Test accuracy 95.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1909 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round   7, Average loss 0.191 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1670 \n",
      "Accuracy: 9620/10000 (96.20%)\n",
      "\n",
      "Round   8, Average loss 0.167 Test accuracy 96.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2213 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round   9, Average loss 0.221 Test accuracy 95.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1568 \n",
      "Accuracy: 9611/10000 (96.11%)\n",
      "\n",
      "Round  10, Average loss 0.157 Test accuracy 96.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2001 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  11, Average loss 0.200 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1790 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  12, Average loss 0.179 Test accuracy 96.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2030 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  13, Average loss 0.203 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1668 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  14, Average loss 0.167 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1703 \n",
      "Accuracy: 9594/10000 (95.94%)\n",
      "\n",
      "Round  15, Average loss 0.170 Test accuracy 95.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1829 \n",
      "Accuracy: 9605/10000 (96.05%)\n",
      "\n",
      "Round  16, Average loss 0.183 Test accuracy 96.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2016 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  17, Average loss 0.202 Test accuracy 95.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2518 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  18, Average loss 0.252 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2048 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  19, Average loss 0.205 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1970 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  20, Average loss 0.197 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1969 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  21, Average loss 0.197 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2053 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  22, Average loss 0.205 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2004 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  23, Average loss 0.200 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2271 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  24, Average loss 0.227 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1766 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  25, Average loss 0.177 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1969 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  26, Average loss 0.197 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1686 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  27, Average loss 0.169 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1828 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  28, Average loss 0.183 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1953 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  29, Average loss 0.195 Test accuracy 95.570\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "(T, sigma)= 0 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3003 \n",
      "Accuracy: 1967/10000 (19.67%)\n",
      "\n",
      "Round   1, Average loss 2.300 Test accuracy 19.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5129 \n",
      "Accuracy: 8752/10000 (87.52%)\n",
      "\n",
      "Round   2, Average loss 1.513 Test accuracy 87.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4513 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round   3, Average loss 0.451 Test accuracy 95.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2146 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round   4, Average loss 0.215 Test accuracy 94.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2644 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round   5, Average loss 0.264 Test accuracy 94.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2227 \n",
      "Accuracy: 9446/10000 (94.46%)\n",
      "\n",
      "Round   6, Average loss 0.223 Test accuracy 94.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2057 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round   7, Average loss 0.206 Test accuracy 95.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1720 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round   8, Average loss 0.172 Test accuracy 94.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1778 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round   9, Average loss 0.178 Test accuracy 95.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1500 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  10, Average loss 0.150 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1553 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  11, Average loss 0.155 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1612 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  12, Average loss 0.161 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1519 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  13, Average loss 0.152 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1594 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  14, Average loss 0.159 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1453 \n",
      "Accuracy: 9599/10000 (95.99%)\n",
      "\n",
      "Round  15, Average loss 0.145 Test accuracy 95.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1641 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round  16, Average loss 0.164 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1691 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  17, Average loss 0.169 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1604 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  18, Average loss 0.160 Test accuracy 95.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1605 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  19, Average loss 0.161 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1462 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  20, Average loss 0.146 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1723 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  21, Average loss 0.172 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2183 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  22, Average loss 0.218 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2140 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  23, Average loss 0.214 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2133 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  24, Average loss 0.213 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2271 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round  25, Average loss 0.227 Test accuracy 95.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1990 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  26, Average loss 0.199 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1802 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  27, Average loss 0.180 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1558 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  28, Average loss 0.156 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2074 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  29, Average loss 0.207 Test accuracy 95.710\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T, sigma)= 1 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3022 \n",
      "Accuracy: 1162/10000 (11.62%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3010 \n",
      "Accuracy: 8496/10000 (84.96%)\n",
      "\n",
      "Round   1, Average loss 1.301 Test accuracy 84.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4299 \n",
      "Accuracy: 9175/10000 (91.75%)\n",
      "\n",
      "Round   2, Average loss 0.430 Test accuracy 91.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3336 \n",
      "Accuracy: 9084/10000 (90.84%)\n",
      "\n",
      "Round   3, Average loss 0.334 Test accuracy 90.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3223 \n",
      "Accuracy: 9059/10000 (90.59%)\n",
      "\n",
      "Round   4, Average loss 0.322 Test accuracy 90.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3085 \n",
      "Accuracy: 9036/10000 (90.36%)\n",
      "\n",
      "Round   5, Average loss 0.309 Test accuracy 90.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3249 \n",
      "Accuracy: 9026/10000 (90.26%)\n",
      "\n",
      "Round   6, Average loss 0.325 Test accuracy 90.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2722 \n",
      "Accuracy: 9241/10000 (92.41%)\n",
      "\n",
      "Round   7, Average loss 0.272 Test accuracy 92.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3115 \n",
      "Accuracy: 8990/10000 (89.90%)\n",
      "\n",
      "Round   8, Average loss 0.312 Test accuracy 89.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3813 \n",
      "Accuracy: 8879/10000 (88.79%)\n",
      "\n",
      "Round   9, Average loss 0.381 Test accuracy 88.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4142 \n",
      "Accuracy: 8771/10000 (87.71%)\n",
      "\n",
      "Round  10, Average loss 0.414 Test accuracy 87.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3277 \n",
      "Accuracy: 8980/10000 (89.80%)\n",
      "\n",
      "Round  11, Average loss 0.328 Test accuracy 89.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3264 \n",
      "Accuracy: 8954/10000 (89.54%)\n",
      "\n",
      "Round  12, Average loss 0.326 Test accuracy 89.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3523 \n",
      "Accuracy: 8913/10000 (89.13%)\n",
      "\n",
      "Round  13, Average loss 0.352 Test accuracy 89.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4060 \n",
      "Accuracy: 8740/10000 (87.40%)\n",
      "\n",
      "Round  14, Average loss 0.406 Test accuracy 87.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3256 \n",
      "Accuracy: 8993/10000 (89.93%)\n",
      "\n",
      "Round  15, Average loss 0.326 Test accuracy 89.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4214 \n",
      "Accuracy: 8730/10000 (87.30%)\n",
      "\n",
      "Round  16, Average loss 0.421 Test accuracy 87.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3340 \n",
      "Accuracy: 8972/10000 (89.72%)\n",
      "\n",
      "Round  17, Average loss 0.334 Test accuracy 89.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4038 \n",
      "Accuracy: 8722/10000 (87.22%)\n",
      "\n",
      "Round  18, Average loss 0.404 Test accuracy 87.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4095 \n",
      "Accuracy: 8812/10000 (88.12%)\n",
      "\n",
      "Round  19, Average loss 0.409 Test accuracy 88.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7288 \n",
      "Accuracy: 7858/10000 (78.58%)\n",
      "\n",
      "Round  20, Average loss 0.729 Test accuracy 78.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7031 \n",
      "Accuracy: 7677/10000 (76.77%)\n",
      "\n",
      "Round  21, Average loss 0.703 Test accuracy 76.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3728 \n",
      "Accuracy: 8824/10000 (88.24%)\n",
      "\n",
      "Round  22, Average loss 0.373 Test accuracy 88.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4029 \n",
      "Accuracy: 9006/10000 (90.06%)\n",
      "\n",
      "Round  23, Average loss 0.403 Test accuracy 90.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4431 \n",
      "Accuracy: 8558/10000 (85.58%)\n",
      "\n",
      "Round  24, Average loss 0.443 Test accuracy 85.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4129 \n",
      "Accuracy: 8926/10000 (89.26%)\n",
      "\n",
      "Round  25, Average loss 0.413 Test accuracy 89.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4194 \n",
      "Accuracy: 8674/10000 (86.74%)\n",
      "\n",
      "Round  26, Average loss 0.419 Test accuracy 86.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4341 \n",
      "Accuracy: 8684/10000 (86.84%)\n",
      "\n",
      "Round  27, Average loss 0.434 Test accuracy 86.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7835 \n",
      "Accuracy: 7373/10000 (73.73%)\n",
      "\n",
      "Round  28, Average loss 0.783 Test accuracy 73.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5555 \n",
      "Accuracy: 8516/10000 (85.16%)\n",
      "\n",
      "Round  29, Average loss 0.555 Test accuracy 85.160\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 1 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 7 10000 \n",
      "\n",
      "(T, sigma)= 1 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2934 \n",
      "Accuracy: 4966/10000 (49.66%)\n",
      "\n",
      "Round   1, Average loss 2.293 Test accuracy 49.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1874 \n",
      "Accuracy: 8942/10000 (89.42%)\n",
      "\n",
      "Round   2, Average loss 1.187 Test accuracy 89.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6606 \n",
      "Accuracy: 9131/10000 (91.31%)\n",
      "\n",
      "Round   3, Average loss 0.661 Test accuracy 91.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7435 \n",
      "Accuracy: 9278/10000 (92.78%)\n",
      "\n",
      "Round   4, Average loss 0.743 Test accuracy 92.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5729 \n",
      "Accuracy: 9180/10000 (91.80%)\n",
      "\n",
      "Round   5, Average loss 0.573 Test accuracy 91.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6380 \n",
      "Accuracy: 9267/10000 (92.67%)\n",
      "\n",
      "Round   6, Average loss 0.638 Test accuracy 92.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6087 \n",
      "Accuracy: 9181/10000 (91.81%)\n",
      "\n",
      "Round   7, Average loss 0.609 Test accuracy 91.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4962 \n",
      "Accuracy: 9218/10000 (92.18%)\n",
      "\n",
      "Round   8, Average loss 0.496 Test accuracy 92.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5751 \n",
      "Accuracy: 9121/10000 (91.21%)\n",
      "\n",
      "Round   9, Average loss 0.575 Test accuracy 91.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5018 \n",
      "Accuracy: 9073/10000 (90.73%)\n",
      "\n",
      "Round  10, Average loss 0.502 Test accuracy 90.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5174 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round  11, Average loss 0.517 Test accuracy 92.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6589 \n",
      "Accuracy: 9143/10000 (91.43%)\n",
      "\n",
      "Round  12, Average loss 0.659 Test accuracy 91.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4748 \n",
      "Accuracy: 8992/10000 (89.92%)\n",
      "\n",
      "Round  13, Average loss 0.475 Test accuracy 89.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5540 \n",
      "Accuracy: 9216/10000 (92.16%)\n",
      "\n",
      "Round  14, Average loss 0.554 Test accuracy 92.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6218 \n",
      "Accuracy: 9153/10000 (91.53%)\n",
      "\n",
      "Round  15, Average loss 0.622 Test accuracy 91.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6014 \n",
      "Accuracy: 8517/10000 (85.17%)\n",
      "\n",
      "Round  16, Average loss 0.601 Test accuracy 85.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4605 \n",
      "Accuracy: 9188/10000 (91.88%)\n",
      "\n",
      "Round  17, Average loss 0.460 Test accuracy 91.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5645 \n",
      "Accuracy: 9177/10000 (91.77%)\n",
      "\n",
      "Round  18, Average loss 0.564 Test accuracy 91.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6336 \n",
      "Accuracy: 8986/10000 (89.86%)\n",
      "\n",
      "Round  19, Average loss 0.634 Test accuracy 89.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4640 \n",
      "Accuracy: 9220/10000 (92.20%)\n",
      "\n",
      "Round  20, Average loss 0.464 Test accuracy 92.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5915 \n",
      "Accuracy: 9079/10000 (90.79%)\n",
      "\n",
      "Round  21, Average loss 0.592 Test accuracy 90.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4724 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round  22, Average loss 0.472 Test accuracy 92.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6785 \n",
      "Accuracy: 9205/10000 (92.05%)\n",
      "\n",
      "Round  23, Average loss 0.679 Test accuracy 92.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3949 \n",
      "Accuracy: 9252/10000 (92.52%)\n",
      "\n",
      "Round  24, Average loss 0.395 Test accuracy 92.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5251 \n",
      "Accuracy: 9280/10000 (92.80%)\n",
      "\n",
      "Round  25, Average loss 0.525 Test accuracy 92.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6104 \n",
      "Accuracy: 9114/10000 (91.14%)\n",
      "\n",
      "Round  26, Average loss 0.610 Test accuracy 91.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4108 \n",
      "Accuracy: 9232/10000 (92.32%)\n",
      "\n",
      "Round  27, Average loss 0.411 Test accuracy 92.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5061 \n",
      "Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Round  28, Average loss 0.506 Test accuracy 92.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6012 \n",
      "Accuracy: 9165/10000 (91.65%)\n",
      "\n",
      "Round  29, Average loss 0.601 Test accuracy 91.650\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T, sigma)= 2 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4617 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round   0, Average loss 2.462 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6063 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round   1, Average loss 3.606 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6820 \n",
      "Accuracy: 7752/10000 (77.52%)\n",
      "\n",
      "Round   2, Average loss 0.682 Test accuracy 77.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1002 \n",
      "Accuracy: 6904/10000 (69.04%)\n",
      "\n",
      "Round   3, Average loss 3.100 Test accuracy 69.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4008 \n",
      "Accuracy: 7707/10000 (77.07%)\n",
      "\n",
      "Round   4, Average loss 2.401 Test accuracy 77.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.1105 \n",
      "Accuracy: 6314/10000 (63.14%)\n",
      "\n",
      "Round   5, Average loss 7.111 Test accuracy 63.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3276 \n",
      "Accuracy: 8341/10000 (83.41%)\n",
      "\n",
      "Round   6, Average loss 4.328 Test accuracy 83.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.5041 \n",
      "Accuracy: 4378/10000 (43.78%)\n",
      "\n",
      "Round   7, Average loss 32.504 Test accuracy 43.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0890 \n",
      "Accuracy: 8844/10000 (88.44%)\n",
      "\n",
      "Round   8, Average loss 3.089 Test accuracy 88.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 114.6360 \n",
      "Accuracy: 1155/10000 (11.55%)\n",
      "\n",
      "Round   9, Average loss 114.636 Test accuracy 11.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2045 \n",
      "Accuracy: 8083/10000 (80.83%)\n",
      "\n",
      "Round  10, Average loss 4.205 Test accuracy 80.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 44.5524 \n",
      "Accuracy: 3888/10000 (38.88%)\n",
      "\n",
      "Round  11, Average loss 44.552 Test accuracy 38.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9588 \n",
      "Accuracy: 8683/10000 (86.83%)\n",
      "\n",
      "Round  12, Average loss 3.959 Test accuracy 86.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 106.5490 \n",
      "Accuracy: 1273/10000 (12.73%)\n",
      "\n",
      "Round  13, Average loss 106.549 Test accuracy 12.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.8800 \n",
      "Accuracy: 8217/10000 (82.17%)\n",
      "\n",
      "Round  14, Average loss 3.880 Test accuracy 82.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 26.7484 \n",
      "Accuracy: 5926/10000 (59.26%)\n",
      "\n",
      "Round  15, Average loss 26.748 Test accuracy 59.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.1414 \n",
      "Accuracy: 8009/10000 (80.09%)\n",
      "\n",
      "Round  16, Average loss 10.141 Test accuracy 80.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 41.5282 \n",
      "Accuracy: 5071/10000 (50.71%)\n",
      "\n",
      "Round  17, Average loss 41.528 Test accuracy 50.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.1043 \n",
      "Accuracy: 8621/10000 (86.21%)\n",
      "\n",
      "Round  18, Average loss 5.104 Test accuracy 86.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 69.5499 \n",
      "Accuracy: 3294/10000 (32.94%)\n",
      "\n",
      "Round  19, Average loss 69.550 Test accuracy 32.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5699 \n",
      "Accuracy: 8766/10000 (87.66%)\n",
      "\n",
      "Round  20, Average loss 2.570 Test accuracy 87.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 130.2925 \n",
      "Accuracy: 1443/10000 (14.43%)\n",
      "\n",
      "Round  21, Average loss 130.293 Test accuracy 14.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8117 \n",
      "Accuracy: 8118/10000 (81.18%)\n",
      "\n",
      "Round  22, Average loss 4.812 Test accuracy 81.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 53.1064 \n",
      "Accuracy: 3971/10000 (39.71%)\n",
      "\n",
      "Round  23, Average loss 53.106 Test accuracy 39.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.0362 \n",
      "Accuracy: 8625/10000 (86.25%)\n",
      "\n",
      "Round  24, Average loss 5.036 Test accuracy 86.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 53.9478 \n",
      "Accuracy: 4055/10000 (40.55%)\n",
      "\n",
      "Round  25, Average loss 53.948 Test accuracy 40.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0690 \n",
      "Accuracy: 8806/10000 (88.06%)\n",
      "\n",
      "Round  26, Average loss 3.069 Test accuracy 88.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 118.2090 \n",
      "Accuracy: 1341/10000 (13.41%)\n",
      "\n",
      "Round  27, Average loss 118.209 Test accuracy 13.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1466 \n",
      "Accuracy: 7796/10000 (77.96%)\n",
      "\n",
      "Round  28, Average loss 4.147 Test accuracy 77.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 80.9419 \n",
      "Accuracy: 3349/10000 (33.49%)\n",
      "\n",
      "Round  29, Average loss 80.942 Test accuracy 33.490\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 2 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 8 10000 \n",
      "\n",
      "(T, sigma)= 2 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3010 \n",
      "Accuracy: 1837/10000 (18.37%)\n",
      "\n",
      "Round   1, Average loss 2.301 Test accuracy 18.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5819 \n",
      "Accuracy: 8809/10000 (88.09%)\n",
      "\n",
      "Round   2, Average loss 1.582 Test accuracy 88.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4978 \n",
      "Accuracy: 8939/10000 (89.39%)\n",
      "\n",
      "Round   3, Average loss 0.498 Test accuracy 89.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3828 \n",
      "Accuracy: 8836/10000 (88.36%)\n",
      "\n",
      "Round   4, Average loss 0.383 Test accuracy 88.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3176 \n",
      "Accuracy: 9066/10000 (90.66%)\n",
      "\n",
      "Round   5, Average loss 0.318 Test accuracy 90.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3216 \n",
      "Accuracy: 9074/10000 (90.74%)\n",
      "\n",
      "Round   6, Average loss 0.322 Test accuracy 90.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3763 \n",
      "Accuracy: 8558/10000 (85.58%)\n",
      "\n",
      "Round   7, Average loss 0.376 Test accuracy 85.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3392 \n",
      "Accuracy: 8932/10000 (89.32%)\n",
      "\n",
      "Round   8, Average loss 0.339 Test accuracy 89.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3717 \n",
      "Accuracy: 8718/10000 (87.18%)\n",
      "\n",
      "Round   9, Average loss 0.372 Test accuracy 87.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3399 \n",
      "Accuracy: 8888/10000 (88.88%)\n",
      "\n",
      "Round  10, Average loss 0.340 Test accuracy 88.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3179 \n",
      "Accuracy: 9081/10000 (90.81%)\n",
      "\n",
      "Round  11, Average loss 0.318 Test accuracy 90.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2988 \n",
      "Accuracy: 9113/10000 (91.13%)\n",
      "\n",
      "Round  12, Average loss 0.299 Test accuracy 91.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2903 \n",
      "Accuracy: 9220/10000 (92.20%)\n",
      "\n",
      "Round  13, Average loss 0.290 Test accuracy 92.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3082 \n",
      "Accuracy: 9092/10000 (90.92%)\n",
      "\n",
      "Round  14, Average loss 0.308 Test accuracy 90.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3808 \n",
      "Accuracy: 8770/10000 (87.70%)\n",
      "\n",
      "Round  15, Average loss 0.381 Test accuracy 87.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2905 \n",
      "Accuracy: 9122/10000 (91.22%)\n",
      "\n",
      "Round  16, Average loss 0.290 Test accuracy 91.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3111 \n",
      "Accuracy: 9088/10000 (90.88%)\n",
      "\n",
      "Round  17, Average loss 0.311 Test accuracy 90.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2956 \n",
      "Accuracy: 9106/10000 (91.06%)\n",
      "\n",
      "Round  18, Average loss 0.296 Test accuracy 91.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2781 \n",
      "Accuracy: 9161/10000 (91.61%)\n",
      "\n",
      "Round  19, Average loss 0.278 Test accuracy 91.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2932 \n",
      "Accuracy: 9160/10000 (91.60%)\n",
      "\n",
      "Round  20, Average loss 0.293 Test accuracy 91.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3078 \n",
      "Accuracy: 9083/10000 (90.83%)\n",
      "\n",
      "Round  21, Average loss 0.308 Test accuracy 90.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3105 \n",
      "Accuracy: 9084/10000 (90.84%)\n",
      "\n",
      "Round  22, Average loss 0.310 Test accuracy 90.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2971 \n",
      "Accuracy: 9115/10000 (91.15%)\n",
      "\n",
      "Round  23, Average loss 0.297 Test accuracy 91.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3117 \n",
      "Accuracy: 9054/10000 (90.54%)\n",
      "\n",
      "Round  24, Average loss 0.312 Test accuracy 90.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2929 \n",
      "Accuracy: 9174/10000 (91.74%)\n",
      "\n",
      "Round  25, Average loss 0.293 Test accuracy 91.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2845 \n",
      "Accuracy: 9146/10000 (91.46%)\n",
      "\n",
      "Round  26, Average loss 0.285 Test accuracy 91.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2789 \n",
      "Accuracy: 9096/10000 (90.96%)\n",
      "\n",
      "Round  27, Average loss 0.279 Test accuracy 90.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2534 \n",
      "Accuracy: 9266/10000 (92.66%)\n",
      "\n",
      "Round  28, Average loss 0.253 Test accuracy 92.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2953 \n",
      "Accuracy: 9072/10000 (90.72%)\n",
      "\n",
      "Round  29, Average loss 0.295 Test accuracy 90.720\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T, sigma)= 3 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2816 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round   1, Average loss 2.282 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1434 \n",
      "Accuracy: 5968/10000 (59.68%)\n",
      "\n",
      "Round   2, Average loss 1.143 Test accuracy 59.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1342 \n",
      "Accuracy: 7932/10000 (79.32%)\n",
      "\n",
      "Round   3, Average loss 1.134 Test accuracy 79.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8817 \n",
      "Accuracy: 7275/10000 (72.75%)\n",
      "\n",
      "Round   4, Average loss 1.882 Test accuracy 72.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9415 \n",
      "Accuracy: 8497/10000 (84.97%)\n",
      "\n",
      "Round   5, Average loss 0.941 Test accuracy 84.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5183 \n",
      "Accuracy: 8852/10000 (88.52%)\n",
      "\n",
      "Round   6, Average loss 0.518 Test accuracy 88.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5233 \n",
      "Accuracy: 7786/10000 (77.86%)\n",
      "\n",
      "Round   7, Average loss 1.523 Test accuracy 77.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6491 \n",
      "Accuracy: 9085/10000 (90.85%)\n",
      "\n",
      "Round   8, Average loss 0.649 Test accuracy 90.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1560 \n",
      "Accuracy: 7583/10000 (75.83%)\n",
      "\n",
      "Round   9, Average loss 2.156 Test accuracy 75.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5742 \n",
      "Accuracy: 9046/10000 (90.46%)\n",
      "\n",
      "Round  10, Average loss 0.574 Test accuracy 90.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8283 \n",
      "Accuracy: 7937/10000 (79.37%)\n",
      "\n",
      "Round  11, Average loss 1.828 Test accuracy 79.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1522 \n",
      "Accuracy: 8433/10000 (84.33%)\n",
      "\n",
      "Round  12, Average loss 1.152 Test accuracy 84.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0556 \n",
      "Accuracy: 7983/10000 (79.83%)\n",
      "\n",
      "Round  13, Average loss 2.056 Test accuracy 79.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3851 \n",
      "Accuracy: 8255/10000 (82.55%)\n",
      "\n",
      "Round  14, Average loss 1.385 Test accuracy 82.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1991 \n",
      "Accuracy: 7769/10000 (77.69%)\n",
      "\n",
      "Round  15, Average loss 2.199 Test accuracy 77.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7778 \n",
      "Accuracy: 8992/10000 (89.92%)\n",
      "\n",
      "Round  16, Average loss 0.778 Test accuracy 89.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5790 \n",
      "Accuracy: 7451/10000 (74.51%)\n",
      "\n",
      "Round  17, Average loss 2.579 Test accuracy 74.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6342 \n",
      "Accuracy: 9167/10000 (91.67%)\n",
      "\n",
      "Round  18, Average loss 0.634 Test accuracy 91.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8150 \n",
      "Accuracy: 8311/10000 (83.11%)\n",
      "\n",
      "Round  19, Average loss 1.815 Test accuracy 83.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4148 \n",
      "Accuracy: 8332/10000 (83.32%)\n",
      "\n",
      "Round  20, Average loss 1.415 Test accuracy 83.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2828 \n",
      "Accuracy: 8762/10000 (87.62%)\n",
      "\n",
      "Round  21, Average loss 1.283 Test accuracy 87.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3785 \n",
      "Accuracy: 7715/10000 (77.15%)\n",
      "\n",
      "Round  22, Average loss 2.378 Test accuracy 77.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5861 \n",
      "Accuracy: 8311/10000 (83.11%)\n",
      "\n",
      "Round  23, Average loss 1.586 Test accuracy 83.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9214 \n",
      "Accuracy: 7627/10000 (76.27%)\n",
      "\n",
      "Round  24, Average loss 1.921 Test accuracy 76.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9621 \n",
      "Accuracy: 9021/10000 (90.21%)\n",
      "\n",
      "Round  25, Average loss 0.962 Test accuracy 90.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0903 \n",
      "Accuracy: 7804/10000 (78.04%)\n",
      "\n",
      "Round  26, Average loss 2.090 Test accuracy 78.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0475 \n",
      "Accuracy: 8859/10000 (88.59%)\n",
      "\n",
      "Round  27, Average loss 1.047 Test accuracy 88.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7587 \n",
      "Accuracy: 6681/10000 (66.81%)\n",
      "\n",
      "Round  28, Average loss 3.759 Test accuracy 66.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7830 \n",
      "Accuracy: 9185/10000 (91.85%)\n",
      "\n",
      "Round  29, Average loss 0.783 Test accuracy 91.850\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 3 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 9 10000 \n",
      "\n",
      "(T, sigma)= 3 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2216 \n",
      "Accuracy: 7713/10000 (77.13%)\n",
      "\n",
      "Round   1, Average loss 2.222 Test accuracy 77.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5355 \n",
      "Accuracy: 9148/10000 (91.48%)\n",
      "\n",
      "Round   2, Average loss 0.536 Test accuracy 91.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2886 \n",
      "Accuracy: 9327/10000 (93.27%)\n",
      "\n",
      "Round   3, Average loss 0.289 Test accuracy 93.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2894 \n",
      "Accuracy: 9251/10000 (92.51%)\n",
      "\n",
      "Round   4, Average loss 0.289 Test accuracy 92.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2382 \n",
      "Accuracy: 9370/10000 (93.70%)\n",
      "\n",
      "Round   5, Average loss 0.238 Test accuracy 93.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2429 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round   6, Average loss 0.243 Test accuracy 93.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2382 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round   7, Average loss 0.238 Test accuracy 94.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2180 \n",
      "Accuracy: 9378/10000 (93.78%)\n",
      "\n",
      "Round   8, Average loss 0.218 Test accuracy 93.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2298 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round   9, Average loss 0.230 Test accuracy 93.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2283 \n",
      "Accuracy: 9389/10000 (93.89%)\n",
      "\n",
      "Round  10, Average loss 0.228 Test accuracy 93.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2291 \n",
      "Accuracy: 9416/10000 (94.16%)\n",
      "\n",
      "Round  11, Average loss 0.229 Test accuracy 94.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2460 \n",
      "Accuracy: 9334/10000 (93.34%)\n",
      "\n",
      "Round  12, Average loss 0.246 Test accuracy 93.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2194 \n",
      "Accuracy: 9392/10000 (93.92%)\n",
      "\n",
      "Round  13, Average loss 0.219 Test accuracy 93.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2342 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round  14, Average loss 0.234 Test accuracy 93.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2214 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round  15, Average loss 0.221 Test accuracy 93.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2671 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  16, Average loss 0.267 Test accuracy 93.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2318 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  17, Average loss 0.232 Test accuracy 93.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2299 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  18, Average loss 0.230 Test accuracy 93.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2078 \n",
      "Accuracy: 9423/10000 (94.23%)\n",
      "\n",
      "Round  19, Average loss 0.208 Test accuracy 94.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2381 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  20, Average loss 0.238 Test accuracy 93.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2121 \n",
      "Accuracy: 9400/10000 (94.00%)\n",
      "\n",
      "Round  21, Average loss 0.212 Test accuracy 94.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2255 \n",
      "Accuracy: 9364/10000 (93.64%)\n",
      "\n",
      "Round  22, Average loss 0.225 Test accuracy 93.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2476 \n",
      "Accuracy: 9416/10000 (94.16%)\n",
      "\n",
      "Round  23, Average loss 0.248 Test accuracy 94.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2262 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round  24, Average loss 0.226 Test accuracy 93.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2368 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round  25, Average loss 0.237 Test accuracy 93.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2175 \n",
      "Accuracy: 9395/10000 (93.95%)\n",
      "\n",
      "Round  26, Average loss 0.218 Test accuracy 93.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2359 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round  27, Average loss 0.236 Test accuracy 93.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2319 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  28, Average loss 0.232 Test accuracy 94.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2340 \n",
      "Accuracy: 9349/10000 (93.49%)\n",
      "\n",
      "Round  29, Average loss 0.234 Test accuracy 93.490\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7409 \n",
      "Accuracy: 7445/10000 (74.45%)\n",
      "\n",
      "Round   1, Average loss 2.741 Test accuracy 74.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.2671 \n",
      "Accuracy: 8180/10000 (81.80%)\n",
      "\n",
      "Round   2, Average loss 10.267 Test accuracy 81.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.4831 \n",
      "Accuracy: 8412/10000 (84.12%)\n",
      "\n",
      "Round   3, Average loss 17.483 Test accuracy 84.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.2446 \n",
      "Accuracy: 8581/10000 (85.81%)\n",
      "\n",
      "Round   4, Average loss 24.245 Test accuracy 85.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.0933 \n",
      "Accuracy: 8202/10000 (82.02%)\n",
      "\n",
      "Round   5, Average loss 35.093 Test accuracy 82.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 44.3790 \n",
      "Accuracy: 7956/10000 (79.56%)\n",
      "\n",
      "Round   6, Average loss 44.379 Test accuracy 79.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.5827 \n",
      "Accuracy: 8562/10000 (85.62%)\n",
      "\n",
      "Round   7, Average loss 31.583 Test accuracy 85.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 90.9223 \n",
      "Accuracy: 7106/10000 (71.06%)\n",
      "\n",
      "Round   8, Average loss 90.922 Test accuracy 71.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.7225 \n",
      "Accuracy: 8783/10000 (87.83%)\n",
      "\n",
      "Round   9, Average loss 27.722 Test accuracy 87.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 62.5651 \n",
      "Accuracy: 7655/10000 (76.55%)\n",
      "\n",
      "Round  10, Average loss 62.565 Test accuracy 76.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.9975 \n",
      "Accuracy: 8620/10000 (86.20%)\n",
      "\n",
      "Round  11, Average loss 29.997 Test accuracy 86.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 94.2271 \n",
      "Accuracy: 7172/10000 (71.72%)\n",
      "\n",
      "Round  12, Average loss 94.227 Test accuracy 71.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 28.2445 \n",
      "Accuracy: 8769/10000 (87.69%)\n",
      "\n",
      "Round  13, Average loss 28.245 Test accuracy 87.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 71.3916 \n",
      "Accuracy: 7366/10000 (73.66%)\n",
      "\n",
      "Round  14, Average loss 71.392 Test accuracy 73.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.5208 \n",
      "Accuracy: 8610/10000 (86.10%)\n",
      "\n",
      "Round  15, Average loss 32.521 Test accuracy 86.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 55.1554 \n",
      "Accuracy: 7732/10000 (77.32%)\n",
      "\n",
      "Round  16, Average loss 55.155 Test accuracy 77.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 51.1152 \n",
      "Accuracy: 7803/10000 (78.03%)\n",
      "\n",
      "Round  17, Average loss 51.115 Test accuracy 78.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 60.8201 \n",
      "Accuracy: 7614/10000 (76.14%)\n",
      "\n",
      "Round  18, Average loss 60.820 Test accuracy 76.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 41.1083 \n",
      "Accuracy: 8162/10000 (81.62%)\n",
      "\n",
      "Round  19, Average loss 41.108 Test accuracy 81.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 117.9098 \n",
      "Accuracy: 6545/10000 (65.45%)\n",
      "\n",
      "Round  20, Average loss 117.910 Test accuracy 65.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 40.2625 \n",
      "Accuracy: 8247/10000 (82.47%)\n",
      "\n",
      "Round  21, Average loss 40.262 Test accuracy 82.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 43.7221 \n",
      "Accuracy: 8165/10000 (81.65%)\n",
      "\n",
      "Round  22, Average loss 43.722 Test accuracy 81.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 46.6546 \n",
      "Accuracy: 8085/10000 (80.85%)\n",
      "\n",
      "Round  23, Average loss 46.655 Test accuracy 80.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 53.4709 \n",
      "Accuracy: 7894/10000 (78.94%)\n",
      "\n",
      "Round  24, Average loss 53.471 Test accuracy 78.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 42.8587 \n",
      "Accuracy: 8270/10000 (82.70%)\n",
      "\n",
      "Round  25, Average loss 42.859 Test accuracy 82.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 51.6648 \n",
      "Accuracy: 7987/10000 (79.87%)\n",
      "\n",
      "Round  26, Average loss 51.665 Test accuracy 79.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 41.5843 \n",
      "Accuracy: 8279/10000 (82.79%)\n",
      "\n",
      "Round  27, Average loss 41.584 Test accuracy 82.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 50.3569 \n",
      "Accuracy: 7933/10000 (79.33%)\n",
      "\n",
      "Round  28, Average loss 50.357 Test accuracy 79.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 49.5463 \n",
      "Accuracy: 8006/10000 (80.06%)\n",
      "\n",
      "Round  29, Average loss 49.546 Test accuracy 80.060\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6528 \n",
      "Accuracy: 8525/10000 (85.25%)\n",
      "\n",
      "Round   1, Average loss 0.653 Test accuracy 85.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1683 \n",
      "Accuracy: 8910/10000 (89.10%)\n",
      "\n",
      "Round   2, Average loss 1.168 Test accuracy 89.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9260 \n",
      "Accuracy: 9041/10000 (90.41%)\n",
      "\n",
      "Round   3, Average loss 1.926 Test accuracy 90.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2998 \n",
      "Accuracy: 9082/10000 (90.82%)\n",
      "\n",
      "Round   4, Average loss 2.300 Test accuracy 90.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5933 \n",
      "Accuracy: 9025/10000 (90.25%)\n",
      "\n",
      "Round   5, Average loss 2.593 Test accuracy 90.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0126 \n",
      "Accuracy: 8942/10000 (89.42%)\n",
      "\n",
      "Round   6, Average loss 3.013 Test accuracy 89.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3290 \n",
      "Accuracy: 8538/10000 (85.38%)\n",
      "\n",
      "Round   7, Average loss 4.329 Test accuracy 85.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0993 \n",
      "Accuracy: 8940/10000 (89.40%)\n",
      "\n",
      "Round   8, Average loss 3.099 Test accuracy 89.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1878 \n",
      "Accuracy: 8990/10000 (89.90%)\n",
      "\n",
      "Round   9, Average loss 3.188 Test accuracy 89.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.5553 \n",
      "Accuracy: 8855/10000 (88.55%)\n",
      "\n",
      "Round  10, Average loss 3.555 Test accuracy 88.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9315 \n",
      "Accuracy: 8802/10000 (88.02%)\n",
      "\n",
      "Round  11, Average loss 3.932 Test accuracy 88.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9404 \n",
      "Accuracy: 8867/10000 (88.67%)\n",
      "\n",
      "Round  12, Average loss 3.940 Test accuracy 88.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1144 \n",
      "Accuracy: 8830/10000 (88.30%)\n",
      "\n",
      "Round  13, Average loss 4.114 Test accuracy 88.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1401 \n",
      "Accuracy: 8854/10000 (88.54%)\n",
      "\n",
      "Round  14, Average loss 4.140 Test accuracy 88.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2036 \n",
      "Accuracy: 8794/10000 (87.94%)\n",
      "\n",
      "Round  15, Average loss 4.204 Test accuracy 87.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.4127 \n",
      "Accuracy: 8733/10000 (87.33%)\n",
      "\n",
      "Round  16, Average loss 4.413 Test accuracy 87.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7628 \n",
      "Accuracy: 8662/10000 (86.62%)\n",
      "\n",
      "Round  17, Average loss 4.763 Test accuracy 86.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.5519 \n",
      "Accuracy: 8804/10000 (88.04%)\n",
      "\n",
      "Round  18, Average loss 4.552 Test accuracy 88.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8139 \n",
      "Accuracy: 8660/10000 (86.60%)\n",
      "\n",
      "Round  19, Average loss 4.814 Test accuracy 86.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7429 \n",
      "Accuracy: 8646/10000 (86.46%)\n",
      "\n",
      "Round  20, Average loss 4.743 Test accuracy 86.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2954 \n",
      "Accuracy: 8731/10000 (87.31%)\n",
      "\n",
      "Round  21, Average loss 4.295 Test accuracy 87.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.5682 \n",
      "Accuracy: 8651/10000 (86.51%)\n",
      "\n",
      "Round  22, Average loss 4.568 Test accuracy 86.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.5022 \n",
      "Accuracy: 8485/10000 (84.85%)\n",
      "\n",
      "Round  23, Average loss 5.502 Test accuracy 84.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3727 \n",
      "Accuracy: 8749/10000 (87.49%)\n",
      "\n",
      "Round  24, Average loss 4.373 Test accuracy 87.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3222 \n",
      "Accuracy: 8692/10000 (86.92%)\n",
      "\n",
      "Round  25, Average loss 4.322 Test accuracy 86.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8024 \n",
      "Accuracy: 8663/10000 (86.63%)\n",
      "\n",
      "Round  26, Average loss 4.802 Test accuracy 86.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7127 \n",
      "Accuracy: 8691/10000 (86.91%)\n",
      "\n",
      "Round  27, Average loss 4.713 Test accuracy 86.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7830 \n",
      "Accuracy: 8816/10000 (88.16%)\n",
      "\n",
      "Round  28, Average loss 4.783 Test accuracy 88.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3108 \n",
      "Accuracy: 8716/10000 (87.16%)\n",
      "\n",
      "Round  29, Average loss 4.311 Test accuracy 87.160\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "(T, sigma)= 5 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8027 \n",
      "Accuracy: 3391/10000 (33.91%)\n",
      "\n",
      "Round   0, Average loss 1.803 Test accuracy 33.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2536 \n",
      "Accuracy: 7413/10000 (74.13%)\n",
      "\n",
      "Round   1, Average loss 3.254 Test accuracy 74.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.6766 \n",
      "Accuracy: 6769/10000 (67.69%)\n",
      "\n",
      "Round   2, Average loss 4.677 Test accuracy 67.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.5467 \n",
      "Accuracy: 4874/10000 (48.74%)\n",
      "\n",
      "Round   3, Average loss 10.547 Test accuracy 48.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.5867 \n",
      "Accuracy: 6913/10000 (69.13%)\n",
      "\n",
      "Round   4, Average loss 11.587 Test accuracy 69.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.8934 \n",
      "Accuracy: 4138/10000 (41.38%)\n",
      "\n",
      "Round   5, Average loss 13.893 Test accuracy 41.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.1869 \n",
      "Accuracy: 7196/10000 (71.96%)\n",
      "\n",
      "Round   6, Average loss 11.187 Test accuracy 71.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.2511 \n",
      "Accuracy: 3813/10000 (38.13%)\n",
      "\n",
      "Round   7, Average loss 14.251 Test accuracy 38.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.2136 \n",
      "Accuracy: 6730/10000 (67.30%)\n",
      "\n",
      "Round   8, Average loss 13.214 Test accuracy 67.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.9939 \n",
      "Accuracy: 3994/10000 (39.94%)\n",
      "\n",
      "Round   9, Average loss 16.994 Test accuracy 39.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.9424 \n",
      "Accuracy: 6524/10000 (65.24%)\n",
      "\n",
      "Round  10, Average loss 16.942 Test accuracy 65.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.1660 \n",
      "Accuracy: 4073/10000 (40.73%)\n",
      "\n",
      "Round  11, Average loss 15.166 Test accuracy 40.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.8131 \n",
      "Accuracy: 6619/10000 (66.19%)\n",
      "\n",
      "Round  12, Average loss 16.813 Test accuracy 66.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 15.1201 \n",
      "Accuracy: 4289/10000 (42.89%)\n",
      "\n",
      "Round  13, Average loss 15.120 Test accuracy 42.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 19.1298 \n",
      "Accuracy: 5892/10000 (58.92%)\n",
      "\n",
      "Round  14, Average loss 19.130 Test accuracy 58.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.4603 \n",
      "Accuracy: 4168/10000 (41.68%)\n",
      "\n",
      "Round  15, Average loss 17.460 Test accuracy 41.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.8551 \n",
      "Accuracy: 5266/10000 (52.66%)\n",
      "\n",
      "Round  16, Average loss 23.855 Test accuracy 52.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.5567 \n",
      "Accuracy: 4129/10000 (41.29%)\n",
      "\n",
      "Round  17, Average loss 22.557 Test accuracy 41.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.9932 \n",
      "Accuracy: 5008/10000 (50.08%)\n",
      "\n",
      "Round  18, Average loss 22.993 Test accuracy 50.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.1984 \n",
      "Accuracy: 4209/10000 (42.09%)\n",
      "\n",
      "Round  19, Average loss 24.198 Test accuracy 42.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.7331 \n",
      "Accuracy: 5127/10000 (51.27%)\n",
      "\n",
      "Round  20, Average loss 22.733 Test accuracy 51.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.6254 \n",
      "Accuracy: 4205/10000 (42.05%)\n",
      "\n",
      "Round  21, Average loss 22.625 Test accuracy 42.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.8992 \n",
      "Accuracy: 4999/10000 (49.99%)\n",
      "\n",
      "Round  22, Average loss 24.899 Test accuracy 49.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.7377 \n",
      "Accuracy: 4424/10000 (44.24%)\n",
      "\n",
      "Round  23, Average loss 22.738 Test accuracy 44.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.4437 \n",
      "Accuracy: 4881/10000 (48.81%)\n",
      "\n",
      "Round  24, Average loss 24.444 Test accuracy 48.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.9209 \n",
      "Accuracy: 4549/10000 (45.49%)\n",
      "\n",
      "Round  25, Average loss 21.921 Test accuracy 45.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.9546 \n",
      "Accuracy: 4753/10000 (47.53%)\n",
      "\n",
      "Round  26, Average loss 22.955 Test accuracy 47.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.3888 \n",
      "Accuracy: 4639/10000 (46.39%)\n",
      "\n",
      "Round  27, Average loss 23.389 Test accuracy 46.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.8569 \n",
      "Accuracy: 4441/10000 (44.41%)\n",
      "\n",
      "Round  28, Average loss 25.857 Test accuracy 44.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.6603 \n",
      "Accuracy: 4683/10000 (46.83%)\n",
      "\n",
      "Round  29, Average loss 24.660 Test accuracy 46.830\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 5 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 11 10000 \n",
      "\n",
      "(T, sigma)= 5 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1588 \n",
      "Accuracy: 6090/10000 (60.90%)\n",
      "\n",
      "Round   1, Average loss 2.159 Test accuracy 60.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6034 \n",
      "Accuracy: 8061/10000 (80.61%)\n",
      "\n",
      "Round   2, Average loss 0.603 Test accuracy 80.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5701 \n",
      "Accuracy: 8349/10000 (83.49%)\n",
      "\n",
      "Round   3, Average loss 0.570 Test accuracy 83.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5125 \n",
      "Accuracy: 8472/10000 (84.72%)\n",
      "\n",
      "Round   4, Average loss 0.513 Test accuracy 84.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5010 \n",
      "Accuracy: 8509/10000 (85.09%)\n",
      "\n",
      "Round   5, Average loss 0.501 Test accuracy 85.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5604 \n",
      "Accuracy: 8463/10000 (84.63%)\n",
      "\n",
      "Round   6, Average loss 0.560 Test accuracy 84.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5023 \n",
      "Accuracy: 8580/10000 (85.80%)\n",
      "\n",
      "Round   7, Average loss 0.502 Test accuracy 85.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8029 \n",
      "Accuracy: 7763/10000 (77.63%)\n",
      "\n",
      "Round   8, Average loss 0.803 Test accuracy 77.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6410 \n",
      "Accuracy: 8119/10000 (81.19%)\n",
      "\n",
      "Round   9, Average loss 0.641 Test accuracy 81.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7024 \n",
      "Accuracy: 8061/10000 (80.61%)\n",
      "\n",
      "Round  10, Average loss 0.702 Test accuracy 80.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4821 \n",
      "Accuracy: 8620/10000 (86.20%)\n",
      "\n",
      "Round  11, Average loss 0.482 Test accuracy 86.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7292 \n",
      "Accuracy: 7907/10000 (79.07%)\n",
      "\n",
      "Round  12, Average loss 0.729 Test accuracy 79.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5645 \n",
      "Accuracy: 8340/10000 (83.40%)\n",
      "\n",
      "Round  13, Average loss 0.565 Test accuracy 83.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6376 \n",
      "Accuracy: 8278/10000 (82.78%)\n",
      "\n",
      "Round  14, Average loss 0.638 Test accuracy 82.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6261 \n",
      "Accuracy: 8374/10000 (83.74%)\n",
      "\n",
      "Round  15, Average loss 0.626 Test accuracy 83.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6674 \n",
      "Accuracy: 8287/10000 (82.87%)\n",
      "\n",
      "Round  16, Average loss 0.667 Test accuracy 82.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7818 \n",
      "Accuracy: 7875/10000 (78.75%)\n",
      "\n",
      "Round  17, Average loss 0.782 Test accuracy 78.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6372 \n",
      "Accuracy: 8151/10000 (81.51%)\n",
      "\n",
      "Round  18, Average loss 0.637 Test accuracy 81.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6586 \n",
      "Accuracy: 8352/10000 (83.52%)\n",
      "\n",
      "Round  19, Average loss 0.659 Test accuracy 83.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6711 \n",
      "Accuracy: 8254/10000 (82.54%)\n",
      "\n",
      "Round  20, Average loss 0.671 Test accuracy 82.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6780 \n",
      "Accuracy: 8122/10000 (81.22%)\n",
      "\n",
      "Round  21, Average loss 0.678 Test accuracy 81.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7183 \n",
      "Accuracy: 8246/10000 (82.46%)\n",
      "\n",
      "Round  22, Average loss 0.718 Test accuracy 82.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7136 \n",
      "Accuracy: 8154/10000 (81.54%)\n",
      "\n",
      "Round  23, Average loss 0.714 Test accuracy 81.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7144 \n",
      "Accuracy: 7951/10000 (79.51%)\n",
      "\n",
      "Round  24, Average loss 0.714 Test accuracy 79.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6232 \n",
      "Accuracy: 8249/10000 (82.49%)\n",
      "\n",
      "Round  25, Average loss 0.623 Test accuracy 82.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7775 \n",
      "Accuracy: 7795/10000 (77.95%)\n",
      "\n",
      "Round  26, Average loss 0.777 Test accuracy 77.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6810 \n",
      "Accuracy: 8093/10000 (80.93%)\n",
      "\n",
      "Round  27, Average loss 0.681 Test accuracy 80.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7765 \n",
      "Accuracy: 7723/10000 (77.23%)\n",
      "\n",
      "Round  28, Average loss 0.777 Test accuracy 77.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6746 \n",
      "Accuracy: 8209/10000 (82.09%)\n",
      "\n",
      "Round  29, Average loss 0.675 Test accuracy 82.090\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "(T, sigma)= 6 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2741 \n",
      "Accuracy: 988/10000 (9.88%)\n",
      "\n",
      "Round   0, Average loss 2.274 Test accuracy 9.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5198 \n",
      "Accuracy: 7135/10000 (71.35%)\n",
      "\n",
      "Round   1, Average loss 2.520 Test accuracy 71.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3656 \n",
      "Accuracy: 7837/10000 (78.37%)\n",
      "\n",
      "Round   2, Average loss 2.366 Test accuracy 78.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3535 \n",
      "Accuracy: 7837/10000 (78.37%)\n",
      "\n",
      "Round   3, Average loss 3.354 Test accuracy 78.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.4919 \n",
      "Accuracy: 5597/10000 (55.97%)\n",
      "\n",
      "Round   4, Average loss 24.492 Test accuracy 55.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.0304 \n",
      "Accuracy: 6800/10000 (68.00%)\n",
      "\n",
      "Round   5, Average loss 12.030 Test accuracy 68.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.4157 \n",
      "Accuracy: 5640/10000 (56.40%)\n",
      "\n",
      "Round   6, Average loss 23.416 Test accuracy 56.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.9600 \n",
      "Accuracy: 6954/10000 (69.54%)\n",
      "\n",
      "Round   7, Average loss 8.960 Test accuracy 69.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.6798 \n",
      "Accuracy: 5008/10000 (50.08%)\n",
      "\n",
      "Round   8, Average loss 31.680 Test accuracy 50.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.7039 \n",
      "Accuracy: 5421/10000 (54.21%)\n",
      "\n",
      "Round   9, Average loss 23.704 Test accuracy 54.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.1734 \n",
      "Accuracy: 6284/10000 (62.84%)\n",
      "\n",
      "Round  10, Average loss 35.173 Test accuracy 62.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 27.8467 \n",
      "Accuracy: 5456/10000 (54.56%)\n",
      "\n",
      "Round  11, Average loss 27.847 Test accuracy 54.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 48.2547 \n",
      "Accuracy: 4890/10000 (48.90%)\n",
      "\n",
      "Round  12, Average loss 48.255 Test accuracy 48.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 37.2585 \n",
      "Accuracy: 4031/10000 (40.31%)\n",
      "\n",
      "Round  13, Average loss 37.259 Test accuracy 40.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 71.7732 \n",
      "Accuracy: 3085/10000 (30.85%)\n",
      "\n",
      "Round  14, Average loss 71.773 Test accuracy 30.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.4486 \n",
      "Accuracy: 7041/10000 (70.41%)\n",
      "\n",
      "Round  15, Average loss 21.449 Test accuracy 70.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 49.4510 \n",
      "Accuracy: 3925/10000 (39.25%)\n",
      "\n",
      "Round  16, Average loss 49.451 Test accuracy 39.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.8975 \n",
      "Accuracy: 6101/10000 (61.01%)\n",
      "\n",
      "Round  17, Average loss 31.897 Test accuracy 61.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 46.5513 \n",
      "Accuracy: 4676/10000 (46.76%)\n",
      "\n",
      "Round  18, Average loss 46.551 Test accuracy 46.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.4221 \n",
      "Accuracy: 5259/10000 (52.59%)\n",
      "\n",
      "Round  19, Average loss 35.422 Test accuracy 52.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 33.8520 \n",
      "Accuracy: 6663/10000 (66.63%)\n",
      "\n",
      "Round  20, Average loss 33.852 Test accuracy 66.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 46.8497 \n",
      "Accuracy: 3149/10000 (31.49%)\n",
      "\n",
      "Round  21, Average loss 46.850 Test accuracy 31.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 32.8292 \n",
      "Accuracy: 7250/10000 (72.50%)\n",
      "\n",
      "Round  22, Average loss 32.829 Test accuracy 72.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 48.1523 \n",
      "Accuracy: 2973/10000 (29.73%)\n",
      "\n",
      "Round  23, Average loss 48.152 Test accuracy 29.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 40.9020 \n",
      "Accuracy: 6157/10000 (61.57%)\n",
      "\n",
      "Round  24, Average loss 40.902 Test accuracy 61.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 42.6482 \n",
      "Accuracy: 3675/10000 (36.75%)\n",
      "\n",
      "Round  25, Average loss 42.648 Test accuracy 36.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 38.0151 \n",
      "Accuracy: 6060/10000 (60.60%)\n",
      "\n",
      "Round  26, Average loss 38.015 Test accuracy 60.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 36.8475 \n",
      "Accuracy: 5636/10000 (56.36%)\n",
      "\n",
      "Round  27, Average loss 36.848 Test accuracy 56.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 43.4884 \n",
      "Accuracy: 4841/10000 (48.41%)\n",
      "\n",
      "Round  28, Average loss 43.488 Test accuracy 48.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 39.0684 \n",
      "Accuracy: 5666/10000 (56.66%)\n",
      "\n",
      "Round  29, Average loss 39.068 Test accuracy 56.660\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 12 10000 \n",
      "\n",
      "(T, sigma)= 6 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2053 \n",
      "Accuracy: 5780/10000 (57.80%)\n",
      "\n",
      "Round   1, Average loss 2.205 Test accuracy 57.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4481 \n",
      "Accuracy: 8760/10000 (87.60%)\n",
      "\n",
      "Round   2, Average loss 0.448 Test accuracy 87.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6953 \n",
      "Accuracy: 8348/10000 (83.48%)\n",
      "\n",
      "Round   3, Average loss 0.695 Test accuracy 83.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6001 \n",
      "Accuracy: 8673/10000 (86.73%)\n",
      "\n",
      "Round   4, Average loss 0.600 Test accuracy 86.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5563 \n",
      "Accuracy: 8778/10000 (87.78%)\n",
      "\n",
      "Round   5, Average loss 0.556 Test accuracy 87.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5435 \n",
      "Accuracy: 8741/10000 (87.41%)\n",
      "\n",
      "Round   6, Average loss 0.544 Test accuracy 87.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5170 \n",
      "Accuracy: 8786/10000 (87.86%)\n",
      "\n",
      "Round   7, Average loss 0.517 Test accuracy 87.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6215 \n",
      "Accuracy: 8755/10000 (87.55%)\n",
      "\n",
      "Round   8, Average loss 0.622 Test accuracy 87.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5543 \n",
      "Accuracy: 8868/10000 (88.68%)\n",
      "\n",
      "Round   9, Average loss 0.554 Test accuracy 88.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5776 \n",
      "Accuracy: 8706/10000 (87.06%)\n",
      "\n",
      "Round  10, Average loss 0.578 Test accuracy 87.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5751 \n",
      "Accuracy: 8886/10000 (88.86%)\n",
      "\n",
      "Round  11, Average loss 0.575 Test accuracy 88.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7455 \n",
      "Accuracy: 8426/10000 (84.26%)\n",
      "\n",
      "Round  12, Average loss 0.746 Test accuracy 84.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6196 \n",
      "Accuracy: 8765/10000 (87.65%)\n",
      "\n",
      "Round  13, Average loss 0.620 Test accuracy 87.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5563 \n",
      "Accuracy: 8844/10000 (88.44%)\n",
      "\n",
      "Round  14, Average loss 0.556 Test accuracy 88.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6063 \n",
      "Accuracy: 8764/10000 (87.64%)\n",
      "\n",
      "Round  15, Average loss 0.606 Test accuracy 87.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0159 \n",
      "Accuracy: 8035/10000 (80.35%)\n",
      "\n",
      "Round  16, Average loss 1.016 Test accuracy 80.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6583 \n",
      "Accuracy: 8650/10000 (86.50%)\n",
      "\n",
      "Round  17, Average loss 0.658 Test accuracy 86.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6998 \n",
      "Accuracy: 8594/10000 (85.94%)\n",
      "\n",
      "Round  18, Average loss 0.700 Test accuracy 85.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6008 \n",
      "Accuracy: 8639/10000 (86.39%)\n",
      "\n",
      "Round  19, Average loss 0.601 Test accuracy 86.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6404 \n",
      "Accuracy: 8847/10000 (88.47%)\n",
      "\n",
      "Round  20, Average loss 0.640 Test accuracy 88.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7349 \n",
      "Accuracy: 8609/10000 (86.09%)\n",
      "\n",
      "Round  21, Average loss 0.735 Test accuracy 86.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6182 \n",
      "Accuracy: 8770/10000 (87.70%)\n",
      "\n",
      "Round  22, Average loss 0.618 Test accuracy 87.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1468 \n",
      "Accuracy: 8058/10000 (80.58%)\n",
      "\n",
      "Round  23, Average loss 1.147 Test accuracy 80.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7197 \n",
      "Accuracy: 8516/10000 (85.16%)\n",
      "\n",
      "Round  24, Average loss 0.720 Test accuracy 85.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1244 \n",
      "Accuracy: 8123/10000 (81.23%)\n",
      "\n",
      "Round  25, Average loss 1.124 Test accuracy 81.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0641 \n",
      "Accuracy: 8180/10000 (81.80%)\n",
      "\n",
      "Round  26, Average loss 1.064 Test accuracy 81.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1644 \n",
      "Accuracy: 8115/10000 (81.15%)\n",
      "\n",
      "Round  27, Average loss 1.164 Test accuracy 81.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0366 \n",
      "Accuracy: 8136/10000 (81.36%)\n",
      "\n",
      "Round  28, Average loss 1.037 Test accuracy 81.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8602 \n",
      "Accuracy: 8417/10000 (84.17%)\n",
      "\n",
      "Round  29, Average loss 0.860 Test accuracy 84.170\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "(T, sigma)= 7 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4591 \n",
      "Accuracy: 7845/10000 (78.45%)\n",
      "\n",
      "Round   1, Average loss 1.459 Test accuracy 78.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3500 \n",
      "Accuracy: 9256/10000 (92.56%)\n",
      "\n",
      "Round   2, Average loss 0.350 Test accuracy 92.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9102 \n",
      "Accuracy: 9098/10000 (90.98%)\n",
      "\n",
      "Round   3, Average loss 0.910 Test accuracy 90.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8469 \n",
      "Accuracy: 9332/10000 (93.32%)\n",
      "\n",
      "Round   4, Average loss 0.847 Test accuracy 93.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9632 \n",
      "Accuracy: 9335/10000 (93.35%)\n",
      "\n",
      "Round   5, Average loss 0.963 Test accuracy 93.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3245 \n",
      "Accuracy: 8955/10000 (89.55%)\n",
      "\n",
      "Round   6, Average loss 1.324 Test accuracy 89.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3277 \n",
      "Accuracy: 9244/10000 (92.44%)\n",
      "\n",
      "Round   7, Average loss 1.328 Test accuracy 92.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0201 \n",
      "Accuracy: 8872/10000 (88.72%)\n",
      "\n",
      "Round   8, Average loss 2.020 Test accuracy 88.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4196 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round   9, Average loss 1.420 Test accuracy 92.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2127 \n",
      "Accuracy: 8906/10000 (89.06%)\n",
      "\n",
      "Round  10, Average loss 2.213 Test accuracy 89.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7572 \n",
      "Accuracy: 9175/10000 (91.75%)\n",
      "\n",
      "Round  11, Average loss 1.757 Test accuracy 91.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3766 \n",
      "Accuracy: 8938/10000 (89.38%)\n",
      "\n",
      "Round  12, Average loss 2.377 Test accuracy 89.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7244 \n",
      "Accuracy: 9315/10000 (93.15%)\n",
      "\n",
      "Round  13, Average loss 1.724 Test accuracy 93.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3800 \n",
      "Accuracy: 8916/10000 (89.16%)\n",
      "\n",
      "Round  14, Average loss 2.380 Test accuracy 89.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5829 \n",
      "Accuracy: 9296/10000 (92.96%)\n",
      "\n",
      "Round  15, Average loss 1.583 Test accuracy 92.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3405 \n",
      "Accuracy: 8874/10000 (88.74%)\n",
      "\n",
      "Round  16, Average loss 2.341 Test accuracy 88.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8941 \n",
      "Accuracy: 9148/10000 (91.48%)\n",
      "\n",
      "Round  17, Average loss 1.894 Test accuracy 91.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1154 \n",
      "Accuracy: 9174/10000 (91.74%)\n",
      "\n",
      "Round  18, Average loss 2.115 Test accuracy 91.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0105 \n",
      "Accuracy: 8767/10000 (87.67%)\n",
      "\n",
      "Round  19, Average loss 3.010 Test accuracy 87.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0406 \n",
      "Accuracy: 9244/10000 (92.44%)\n",
      "\n",
      "Round  20, Average loss 2.041 Test accuracy 92.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8715 \n",
      "Accuracy: 8827/10000 (88.27%)\n",
      "\n",
      "Round  21, Average loss 2.872 Test accuracy 88.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2076 \n",
      "Accuracy: 9226/10000 (92.26%)\n",
      "\n",
      "Round  22, Average loss 2.208 Test accuracy 92.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9176 \n",
      "Accuracy: 8849/10000 (88.49%)\n",
      "\n",
      "Round  23, Average loss 2.918 Test accuracy 88.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1971 \n",
      "Accuracy: 9189/10000 (91.89%)\n",
      "\n",
      "Round  24, Average loss 2.197 Test accuracy 91.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3352 \n",
      "Accuracy: 9078/10000 (90.78%)\n",
      "\n",
      "Round  25, Average loss 2.335 Test accuracy 90.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3481 \n",
      "Accuracy: 9171/10000 (91.71%)\n",
      "\n",
      "Round  26, Average loss 2.348 Test accuracy 91.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8965 \n",
      "Accuracy: 8865/10000 (88.65%)\n",
      "\n",
      "Round  27, Average loss 2.896 Test accuracy 88.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.4329 \n",
      "Accuracy: 9172/10000 (91.72%)\n",
      "\n",
      "Round  28, Average loss 2.433 Test accuracy 91.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0946 \n",
      "Accuracy: 8836/10000 (88.36%)\n",
      "\n",
      "Round  29, Average loss 3.095 Test accuracy 88.360\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 7 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 13 10000 \n",
      "\n",
      "(T, sigma)= 7 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2296 \n",
      "Accuracy: 6832/10000 (68.32%)\n",
      "\n",
      "Round   1, Average loss 2.230 Test accuracy 68.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5288 \n",
      "Accuracy: 9164/10000 (91.64%)\n",
      "\n",
      "Round   2, Average loss 0.529 Test accuracy 91.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2630 \n",
      "Accuracy: 9292/10000 (92.92%)\n",
      "\n",
      "Round   3, Average loss 0.263 Test accuracy 92.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2450 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round   4, Average loss 0.245 Test accuracy 93.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2608 \n",
      "Accuracy: 9279/10000 (92.79%)\n",
      "\n",
      "Round   5, Average loss 0.261 Test accuracy 92.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2218 \n",
      "Accuracy: 9349/10000 (93.49%)\n",
      "\n",
      "Round   6, Average loss 0.222 Test accuracy 93.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2247 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round   7, Average loss 0.225 Test accuracy 93.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2072 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round   8, Average loss 0.207 Test accuracy 94.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2003 \n",
      "Accuracy: 9440/10000 (94.40%)\n",
      "\n",
      "Round   9, Average loss 0.200 Test accuracy 94.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2211 \n",
      "Accuracy: 9339/10000 (93.39%)\n",
      "\n",
      "Round  10, Average loss 0.221 Test accuracy 93.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2067 \n",
      "Accuracy: 9401/10000 (94.01%)\n",
      "\n",
      "Round  11, Average loss 0.207 Test accuracy 94.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2233 \n",
      "Accuracy: 9397/10000 (93.97%)\n",
      "\n",
      "Round  12, Average loss 0.223 Test accuracy 93.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2394 \n",
      "Accuracy: 9344/10000 (93.44%)\n",
      "\n",
      "Round  13, Average loss 0.239 Test accuracy 93.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2130 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  14, Average loss 0.213 Test accuracy 94.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2228 \n",
      "Accuracy: 9355/10000 (93.55%)\n",
      "\n",
      "Round  15, Average loss 0.223 Test accuracy 93.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2424 \n",
      "Accuracy: 9285/10000 (92.85%)\n",
      "\n",
      "Round  16, Average loss 0.242 Test accuracy 92.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2081 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round  17, Average loss 0.208 Test accuracy 93.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2256 \n",
      "Accuracy: 9322/10000 (93.22%)\n",
      "\n",
      "Round  18, Average loss 0.226 Test accuracy 93.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2165 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  19, Average loss 0.216 Test accuracy 93.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2173 \n",
      "Accuracy: 9357/10000 (93.57%)\n",
      "\n",
      "Round  20, Average loss 0.217 Test accuracy 93.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2382 \n",
      "Accuracy: 9335/10000 (93.35%)\n",
      "\n",
      "Round  21, Average loss 0.238 Test accuracy 93.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2165 \n",
      "Accuracy: 9356/10000 (93.56%)\n",
      "\n",
      "Round  22, Average loss 0.216 Test accuracy 93.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2389 \n",
      "Accuracy: 9336/10000 (93.36%)\n",
      "\n",
      "Round  23, Average loss 0.239 Test accuracy 93.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2291 \n",
      "Accuracy: 9331/10000 (93.31%)\n",
      "\n",
      "Round  24, Average loss 0.229 Test accuracy 93.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2186 \n",
      "Accuracy: 9404/10000 (94.04%)\n",
      "\n",
      "Round  25, Average loss 0.219 Test accuracy 94.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2278 \n",
      "Accuracy: 9342/10000 (93.42%)\n",
      "\n",
      "Round  26, Average loss 0.228 Test accuracy 93.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2100 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round  27, Average loss 0.210 Test accuracy 93.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2359 \n",
      "Accuracy: 9316/10000 (93.16%)\n",
      "\n",
      "Round  28, Average loss 0.236 Test accuracy 93.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2242 \n",
      "Accuracy: 9367/10000 (93.67%)\n",
      "\n",
      "Round  29, Average loss 0.224 Test accuracy 93.670\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 14 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 14 10000 \n",
      "\n",
      "(T, sigma)= 8 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3009 \n",
      "Accuracy: 1678/10000 (16.78%)\n",
      "\n",
      "Round   0, Average loss 2.301 Test accuracy 16.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2518 \n",
      "Accuracy: 3783/10000 (37.83%)\n",
      "\n",
      "Round   1, Average loss 2.252 Test accuracy 37.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5719 \n",
      "Accuracy: 6910/10000 (69.10%)\n",
      "\n",
      "Round   2, Average loss 1.572 Test accuracy 69.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2897 \n",
      "Accuracy: 7675/10000 (76.75%)\n",
      "\n",
      "Round   3, Average loss 1.290 Test accuracy 76.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8417 \n",
      "Accuracy: 7816/10000 (78.16%)\n",
      "\n",
      "Round   4, Average loss 0.842 Test accuracy 78.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6488 \n",
      "Accuracy: 7902/10000 (79.02%)\n",
      "\n",
      "Round   5, Average loss 0.649 Test accuracy 79.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5073 \n",
      "Accuracy: 7038/10000 (70.38%)\n",
      "\n",
      "Round   6, Average loss 1.507 Test accuracy 70.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8481 \n",
      "Accuracy: 7549/10000 (75.49%)\n",
      "\n",
      "Round   7, Average loss 0.848 Test accuracy 75.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7217 \n",
      "Accuracy: 7459/10000 (74.59%)\n",
      "\n",
      "Round   8, Average loss 1.722 Test accuracy 74.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7040 \n",
      "Accuracy: 8002/10000 (80.02%)\n",
      "\n",
      "Round   9, Average loss 0.704 Test accuracy 80.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9748 \n",
      "Accuracy: 6854/10000 (68.54%)\n",
      "\n",
      "Round  10, Average loss 0.975 Test accuracy 68.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9390 \n",
      "Accuracy: 7283/10000 (72.83%)\n",
      "\n",
      "Round  11, Average loss 0.939 Test accuracy 72.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8497 \n",
      "Accuracy: 7429/10000 (74.29%)\n",
      "\n",
      "Round  12, Average loss 0.850 Test accuracy 74.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2462 \n",
      "Accuracy: 7728/10000 (77.28%)\n",
      "\n",
      "Round  13, Average loss 1.246 Test accuracy 77.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8032 \n",
      "Accuracy: 7656/10000 (76.56%)\n",
      "\n",
      "Round  14, Average loss 0.803 Test accuracy 76.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9532 \n",
      "Accuracy: 7323/10000 (73.23%)\n",
      "\n",
      "Round  15, Average loss 0.953 Test accuracy 73.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7864 \n",
      "Accuracy: 7536/10000 (75.36%)\n",
      "\n",
      "Round  16, Average loss 0.786 Test accuracy 75.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1986 \n",
      "Accuracy: 7661/10000 (76.61%)\n",
      "\n",
      "Round  17, Average loss 1.199 Test accuracy 76.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8333 \n",
      "Accuracy: 7659/10000 (76.59%)\n",
      "\n",
      "Round  18, Average loss 0.833 Test accuracy 76.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6786 \n",
      "Accuracy: 8254/10000 (82.54%)\n",
      "\n",
      "Round  19, Average loss 0.679 Test accuracy 82.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7994 \n",
      "Accuracy: 7714/10000 (77.14%)\n",
      "\n",
      "Round  20, Average loss 0.799 Test accuracy 77.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6443 \n",
      "Accuracy: 8301/10000 (83.01%)\n",
      "\n",
      "Round  21, Average loss 0.644 Test accuracy 83.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7549 \n",
      "Accuracy: 8476/10000 (84.76%)\n",
      "\n",
      "Round  22, Average loss 0.755 Test accuracy 84.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7340 \n",
      "Accuracy: 7781/10000 (77.81%)\n",
      "\n",
      "Round  23, Average loss 0.734 Test accuracy 77.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7948 \n",
      "Accuracy: 7660/10000 (76.60%)\n",
      "\n",
      "Round  24, Average loss 0.795 Test accuracy 76.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8627 \n",
      "Accuracy: 7536/10000 (75.36%)\n",
      "\n",
      "Round  25, Average loss 0.863 Test accuracy 75.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9502 \n",
      "Accuracy: 7301/10000 (73.01%)\n",
      "\n",
      "Round  26, Average loss 0.950 Test accuracy 73.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6468 \n",
      "Accuracy: 8016/10000 (80.16%)\n",
      "\n",
      "Round  27, Average loss 0.647 Test accuracy 80.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2964 \n",
      "Accuracy: 7867/10000 (78.67%)\n",
      "\n",
      "Round  28, Average loss 1.296 Test accuracy 78.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6655 \n",
      "Accuracy: 8013/10000 (80.13%)\n",
      "\n",
      "Round  29, Average loss 0.666 Test accuracy 80.130\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 14 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 8 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 14 10000 \n",
      "\n",
      "(T, sigma)= 8 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.302 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3007 \n",
      "Accuracy: 1033/10000 (10.33%)\n",
      "\n",
      "Round   2, Average loss 2.301 Test accuracy 10.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2782 \n",
      "Accuracy: 5257/10000 (52.57%)\n",
      "\n",
      "Round   3, Average loss 2.278 Test accuracy 52.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1702 \n",
      "Accuracy: 8741/10000 (87.41%)\n",
      "\n",
      "Round   4, Average loss 2.170 Test accuracy 87.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0939 \n",
      "Accuracy: 8844/10000 (88.44%)\n",
      "\n",
      "Round   5, Average loss 2.094 Test accuracy 88.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9978 \n",
      "Accuracy: 8730/10000 (87.30%)\n",
      "\n",
      "Round   6, Average loss 1.998 Test accuracy 87.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9841 \n",
      "Accuracy: 8894/10000 (88.94%)\n",
      "\n",
      "Round   7, Average loss 1.984 Test accuracy 88.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9836 \n",
      "Accuracy: 9183/10000 (91.83%)\n",
      "\n",
      "Round   8, Average loss 1.984 Test accuracy 91.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9514 \n",
      "Accuracy: 9099/10000 (90.99%)\n",
      "\n",
      "Round   9, Average loss 1.951 Test accuracy 90.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9304 \n",
      "Accuracy: 8885/10000 (88.85%)\n",
      "\n",
      "Round  10, Average loss 1.930 Test accuracy 88.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9192 \n",
      "Accuracy: 9030/10000 (90.30%)\n",
      "\n",
      "Round  11, Average loss 1.919 Test accuracy 90.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9344 \n",
      "Accuracy: 9021/10000 (90.21%)\n",
      "\n",
      "Round  12, Average loss 1.934 Test accuracy 90.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8496 \n",
      "Accuracy: 9114/10000 (91.14%)\n",
      "\n",
      "Round  13, Average loss 1.850 Test accuracy 91.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7526 \n",
      "Accuracy: 9156/10000 (91.56%)\n",
      "\n",
      "Round  14, Average loss 1.753 Test accuracy 91.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8685 \n",
      "Accuracy: 9126/10000 (91.26%)\n",
      "\n",
      "Round  15, Average loss 1.868 Test accuracy 91.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9171 \n",
      "Accuracy: 9112/10000 (91.12%)\n",
      "\n",
      "Round  16, Average loss 1.917 Test accuracy 91.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8881 \n",
      "Accuracy: 9109/10000 (91.09%)\n",
      "\n",
      "Round  17, Average loss 1.888 Test accuracy 91.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9111 \n",
      "Accuracy: 9084/10000 (90.84%)\n",
      "\n",
      "Round  18, Average loss 1.911 Test accuracy 90.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9245 \n",
      "Accuracy: 9127/10000 (91.27%)\n",
      "\n",
      "Round  19, Average loss 1.924 Test accuracy 91.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8339 \n",
      "Accuracy: 9140/10000 (91.40%)\n",
      "\n",
      "Round  20, Average loss 1.834 Test accuracy 91.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8525 \n",
      "Accuracy: 8995/10000 (89.95%)\n",
      "\n",
      "Round  21, Average loss 1.853 Test accuracy 89.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9529 \n",
      "Accuracy: 9005/10000 (90.05%)\n",
      "\n",
      "Round  22, Average loss 1.953 Test accuracy 90.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9249 \n",
      "Accuracy: 9035/10000 (90.35%)\n",
      "\n",
      "Round  23, Average loss 1.925 Test accuracy 90.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9094 \n",
      "Accuracy: 9123/10000 (91.23%)\n",
      "\n",
      "Round  24, Average loss 1.909 Test accuracy 91.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9216 \n",
      "Accuracy: 8910/10000 (89.10%)\n",
      "\n",
      "Round  25, Average loss 1.922 Test accuracy 89.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8484 \n",
      "Accuracy: 9182/10000 (91.82%)\n",
      "\n",
      "Round  26, Average loss 1.848 Test accuracy 91.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7877 \n",
      "Accuracy: 8878/10000 (88.78%)\n",
      "\n",
      "Round  27, Average loss 1.788 Test accuracy 88.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8256 \n",
      "Accuracy: 9233/10000 (92.33%)\n",
      "\n",
      "Round  28, Average loss 1.826 Test accuracy 92.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7586 \n",
      "Accuracy: 9200/10000 (92.00%)\n",
      "\n",
      "Round  29, Average loss 1.759 Test accuracy 92.000\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 15 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 15 10000 \n",
      "\n",
      "(T, sigma)= 9 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1573 \n",
      "Accuracy: 3347/10000 (33.47%)\n",
      "\n",
      "Round   0, Average loss 2.157 Test accuracy 33.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1703 \n",
      "Accuracy: 4666/10000 (46.66%)\n",
      "\n",
      "Round   1, Average loss 2.170 Test accuracy 46.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3377 \n",
      "Accuracy: 5750/10000 (57.50%)\n",
      "\n",
      "Round   2, Average loss 1.338 Test accuracy 57.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1002 \n",
      "Accuracy: 6152/10000 (61.52%)\n",
      "\n",
      "Round   3, Average loss 1.100 Test accuracy 61.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0972 \n",
      "Accuracy: 6034/10000 (60.34%)\n",
      "\n",
      "Round   4, Average loss 2.097 Test accuracy 60.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1044 \n",
      "Accuracy: 6407/10000 (64.07%)\n",
      "\n",
      "Round   5, Average loss 2.104 Test accuracy 64.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3100 \n",
      "Accuracy: 6879/10000 (68.79%)\n",
      "\n",
      "Round   6, Average loss 1.310 Test accuracy 68.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.4172 \n",
      "Accuracy: 6442/10000 (64.42%)\n",
      "\n",
      "Round   7, Average loss 14.417 Test accuracy 64.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1435 \n",
      "Accuracy: 3474/10000 (34.74%)\n",
      "\n",
      "Round   8, Average loss 2.144 Test accuracy 34.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9318 \n",
      "Accuracy: 7022/10000 (70.22%)\n",
      "\n",
      "Round   9, Average loss 2.932 Test accuracy 70.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6453 \n",
      "Accuracy: 3874/10000 (38.74%)\n",
      "\n",
      "Round  10, Average loss 1.645 Test accuracy 38.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9673 \n",
      "Accuracy: 6840/10000 (68.40%)\n",
      "\n",
      "Round  11, Average loss 2.967 Test accuracy 68.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5744 \n",
      "Accuracy: 5625/10000 (56.25%)\n",
      "\n",
      "Round  12, Average loss 1.574 Test accuracy 56.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3910 \n",
      "Accuracy: 6393/10000 (63.93%)\n",
      "\n",
      "Round  13, Average loss 4.391 Test accuracy 63.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5636 \n",
      "Accuracy: 4513/10000 (45.13%)\n",
      "\n",
      "Round  14, Average loss 1.564 Test accuracy 45.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.1713 \n",
      "Accuracy: 7318/10000 (73.18%)\n",
      "\n",
      "Round  15, Average loss 8.171 Test accuracy 73.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6589 \n",
      "Accuracy: 3693/10000 (36.93%)\n",
      "\n",
      "Round  16, Average loss 1.659 Test accuracy 36.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3165 \n",
      "Accuracy: 7437/10000 (74.37%)\n",
      "\n",
      "Round  17, Average loss 1.316 Test accuracy 74.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3791 \n",
      "Accuracy: 6313/10000 (63.13%)\n",
      "\n",
      "Round  18, Average loss 1.379 Test accuracy 63.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.3007 \n",
      "Accuracy: 6229/10000 (62.29%)\n",
      "\n",
      "Round  19, Average loss 13.301 Test accuracy 62.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7819 \n",
      "Accuracy: 4384/10000 (43.84%)\n",
      "\n",
      "Round  20, Average loss 1.782 Test accuracy 43.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8438 \n",
      "Accuracy: 6955/10000 (69.55%)\n",
      "\n",
      "Round  21, Average loss 3.844 Test accuracy 69.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3663 \n",
      "Accuracy: 6396/10000 (63.96%)\n",
      "\n",
      "Round  22, Average loss 1.366 Test accuracy 63.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0454 \n",
      "Accuracy: 6968/10000 (69.68%)\n",
      "\n",
      "Round  23, Average loss 3.045 Test accuracy 69.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5847 \n",
      "Accuracy: 5690/10000 (56.90%)\n",
      "\n",
      "Round  24, Average loss 1.585 Test accuracy 56.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.4380 \n",
      "Accuracy: 6925/10000 (69.25%)\n",
      "\n",
      "Round  25, Average loss 11.438 Test accuracy 69.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6290 \n",
      "Accuracy: 6046/10000 (60.46%)\n",
      "\n",
      "Round  26, Average loss 1.629 Test accuracy 60.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2511 \n",
      "Accuracy: 6978/10000 (69.78%)\n",
      "\n",
      "Round  27, Average loss 4.251 Test accuracy 69.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0920 \n",
      "Accuracy: 7212/10000 (72.12%)\n",
      "\n",
      "Round  28, Average loss 1.092 Test accuracy 72.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4683 \n",
      "Accuracy: 6289/10000 (62.89%)\n",
      "\n",
      "Round  29, Average loss 7.468 Test accuracy 62.890\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 15 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 9 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 15 10000 \n",
      "\n",
      "(T, sigma)= 9 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   3, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   9, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1009/10000 (10.09%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 10.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 10.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  26, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 1032/10000 (10.32%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 10.320\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 16 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 16 10000 \n",
      "\n",
      "(T, sigma)= 10 0.1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9648 \n",
      "Accuracy: 4637/10000 (46.37%)\n",
      "\n",
      "Round   1, Average loss 1.965 Test accuracy 46.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4092 \n",
      "Accuracy: 6916/10000 (69.16%)\n",
      "\n",
      "Round   2, Average loss 1.409 Test accuracy 69.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2342 \n",
      "Accuracy: 6988/10000 (69.88%)\n",
      "\n",
      "Round   3, Average loss 1.234 Test accuracy 69.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9791 \n",
      "Accuracy: 6891/10000 (68.91%)\n",
      "\n",
      "Round   4, Average loss 1.979 Test accuracy 68.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5952 \n",
      "Accuracy: 7274/10000 (72.74%)\n",
      "\n",
      "Round   5, Average loss 1.595 Test accuracy 72.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8971 \n",
      "Accuracy: 7661/10000 (76.61%)\n",
      "\n",
      "Round   6, Average loss 2.897 Test accuracy 76.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6469 \n",
      "Accuracy: 7225/10000 (72.25%)\n",
      "\n",
      "Round   7, Average loss 1.647 Test accuracy 72.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8187 \n",
      "Accuracy: 7428/10000 (74.28%)\n",
      "\n",
      "Round   8, Average loss 2.819 Test accuracy 74.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7453 \n",
      "Accuracy: 6961/10000 (69.61%)\n",
      "\n",
      "Round   9, Average loss 1.745 Test accuracy 69.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.5438 \n",
      "Accuracy: 6549/10000 (65.49%)\n",
      "\n",
      "Round  10, Average loss 3.544 Test accuracy 65.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6579 \n",
      "Accuracy: 6809/10000 (68.09%)\n",
      "\n",
      "Round  11, Average loss 1.658 Test accuracy 68.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7949 \n",
      "Accuracy: 6655/10000 (66.55%)\n",
      "\n",
      "Round  12, Average loss 3.795 Test accuracy 66.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1958 \n",
      "Accuracy: 6258/10000 (62.58%)\n",
      "\n",
      "Round  13, Average loss 2.196 Test accuracy 62.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1495 \n",
      "Accuracy: 7018/10000 (70.18%)\n",
      "\n",
      "Round  14, Average loss 4.149 Test accuracy 70.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0553 \n",
      "Accuracy: 6177/10000 (61.77%)\n",
      "\n",
      "Round  15, Average loss 2.055 Test accuracy 61.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2023 \n",
      "Accuracy: 6652/10000 (66.52%)\n",
      "\n",
      "Round  16, Average loss 5.202 Test accuracy 66.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8986 \n",
      "Accuracy: 6163/10000 (61.63%)\n",
      "\n",
      "Round  17, Average loss 1.899 Test accuracy 61.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.4558 \n",
      "Accuracy: 7121/10000 (71.21%)\n",
      "\n",
      "Round  18, Average loss 3.456 Test accuracy 71.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3674 \n",
      "Accuracy: 7323/10000 (73.23%)\n",
      "\n",
      "Round  19, Average loss 1.367 Test accuracy 73.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.6371 \n",
      "Accuracy: 7558/10000 (75.58%)\n",
      "\n",
      "Round  20, Average loss 4.637 Test accuracy 75.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2813 \n",
      "Accuracy: 7330/10000 (73.30%)\n",
      "\n",
      "Round  21, Average loss 1.281 Test accuracy 73.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3242 \n",
      "Accuracy: 7800/10000 (78.00%)\n",
      "\n",
      "Round  22, Average loss 3.324 Test accuracy 78.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3198 \n",
      "Accuracy: 7165/10000 (71.65%)\n",
      "\n",
      "Round  23, Average loss 1.320 Test accuracy 71.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8983 \n",
      "Accuracy: 7589/10000 (75.89%)\n",
      "\n",
      "Round  24, Average loss 3.898 Test accuracy 75.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3120 \n",
      "Accuracy: 7419/10000 (74.19%)\n",
      "\n",
      "Round  25, Average loss 1.312 Test accuracy 74.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0022 \n",
      "Accuracy: 7334/10000 (73.34%)\n",
      "\n",
      "Round  26, Average loss 4.002 Test accuracy 73.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3806 \n",
      "Accuracy: 7215/10000 (72.15%)\n",
      "\n",
      "Round  27, Average loss 1.381 Test accuracy 72.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.4523 \n",
      "Accuracy: 7553/10000 (75.53%)\n",
      "\n",
      "Round  28, Average loss 4.452 Test accuracy 75.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5761 \n",
      "Accuracy: 6824/10000 (68.24%)\n",
      "\n",
      "Round  29, Average loss 1.576 Test accuracy 68.240\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 16 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 16 10000 \n",
      "\n",
      "(T, sigma)= 10 1.0 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 998/10000 (9.98%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3019 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   1, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1816 \n",
      "Accuracy: 5898/10000 (58.98%)\n",
      "\n",
      "Round   2, Average loss 2.182 Test accuracy 58.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2493 \n",
      "Accuracy: 8019/10000 (80.19%)\n",
      "\n",
      "Round   3, Average loss 1.249 Test accuracy 80.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5658 \n",
      "Accuracy: 8337/10000 (83.37%)\n",
      "\n",
      "Round   4, Average loss 1.566 Test accuracy 83.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9268 \n",
      "Accuracy: 8459/10000 (84.59%)\n",
      "\n",
      "Round   5, Average loss 0.927 Test accuracy 84.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4388 \n",
      "Accuracy: 7927/10000 (79.27%)\n",
      "\n",
      "Round   6, Average loss 1.439 Test accuracy 79.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8524 \n",
      "Accuracy: 8094/10000 (80.94%)\n",
      "\n",
      "Round   7, Average loss 0.852 Test accuracy 80.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3329 \n",
      "Accuracy: 7911/10000 (79.11%)\n",
      "\n",
      "Round   8, Average loss 1.333 Test accuracy 79.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0872 \n",
      "Accuracy: 8532/10000 (85.32%)\n",
      "\n",
      "Round   9, Average loss 1.087 Test accuracy 85.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9519 \n",
      "Accuracy: 8308/10000 (83.08%)\n",
      "\n",
      "Round  10, Average loss 0.952 Test accuracy 83.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3353 \n",
      "Accuracy: 8643/10000 (86.43%)\n",
      "\n",
      "Round  11, Average loss 1.335 Test accuracy 86.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9484 \n",
      "Accuracy: 8145/10000 (81.45%)\n",
      "\n",
      "Round  12, Average loss 0.948 Test accuracy 81.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0419 \n",
      "Accuracy: 8088/10000 (80.88%)\n",
      "\n",
      "Round  13, Average loss 1.042 Test accuracy 80.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0582 \n",
      "Accuracy: 8331/10000 (83.31%)\n",
      "\n",
      "Round  14, Average loss 1.058 Test accuracy 83.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0267 \n",
      "Accuracy: 8462/10000 (84.62%)\n",
      "\n",
      "Round  15, Average loss 1.027 Test accuracy 84.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2418 \n",
      "Accuracy: 7201/10000 (72.01%)\n",
      "\n",
      "Round  16, Average loss 1.242 Test accuracy 72.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9896 \n",
      "Accuracy: 8607/10000 (86.07%)\n",
      "\n",
      "Round  17, Average loss 0.990 Test accuracy 86.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2740 \n",
      "Accuracy: 8478/10000 (84.78%)\n",
      "\n",
      "Round  18, Average loss 1.274 Test accuracy 84.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0876 \n",
      "Accuracy: 7931/10000 (79.31%)\n",
      "\n",
      "Round  19, Average loss 1.088 Test accuracy 79.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6756 \n",
      "Accuracy: 8771/10000 (87.71%)\n",
      "\n",
      "Round  20, Average loss 0.676 Test accuracy 87.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7833 \n",
      "Accuracy: 8307/10000 (83.07%)\n",
      "\n",
      "Round  21, Average loss 0.783 Test accuracy 83.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4870 \n",
      "Accuracy: 8034/10000 (80.34%)\n",
      "\n",
      "Round  22, Average loss 1.487 Test accuracy 80.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6620 \n",
      "Accuracy: 8511/10000 (85.11%)\n",
      "\n",
      "Round  23, Average loss 0.662 Test accuracy 85.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2969 \n",
      "Accuracy: 8339/10000 (83.39%)\n",
      "\n",
      "Round  24, Average loss 1.297 Test accuracy 83.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7412 \n",
      "Accuracy: 8699/10000 (86.99%)\n",
      "\n",
      "Round  25, Average loss 0.741 Test accuracy 86.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7102 \n",
      "Accuracy: 7753/10000 (77.53%)\n",
      "\n",
      "Round  26, Average loss 1.710 Test accuracy 77.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2234 \n",
      "Accuracy: 7595/10000 (75.95%)\n",
      "\n",
      "Round  27, Average loss 1.223 Test accuracy 75.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7853 \n",
      "Accuracy: 8318/10000 (83.18%)\n",
      "\n",
      "Round  28, Average loss 0.785 Test accuracy 83.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4601 \n",
      "Accuracy: 7899/10000 (78.99%)\n",
      "\n",
      "Round  29, Average loss 1.460 Test accuracy 78.990\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "N = args.num_users\n",
    "K = args.num_partition\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "# m_array = np.array(range(4,16)) # m is the number of received result @ master\n",
    "T_array = np.array([0,1,2,3,4,5,6,7,8,9,10]) # m is the number of received result @ master\n",
    "sigma_array = np.array([0.1, 1])\n",
    "\n",
    "\n",
    "loss_test_arr_v2 = np.empty((len(T_array),len(sigma_array),N_trials,N_epochs))\n",
    "acc_test_arr_v2  = np.empty((len(T_array),len(sigma_array),N_trials,N_epochs))\n",
    "\n",
    "for T_idx in range(len(T_array)):\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    T = T_array[T_idx]\n",
    "    \n",
    "    if T == 0:\n",
    "        Noise_Alloc = []\n",
    "    elif T == 1:\n",
    "        Noise_Alloc = [3]\n",
    "    elif T == 2:\n",
    "        Noise_Alloc = [0,7]\n",
    "    elif T == 3:\n",
    "        Noise_Alloc = [0,4,8]\n",
    "    elif T == 4:\n",
    "        Noise_Alloc = [0,3,6,9]\n",
    "    elif T == 5:\n",
    "        Noise_Alloc = [0,3,5,7,10]\n",
    "    elif T == 6:\n",
    "        Noise_Alloc = [0,2,4,7,9,11]\n",
    "    elif T == 7:\n",
    "        Noise_Alloc = [0,2,4,6,8,10,12] # np.random.choice(range(K+T), T, replace=False)\n",
    "    elif T == 8:\n",
    "        Noise_Alloc = [0,2,4,6,7,9,11,13] # np.random.choice(range(K+T), T, replace=False)\n",
    "    elif T == 9:\n",
    "        Noise_Alloc = [0,2,4,5,7,9,10,12,14] # np.random.choice(range(K+T), T, replace=False)\n",
    "    elif T == 10:\n",
    "        Noise_Alloc = [0,2,4,5,7,8,10,11,13,15] # np.random.choice(range(K+T), T, replace=False)\n",
    "    else:\n",
    "        Noise_Alloc = np.random.choice(range(K+T), T, replace=False)\n",
    "        \n",
    "    Signal_Alloc = []\n",
    "    for i in range(K+T):\n",
    "        if i not in Noise_Alloc:\n",
    "            Signal_Alloc.append(i)\n",
    "\n",
    "    j_array = np.array(range(K+T))\n",
    "    # print(\"j: \",(2*j_array+1)*math.pi/2/K,'\\n')\n",
    "\n",
    "    alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "    i_array = np.array(range(N))\n",
    "    z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "    \n",
    "    for sigma_idx in range(len(sigma_array)):\n",
    "        \n",
    "        sigma = sigma_array[sigma_idx]\n",
    "\n",
    "        X_tilde,a,b = BACC_Enc_withNoise(encoding_input_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "        y_tilde,a,b = BACC_Enc_withNoise(encoding_label_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "\n",
    "        m = N # m is the number of received result @ master\n",
    "    #     print('number of results:',m)\n",
    "\n",
    "        for trial_idx in range(N_trials):\n",
    "            print('(T, sigma)=',T,sigma,') ',trial_idx,'-th Trial!!')\n",
    "\n",
    "            net_glob = CNNMnist2(args=args)\n",
    "            net_glob.cuda()\n",
    "            net_glob.train()\n",
    "\n",
    "            # copy weights\n",
    "            w_glob = net_glob.state_dict()\n",
    "\n",
    "            for iter in range(N_epochs): #args.epochs\n",
    "                w_locals, loss_locals = [], []\n",
    "                idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "                idxs_users = np.sort(idxs_users)\n",
    "                print('selected users:',idxs_users)\n",
    "\n",
    "                dec_z_array = []\n",
    "                for idx in idxs_users: #for idx in range(N):\n",
    "            #         print(idx)\n",
    "                    local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                    w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                    w_locals.append(copy.deepcopy(w))\n",
    "                    loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                    dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "                # update global weights\n",
    "                #w_glob = FedAvg(w_locals)\n",
    "                w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "                # copy weight to net_glob\n",
    "                net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                # print loss\n",
    "            #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "            #     loss_train_arr.append(loss_train)\n",
    "\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                acc_test_arr_v2[T_idx][sigma_idx][trial_idx][iter] = acc_test\n",
    "                loss_test_arr_v2[T_idx][sigma_idx][trial_idx][iter] = loss_test\n",
    "                if iter % 1 ==0:\n",
    "                    print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "                #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(\"./plot/MNIST_LeNet_N15_K6_T_4_to_10_sigma_0_to_1_test_acc\",\"wb\")\n",
    "pickle.dump(acc_test_arr_v2,filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_v2 = np.mean(acc_test_arr_v2, axis=2)\n",
    "# print(acc_test_arr.shape)\n",
    "print(plot_acc_v2.shape)\n",
    "\n",
    "sigma_sel = 0\n",
    "\n",
    "title_name = 'Sigma ='+str(sigma_array[sigma_sel])\n",
    "plt.plot(plot_acc[0,sigma_sel,:],label='T=0')\n",
    "plt.plot(plot_acc[1,sigma_sel,:],label='T=1')\n",
    "plt.plot(plot_acc[2,sigma_sel,:],label='T=2')\n",
    "plt.plot(plot_acc[3,sigma_sel,:],label='T=3')\n",
    "plt.plot(plot_acc_v2[0,sigma_sel,:],label='T=4')\n",
    "plt.plot(plot_acc_v2[1,sigma_sel,:],label='T=5')\n",
    "plt.plot(plot_acc_v2[2,sigma_sel,:],label='T=6')\n",
    "plt.plot(plot_acc_v2[3,sigma_sel,:],label='T=7')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()\n",
    "\n",
    "sigma_sel = 1\n",
    "\n",
    "title_name = 'Sigma ='+str(sigma_array[sigma_sel])\n",
    "plt.plot(plot_acc[0,sigma_sel,:],label='T=0')\n",
    "plt.plot(plot_acc[1,sigma_sel,:],label='T=1')\n",
    "plt.plot(plot_acc[2,sigma_sel,:],label='T=2')\n",
    "plt.plot(plot_acc[3,sigma_sel,:],label='T=3')\n",
    "plt.plot(plot_acc_v2[0,sigma_sel,:],label='T=4')\n",
    "plt.plot(plot_acc_v2[1,sigma_sel,:],label='T=5')\n",
    "plt.plot(plot_acc_v2[2,sigma_sel,:],label='T=6')\n",
    "plt.plot(plot_acc_v2[3,sigma_sel,:],label='T=7')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()\n",
    "\n",
    "sigma_sel = 2\n",
    "\n",
    "title_name = 'Sigma ='+str(sigma_array[sigma_sel])\n",
    "plt.plot(plot_acc[0,sigma_sel,:],label='T=0')\n",
    "# plt.plot(plot_acc[1,sigma_sel,:],label='T=1')\n",
    "plt.plot(plot_acc[2,sigma_sel,:],label='T=2')\n",
    "plt.plot(plot_acc[3,sigma_sel,:],label='T=3')\n",
    "plt.plot(plot_acc_v2[0,sigma_sel,:],label='T=4')\n",
    "# plt.plot(plot_acc_v2[1,sigma_sel,:],label='T=5')\n",
    "# plt.plot(plot_acc_v2[2,sigma_sel,:],label='T=6')\n",
    "plt.plot(plot_acc_v2[3,sigma_sel,:],label='T=7')\n",
    "plt.plot(plot_acc_v2[4,sigma_sel,:],label='T=8')\n",
    "plt.plot(plot_acc_v2[5,sigma_sel,:],label='T=9')\n",
    "plt.plot(plot_acc_v2[6,sigma_sel,:],label='T=10')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3021 \n",
      "Accuracy: 1137/10000 (11.37%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2502 \n",
      "Accuracy: 7330/10000 (73.30%)\n",
      "\n",
      "Round   1, Average loss 2.250 Test accuracy 73.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4723 \n",
      "Accuracy: 8847/10000 (88.47%)\n",
      "\n",
      "Round   2, Average loss 0.472 Test accuracy 88.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3491 \n",
      "Accuracy: 8881/10000 (88.81%)\n",
      "\n",
      "Round   3, Average loss 0.349 Test accuracy 88.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2998 \n",
      "Accuracy: 9100/10000 (91.00%)\n",
      "\n",
      "Round   4, Average loss 0.300 Test accuracy 91.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3342 \n",
      "Accuracy: 8961/10000 (89.61%)\n",
      "\n",
      "Round   5, Average loss 0.334 Test accuracy 89.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3200 \n",
      "Accuracy: 9006/10000 (90.06%)\n",
      "\n",
      "Round   6, Average loss 0.320 Test accuracy 90.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3408 \n",
      "Accuracy: 8961/10000 (89.61%)\n",
      "\n",
      "Round   7, Average loss 0.341 Test accuracy 89.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3372 \n",
      "Accuracy: 9000/10000 (90.00%)\n",
      "\n",
      "Round   8, Average loss 0.337 Test accuracy 90.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3618 \n",
      "Accuracy: 8946/10000 (89.46%)\n",
      "\n",
      "Round   9, Average loss 0.362 Test accuracy 89.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3079 \n",
      "Accuracy: 9095/10000 (90.95%)\n",
      "\n",
      "Round  10, Average loss 0.308 Test accuracy 90.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3186 \n",
      "Accuracy: 9099/10000 (90.99%)\n",
      "\n",
      "Round  11, Average loss 0.319 Test accuracy 90.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3327 \n",
      "Accuracy: 8989/10000 (89.89%)\n",
      "\n",
      "Round  12, Average loss 0.333 Test accuracy 89.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3095 \n",
      "Accuracy: 9084/10000 (90.84%)\n",
      "\n",
      "Round  13, Average loss 0.310 Test accuracy 90.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3381 \n",
      "Accuracy: 8992/10000 (89.92%)\n",
      "\n",
      "Round  14, Average loss 0.338 Test accuracy 89.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3860 \n",
      "Accuracy: 8781/10000 (87.81%)\n",
      "\n",
      "Round  15, Average loss 0.386 Test accuracy 87.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3287 \n",
      "Accuracy: 9015/10000 (90.15%)\n",
      "\n",
      "Round  16, Average loss 0.329 Test accuracy 90.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4077 \n",
      "Accuracy: 8845/10000 (88.45%)\n",
      "\n",
      "Round  17, Average loss 0.408 Test accuracy 88.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3641 \n",
      "Accuracy: 8875/10000 (88.75%)\n",
      "\n",
      "Round  18, Average loss 0.364 Test accuracy 88.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4463 \n",
      "Accuracy: 8699/10000 (86.99%)\n",
      "\n",
      "Round  19, Average loss 0.446 Test accuracy 86.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4066 \n",
      "Accuracy: 8787/10000 (87.87%)\n",
      "\n",
      "Round  20, Average loss 0.407 Test accuracy 87.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4231 \n",
      "Accuracy: 8607/10000 (86.07%)\n",
      "\n",
      "Round  21, Average loss 0.423 Test accuracy 86.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4110 \n",
      "Accuracy: 8690/10000 (86.90%)\n",
      "\n",
      "Round  22, Average loss 0.411 Test accuracy 86.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5298 \n",
      "Accuracy: 8352/10000 (83.52%)\n",
      "\n",
      "Round  23, Average loss 0.530 Test accuracy 83.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4126 \n",
      "Accuracy: 8704/10000 (87.04%)\n",
      "\n",
      "Round  24, Average loss 0.413 Test accuracy 87.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4511 \n",
      "Accuracy: 8629/10000 (86.29%)\n",
      "\n",
      "Round  25, Average loss 0.451 Test accuracy 86.290\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3922 \n",
      "Accuracy: 8713/10000 (87.13%)\n",
      "\n",
      "Round  26, Average loss 0.392 Test accuracy 87.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3606 \n",
      "Accuracy: 8928/10000 (89.28%)\n",
      "\n",
      "Round  27, Average loss 0.361 Test accuracy 89.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3732 \n",
      "Accuracy: 8801/10000 (88.01%)\n",
      "\n",
      "Round  28, Average loss 0.373 Test accuracy 88.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4126 \n",
      "Accuracy: 8879/10000 (88.79%)\n",
      "\n",
      "Round  29, Average loss 0.413 Test accuracy 88.790\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0266 \n",
      "Accuracy: 7959/10000 (79.59%)\n",
      "\n",
      "Round   1, Average loss 2.027 Test accuracy 79.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2932 \n",
      "Accuracy: 9241/10000 (92.41%)\n",
      "\n",
      "Round   2, Average loss 0.293 Test accuracy 92.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2591 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round   3, Average loss 0.259 Test accuracy 92.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2523 \n",
      "Accuracy: 9276/10000 (92.76%)\n",
      "\n",
      "Round   4, Average loss 0.252 Test accuracy 92.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2563 \n",
      "Accuracy: 9286/10000 (92.86%)\n",
      "\n",
      "Round   5, Average loss 0.256 Test accuracy 92.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2629 \n",
      "Accuracy: 9275/10000 (92.75%)\n",
      "\n",
      "Round   6, Average loss 0.263 Test accuracy 92.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2762 \n",
      "Accuracy: 9261/10000 (92.61%)\n",
      "\n",
      "Round   7, Average loss 0.276 Test accuracy 92.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2639 \n",
      "Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Round   8, Average loss 0.264 Test accuracy 92.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2993 \n",
      "Accuracy: 9197/10000 (91.97%)\n",
      "\n",
      "Round   9, Average loss 0.299 Test accuracy 91.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3060 \n",
      "Accuracy: 9165/10000 (91.65%)\n",
      "\n",
      "Round  10, Average loss 0.306 Test accuracy 91.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2991 \n",
      "Accuracy: 9154/10000 (91.54%)\n",
      "\n",
      "Round  11, Average loss 0.299 Test accuracy 91.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2737 \n",
      "Accuracy: 9235/10000 (92.35%)\n",
      "\n",
      "Round  12, Average loss 0.274 Test accuracy 92.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2954 \n",
      "Accuracy: 9179/10000 (91.79%)\n",
      "\n",
      "Round  13, Average loss 0.295 Test accuracy 91.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3334 \n",
      "Accuracy: 9098/10000 (90.98%)\n",
      "\n",
      "Round  14, Average loss 0.333 Test accuracy 90.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3331 \n",
      "Accuracy: 9032/10000 (90.32%)\n",
      "\n",
      "Round  15, Average loss 0.333 Test accuracy 90.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2635 \n",
      "Accuracy: 9240/10000 (92.40%)\n",
      "\n",
      "Round  16, Average loss 0.264 Test accuracy 92.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2831 \n",
      "Accuracy: 9219/10000 (92.19%)\n",
      "\n",
      "Round  17, Average loss 0.283 Test accuracy 92.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3069 \n",
      "Accuracy: 9239/10000 (92.39%)\n",
      "\n",
      "Round  18, Average loss 0.307 Test accuracy 92.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3468 \n",
      "Accuracy: 9111/10000 (91.11%)\n",
      "\n",
      "Round  19, Average loss 0.347 Test accuracy 91.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3052 \n",
      "Accuracy: 9125/10000 (91.25%)\n",
      "\n",
      "Round  20, Average loss 0.305 Test accuracy 91.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3074 \n",
      "Accuracy: 9137/10000 (91.37%)\n",
      "\n",
      "Round  21, Average loss 0.307 Test accuracy 91.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3201 \n",
      "Accuracy: 9122/10000 (91.22%)\n",
      "\n",
      "Round  22, Average loss 0.320 Test accuracy 91.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2962 \n",
      "Accuracy: 9209/10000 (92.09%)\n",
      "\n",
      "Round  23, Average loss 0.296 Test accuracy 92.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3118 \n",
      "Accuracy: 9176/10000 (91.76%)\n",
      "\n",
      "Round  24, Average loss 0.312 Test accuracy 91.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3226 \n",
      "Accuracy: 9116/10000 (91.16%)\n",
      "\n",
      "Round  25, Average loss 0.323 Test accuracy 91.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3098 \n",
      "Accuracy: 9106/10000 (91.06%)\n",
      "\n",
      "Round  26, Average loss 0.310 Test accuracy 91.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3131 \n",
      "Accuracy: 9159/10000 (91.59%)\n",
      "\n",
      "Round  27, Average loss 0.313 Test accuracy 91.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2939 \n",
      "Accuracy: 9205/10000 (92.05%)\n",
      "\n",
      "Round  28, Average loss 0.294 Test accuracy 92.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2833 \n",
      "Accuracy: 9202/10000 (92.02%)\n",
      "\n",
      "Round  29, Average loss 0.283 Test accuracy 92.020\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3006 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round   0, Average loss 2.301 Test accuracy 11.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2867 \n",
      "Accuracy: 1347/10000 (13.47%)\n",
      "\n",
      "Round   1, Average loss 2.287 Test accuracy 13.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1283 \n",
      "Accuracy: 7710/10000 (77.10%)\n",
      "\n",
      "Round   2, Average loss 1.128 Test accuracy 77.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5590 \n",
      "Accuracy: 8144/10000 (81.44%)\n",
      "\n",
      "Round   3, Average loss 0.559 Test accuracy 81.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3969 \n",
      "Accuracy: 8753/10000 (87.53%)\n",
      "\n",
      "Round   4, Average loss 0.397 Test accuracy 87.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4098 \n",
      "Accuracy: 8679/10000 (86.79%)\n",
      "\n",
      "Round   5, Average loss 0.410 Test accuracy 86.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4535 \n",
      "Accuracy: 8568/10000 (85.68%)\n",
      "\n",
      "Round   6, Average loss 0.454 Test accuracy 85.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3614 \n",
      "Accuracy: 8952/10000 (89.52%)\n",
      "\n",
      "Round   7, Average loss 0.361 Test accuracy 89.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3958 \n",
      "Accuracy: 8771/10000 (87.71%)\n",
      "\n",
      "Round   8, Average loss 0.396 Test accuracy 87.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3709 \n",
      "Accuracy: 8866/10000 (88.66%)\n",
      "\n",
      "Round   9, Average loss 0.371 Test accuracy 88.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3581 \n",
      "Accuracy: 8936/10000 (89.36%)\n",
      "\n",
      "Round  10, Average loss 0.358 Test accuracy 89.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4446 \n",
      "Accuracy: 8711/10000 (87.11%)\n",
      "\n",
      "Round  11, Average loss 0.445 Test accuracy 87.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3856 \n",
      "Accuracy: 8882/10000 (88.82%)\n",
      "\n",
      "Round  12, Average loss 0.386 Test accuracy 88.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4953 \n",
      "Accuracy: 8591/10000 (85.91%)\n",
      "\n",
      "Round  13, Average loss 0.495 Test accuracy 85.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4748 \n",
      "Accuracy: 8671/10000 (86.71%)\n",
      "\n",
      "Round  14, Average loss 0.475 Test accuracy 86.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4404 \n",
      "Accuracy: 8736/10000 (87.36%)\n",
      "\n",
      "Round  15, Average loss 0.440 Test accuracy 87.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5441 \n",
      "Accuracy: 8546/10000 (85.46%)\n",
      "\n",
      "Round  16, Average loss 0.544 Test accuracy 85.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4849 \n",
      "Accuracy: 8663/10000 (86.63%)\n",
      "\n",
      "Round  17, Average loss 0.485 Test accuracy 86.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4551 \n",
      "Accuracy: 8772/10000 (87.72%)\n",
      "\n",
      "Round  18, Average loss 0.455 Test accuracy 87.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4188 \n",
      "Accuracy: 8863/10000 (88.63%)\n",
      "\n",
      "Round  19, Average loss 0.419 Test accuracy 88.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4442 \n",
      "Accuracy: 8751/10000 (87.51%)\n",
      "\n",
      "Round  20, Average loss 0.444 Test accuracy 87.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3897 \n",
      "Accuracy: 8893/10000 (88.93%)\n",
      "\n",
      "Round  21, Average loss 0.390 Test accuracy 88.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5105 \n",
      "Accuracy: 8594/10000 (85.94%)\n",
      "\n",
      "Round  22, Average loss 0.511 Test accuracy 85.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5826 \n",
      "Accuracy: 8358/10000 (83.58%)\n",
      "\n",
      "Round  23, Average loss 0.583 Test accuracy 83.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5137 \n",
      "Accuracy: 8574/10000 (85.74%)\n",
      "\n",
      "Round  24, Average loss 0.514 Test accuracy 85.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4212 \n",
      "Accuracy: 8814/10000 (88.14%)\n",
      "\n",
      "Round  25, Average loss 0.421 Test accuracy 88.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5835 \n",
      "Accuracy: 8510/10000 (85.10%)\n",
      "\n",
      "Round  26, Average loss 0.583 Test accuracy 85.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5014 \n",
      "Accuracy: 8549/10000 (85.49%)\n",
      "\n",
      "Round  27, Average loss 0.501 Test accuracy 85.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7211 \n",
      "Accuracy: 8081/10000 (80.81%)\n",
      "\n",
      "Round  28, Average loss 0.721 Test accuracy 80.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5447 \n",
      "Accuracy: 8478/10000 (84.78%)\n",
      "\n",
      "Round  29, Average loss 0.545 Test accuracy 84.780\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5814 \n",
      "Accuracy: 7609/10000 (76.09%)\n",
      "\n",
      "Round   1, Average loss 1.581 Test accuracy 76.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9816 \n",
      "Accuracy: 8930/10000 (89.30%)\n",
      "\n",
      "Round   2, Average loss 0.982 Test accuracy 89.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7049 \n",
      "Accuracy: 9046/10000 (90.46%)\n",
      "\n",
      "Round   3, Average loss 1.705 Test accuracy 90.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2611 \n",
      "Accuracy: 8945/10000 (89.45%)\n",
      "\n",
      "Round   4, Average loss 2.261 Test accuracy 89.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4544 \n",
      "Accuracy: 8982/10000 (89.82%)\n",
      "\n",
      "Round   5, Average loss 2.454 Test accuracy 89.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6377 \n",
      "Accuracy: 9009/10000 (90.09%)\n",
      "\n",
      "Round   6, Average loss 2.638 Test accuracy 90.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9719 \n",
      "Accuracy: 8952/10000 (89.52%)\n",
      "\n",
      "Round   7, Average loss 2.972 Test accuracy 89.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9891 \n",
      "Accuracy: 8974/10000 (89.74%)\n",
      "\n",
      "Round   8, Average loss 2.989 Test accuracy 89.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.4588 \n",
      "Accuracy: 8890/10000 (88.90%)\n",
      "\n",
      "Round   9, Average loss 3.459 Test accuracy 88.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9527 \n",
      "Accuracy: 8642/10000 (86.42%)\n",
      "\n",
      "Round  10, Average loss 3.953 Test accuracy 86.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9286 \n",
      "Accuracy: 8860/10000 (88.60%)\n",
      "\n",
      "Round  11, Average loss 3.929 Test accuracy 88.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2953 \n",
      "Accuracy: 8622/10000 (86.22%)\n",
      "\n",
      "Round  12, Average loss 4.295 Test accuracy 86.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8179 \n",
      "Accuracy: 8872/10000 (88.72%)\n",
      "\n",
      "Round  13, Average loss 3.818 Test accuracy 88.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8848 \n",
      "Accuracy: 8470/10000 (84.70%)\n",
      "\n",
      "Round  14, Average loss 4.885 Test accuracy 84.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3634 \n",
      "Accuracy: 8817/10000 (88.17%)\n",
      "\n",
      "Round  15, Average loss 4.363 Test accuracy 88.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2586 \n",
      "Accuracy: 8793/10000 (87.93%)\n",
      "\n",
      "Round  16, Average loss 4.259 Test accuracy 87.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3891 \n",
      "Accuracy: 8610/10000 (86.10%)\n",
      "\n",
      "Round  17, Average loss 4.389 Test accuracy 86.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8099 \n",
      "Accuracy: 8927/10000 (89.27%)\n",
      "\n",
      "Round  18, Average loss 3.810 Test accuracy 89.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2924 \n",
      "Accuracy: 8811/10000 (88.11%)\n",
      "\n",
      "Round  19, Average loss 4.292 Test accuracy 88.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.9224 \n",
      "Accuracy: 8397/10000 (83.97%)\n",
      "\n",
      "Round  20, Average loss 5.922 Test accuracy 83.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9647 \n",
      "Accuracy: 8741/10000 (87.41%)\n",
      "\n",
      "Round  21, Average loss 4.965 Test accuracy 87.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1063 \n",
      "Accuracy: 8897/10000 (88.97%)\n",
      "\n",
      "Round  22, Average loss 4.106 Test accuracy 88.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.1860 \n",
      "Accuracy: 8650/10000 (86.50%)\n",
      "\n",
      "Round  23, Average loss 5.186 Test accuracy 86.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.1974 \n",
      "Accuracy: 8404/10000 (84.04%)\n",
      "\n",
      "Round  24, Average loss 6.197 Test accuracy 84.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3289 \n",
      "Accuracy: 8799/10000 (87.99%)\n",
      "\n",
      "Round  25, Average loss 4.329 Test accuracy 87.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.4021 \n",
      "Accuracy: 8678/10000 (86.78%)\n",
      "\n",
      "Round  26, Average loss 4.402 Test accuracy 86.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.0693 \n",
      "Accuracy: 8877/10000 (88.77%)\n",
      "\n",
      "Round  27, Average loss 5.069 Test accuracy 88.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.6929 \n",
      "Accuracy: 8558/10000 (85.58%)\n",
      "\n",
      "Round  28, Average loss 5.693 Test accuracy 85.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.6630 \n",
      "Accuracy: 8550/10000 (85.50%)\n",
      "\n",
      "Round  29, Average loss 6.663 Test accuracy 85.500\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2696 \n",
      "Accuracy: 7027/10000 (70.27%)\n",
      "\n",
      "Round   1, Average loss 2.270 Test accuracy 70.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3736 \n",
      "Accuracy: 8932/10000 (89.32%)\n",
      "\n",
      "Round   2, Average loss 0.374 Test accuracy 89.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3701 \n",
      "Accuracy: 8932/10000 (89.32%)\n",
      "\n",
      "Round   3, Average loss 0.370 Test accuracy 89.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3544 \n",
      "Accuracy: 8953/10000 (89.53%)\n",
      "\n",
      "Round   4, Average loss 0.354 Test accuracy 89.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3483 \n",
      "Accuracy: 9073/10000 (90.73%)\n",
      "\n",
      "Round   5, Average loss 0.348 Test accuracy 90.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3406 \n",
      "Accuracy: 9083/10000 (90.83%)\n",
      "\n",
      "Round   6, Average loss 0.341 Test accuracy 90.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4552 \n",
      "Accuracy: 8799/10000 (87.99%)\n",
      "\n",
      "Round   7, Average loss 0.455 Test accuracy 87.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3468 \n",
      "Accuracy: 9069/10000 (90.69%)\n",
      "\n",
      "Round   8, Average loss 0.347 Test accuracy 90.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3612 \n",
      "Accuracy: 9092/10000 (90.92%)\n",
      "\n",
      "Round   9, Average loss 0.361 Test accuracy 90.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4574 \n",
      "Accuracy: 8792/10000 (87.92%)\n",
      "\n",
      "Round  10, Average loss 0.457 Test accuracy 87.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3993 \n",
      "Accuracy: 9025/10000 (90.25%)\n",
      "\n",
      "Round  11, Average loss 0.399 Test accuracy 90.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4556 \n",
      "Accuracy: 8725/10000 (87.25%)\n",
      "\n",
      "Round  12, Average loss 0.456 Test accuracy 87.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3817 \n",
      "Accuracy: 9015/10000 (90.15%)\n",
      "\n",
      "Round  13, Average loss 0.382 Test accuracy 90.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4610 \n",
      "Accuracy: 8820/10000 (88.20%)\n",
      "\n",
      "Round  14, Average loss 0.461 Test accuracy 88.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3590 \n",
      "Accuracy: 8978/10000 (89.78%)\n",
      "\n",
      "Round  15, Average loss 0.359 Test accuracy 89.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3794 \n",
      "Accuracy: 8978/10000 (89.78%)\n",
      "\n",
      "Round  16, Average loss 0.379 Test accuracy 89.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4052 \n",
      "Accuracy: 8903/10000 (89.03%)\n",
      "\n",
      "Round  17, Average loss 0.405 Test accuracy 89.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4834 \n",
      "Accuracy: 8947/10000 (89.47%)\n",
      "\n",
      "Round  18, Average loss 0.483 Test accuracy 89.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4386 \n",
      "Accuracy: 8669/10000 (86.69%)\n",
      "\n",
      "Round  19, Average loss 0.439 Test accuracy 86.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3943 \n",
      "Accuracy: 9035/10000 (90.35%)\n",
      "\n",
      "Round  20, Average loss 0.394 Test accuracy 90.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4587 \n",
      "Accuracy: 8850/10000 (88.50%)\n",
      "\n",
      "Round  21, Average loss 0.459 Test accuracy 88.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4557 \n",
      "Accuracy: 8859/10000 (88.59%)\n",
      "\n",
      "Round  22, Average loss 0.456 Test accuracy 88.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5394 \n",
      "Accuracy: 8736/10000 (87.36%)\n",
      "\n",
      "Round  23, Average loss 0.539 Test accuracy 87.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4057 \n",
      "Accuracy: 8979/10000 (89.79%)\n",
      "\n",
      "Round  24, Average loss 0.406 Test accuracy 89.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4388 \n",
      "Accuracy: 8972/10000 (89.72%)\n",
      "\n",
      "Round  25, Average loss 0.439 Test accuracy 89.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4700 \n",
      "Accuracy: 8897/10000 (88.97%)\n",
      "\n",
      "Round  26, Average loss 0.470 Test accuracy 88.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5225 \n",
      "Accuracy: 8764/10000 (87.64%)\n",
      "\n",
      "Round  27, Average loss 0.523 Test accuracy 87.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4399 \n",
      "Accuracy: 9017/10000 (90.17%)\n",
      "\n",
      "Round  28, Average loss 0.440 Test accuracy 90.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4691 \n",
      "Accuracy: 8853/10000 (88.53%)\n",
      "\n",
      "Round  29, Average loss 0.469 Test accuracy 88.530\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3019 \n",
      "Accuracy: 946/10000 (9.46%)\n",
      "\n",
      "Round   1, Average loss 2.302 Test accuracy 9.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1112 \n",
      "Accuracy: 2718/10000 (27.18%)\n",
      "\n",
      "Round   2, Average loss 2.111 Test accuracy 27.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8424 \n",
      "Accuracy: 4660/10000 (46.60%)\n",
      "\n",
      "Round   3, Average loss 1.842 Test accuracy 46.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1415 \n",
      "Accuracy: 5138/10000 (51.38%)\n",
      "\n",
      "Round   4, Average loss 2.141 Test accuracy 51.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1404 \n",
      "Accuracy: 7274/10000 (72.74%)\n",
      "\n",
      "Round   5, Average loss 1.140 Test accuracy 72.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9863 \n",
      "Accuracy: 5901/10000 (59.01%)\n",
      "\n",
      "Round   6, Average loss 1.986 Test accuracy 59.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1546 \n",
      "Accuracy: 7322/10000 (73.22%)\n",
      "\n",
      "Round   7, Average loss 1.155 Test accuracy 73.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4272 \n",
      "Accuracy: 6018/10000 (60.18%)\n",
      "\n",
      "Round   8, Average loss 1.427 Test accuracy 60.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6233 \n",
      "Accuracy: 6266/10000 (62.66%)\n",
      "\n",
      "Round   9, Average loss 1.623 Test accuracy 62.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0635 \n",
      "Accuracy: 5955/10000 (59.55%)\n",
      "\n",
      "Round  10, Average loss 2.064 Test accuracy 59.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2051 \n",
      "Accuracy: 5666/10000 (56.66%)\n",
      "\n",
      "Round  11, Average loss 2.205 Test accuracy 56.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1156 \n",
      "Accuracy: 6723/10000 (67.23%)\n",
      "\n",
      "Round  12, Average loss 1.116 Test accuracy 67.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6602 \n",
      "Accuracy: 6285/10000 (62.85%)\n",
      "\n",
      "Round  13, Average loss 1.660 Test accuracy 62.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0551 \n",
      "Accuracy: 6877/10000 (68.77%)\n",
      "\n",
      "Round  14, Average loss 1.055 Test accuracy 68.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1236 \n",
      "Accuracy: 6334/10000 (63.34%)\n",
      "\n",
      "Round  15, Average loss 2.124 Test accuracy 63.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1576 \n",
      "Accuracy: 6845/10000 (68.45%)\n",
      "\n",
      "Round  16, Average loss 1.158 Test accuracy 68.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6027 \n",
      "Accuracy: 6809/10000 (68.09%)\n",
      "\n",
      "Round  17, Average loss 1.603 Test accuracy 68.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4138 \n",
      "Accuracy: 4595/10000 (45.95%)\n",
      "\n",
      "Round  18, Average loss 2.414 Test accuracy 45.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7554 \n",
      "Accuracy: 6790/10000 (67.90%)\n",
      "\n",
      "Round  19, Average loss 1.755 Test accuracy 67.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7089 \n",
      "Accuracy: 5337/10000 (53.37%)\n",
      "\n",
      "Round  20, Average loss 2.709 Test accuracy 53.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4572 \n",
      "Accuracy: 6210/10000 (62.10%)\n",
      "\n",
      "Round  21, Average loss 1.457 Test accuracy 62.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2023 \n",
      "Accuracy: 4864/10000 (48.64%)\n",
      "\n",
      "Round  22, Average loss 3.202 Test accuracy 48.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3451 \n",
      "Accuracy: 6659/10000 (66.59%)\n",
      "\n",
      "Round  23, Average loss 1.345 Test accuracy 66.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7431 \n",
      "Accuracy: 6597/10000 (65.97%)\n",
      "\n",
      "Round  24, Average loss 1.743 Test accuracy 65.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8674 \n",
      "Accuracy: 6218/10000 (62.18%)\n",
      "\n",
      "Round  25, Average loss 1.867 Test accuracy 62.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7284 \n",
      "Accuracy: 6498/10000 (64.98%)\n",
      "\n",
      "Round  26, Average loss 1.728 Test accuracy 64.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6723 \n",
      "Accuracy: 6569/10000 (65.69%)\n",
      "\n",
      "Round  27, Average loss 1.672 Test accuracy 65.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7697 \n",
      "Accuracy: 6092/10000 (60.92%)\n",
      "\n",
      "Round  28, Average loss 1.770 Test accuracy 60.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4800 \n",
      "Accuracy: 6677/10000 (66.77%)\n",
      "\n",
      "Round  29, Average loss 1.480 Test accuracy 66.770\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 4 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 10 10000 \n",
      "\n",
      "(T, sigma)= 4 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3011 \n",
      "Accuracy: 1418/10000 (14.18%)\n",
      "\n",
      "Round   0, Average loss 2.301 Test accuracy 14.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0605 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   1, Average loss 3.060 Test accuracy 10.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8841 \n",
      "Accuracy: 3592/10000 (35.92%)\n",
      "\n",
      "Round   2, Average loss 1.884 Test accuracy 35.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5169 \n",
      "Accuracy: 5141/10000 (51.41%)\n",
      "\n",
      "Round   3, Average loss 1.517 Test accuracy 51.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4262 \n",
      "Accuracy: 6409/10000 (64.09%)\n",
      "\n",
      "Round   4, Average loss 1.426 Test accuracy 64.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1407 \n",
      "Accuracy: 5979/10000 (59.79%)\n",
      "\n",
      "Round   5, Average loss 1.141 Test accuracy 59.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2883 \n",
      "Accuracy: 5599/10000 (55.99%)\n",
      "\n",
      "Round   6, Average loss 2.288 Test accuracy 55.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.5254 \n",
      "Accuracy: 3800/10000 (38.00%)\n",
      "\n",
      "Round   7, Average loss 4.525 Test accuracy 38.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4725 \n",
      "Accuracy: 7114/10000 (71.14%)\n",
      "\n",
      "Round   8, Average loss 1.473 Test accuracy 71.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2861 \n",
      "Accuracy: 4372/10000 (43.72%)\n",
      "\n",
      "Round   9, Average loss 5.286 Test accuracy 43.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6918 \n",
      "Accuracy: 5764/10000 (57.64%)\n",
      "\n",
      "Round  10, Average loss 3.692 Test accuracy 57.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7166 \n",
      "Accuracy: 4939/10000 (49.39%)\n",
      "\n",
      "Round  11, Average loss 3.717 Test accuracy 49.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2930 \n",
      "Accuracy: 5790/10000 (57.90%)\n",
      "\n",
      "Round  12, Average loss 2.293 Test accuracy 57.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0396 \n",
      "Accuracy: 4905/10000 (49.05%)\n",
      "\n",
      "Round  13, Average loss 4.040 Test accuracy 49.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2626 \n",
      "Accuracy: 5296/10000 (52.96%)\n",
      "\n",
      "Round  14, Average loss 2.263 Test accuracy 52.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8503 \n",
      "Accuracy: 4320/10000 (43.20%)\n",
      "\n",
      "Round  15, Average loss 4.850 Test accuracy 43.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3638 \n",
      "Accuracy: 6219/10000 (62.19%)\n",
      "\n",
      "Round  16, Average loss 2.364 Test accuracy 62.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.1361 \n",
      "Accuracy: 4814/10000 (48.14%)\n",
      "\n",
      "Round  17, Average loss 5.136 Test accuracy 48.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7139 \n",
      "Accuracy: 4883/10000 (48.83%)\n",
      "\n",
      "Round  18, Average loss 3.714 Test accuracy 48.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.0874 \n",
      "Accuracy: 4735/10000 (47.35%)\n",
      "\n",
      "Round  19, Average loss 5.087 Test accuracy 47.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1635 \n",
      "Accuracy: 6897/10000 (68.97%)\n",
      "\n",
      "Round  20, Average loss 1.163 Test accuracy 68.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3248 \n",
      "Accuracy: 4284/10000 (42.84%)\n",
      "\n",
      "Round  21, Average loss 3.325 Test accuracy 42.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2763 \n",
      "Accuracy: 4363/10000 (43.63%)\n",
      "\n",
      "Round  22, Average loss 4.276 Test accuracy 43.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3955 \n",
      "Accuracy: 5362/10000 (53.62%)\n",
      "\n",
      "Round  23, Average loss 2.396 Test accuracy 53.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.0911 \n",
      "Accuracy: 3887/10000 (38.87%)\n",
      "\n",
      "Round  24, Average loss 5.091 Test accuracy 38.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0240 \n",
      "Accuracy: 7259/10000 (72.59%)\n",
      "\n",
      "Round  25, Average loss 1.024 Test accuracy 72.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3241 \n",
      "Accuracy: 3906/10000 (39.06%)\n",
      "\n",
      "Round  26, Average loss 4.324 Test accuracy 39.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9652 \n",
      "Accuracy: 4178/10000 (41.78%)\n",
      "\n",
      "Round  27, Average loss 4.965 Test accuracy 41.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6840 \n",
      "Accuracy: 6170/10000 (61.70%)\n",
      "\n",
      "Round  28, Average loss 2.684 Test accuracy 61.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.1483 \n",
      "Accuracy: 4027/10000 (40.27%)\n",
      "\n",
      "Round  29, Average loss 7.148 Test accuracy 40.270\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "N = args.num_users\n",
    "K = args.num_partition\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "# m_array = np.array(range(4,16)) # m is the number of received result @ master\n",
    "alloc_Num = 7\n",
    "sigma_array = np.array([1])\n",
    "\n",
    "\n",
    "loss_test_arr_v3 = np.empty((alloc_Num,len(sigma_array),N_trials,N_epochs))\n",
    "acc_test_arr_v3  = np.empty((alloc_Num,len(sigma_array),N_trials,N_epochs))\n",
    "\n",
    "for alloc_idx in range(alloc_Num):\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    T = 4\n",
    "    \n",
    "    if alloc_idx == 0:\n",
    "        Noise_Alloc = [0,1,2,3]\n",
    "    elif alloc_idx == 1:\n",
    "        Noise_Alloc = [0,2,4,6]\n",
    "    elif alloc_idx == 2:\n",
    "        Noise_Alloc = [1,3,5,7]\n",
    "    elif alloc_idx == 3:\n",
    "        Noise_Alloc = [0,3,6,9]\n",
    "    elif alloc_idx == 4:\n",
    "        Noise_Alloc = [6,7,8,9]\n",
    "    elif alloc_idx == 5:\n",
    "        Noise_Alloc = [1,3,5,8]\n",
    "    else:\n",
    "        Noise_Alloc = [1,3,6,8]\n",
    "    Signal_Alloc = []\n",
    "    for i in range(K+T):\n",
    "        if i not in Noise_Alloc:\n",
    "            Signal_Alloc.append(i)\n",
    "\n",
    "    j_array = np.array(range(K+T))\n",
    "    # print(\"j: \",(2*j_array+1)*math.pi/2/K,'\\n')\n",
    "\n",
    "    alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "    i_array = np.array(range(N))\n",
    "    z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "    \n",
    "    for sigma_idx in range(len(sigma_array)):\n",
    "        \n",
    "        sigma = sigma_array[sigma_idx]\n",
    "\n",
    "        X_tilde,a,b = BACC_Enc_withNoise(encoding_input_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "        y_tilde,a,b = BACC_Enc_withNoise(encoding_label_array_np, N, K, T, sigma, _Noise_Alloc = Noise_Alloc) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "\n",
    "        m = N # m is the number of received result @ master\n",
    "    #     print('number of results:',m)\n",
    "\n",
    "        for trial_idx in range(N_trials):\n",
    "            print('(T, sigma)=',T,sigma,') ',trial_idx,'-th Trial!!')\n",
    "\n",
    "            net_glob = CNNMnist2(args=args)\n",
    "            net_glob.cuda()\n",
    "            net_glob.train()\n",
    "\n",
    "            # copy weights\n",
    "            w_glob = net_glob.state_dict()\n",
    "\n",
    "            for iter in range(N_epochs): #args.epochs\n",
    "                w_locals, loss_locals = [], []\n",
    "                idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "                idxs_users = np.sort(idxs_users)\n",
    "                print('selected users:',idxs_users)\n",
    "\n",
    "                dec_z_array = []\n",
    "                for idx in idxs_users: #for idx in range(N):\n",
    "            #         print(idx)\n",
    "                    local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                    w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                    w_locals.append(copy.deepcopy(w))\n",
    "                    loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                    dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "                # update global weights\n",
    "                #w_glob = FedAvg(w_locals)\n",
    "                w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "                # copy weight to net_glob\n",
    "                net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                # print loss\n",
    "            #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "            #     loss_train_arr.append(loss_train)\n",
    "\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                acc_test_arr_v3[T_idx][sigma_idx][trial_idx][iter] = acc_test\n",
    "                loss_test_arr_v3[T_idx][sigma_idx][trial_idx][iter] = loss_test\n",
    "                if iter % 1 ==0:\n",
    "                    print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "                #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1, 1, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma_sel = 0\n",
    "\n",
    "plot_acc_v3 = acc_test_arr_v3\n",
    "\n",
    "print(plot_acc_v3.shape)\n",
    "\n",
    "# if alloc_idx == 0:\n",
    "#     Noise_Alloc = [0,1,2,3]\n",
    "# elif alloc_idx == 1:\n",
    "#     Noise_Alloc = [0,2,4,6]\n",
    "# elif alloc_idx == 2:\n",
    "#     Noise_Alloc = [1,3,5,7]\n",
    "# elif alloc_idx == 3:\n",
    "#     Noise_Alloc = [0,3,6,9]\n",
    "# elif alloc_idx == 4:\n",
    "#     Noise_Alloc = [6,7,8,9]\n",
    "# elif alloc_idx == 5:\n",
    "#     Noise_Alloc = [1,3,5,8]\n",
    "# else:\n",
    "#     Noise_Alloc = [1,3,6,8]\n",
    "\n",
    "plt.plot(plot_acc_v3[0,sigma_sel,0,:],label='[0,1,2,3]')\n",
    "plt.plot(plot_acc_v3[1,sigma_sel,0,:],label='[0,2,4,6]')\n",
    "plt.plot(plot_acc_v3[2,sigma_sel,0,:],label='[1,3,5,7]')\n",
    "plt.plot(plot_acc_v3[3,sigma_sel,0,:],label='[0,3,6,9]')\n",
    "# plt.plot(acc_test_arr_uncoded,'r',label='uncoded')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(title_name)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-323 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000\n",
      " 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000\n",
      " 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000 0.e+000\n",
      " 0.e+000 0.e+000 0.e+000]\n"
     ]
    }
   ],
   "source": [
    "print(acc_test_arr_v3[0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
