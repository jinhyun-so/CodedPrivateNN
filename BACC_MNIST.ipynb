{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2\n",
    "from models.Fed import FedAvg\n",
    "from models.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models.test import test_img\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Define the Loss function\n",
    "\n",
    "As we encode the labels as well, cross entropy function should take the one-hot vector with softed value as an input.\n",
    "However, cross entorpy function supported by pytorch only takes one dimensional label (e.g [1,0,9,...] where entries presents class labels).\n",
    "Hence, now I define my cross entropy function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_entropy(input, target, size_average=True):\n",
    "    \"\"\" Cross entropy that accepts soft targets\n",
    "    Args:\n",
    "         pred: predictions for neural network\n",
    "         targets: targets, can be soft\n",
    "         size_average: if false, sum is returned instead of mean\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        input = torch.FloatTensor([[1.1, 2.8, 1.3], [1.1, 2.1, 4.8]])\n",
    "        input = torch.autograd.Variable(out, requires_grad=True)\n",
    "\n",
    "        target = torch.FloatTensor([[0.05, 0.9, 0.05], [0.05, 0.05, 0.9]])\n",
    "        target = torch.autograd.Variable(y1)\n",
    "        loss = cross_entropy(input, target)\n",
    "        loss.backward()\n",
    "    \"\"\"\n",
    "    logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    if size_average:\n",
    "        return torch.mean(torch.sum(-target * logsoftmax(input) , dim=1))\n",
    "    else:\n",
    "        return torch.sum(torch.sum(-target * logsoftmax(input), dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Test my_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([2, 4, 0])\n",
      "tensor([[0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, autograd\n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target = torch.LongTensor([2,4,0])\n",
    "\n",
    "one_hot = torch.nn.functional.one_hot(target,num_classes=5)\n",
    "\n",
    "print(input.dim())\n",
    "print(target)\n",
    "print(one_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.FloatTensor' as parameter 'weight' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-54db371e0781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    611\u001b[0m                 raise TypeError(\"cannot assign '{}' as parameter '{}' \"\n\u001b[0;32m    612\u001b[0m                                 \u001b[1;34m\"(torch.nn.Parameter or None expected)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m                                 .format(torch.typename(value), name))\n\u001b[0m\u001b[0;32m    614\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot assign 'torch.FloatTensor' as parameter 'weight' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(2, 2)\n",
    "model.weight = torch.FloatTensor([[1,0],[0,1]])\n",
    "print(model.weight)\n",
    "print(model.bias)\n",
    "x = torch.randn(1, 2)\n",
    "# target = torch.randn(1, 2)\n",
    "output = model(x)\n",
    "print(x)\n",
    "print(output)\n",
    "# loss = my_loss(output, target)\n",
    "# loss.backward()\n",
    "# print(model.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "following outputs should be same.\n",
      "tensor(2.6336, grad_fn=<NllLossBackward>)\n",
      "tensor(2.6336, grad_fn=<NllLossBackward>)\n",
      "tensor(2.6336, grad_fn=<NllLossBackward>)\n",
      "tensor(2.6336, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nfollowing outputs should be same.\")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss_defalut = loss(input, target)\n",
    "print(loss_defalut)\n",
    "loss_defalut.backward()\n",
    "print(loss_defalut)\n",
    "\n",
    "\n",
    "print(loss(input, target))\n",
    "print(my_cross_entropy(input, one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "tensor(0.6178)\n",
      "tensor(0.5927)\n"
     ]
    }
   ],
   "source": [
    "out = torch.FloatTensor([[0.05, 0.9, 0.05], [0.05, 0.05, 0.9], [0.9, 0.05, 0.05]])\n",
    "out = torch.autograd.Variable(out)\n",
    "\n",
    "# Categorical targets\n",
    "y = torch.LongTensor([1, 2, 0])\n",
    "y = torch.autograd.Variable(y)\n",
    "\n",
    "# One-hot encoded targets\n",
    "y1 = torch.FloatTensor([[0, 1, 0], [0, 0, 1], [1, 0, 0]])\n",
    "y1 = torch.autograd.Variable(y1)\n",
    "\n",
    "print(y1)\n",
    "\n",
    "# Calculating the loss\n",
    "loss_val = nn.CrossEntropyLoss()(out, y)\n",
    "loss_val1 = nn.BCEWithLogitsLoss()(out, y1)\n",
    "\n",
    "print(loss_val)\n",
    "print(loss_val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether my_cross_entropy function works properly with soft-valued one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0]])\n",
      "tensor(2.6336, grad_fn=<MeanBackward0>)\n",
      "\n",
      "check the soft valued one-hot vector\n",
      "tensor([[ 0.0000,  0.1000,  0.9000,  0.1000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.1000,  0.9000],\n",
      "        [ 1.1000, -0.1000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(2.6009, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target = torch.LongTensor([2,4,0])\n",
    "one_hot = torch.nn.functional.one_hot(target,num_classes=5)\n",
    "print(one_hot)\n",
    "print(my_cross_entropy(input, one_hot))\n",
    "print()\n",
    "\n",
    "print(\"check the soft valued one-hot vector\")\n",
    "one_hot = torch.FloatTensor([[0,0.1, 0.9, 0.1, 0],[0, 0, 0, 0.1, 0.9],[1.1, -0.1, 0,0,0]])\n",
    "print(one_hot)\n",
    "print(my_cross_entropy(input, one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_argument:    \n",
    "    epochs = 200    #\"rounds of training\"\n",
    "    num_users = 15  # \"number of users: K\"\n",
    "    frac = 0.5 #\"the fraction of clients: C\"\n",
    "    local_ep = 1 #\"the number of local epochs: E\"\n",
    "    local_bs = 200 #\"local batch size: B\"\n",
    "    bs=128 #\"test batch size\"\n",
    "    lr=0.01 #\"learning rate\"\n",
    "    momentum=0.5 # \"SGD momentum (default: 0.5)\"\n",
    "    split='user' # \"train-test split type, user or sample\"\n",
    "    opt='ADAM'\n",
    "    loss='Default' # 'Custom' or 'Default'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num=9 #, help='number of each kind of kernel')\n",
    "    kernel_sizes='3,4,5' #  help='comma-separated kernel size to use for convolution')\n",
    "    norm='None' #, help=\"batch_norm, layer_norm, or None\")\n",
    "    num_filters=32 #, help=\"number of filters for conv nets\")\n",
    "    max_pool='True' #help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    dataset='mnist' #, help=\"name of dataset\")\n",
    "    iid=1\n",
    "    num_classes=10#, help=\"number of classes\")\n",
    "    num_channels=1#, help=\"number of channels of imges\")\n",
    "    gpu=1#, help=\"GPU ID, -1 for CPU\")\n",
    "    stopping_rounds=10#, help='rounds of early stopping')\n",
    "    verbose='False'#, help='verbose print')\n",
    "    seed=1#, help='random seed (default: 1)')\n",
    "    \n",
    "args = my_argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "# load dataset and split users\n",
    "if args.dataset == 'mnist':\n",
    "    trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "    dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "    # sample users\n",
    "    if args.iid:\n",
    "        dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "elif args.dataset == 'cifar':\n",
    "    trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "    dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "    if args.iid:\n",
    "        dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        exit('Error: only consider IID setting in CIFAR10')\n",
    "else:\n",
    "    exit('Error: unrecognized dataset')\n",
    "img_size = dataset_train[0][0].shape\n",
    "\n",
    "# print(dataset_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train CNN with Torch's CrossEntropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNMnist2(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_glob = CNNMnist2(args=args)\n",
    "net_glob.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNMnist2(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.343 Test accuracy 9.800\n",
      "\n",
      "Test set: Average loss: 2.3013 \n",
      "Accuracy: 1823/10000 (18.23%)\n",
      "\n",
      "Round   1, Average loss 2.098 Test accuracy 18.230\n",
      "\n",
      "Test set: Average loss: 0.7712 \n",
      "Accuracy: 8988/10000 (89.88%)\n",
      "\n",
      "Round   2, Average loss 1.264 Test accuracy 89.880\n",
      "\n",
      "Test set: Average loss: 0.1878 \n",
      "Accuracy: 9523/10000 (95.23%)\n",
      "\n",
      "Round   3, Average loss 0.661 Test accuracy 95.230\n",
      "\n",
      "Test set: Average loss: 0.1428 \n",
      "Accuracy: 9633/10000 (96.33%)\n",
      "\n",
      "Round   4, Average loss 0.478 Test accuracy 96.330\n",
      "\n",
      "Test set: Average loss: 0.1150 \n",
      "Accuracy: 9677/10000 (96.77%)\n",
      "\n",
      "Round   5, Average loss 0.403 Test accuracy 96.770\n",
      "\n",
      "Test set: Average loss: 0.1033 \n",
      "Accuracy: 9703/10000 (97.03%)\n",
      "\n",
      "Round   6, Average loss 0.367 Test accuracy 97.030\n",
      "\n",
      "Test set: Average loss: 0.0901 \n",
      "Accuracy: 9733/10000 (97.33%)\n",
      "\n",
      "Round   7, Average loss 0.343 Test accuracy 97.330\n",
      "\n",
      "Test set: Average loss: 0.0845 \n",
      "Accuracy: 9754/10000 (97.54%)\n",
      "\n",
      "Round   8, Average loss 0.318 Test accuracy 97.540\n",
      "\n",
      "Test set: Average loss: 0.0821 \n",
      "Accuracy: 9754/10000 (97.54%)\n",
      "\n",
      "Round   9, Average loss 0.308 Test accuracy 97.540\n"
     ]
    }
   ],
   "source": [
    "print(net_glob)\n",
    "net_glob.train()\n",
    "\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()\n",
    "\n",
    "# training\n",
    "loss_train = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "cv_loss, cv_acc = [], []\n",
    "val_loss_pre, counter = 0, 0\n",
    "net_best = None\n",
    "best_loss = None\n",
    "val_acc_list, net_list = [], []\n",
    "\n",
    "for iter in range(10): #args.epochs\n",
    "    w_locals, loss_locals = [], []\n",
    "    m = 15\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    for idx in idxs_users:\n",
    "#         print(idx)\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    \n",
    "    loss_train.append(loss_avg)\n",
    "    \n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "    acc_test_arr.append(acc_test)\n",
    "    loss_test_arr.append(loss_test)\n",
    "    if iter % 1 ==0:\n",
    "        print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "    #print(loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train CNN with Customized Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.loss='Custom' # 'Custom' or 'Default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.309 Test accuracy 9.800\n",
      "\n",
      "Test set: Average loss: 1.9062 \n",
      "Accuracy: 8132/10000 (81.32%)\n",
      "\n",
      "Round   1, Average loss 1.646 Test accuracy 81.320\n",
      "\n",
      "Test set: Average loss: 0.1939 \n",
      "Accuracy: 9448/10000 (94.48%)\n",
      "\n",
      "Round   2, Average loss 0.732 Test accuracy 94.480\n",
      "\n",
      "Test set: Average loss: 0.1276 \n",
      "Accuracy: 9642/10000 (96.42%)\n",
      "\n",
      "Round   3, Average loss 0.396 Test accuracy 96.420\n",
      "\n",
      "Test set: Average loss: 0.1027 \n",
      "Accuracy: 9705/10000 (97.05%)\n",
      "\n",
      "Round   4, Average loss 0.320 Test accuracy 97.050\n",
      "\n",
      "Test set: Average loss: 0.0857 \n",
      "Accuracy: 9746/10000 (97.46%)\n",
      "\n",
      "Round   5, Average loss 0.277 Test accuracy 97.460\n",
      "\n",
      "Test set: Average loss: 0.0766 \n",
      "Accuracy: 9767/10000 (97.67%)\n",
      "\n",
      "Round   6, Average loss 0.249 Test accuracy 97.670\n",
      "\n",
      "Test set: Average loss: 0.0694 \n",
      "Accuracy: 9793/10000 (97.93%)\n",
      "\n",
      "Round   7, Average loss 0.235 Test accuracy 97.930\n",
      "\n",
      "Test set: Average loss: 0.0643 \n",
      "Accuracy: 9805/10000 (98.05%)\n",
      "\n",
      "Round   8, Average loss 0.222 Test accuracy 98.050\n",
      "\n",
      "Test set: Average loss: 0.0613 \n",
      "Accuracy: 9830/10000 (98.30%)\n",
      "\n",
      "Round   9, Average loss 0.213 Test accuracy 98.300\n"
     ]
    }
   ],
   "source": [
    "net_glob = CNNMnist2(args=args)\n",
    "net_glob.cuda()\n",
    "net_glob.train()\n",
    "\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()\n",
    "\n",
    "# training\n",
    "loss_train = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "cv_loss, cv_acc = [], []\n",
    "val_loss_pre, counter = 0, 0\n",
    "net_best = None\n",
    "best_loss = None\n",
    "val_acc_list, net_list = [], []\n",
    "\n",
    "for iter in range(10): #args.epochs\n",
    "    w_locals, loss_locals = [], []\n",
    "    m = 15\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    for idx in range(args.num_users):\n",
    "#         print(idx)\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    \n",
    "    loss_train.append(loss_avg)\n",
    "    \n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "    acc_test_arr.append(acc_test)\n",
    "    loss_test_arr.append(loss_test)\n",
    "    if iter % 1 ==0:\n",
    "        print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "    #print(loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train CNN by utilizing BACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. BACC encoding for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_argument:    \n",
    "    epochs = 200    #\"rounds of training\"\n",
    "    num_users = 15  # \"number of users: N\"\n",
    "    num_partition = 6 # \"number of users: K\"\n",
    "    frac = 0.5 #\"the fraction of clients: C\"\n",
    "    local_ep = 1 #\"the number of local epochs: E\"\n",
    "    local_bs = 200 #\"local batch size: B\"\n",
    "    bs=200 #\"test batch size\"\n",
    "    lr=0.01 #\"learning rate\"\n",
    "    momentum=0.5 # \"SGD momentum (default: 0.5)\"\n",
    "    split='user' # \"train-test split type, user or sample\"\n",
    "    opt='ADAM'\n",
    "    loss='Custom' # 'Custom' or 'Default'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num=9 #, help='number of each kind of kernel')\n",
    "    kernel_sizes='3,4,5' #  help='comma-separated kernel size to use for convolution')\n",
    "    norm='None' #, help=\"batch_norm, layer_norm, or None\")\n",
    "    num_filters=32 #, help=\"number of filters for conv nets\")\n",
    "    max_pool='True' #help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    dataset='mnist' #, help=\"name of dataset\")\n",
    "    iid=1\n",
    "    num_classes=10#, help=\"number of classes\")\n",
    "    num_channels=1#, help=\"number of channels of imges\")\n",
    "    gpu=1#, help=\"GPU ID, -1 for CPU\")\n",
    "    stopping_rounds=10#, help='rounds of early stopping')\n",
    "    verbose='False'#, help='verbose print')\n",
    "    seed=1#, help='random seed (default: 1)')\n",
    "    \n",
    "args = my_argument()\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "# load dataset and split users\n",
    "trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "\n",
    "dict_users = mnist_iid(dataset_train, args.num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X: (60000, 784)\n",
      "size of Y: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "encoding_input_array_np = np.empty((len(dataset_train),28*28))\n",
    "encoding_label_array_np = np.empty((len(dataset_train),args.num_classes))\n",
    "print(\"size of X:\" ,encoding_input_array_np.shape)\n",
    "print(\"size of Y:\" ,encoding_label_array_np.shape)\n",
    "\n",
    "Size_submatrices = int(60000/args.num_users)\n",
    "\n",
    "for i in range(args.num_users):\n",
    "    \n",
    "    stt_pos = i*Size_submatrices\n",
    "    end_pos = (i+1)*Size_submatrices\n",
    "#     print(i,stt_pos,end_pos)\n",
    "    Temp_train = DataLoader(DatasetSplit(dataset_train, dict_users[i]), batch_size=Size_submatrices, shuffle=True)\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(Temp_train):\n",
    "        \n",
    "        images_np = images.detach().cpu().numpy()\n",
    "        encoding_input_array_np[stt_pos:end_pos,:] = np.reshape(images_np, (Size_submatrices,28*28))\n",
    "#         print(encoding_input_array_np[stt_pos:end_pos,:].shape)\n",
    "\n",
    "        onehot_labels = torch.nn.functional.one_hot(labels,num_classes=args.num_classes)\n",
    "        labels_np = onehot_labels.detach().cpu().numpy()\n",
    "#         print(labels_np.shape)\n",
    "        encoding_label_array_np[stt_pos:end_pos,:] = labels_np\n",
    "\n",
    "\n",
    "# print(labels_np[0:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_array:  [ 0.96592583  0.70710678  0.25881905 -0.25881905 -0.70710678 -0.96592583] \n",
      "\n",
      "z_array:  [ 1.          0.9781476   0.91354546  0.80901699  0.66913061  0.5\n",
      "  0.30901699  0.10452846 -0.10452846 -0.30901699 -0.5        -0.66913061\n",
      " -0.80901699 -0.91354546 -0.9781476 ] \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n",
      "@BACC_Enc: N,K, m_i= 15 6 10000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "N= args.num_users\n",
    "K= args.num_partition\n",
    "\n",
    "\n",
    "j_array = np.array(range(K))\n",
    "# print(\"j: \",(2*j_array+1)*math.pi/2/K,'\\n')\n",
    "\n",
    "alpha_array = np.cos((2*j_array+1)*math.pi/(2*K)) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "print(\"alpha_array: \",alpha_array,'\\n')\n",
    "\n",
    "i_array = np.array(range(N))\n",
    "z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "print(\"z_array: \",z_array,'\\n')\n",
    "\n",
    "X_tilde = BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "y_tilde = BACC_Enc(encoding_label_array_np, alpha_array, z_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10000, 784)\n",
      "(15, 10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_tilde.shape)\n",
    "print(y_tilde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of results: 4\n",
      "(m= 4 )  0 -th Trial!!\n",
      "selected users: [ 1  4  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  4 13]\n",
      "\n",
      "Test set: Average loss: 2.2321 \n",
      "Accuracy: 1568/10000 (15.68%)\n",
      "\n",
      "Round   2, Average loss 2.232 Test accuracy 15.680\n",
      "selected users: [ 0  4 10 11]\n",
      "\n",
      "Test set: Average loss: 3.0020 \n",
      "Accuracy: 1771/10000 (17.71%)\n",
      "\n",
      "Round   3, Average loss 3.002 Test accuracy 17.710\n",
      "selected users: [ 0  1  4 10]\n",
      "\n",
      "Test set: Average loss: 2.5208 \n",
      "Accuracy: 1060/10000 (10.60%)\n",
      "\n",
      "Round   4, Average loss 2.521 Test accuracy 10.600\n",
      "selected users: [2 4 6 7]\n",
      "\n",
      "Test set: Average loss: 2.3053 \n",
      "Accuracy: 981/10000 (9.81%)\n",
      "\n",
      "Round   5, Average loss 2.305 Test accuracy 9.810\n",
      "selected users: [ 4  8 12 13]\n",
      "\n",
      "Test set: Average loss: 3.6363 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 3.636 Test accuracy 9.800\n",
      "selected users: [ 1  6  7 12]\n",
      "\n",
      "Test set: Average loss: 2.2142 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.214 Test accuracy 9.800\n",
      "selected users: [0 2 3 4]\n",
      "\n",
      "Test set: Average loss: 28467.7848 \n",
      "Accuracy: 575/10000 (5.75%)\n",
      "\n",
      "Round   8, Average loss 28467.785 Test accuracy 5.750\n",
      "selected users: [ 0 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1423.5108 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 1423.511 Test accuracy 9.800\n",
      "selected users: [ 2  7 11 12]\n",
      "\n",
      "Test set: Average loss: 2.2531 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.253 Test accuracy 9.800\n",
      "selected users: [ 3  6  9 10]\n",
      "\n",
      "Test set: Average loss: 441.4736 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 441.474 Test accuracy 9.800\n",
      "selected users: [1 5 8 9]\n",
      "\n",
      "Test set: Average loss: 18424.5080 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 18424.508 Test accuracy 9.800\n",
      "selected users: [ 4  6  9 12]\n",
      "\n",
      "Test set: Average loss: 71595.4632 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 71595.463 Test accuracy 9.800\n",
      "selected users: [ 2  5  8 13]\n",
      "\n",
      "Test set: Average loss: 102154.6729 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 102154.673 Test accuracy 9.800\n",
      "selected users: [ 2  6 10 12]\n",
      "\n",
      "Test set: Average loss: 296945.6696 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 296945.670 Test accuracy 9.800\n",
      "selected users: [ 1  6  7 10]\n",
      "\n",
      "Test set: Average loss: 1230283.4393 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 1230283.439 Test accuracy 9.800\n",
      "selected users: [ 2  7  9 12]\n",
      "\n",
      "Test set: Average loss: 3328137.9132 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 3328137.913 Test accuracy 9.800\n",
      "selected users: [ 1  8 11 13]\n",
      "\n",
      "Test set: Average loss: 10990323.7964 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 10990323.796 Test accuracy 9.800\n",
      "selected users: [ 5  8  9 11]\n",
      "\n",
      "Test set: Average loss: 38550829.9573 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 38550829.957 Test accuracy 9.800\n",
      "selected users: [3 4 5 6]\n",
      "\n",
      "Test set: Average loss: 175127319.8251 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 175127319.825 Test accuracy 9.800\n",
      "selected users: [ 2  4  7 10]\n",
      "\n",
      "Test set: Average loss: 592091338.0011 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 592091338.001 Test accuracy 9.800\n",
      "selected users: [ 0  1  9 11]\n",
      "\n",
      "Test set: Average loss: 1979160358.5709 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 1979160358.571 Test accuracy 9.800\n",
      "selected users: [ 3  4  7 13]\n",
      "\n",
      "Test set: Average loss: 6543898576.9650 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 6543898576.965 Test accuracy 9.800\n",
      "selected users: [ 0  3 10 11]\n",
      "\n",
      "Test set: Average loss: 21753673812.0379 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 21753673812.038 Test accuracy 9.800\n",
      "selected users: [ 6  8  9 10]\n",
      "\n",
      "Test set: Average loss: 73650394472.9275 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 73650394472.928 Test accuracy 9.800\n",
      "selected users: [ 6  8 12 14]\n",
      "\n",
      "Test set: Average loss: 248485225538.0156 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 248485225538.016 Test accuracy 9.800\n",
      "selected users: [ 1  2 13 14]\n",
      "\n",
      "Test set: Average loss: 805874162678.6512 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 805874162678.651 Test accuracy 9.800\n",
      "selected users: [0 1 4 9]\n",
      "\n",
      "Test set: Average loss: 2724255879923.7837 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2724255879923.784 Test accuracy 9.800\n",
      "selected users: [ 0  7 10 14]\n",
      "\n",
      "Test set: Average loss: 9198768540040.0566 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 9198768540040.057 Test accuracy 9.800\n",
      "(m= 4 )  1 -th Trial!!\n",
      "selected users: [1 3 5 6]\n",
      "\n",
      "Test set: Average loss: 53.5875 \n",
      "Accuracy: 1024/10000 (10.24%)\n",
      "\n",
      "Round   0, Average loss 53.588 Test accuracy 10.240\n",
      "selected users: [ 0  3  4 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  9 10 11]\n",
      "\n",
      "Test set: Average loss: 2.2121 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.212 Test accuracy 9.800\n",
      "selected users: [ 4  5  9 10]\n",
      "\n",
      "Test set: Average loss: 2.1863 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.186 Test accuracy 9.800\n",
      "selected users: [4 5 8 9]\n",
      "\n",
      "Test set: Average loss: 51.5931 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 51.593 Test accuracy 9.800\n",
      "selected users: [0 5 7 8]\n",
      "\n",
      "Test set: Average loss: 2.2899 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.290 Test accuracy 9.800\n",
      "selected users: [ 4  7  9 11]\n",
      "\n",
      "Test set: Average loss: 35.5336 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 35.534 Test accuracy 9.800\n",
      "selected users: [ 2  6  8 14]\n",
      "\n",
      "Test set: Average loss: 2.2084 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.208 Test accuracy 9.800\n",
      "selected users: [2 4 7 9]\n",
      "\n",
      "Test set: Average loss: 4166.3804 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 4166.380 Test accuracy 9.800\n",
      "selected users: [ 0  4 10 14]\n",
      "\n",
      "Test set: Average loss: 1661.7348 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 1661.735 Test accuracy 9.800\n",
      "selected users: [ 2  3 11 12]\n",
      "\n",
      "Test set: Average loss: 30265.2331 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 30265.233 Test accuracy 9.800\n",
      "selected users: [ 0  2 10 11]\n",
      "\n",
      "Test set: Average loss: 2.1976 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.198 Test accuracy 9.800\n",
      "selected users: [ 2  4  5 11]\n",
      "\n",
      "Test set: Average loss: 2.1900 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.190 Test accuracy 9.800\n",
      "selected users: [ 3  7 11 12]\n",
      "\n",
      "Test set: Average loss: 2.2022 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.202 Test accuracy 9.800\n",
      "selected users: [1 6 8 9]\n",
      "\n",
      "Test set: Average loss: 2.1842 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.184 Test accuracy 9.800\n",
      "selected users: [ 6  7  8 12]\n",
      "\n",
      "Test set: Average loss: 2.1822 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.182 Test accuracy 9.800\n",
      "selected users: [3 4 6 7]\n",
      "\n",
      "Test set: Average loss: 2.1881 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.188 Test accuracy 9.800\n",
      "selected users: [ 6  7  9 12]\n",
      "\n",
      "Test set: Average loss: 2.1838 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.184 Test accuracy 9.800\n",
      "selected users: [ 4  6  7 11]\n",
      "\n",
      "Test set: Average loss: 2.1819 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.182 Test accuracy 9.800\n",
      "selected users: [ 1  4  5 13]\n",
      "\n",
      "Test set: Average loss: 2.1826 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.183 Test accuracy 9.800\n",
      "selected users: [ 0  3  4 11]\n",
      "\n",
      "Test set: Average loss: 2.1819 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.182 Test accuracy 9.800\n",
      "selected users: [ 0  8  9 13]\n",
      "\n",
      "Test set: Average loss: 2.1819 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.182 Test accuracy 9.800\n",
      "selected users: [ 0  2  9 10]\n",
      "\n",
      "Test set: Average loss: 2.1831 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.183 Test accuracy 9.800\n",
      "selected users: [ 1  3  6 12]\n",
      "\n",
      "Test set: Average loss: 2.1831 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.183 Test accuracy 9.800\n",
      "selected users: [ 3  4 10 12]\n",
      "\n",
      "Test set: Average loss: 2.1831 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.183 Test accuracy 9.800\n",
      "selected users: [ 3  5  8 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1831 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.183 Test accuracy 9.800\n",
      "selected users: [ 2  8  9 13]\n",
      "\n",
      "Test set: Average loss: 2.1838 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.184 Test accuracy 9.800\n",
      "selected users: [ 3  5  7 12]\n",
      "\n",
      "Test set: Average loss: 2.1838 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.184 Test accuracy 9.800\n",
      "selected users: [ 3  8 12 14]\n",
      "\n",
      "Test set: Average loss: 2.1838 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.184 Test accuracy 9.800\n",
      "selected users: [5 6 7 9]\n",
      "\n",
      "Test set: Average loss: 2.1838 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.184 Test accuracy 9.800\n",
      "(m= 4 )  2 -th Trial!!\n",
      "selected users: [ 7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 2.1752 \n",
      "Accuracy: 2096/10000 (20.96%)\n",
      "\n",
      "Round   0, Average loss 2.175 Test accuracy 20.960\n",
      "selected users: [ 1  2  6 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 5 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  5  6 11]\n",
      "\n",
      "Test set: Average loss: 1.5754 \n",
      "Accuracy: 3947/10000 (39.47%)\n",
      "\n",
      "Round   3, Average loss 1.575 Test accuracy 39.470\n",
      "selected users: [ 2  4  9 12]\n",
      "\n",
      "Test set: Average loss: 2.3870 \n",
      "Accuracy: 5001/10000 (50.01%)\n",
      "\n",
      "Round   4, Average loss 2.387 Test accuracy 50.010\n",
      "selected users: [ 3  5  7 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  9 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 7 8 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  7 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  6 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  8 10 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  8 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  7 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  4  5 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  4  5 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 5  7 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5  7 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  7 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 981/10000 (9.81%)\n",
      "\n",
      "Round  20, Average loss 2.302 Test accuracy 9.810\n",
      "selected users: [ 0  6  9 11]\n",
      "\n",
      "Test set: Average loss: 2.3024 \n",
      "Accuracy: 981/10000 (9.81%)\n",
      "\n",
      "Round  21, Average loss 2.302 Test accuracy 9.810\n",
      "selected users: [ 1  4 11 13]\n",
      "\n",
      "Test set: Average loss: 32884.7540 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  22, Average loss 32884.754 Test accuracy 9.820\n",
      "selected users: [ 6 10 12 13]\n",
      "\n",
      "Test set: Average loss: 142749.4810 \n",
      "Accuracy: 982/10000 (9.82%)\n",
      "\n",
      "Round  23, Average loss 142749.481 Test accuracy 9.820\n",
      "selected users: [ 0  7 12 13]\n",
      "\n",
      "Test set: Average loss: 835946.7028 \n",
      "Accuracy: 983/10000 (9.83%)\n",
      "\n",
      "Round  24, Average loss 835946.703 Test accuracy 9.830\n",
      "selected users: [ 7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 4374946.5460 \n",
      "Accuracy: 985/10000 (9.85%)\n",
      "\n",
      "Round  25, Average loss 4374946.546 Test accuracy 9.850\n",
      "selected users: [ 4  5  6 11]\n",
      "\n",
      "Test set: Average loss: 15547627.4676 \n",
      "Accuracy: 986/10000 (9.86%)\n",
      "\n",
      "Round  26, Average loss 15547627.468 Test accuracy 9.860\n",
      "selected users: [ 1  9 11 12]\n",
      "\n",
      "Test set: Average loss: 65739409.3351 \n",
      "Accuracy: 987/10000 (9.87%)\n",
      "\n",
      "Round  27, Average loss 65739409.335 Test accuracy 9.870\n",
      "selected users: [ 8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 263639379.4853 \n",
      "Accuracy: 988/10000 (9.88%)\n",
      "\n",
      "Round  28, Average loss 263639379.485 Test accuracy 9.880\n",
      "selected users: [ 3  5  6 12]\n",
      "\n",
      "Test set: Average loss: 847767635.4855 \n",
      "Accuracy: 987/10000 (9.87%)\n",
      "\n",
      "Round  29, Average loss 847767635.486 Test accuracy 9.870\n",
      "(m= 4 )  3 -th Trial!!\n",
      "selected users: [ 1  7 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  8 10 11]\n",
      "\n",
      "Test set: Average loss: 2.0546 \n",
      "Accuracy: 2092/10000 (20.92%)\n",
      "\n",
      "Round   1, Average loss 2.055 Test accuracy 20.920\n",
      "selected users: [ 1  5  6 10]\n",
      "\n",
      "Test set: Average loss: 2.0904 \n",
      "Accuracy: 1984/10000 (19.84%)\n",
      "\n",
      "Round   2, Average loss 2.090 Test accuracy 19.840\n",
      "selected users: [ 3  8 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 1 2 7]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [2 4 5 7]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [2 3 5 6]\n",
      "\n",
      "Test set: Average loss: 2.3987 \n",
      "Accuracy: 1048/10000 (10.48%)\n",
      "\n",
      "Round   6, Average loss 2.399 Test accuracy 10.480\n",
      "selected users: [ 2  4  9 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  7 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  5  8 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5  9 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  4 10 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  5 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  9 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  7 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 5 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  7  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  4 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5  8 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 4 6 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 3 4 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5  8 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  6  7 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  7  8 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  8 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5  6 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "(m= 4 )  4 -th Trial!!\n",
      "selected users: [ 4  6  8 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  8 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  8 10 11]\n",
      "\n",
      "Test set: Average loss: 1.7592 \n",
      "Accuracy: 3721/10000 (37.21%)\n",
      "\n",
      "Round   2, Average loss 1.759 Test accuracy 37.210\n",
      "selected users: [ 1  2  5 14]\n",
      "\n",
      "Test set: Average loss: 2.0038 \n",
      "Accuracy: 2436/10000 (24.36%)\n",
      "\n",
      "Round   3, Average loss 2.004 Test accuracy 24.360\n",
      "selected users: [ 0  6  8 13]\n",
      "\n",
      "Test set: Average loss: 2.1656 \n",
      "Accuracy: 1706/10000 (17.06%)\n",
      "\n",
      "Round   4, Average loss 2.166 Test accuracy 17.060\n",
      "selected users: [ 9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 5809.6075 \n",
      "Accuracy: 1069/10000 (10.69%)\n",
      "\n",
      "Round   5, Average loss 5809.608 Test accuracy 10.690\n",
      "selected users: [ 0  5  6 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5  7 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  5 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  9 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  6 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  9 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  6 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  6  7 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  3  6 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1 11 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [2 4 6 8]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  7 10 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 6  9 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  6 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 1 4 7]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  9 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  8 11 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  5  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 4 6 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "(m= 4 )  5 -th Trial!!\n",
      "selected users: [ 3  4 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  5 14]\n",
      "\n",
      "Test set: Average loss: 1.9162 \n",
      "Accuracy: 2055/10000 (20.55%)\n",
      "\n",
      "Round   1, Average loss 1.916 Test accuracy 20.550\n",
      "selected users: [ 3  5 10 13]\n",
      "\n",
      "Test set: Average loss: 1.9164 \n",
      "Accuracy: 3336/10000 (33.36%)\n",
      "\n",
      "Round   2, Average loss 1.916 Test accuracy 33.360\n",
      "selected users: [ 4 11 12 14]\n",
      "\n",
      "Test set: Average loss: 9.9938 \n",
      "Accuracy: 5657/10000 (56.57%)\n",
      "\n",
      "Round   3, Average loss 9.994 Test accuracy 56.570\n",
      "selected users: [ 4  6  7 14]\n",
      "\n",
      "Test set: Average loss: 5.1871 \n",
      "Accuracy: 3573/10000 (35.73%)\n",
      "\n",
      "Round   4, Average loss 5.187 Test accuracy 35.730\n",
      "selected users: [ 1  4  8 11]\n",
      "\n",
      "Test set: Average loss: 189.2262 \n",
      "Accuracy: 5537/10000 (55.37%)\n",
      "\n",
      "Round   5, Average loss 189.226 Test accuracy 55.370\n",
      "selected users: [0 2 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 5  7  8 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 2 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  8 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 5  7 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  7 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  8 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  7 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  5 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 2 7 8]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 1 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  5 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  4  8 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4  5 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 2 3 4]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4  7 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  8 10 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  5  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [1 4 7 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 5  6  8 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5  8 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "(m= 4 )  6 -th Trial!!\n",
      "selected users: [ 2  8  9 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  8 10 13]\n",
      "\n",
      "Test set: Average loss: 1.9293 \n",
      "Accuracy: 3254/10000 (32.54%)\n",
      "\n",
      "Round   1, Average loss 1.929 Test accuracy 32.540\n",
      "selected users: [ 0  3  6 11]\n",
      "\n",
      "Test set: Average loss: 11.9440 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round   2, Average loss 11.944 Test accuracy 92.970\n",
      "selected users: [1 3 5 9]\n",
      "\n",
      "Test set: Average loss: 35.9027 \n",
      "Accuracy: 9483/10000 (94.83%)\n",
      "\n",
      "Round   3, Average loss 35.903 Test accuracy 94.830\n",
      "selected users: [ 6  7  8 13]\n",
      "\n",
      "Test set: Average loss: 294.0077 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round   4, Average loss 294.008 Test accuracy 95.060\n",
      "selected users: [ 6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2357.5042 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round   5, Average loss 2357.504 Test accuracy 95.560\n",
      "selected users: [ 3  5  6 10]\n",
      "\n",
      "Test set: Average loss: 12778.6239 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round   6, Average loss 12778.624 Test accuracy 94.560\n",
      "selected users: [ 1  9 12 14]\n",
      "\n",
      "Test set: Average loss: 41042.0460 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round   7, Average loss 41042.046 Test accuracy 95.420\n",
      "selected users: [ 1  8  9 12]\n",
      "\n",
      "Test set: Average loss: 109046.5248 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round   8, Average loss 109046.525 Test accuracy 95.530\n",
      "selected users: [ 7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 382130.6456 \n",
      "Accuracy: 9438/10000 (94.38%)\n",
      "\n",
      "Round   9, Average loss 382130.646 Test accuracy 94.380\n",
      "selected users: [ 0  5 12 13]\n",
      "\n",
      "Test set: Average loss: 1321351.5720 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  10, Average loss 1321351.572 Test accuracy 94.790\n",
      "selected users: [1 2 3 4]\n",
      "\n",
      "Test set: Average loss: 18984798.9056 \n",
      "Accuracy: 8492/10000 (84.92%)\n",
      "\n",
      "Round  11, Average loss 18984798.906 Test accuracy 84.920\n",
      "selected users: [ 1 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25765802.1888 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round  12, Average loss 25765802.189 Test accuracy 93.870\n",
      "selected users: [ 0 10 12 14]\n",
      "\n",
      "Test set: Average loss: 79750517.0432 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round  13, Average loss 79750517.043 Test accuracy 94.610\n",
      "selected users: [ 2  6  8 14]\n",
      "\n",
      "Test set: Average loss: 252632319.5904 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  14, Average loss 252632319.590 Test accuracy 94.980\n",
      "selected users: [ 2  3  9 13]\n",
      "\n",
      "Test set: Average loss: 837736708.5056 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round  15, Average loss 837736708.506 Test accuracy 95.070\n",
      "selected users: [ 3  6 11 12]\n",
      "\n",
      "Test set: Average loss: 2819809787.9040 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  16, Average loss 2819809787.904 Test accuracy 95.180\n",
      "selected users: [ 2 10 12 13]\n",
      "\n",
      "Test set: Average loss: 9459577343.1808 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  17, Average loss 9459577343.181 Test accuracy 95.180\n",
      "selected users: [ 2  7  8 11]\n",
      "\n",
      "Test set: Average loss: 31899057284.7104 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round  18, Average loss 31899057284.710 Test accuracy 95.170\n",
      "selected users: [ 2 12 13 14]\n",
      "\n",
      "Test set: Average loss: 107355362243.3792 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round  19, Average loss 107355362243.379 Test accuracy 95.190\n",
      "selected users: [ 1  3  7 14]\n",
      "\n",
      "Test set: Average loss: 361911995387.0848 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  20, Average loss 361911995387.085 Test accuracy 95.200\n",
      "selected users: [ 0  1  2 14]\n",
      "\n",
      "Test set: Average loss: 1219941100630.8352 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  21, Average loss 1219941100630.835 Test accuracy 95.200\n",
      "selected users: [ 4  5  9 14]\n",
      "\n",
      "Test set: Average loss: 4117201203442.4834 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  22, Average loss 4117201203442.483 Test accuracy 95.200\n",
      "selected users: [ 6  8  9 12]\n",
      "\n",
      "Test set: Average loss: 13892715990849.9453 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  23, Average loss 13892715990849.945 Test accuracy 95.210\n",
      "selected users: [ 8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 46909420957650.1250 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  24, Average loss 46909420957650.125 Test accuracy 95.210\n",
      "selected users: [ 0  3  5 11]\n",
      "\n",
      "Test set: Average loss: 158348739866945.1250 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  25, Average loss 158348739866945.125 Test accuracy 95.210\n",
      "selected users: [ 4  5  8 12]\n",
      "\n",
      "Test set: Average loss: 534429473059320.6250 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  26, Average loss 534429473059320.625 Test accuracy 95.210\n",
      "selected users: [ 2 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1803586611323705.7500 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  27, Average loss 1803586611323705.750 Test accuracy 95.210\n",
      "selected users: [0 7 8 9]\n",
      "\n",
      "Test set: Average loss: 6087040352415593.0000 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  28, Average loss 6087040352415593.000 Test accuracy 95.210\n",
      "selected users: [ 5  9 11 13]\n",
      "\n",
      "Test set: Average loss: 20544424902724788.0000 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  29, Average loss 20544424902724788.000 Test accuracy 95.210\n",
      "(m= 4 )  7 -th Trial!!\n",
      "selected users: [ 3  7  8 12]\n",
      "\n",
      "Test set: Average loss: 2.2971 \n",
      "Accuracy: 1396/10000 (13.96%)\n",
      "\n",
      "Round   0, Average loss 2.297 Test accuracy 13.960\n",
      "selected users: [ 3  5  8 14]\n",
      "\n",
      "Test set: Average loss: 0.5587 \n",
      "Accuracy: 9289/10000 (92.89%)\n",
      "\n",
      "Round   1, Average loss 0.559 Test accuracy 92.890\n",
      "selected users: [ 1  4  5 11]\n",
      "\n",
      "Test set: Average loss: 143.7961 \n",
      "Accuracy: 9329/10000 (93.29%)\n",
      "\n",
      "Round   2, Average loss 143.796 Test accuracy 93.290\n",
      "selected users: [ 1  4  7 10]\n",
      "\n",
      "Test set: Average loss: 3109.5833 \n",
      "Accuracy: 9188/10000 (91.88%)\n",
      "\n",
      "Round   3, Average loss 3109.583 Test accuracy 91.880\n",
      "selected users: [ 3  7  8 11]\n",
      "\n",
      "Test set: Average loss: 6342.1776 \n",
      "Accuracy: 9346/10000 (93.46%)\n",
      "\n",
      "Round   4, Average loss 6342.178 Test accuracy 93.460\n",
      "selected users: [ 0  2  4 10]\n",
      "\n",
      "Test set: Average loss: 51627.8733 \n",
      "Accuracy: 9264/10000 (92.64%)\n",
      "\n",
      "Round   5, Average loss 51627.873 Test accuracy 92.640\n",
      "selected users: [ 0  1  9 14]\n",
      "\n",
      "Test set: Average loss: 101625.7927 \n",
      "Accuracy: 9378/10000 (93.78%)\n",
      "\n",
      "Round   6, Average loss 101625.793 Test accuracy 93.780\n",
      "selected users: [ 3  8  9 11]\n",
      "\n",
      "Test set: Average loss: 296022.0996 \n",
      "Accuracy: 9404/10000 (94.04%)\n",
      "\n",
      "Round   7, Average loss 296022.100 Test accuracy 94.040\n",
      "selected users: [1 3 6 7]\n",
      "\n",
      "Test set: Average loss: 1011064.6544 \n",
      "Accuracy: 7780/10000 (77.80%)\n",
      "\n",
      "Round   8, Average loss 1011064.654 Test accuracy 77.800\n",
      "selected users: [ 0  1  9 12]\n",
      "\n",
      "Test set: Average loss: 645150.5132 \n",
      "Accuracy: 9347/10000 (93.47%)\n",
      "\n",
      "Round   9, Average loss 645150.513 Test accuracy 93.470\n",
      "selected users: [ 9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 3106146.6176 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  10, Average loss 3106146.618 Test accuracy 94.630\n",
      "selected users: [ 0  2  4 12]\n",
      "\n",
      "Test set: Average loss: 10322828.2624 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  11, Average loss 10322828.262 Test accuracy 94.900\n",
      "selected users: [ 4  5  7 12]\n",
      "\n",
      "Test set: Average loss: 34121762.1504 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  12, Average loss 34121762.150 Test accuracy 94.760\n",
      "selected users: [3 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 115946960.2304 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round  13, Average loss 115946960.230 Test accuracy 94.610\n",
      "selected users: [10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 506860534.5792 \n",
      "Accuracy: 9333/10000 (93.33%)\n",
      "\n",
      "Round  14, Average loss 506860534.579 Test accuracy 93.330\n",
      "selected users: [ 1  3  4 13]\n",
      "\n",
      "Test set: Average loss: 1609756042.8544 \n",
      "Accuracy: 9373/10000 (93.73%)\n",
      "\n",
      "Round  15, Average loss 1609756042.854 Test accuracy 93.730\n",
      "selected users: [ 1  2  7 11]\n",
      "\n",
      "Test set: Average loss: 5246729886.1056 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round  16, Average loss 5246729886.106 Test accuracy 93.880\n",
      "selected users: [5 7 8 9]\n",
      "\n",
      "Test set: Average loss: 17663573413.0688 \n",
      "Accuracy: 9392/10000 (93.92%)\n",
      "\n",
      "Round  17, Average loss 17663573413.069 Test accuracy 93.920\n",
      "selected users: [ 2  8 10 14]\n",
      "\n",
      "Test set: Average loss: 58840455210.5984 \n",
      "Accuracy: 9401/10000 (94.01%)\n",
      "\n",
      "Round  18, Average loss 58840455210.598 Test accuracy 94.010\n",
      "selected users: [ 6 10 13 14]\n",
      "\n",
      "Test set: Average loss: 197199027765.2480 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  19, Average loss 197199027765.248 Test accuracy 94.030\n",
      "selected users: [0 2 5 8]\n",
      "\n",
      "Test set: Average loss: 658530857333.5552 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  20, Average loss 658530857333.555 Test accuracy 94.020\n",
      "selected users: [ 3  7 12 13]\n",
      "\n",
      "Test set: Average loss: 2215174152912.8960 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  21, Average loss 2215174152912.896 Test accuracy 94.020\n",
      "selected users: [ 0  5  6 10]\n",
      "\n",
      "Test set: Average loss: 7488563337337.2412 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  22, Average loss 7488563337337.241 Test accuracy 94.030\n",
      "selected users: [ 3  9 12 14]\n",
      "\n",
      "Test set: Average loss: 25243841490373.8359 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  23, Average loss 25243841490373.836 Test accuracy 94.030\n",
      "selected users: [ 6  8  9 11]\n",
      "\n",
      "Test set: Average loss: 85164927987220.4844 \n",
      "Accuracy: 9405/10000 (94.05%)\n",
      "\n",
      "Round  24, Average loss 85164927987220.484 Test accuracy 94.050\n",
      "selected users: [ 7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 287013216994512.0625 \n",
      "Accuracy: 9405/10000 (94.05%)\n",
      "\n",
      "Round  25, Average loss 287013216994512.062 Test accuracy 94.050\n",
      "selected users: [ 6  7  9 13]\n",
      "\n",
      "Test set: Average loss: 968494797167788.0000 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round  26, Average loss 968494797167788.000 Test accuracy 94.060\n",
      "selected users: [1 2 3 8]\n",
      "\n",
      "Test set: Average loss: 3267672724089707.0000 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round  27, Average loss 3267672724089707.000 Test accuracy 94.060\n",
      "selected users: [ 0  3  9 12]\n",
      "\n",
      "Test set: Average loss: 11026279536539572.0000 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round  28, Average loss 11026279536539572.000 Test accuracy 94.060\n",
      "selected users: [ 1  7 13 14]\n",
      "\n",
      "Test set: Average loss: 37206872435908520.0000 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round  29, Average loss 37206872435908520.000 Test accuracy 94.060\n",
      "(m= 4 )  8 -th Trial!!\n",
      "selected users: [ 2  3  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  8  9 14]\n",
      "\n",
      "Test set: Average loss: 2.0964 \n",
      "Accuracy: 1904/10000 (19.04%)\n",
      "\n",
      "Round   1, Average loss 2.096 Test accuracy 19.040\n",
      "selected users: [ 5  7  8 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [1 2 3 6]\n",
      "\n",
      "Test set: Average loss: 3.1246 \n",
      "Accuracy: 3355/10000 (33.55%)\n",
      "\n",
      "Round   3, Average loss 3.125 Test accuracy 33.550\n",
      "selected users: [ 0  1  2 10]\n",
      "\n",
      "Test set: Average loss: 1.9387 \n",
      "Accuracy: 2373/10000 (23.73%)\n",
      "\n",
      "Round   4, Average loss 1.939 Test accuracy 23.730\n",
      "selected users: [4 5 6 8]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [2 3 8 9]\n",
      "\n",
      "Test set: Average loss: 3.3413 \n",
      "Accuracy: 1970/10000 (19.70%)\n",
      "\n",
      "Round   6, Average loss 3.341 Test accuracy 19.700\n",
      "selected users: [ 1  4  8 13]\n",
      "\n",
      "Test set: Average loss: 2.2354 \n",
      "Accuracy: 1272/10000 (12.72%)\n",
      "\n",
      "Round   7, Average loss 2.235 Test accuracy 12.720\n",
      "selected users: [ 2  4 12 13]\n",
      "\n",
      "Test set: Average loss: 126.4376 \n",
      "Accuracy: 2954/10000 (29.54%)\n",
      "\n",
      "Round   8, Average loss 126.438 Test accuracy 29.540\n",
      "selected users: [ 1  3 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  6 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  8  9 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  6  9 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  4  5 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 5  7  9 10]\n",
      "\n",
      "Test set: Average loss: 2.2980 \n",
      "Accuracy: 1000/10000 (10.00%)\n",
      "\n",
      "Round  14, Average loss 2.298 Test accuracy 10.000\n",
      "selected users: [ 1  3  4 13]\n",
      "\n",
      "Test set: Average loss: 2.2991 \n",
      "Accuracy: 995/10000 (9.95%)\n",
      "\n",
      "Round  15, Average loss 2.299 Test accuracy 9.950\n",
      "selected users: [ 1  5  7 14]\n",
      "\n",
      "Test set: Average loss: 2.2931 \n",
      "Accuracy: 1021/10000 (10.21%)\n",
      "\n",
      "Round  16, Average loss 2.293 Test accuracy 10.210\n",
      "selected users: [ 3  8 11 12]\n",
      "\n",
      "Test set: Average loss: 2.2964 \n",
      "Accuracy: 1007/10000 (10.07%)\n",
      "\n",
      "Round  17, Average loss 2.296 Test accuracy 10.070\n",
      "selected users: [ 1  4  5 14]\n",
      "\n",
      "Test set: Average loss: 2.2874 \n",
      "Accuracy: 1046/10000 (10.46%)\n",
      "\n",
      "Round  18, Average loss 2.287 Test accuracy 10.460\n",
      "selected users: [ 2  4  5 11]\n",
      "\n",
      "Test set: Average loss: 2.2876 \n",
      "Accuracy: 1045/10000 (10.45%)\n",
      "\n",
      "Round  19, Average loss 2.288 Test accuracy 10.450\n",
      "selected users: [ 1  4  7 10]\n",
      "\n",
      "Test set: Average loss: 2.2849 \n",
      "Accuracy: 1057/10000 (10.57%)\n",
      "\n",
      "Round  20, Average loss 2.285 Test accuracy 10.570\n",
      "selected users: [ 3  6 12 14]\n",
      "\n",
      "Test set: Average loss: 2.2867 \n",
      "Accuracy: 1049/10000 (10.49%)\n",
      "\n",
      "Round  21, Average loss 2.287 Test accuracy 10.490\n",
      "selected users: [ 1  5 11 14]\n",
      "\n",
      "Test set: Average loss: 2.2858 \n",
      "Accuracy: 1053/10000 (10.53%)\n",
      "\n",
      "Round  22, Average loss 2.286 Test accuracy 10.530\n",
      "selected users: [1 3 5 7]\n",
      "\n",
      "Test set: Average loss: 2.2885 \n",
      "Accuracy: 1041/10000 (10.41%)\n",
      "\n",
      "Round  23, Average loss 2.289 Test accuracy 10.410\n",
      "selected users: [ 4  5  7 12]\n",
      "\n",
      "Test set: Average loss: 2.2878 \n",
      "Accuracy: 1044/10000 (10.44%)\n",
      "\n",
      "Round  24, Average loss 2.288 Test accuracy 10.440\n",
      "selected users: [ 4  8  9 10]\n",
      "\n",
      "Test set: Average loss: 2.2878 \n",
      "Accuracy: 1044/10000 (10.44%)\n",
      "\n",
      "Round  25, Average loss 2.288 Test accuracy 10.440\n",
      "selected users: [ 1  3  9 10]\n",
      "\n",
      "Test set: Average loss: 2.2878 \n",
      "Accuracy: 1044/10000 (10.44%)\n",
      "\n",
      "Round  26, Average loss 2.288 Test accuracy 10.440\n",
      "selected users: [4 5 7 9]\n",
      "\n",
      "Test set: Average loss: 2.2878 \n",
      "Accuracy: 1044/10000 (10.44%)\n",
      "\n",
      "Round  27, Average loss 2.288 Test accuracy 10.440\n",
      "selected users: [ 3  7  8 13]\n",
      "\n",
      "Test set: Average loss: 2.2878 \n",
      "Accuracy: 1044/10000 (10.44%)\n",
      "\n",
      "Round  28, Average loss 2.288 Test accuracy 10.440\n",
      "selected users: [ 0  7 10 14]\n",
      "\n",
      "Test set: Average loss: 2.2878 \n",
      "Accuracy: 1044/10000 (10.44%)\n",
      "\n",
      "Round  29, Average loss 2.288 Test accuracy 10.440\n",
      "(m= 4 )  9 -th Trial!!\n",
      "selected users: [2 5 6 8]\n",
      "\n",
      "Test set: Average loss: 2.0461 \n",
      "Accuracy: 2597/10000 (25.97%)\n",
      "\n",
      "Round   0, Average loss 2.046 Test accuracy 25.970\n",
      "selected users: [ 0  1 10 14]\n",
      "\n",
      "Test set: Average loss: 346.4173 \n",
      "Accuracy: 90/10000 (0.90%)\n",
      "\n",
      "Round   1, Average loss 346.417 Test accuracy 0.900\n",
      "selected users: [2 3 4 7]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [5 7 8 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  6 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [2 3 6 7]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4  7 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 6  9 12 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  3 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   9, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  7 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  10, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5  8 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  8 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  5  8 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  6  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  5  6 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  16, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  7 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  5 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  8 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [1 3 7 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [2 3 8 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  6  7 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  5 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  6 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [3 4 6 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5  9 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [2 3 7 8]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  9 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "number of results: 5\n",
      "(m= 5 )  0 -th Trial!!\n",
      "selected users: [ 5  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  6  9 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5337 \n",
      "Accuracy: 4867/10000 (48.67%)\n",
      "\n",
      "Round   2, Average loss 1.534 Test accuracy 48.670\n",
      "selected users: [ 0  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 7.4600 \n",
      "Accuracy: 9359/10000 (93.59%)\n",
      "\n",
      "Round   3, Average loss 7.460 Test accuracy 93.590\n",
      "selected users: [ 0  3  5 11 12]\n",
      "\n",
      "Test set: Average loss: 350.5276 \n",
      "Accuracy: 9263/10000 (92.63%)\n",
      "\n",
      "Round   4, Average loss 350.528 Test accuracy 92.630\n",
      "selected users: [ 2  4  5  7 14]\n",
      "\n",
      "Test set: Average loss: 236.2899 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round   5, Average loss 236.290 Test accuracy 94.020\n",
      "selected users: [ 1  4 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1442.1261 \n",
      "Accuracy: 9452/10000 (94.52%)\n",
      "\n",
      "Round   6, Average loss 1442.126 Test accuracy 94.520\n",
      "selected users: [0 3 4 6 9]\n",
      "\n",
      "Test set: Average loss: 5320.6036 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round   7, Average loss 5320.604 Test accuracy 94.450\n",
      "selected users: [ 0  1  5  8 14]\n",
      "\n",
      "Test set: Average loss: 9088.8756 \n",
      "Accuracy: 9437/10000 (94.37%)\n",
      "\n",
      "Round   8, Average loss 9088.876 Test accuracy 94.370\n",
      "selected users: [ 1  2  4  6 13]\n",
      "\n",
      "Test set: Average loss: 7618.0990 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round   9, Average loss 7618.099 Test accuracy 94.880\n",
      "selected users: [ 3  6  7  9 10]\n",
      "\n",
      "Test set: Average loss: 13271.0727 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round  10, Average loss 13271.073 Test accuracy 93.370\n",
      "selected users: [ 6  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 19363.7273 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  11, Average loss 19363.727 Test accuracy 94.490\n",
      "selected users: [ 0  3  7 12 14]\n",
      "\n",
      "Test set: Average loss: 16527.9508 \n",
      "Accuracy: 9395/10000 (93.95%)\n",
      "\n",
      "Round  12, Average loss 16527.951 Test accuracy 93.950\n",
      "selected users: [ 6  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 69361.4584 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  13, Average loss 69361.458 Test accuracy 95.250\n",
      "selected users: [ 0  5 10 11 13]\n",
      "\n",
      "Test set: Average loss: 160825.3686 \n",
      "Accuracy: 9466/10000 (94.66%)\n",
      "\n",
      "Round  14, Average loss 160825.369 Test accuracy 94.660\n",
      "selected users: [ 1  2 11 13 14]\n",
      "\n",
      "Test set: Average loss: 248711.9056 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  15, Average loss 248711.906 Test accuracy 94.980\n",
      "selected users: [ 0  2  5 12 14]\n",
      "\n",
      "Test set: Average loss: 477957.3352 \n",
      "Accuracy: 9458/10000 (94.58%)\n",
      "\n",
      "Round  16, Average loss 477957.335 Test accuracy 94.580\n",
      "selected users: [ 0  4  5  7 10]\n",
      "\n",
      "Test set: Average loss: 1113708.8784 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  17, Average loss 1113708.878 Test accuracy 94.410\n",
      "selected users: [ 1  4  8 10 11]\n",
      "\n",
      "Test set: Average loss: 1965810.8912 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  18, Average loss 1965810.891 Test accuracy 94.790\n",
      "selected users: [ 0  3  5 13 14]\n",
      "\n",
      "Test set: Average loss: 3443564.8064 \n",
      "Accuracy: 9435/10000 (94.35%)\n",
      "\n",
      "Round  19, Average loss 3443564.806 Test accuracy 94.350\n",
      "selected users: [ 3  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 6093127.1232 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round  20, Average loss 6093127.123 Test accuracy 94.060\n",
      "selected users: [ 0  1  4  5 14]\n",
      "\n",
      "Test set: Average loss: 10141844.8640 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  21, Average loss 10141844.864 Test accuracy 94.500\n",
      "selected users: [ 3  5  6 11 14]\n",
      "\n",
      "Test set: Average loss: 17069172.7744 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  22, Average loss 17069172.774 Test accuracy 94.760\n",
      "selected users: [0 1 4 5 9]\n",
      "\n",
      "Test set: Average loss: 30648734.7712 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round  23, Average loss 30648734.771 Test accuracy 94.770\n",
      "selected users: [ 1  2  5  7 14]\n",
      "\n",
      "Test set: Average loss: 51927802.5216 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  24, Average loss 51927802.522 Test accuracy 94.790\n",
      "selected users: [ 1  5  6  7 14]\n",
      "\n",
      "Test set: Average loss: 91305928.6016 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round  25, Average loss 91305928.602 Test accuracy 94.750\n",
      "selected users: [ 0  6  8 10 11]\n",
      "\n",
      "Test set: Average loss: 162291979.9808 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  26, Average loss 162291979.981 Test accuracy 94.760\n",
      "selected users: [ 2  4  5  8 10]\n",
      "\n",
      "Test set: Average loss: 286775752.7040 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  27, Average loss 286775752.704 Test accuracy 94.630\n",
      "selected users: [ 0 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 507034779.6480 \n",
      "Accuracy: 9458/10000 (94.58%)\n",
      "\n",
      "Round  28, Average loss 507034779.648 Test accuracy 94.580\n",
      "selected users: [ 4  6  7 10 12]\n",
      "\n",
      "Test set: Average loss: 877265317.0688 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round  29, Average loss 877265317.069 Test accuracy 94.640\n",
      "(m= 5 )  1 -th Trial!!\n",
      "selected users: [ 1  3  5 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 986/10000 (9.86%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.860\n",
      "selected users: [ 1  3  4 10 11]\n",
      "\n",
      "Test set: Average loss: 1.4188 \n",
      "Accuracy: 7064/10000 (70.64%)\n",
      "\n",
      "Round   2, Average loss 1.419 Test accuracy 70.640\n",
      "selected users: [ 0  1  2  4 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.7477 \n",
      "Accuracy: 4530/10000 (45.30%)\n",
      "\n",
      "Round   3, Average loss 2.748 Test accuracy 45.300\n",
      "selected users: [ 1  2  9 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  4  7 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  5  9 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  5  7 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 1.7273 \n",
      "Accuracy: 6351/10000 (63.51%)\n",
      "\n",
      "Round   9, Average loss 1.727 Test accuracy 63.510\n",
      "selected users: [ 2  4  7 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7560 \n",
      "Accuracy: 8092/10000 (80.92%)\n",
      "\n",
      "Round  10, Average loss 0.756 Test accuracy 80.920\n",
      "selected users: [ 1  4  7  8 14]\n",
      "\n",
      "Test set: Average loss: 5.9203 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  11, Average loss 5.920 Test accuracy 95.140\n",
      "selected users: [ 6  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 42.1183 \n",
      "Accuracy: 9619/10000 (96.19%)\n",
      "\n",
      "Round  12, Average loss 42.118 Test accuracy 96.190\n",
      "selected users: [ 0  4  7 13 14]\n",
      "\n",
      "Test set: Average loss: 9.6967 \n",
      "Accuracy: 9268/10000 (92.68%)\n",
      "\n",
      "Round  13, Average loss 9.697 Test accuracy 92.680\n",
      "selected users: [ 0  3  6 11 12]\n",
      "\n",
      "Test set: Average loss: 226.8399 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  14, Average loss 226.840 Test accuracy 95.560\n",
      "selected users: [ 1  2  4 10 11]\n",
      "\n",
      "Test set: Average loss: 2923.8331 \n",
      "Accuracy: 9448/10000 (94.48%)\n",
      "\n",
      "Round  15, Average loss 2923.833 Test accuracy 94.480\n",
      "selected users: [ 1  6 11 13 14]\n",
      "\n",
      "Test set: Average loss: 6420.7825 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round  16, Average loss 6420.782 Test accuracy 94.930\n",
      "selected users: [ 1  3  4  7 10]\n",
      "\n",
      "Test set: Average loss: 20662.3524 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  17, Average loss 20662.352 Test accuracy 94.280\n",
      "selected users: [ 1  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 30164.4394 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round  18, Average loss 30164.439 Test accuracy 94.770\n",
      "selected users: [ 3  6  7 12 13]\n",
      "\n",
      "Test set: Average loss: 25969.0435 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round  19, Average loss 25969.044 Test accuracy 94.700\n",
      "selected users: [ 0  4  7 12 14]\n",
      "\n",
      "Test set: Average loss: 33511.2689 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  20, Average loss 33511.269 Test accuracy 95.260\n",
      "selected users: [ 4  7  8 10 11]\n",
      "\n",
      "Test set: Average loss: 90544.4918 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round  21, Average loss 90544.492 Test accuracy 95.440\n",
      "selected users: [ 1  3  7 12 13]\n",
      "\n",
      "Test set: Average loss: 103573.0953 \n",
      "Accuracy: 9523/10000 (95.23%)\n",
      "\n",
      "Round  22, Average loss 103573.095 Test accuracy 95.230\n",
      "selected users: [ 8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 138355.0170 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  23, Average loss 138355.017 Test accuracy 95.460\n",
      "selected users: [ 4  5  7 11 13]\n",
      "\n",
      "Test set: Average loss: 220408.0806 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  24, Average loss 220408.081 Test accuracy 95.650\n",
      "selected users: [ 2  5  6 10 12]\n",
      "\n",
      "Test set: Average loss: 331932.4936 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  25, Average loss 331932.494 Test accuracy 95.550\n",
      "selected users: [ 3  4  7 11 12]\n",
      "\n",
      "Test set: Average loss: 464380.8324 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round  26, Average loss 464380.832 Test accuracy 95.070\n",
      "selected users: [ 4  5  6  8 10]\n",
      "\n",
      "Test set: Average loss: 1025047.0856 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  27, Average loss 1025047.086 Test accuracy 95.680\n",
      "selected users: [ 3  5  7  9 13]\n",
      "\n",
      "Test set: Average loss: 1526656.9568 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  28, Average loss 1526656.957 Test accuracy 95.590\n",
      "selected users: [ 1  4 10 11 14]\n",
      "\n",
      "Test set: Average loss: 3223116.3712 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  29, Average loss 3223116.371 Test accuracy 95.670\n",
      "(m= 5 )  2 -th Trial!!\n",
      "selected users: [ 4  5  9 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  6  7  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  3  6  8 13]\n",
      "\n",
      "Test set: Average loss: 1.5683 \n",
      "Accuracy: 6894/10000 (68.94%)\n",
      "\n",
      "Round   2, Average loss 1.568 Test accuracy 68.940\n",
      "selected users: [ 0  3  5  8 14]\n",
      "\n",
      "Test set: Average loss: 8.4681 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round   3, Average loss 8.468 Test accuracy 92.490\n",
      "selected users: [ 4  7 10 13 14]\n",
      "\n",
      "Test set: Average loss: 278.5798 \n",
      "Accuracy: 9155/10000 (91.55%)\n",
      "\n",
      "Round   4, Average loss 278.580 Test accuracy 91.550\n",
      "selected users: [0 1 5 7 9]\n",
      "\n",
      "Test set: Average loss: 1889.7311 \n",
      "Accuracy: 9097/10000 (90.97%)\n",
      "\n",
      "Round   5, Average loss 1889.731 Test accuracy 90.970\n",
      "selected users: [ 3  4  5  7 13]\n",
      "\n",
      "Test set: Average loss: 365.6739 \n",
      "Accuracy: 9207/10000 (92.07%)\n",
      "\n",
      "Round   6, Average loss 365.674 Test accuracy 92.070\n",
      "selected users: [ 1  2  3  5 12]\n",
      "\n",
      "Test set: Average loss: 1200.7435 \n",
      "Accuracy: 9024/10000 (90.24%)\n",
      "\n",
      "Round   7, Average loss 1200.744 Test accuracy 90.240\n",
      "selected users: [ 1  2  9 11 13]\n",
      "\n",
      "Test set: Average loss: 59.9092 \n",
      "Accuracy: 6515/10000 (65.15%)\n",
      "\n",
      "Round   8, Average loss 59.909 Test accuracy 65.150\n",
      "selected users: [ 2  6  9 10 11]\n",
      "\n",
      "Test set: Average loss: 267.6250 \n",
      "Accuracy: 9271/10000 (92.71%)\n",
      "\n",
      "Round   9, Average loss 267.625 Test accuracy 92.710\n",
      "selected users: [ 6  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2925.1422 \n",
      "Accuracy: 9432/10000 (94.32%)\n",
      "\n",
      "Round  10, Average loss 2925.142 Test accuracy 94.320\n",
      "selected users: [2 3 4 7 8]\n",
      "\n",
      "Test set: Average loss: 7513.0826 \n",
      "Accuracy: 9384/10000 (93.84%)\n",
      "\n",
      "Round  11, Average loss 7513.083 Test accuracy 93.840\n",
      "selected users: [ 1  2 10 12 13]\n",
      "\n",
      "Test set: Average loss: 5731.4866 \n",
      "Accuracy: 9312/10000 (93.12%)\n",
      "\n",
      "Round  12, Average loss 5731.487 Test accuracy 93.120\n",
      "selected users: [ 0  1  3  4 14]\n",
      "\n",
      "Test set: Average loss: 40221.8577 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round  13, Average loss 40221.858 Test accuracy 93.760\n",
      "selected users: [ 2  3  8  9 13]\n",
      "\n",
      "Test set: Average loss: 20386.7129 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round  14, Average loss 20386.713 Test accuracy 94.820\n",
      "selected users: [ 1  4  9 11 13]\n",
      "\n",
      "Test set: Average loss: 51478.2251 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  15, Average loss 51478.225 Test accuracy 94.650\n",
      "selected users: [ 1  3  7 10 13]\n",
      "\n",
      "Test set: Average loss: 57382.8677 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  16, Average loss 57382.868 Test accuracy 94.710\n",
      "selected users: [ 4  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 146482.5355 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  17, Average loss 146482.535 Test accuracy 94.650\n",
      "selected users: [ 5  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 610535.4676 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round  18, Average loss 610535.468 Test accuracy 93.100\n",
      "selected users: [ 5  6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1477352.9464 \n",
      "Accuracy: 9294/10000 (92.94%)\n",
      "\n",
      "Round  19, Average loss 1477352.946 Test accuracy 92.940\n",
      "selected users: [ 8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2324731.1248 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round  20, Average loss 2324731.125 Test accuracy 93.540\n",
      "selected users: [ 4  6  9 11 13]\n",
      "\n",
      "Test set: Average loss: 4066612.8960 \n",
      "Accuracy: 9365/10000 (93.65%)\n",
      "\n",
      "Round  21, Average loss 4066612.896 Test accuracy 93.650\n",
      "selected users: [1 4 6 8 9]\n",
      "\n",
      "Test set: Average loss: 8054048.3328 \n",
      "Accuracy: 9325/10000 (93.25%)\n",
      "\n",
      "Round  22, Average loss 8054048.333 Test accuracy 93.250\n",
      "selected users: [ 0  5  6  9 14]\n",
      "\n",
      "Test set: Average loss: 15160966.7328 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  23, Average loss 15160966.733 Test accuracy 93.380\n",
      "selected users: [ 0  4 11 12 13]\n",
      "\n",
      "Test set: Average loss: 28114875.5968 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round  24, Average loss 28114875.597 Test accuracy 93.280\n",
      "selected users: [ 1  4  6  8 14]\n",
      "\n",
      "Test set: Average loss: 48468191.9232 \n",
      "Accuracy: 9333/10000 (93.33%)\n",
      "\n",
      "Round  25, Average loss 48468191.923 Test accuracy 93.330\n",
      "selected users: [ 0  2  5  6 14]\n",
      "\n",
      "Test set: Average loss: 79081332.2752 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round  26, Average loss 79081332.275 Test accuracy 93.520\n",
      "selected users: [ 1  3  5  7 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 139478787.6864 \n",
      "Accuracy: 9355/10000 (93.55%)\n",
      "\n",
      "Round  27, Average loss 139478787.686 Test accuracy 93.550\n",
      "selected users: [0 3 5 6 8]\n",
      "\n",
      "Test set: Average loss: 244835603.8656 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round  28, Average loss 244835603.866 Test accuracy 93.430\n",
      "selected users: [ 2  3  4  7 14]\n",
      "\n",
      "Test set: Average loss: 415292825.8048 \n",
      "Accuracy: 9357/10000 (93.57%)\n",
      "\n",
      "Round  29, Average loss 415292825.805 Test accuracy 93.570\n",
      "(m= 5 )  3 -th Trial!!\n",
      "selected users: [ 2  4 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  4  6  8 14]\n",
      "\n",
      "Test set: Average loss: 2.2949 \n",
      "Accuracy: 1543/10000 (15.43%)\n",
      "\n",
      "Round   1, Average loss 2.295 Test accuracy 15.430\n",
      "selected users: [ 1  5  8  9 12]\n",
      "\n",
      "Test set: Average loss: 13.0866 \n",
      "Accuracy: 8399/10000 (83.99%)\n",
      "\n",
      "Round   2, Average loss 13.087 Test accuracy 83.990\n",
      "selected users: [0 1 2 5 7]\n",
      "\n",
      "Test set: Average loss: 1.7995 \n",
      "Accuracy: 3573/10000 (35.73%)\n",
      "\n",
      "Round   3, Average loss 1.799 Test accuracy 35.730\n",
      "selected users: [ 3  6  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1988 \n",
      "Accuracy: 9448/10000 (94.48%)\n",
      "\n",
      "Round   4, Average loss 0.199 Test accuracy 94.480\n",
      "selected users: [ 1  2  6 10 12]\n",
      "\n",
      "Test set: Average loss: 3.5836 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round   5, Average loss 3.584 Test accuracy 93.240\n",
      "selected users: [ 0  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 107.6215 \n",
      "Accuracy: 9244/10000 (92.44%)\n",
      "\n",
      "Round   6, Average loss 107.622 Test accuracy 92.440\n",
      "selected users: [ 1  2  5  7 13]\n",
      "\n",
      "Test set: Average loss: 6.3892 \n",
      "Accuracy: 8498/10000 (84.98%)\n",
      "\n",
      "Round   7, Average loss 6.389 Test accuracy 84.980\n",
      "selected users: [ 2  4  6 12 14]\n",
      "\n",
      "Test set: Average loss: 3.7665 \n",
      "Accuracy: 7545/10000 (75.45%)\n",
      "\n",
      "Round   8, Average loss 3.767 Test accuracy 75.450\n",
      "selected users: [ 2  4  7  8 10]\n",
      "\n",
      "Test set: Average loss: 650.5163 \n",
      "Accuracy: 9137/10000 (91.37%)\n",
      "\n",
      "Round   9, Average loss 650.516 Test accuracy 91.370\n",
      "selected users: [ 1  5  6  9 13]\n",
      "\n",
      "Test set: Average loss: 844.4325 \n",
      "Accuracy: 9317/10000 (93.17%)\n",
      "\n",
      "Round  10, Average loss 844.432 Test accuracy 93.170\n",
      "selected users: [ 2  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 49.6337 \n",
      "Accuracy: 8295/10000 (82.95%)\n",
      "\n",
      "Round  11, Average loss 49.634 Test accuracy 82.950\n",
      "selected users: [ 6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 5889.8461 \n",
      "Accuracy: 9262/10000 (92.62%)\n",
      "\n",
      "Round  12, Average loss 5889.846 Test accuracy 92.620\n",
      "selected users: [ 3  4  7  9 14]\n",
      "\n",
      "Test set: Average loss: 5921.5001 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round  13, Average loss 5921.500 Test accuracy 93.880\n",
      "selected users: [ 0  2  7  9 13]\n",
      "\n",
      "Test set: Average loss: 656.1500 \n",
      "Accuracy: 9395/10000 (93.95%)\n",
      "\n",
      "Round  14, Average loss 656.150 Test accuracy 93.950\n",
      "selected users: [ 0  5  7 10 13]\n",
      "\n",
      "Test set: Average loss: 8016.6230 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  15, Average loss 8016.623 Test accuracy 94.300\n",
      "selected users: [ 2  3  5  9 14]\n",
      "\n",
      "Test set: Average loss: 22748.1193 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  16, Average loss 22748.119 Test accuracy 94.280\n",
      "selected users: [1 3 4 5 7]\n",
      "\n",
      "Test set: Average loss: 36352.6781 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round  17, Average loss 36352.678 Test accuracy 94.700\n",
      "selected users: [ 3  4  8 13 14]\n",
      "\n",
      "Test set: Average loss: 23563.4919 \n",
      "Accuracy: 9494/10000 (94.94%)\n",
      "\n",
      "Round  18, Average loss 23563.492 Test accuracy 94.940\n",
      "selected users: [ 0  4  5 11 13]\n",
      "\n",
      "Test set: Average loss: 121154.1360 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  19, Average loss 121154.136 Test accuracy 94.490\n",
      "selected users: [ 1  3  7 13 14]\n",
      "\n",
      "Test set: Average loss: 98501.6535 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round  20, Average loss 98501.654 Test accuracy 94.970\n",
      "selected users: [ 0  5 11 12 13]\n",
      "\n",
      "Test set: Average loss: 296752.2296 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round  21, Average loss 296752.230 Test accuracy 94.550\n",
      "selected users: [ 2  6  7  8 11]\n",
      "\n",
      "Test set: Average loss: 521859.1236 \n",
      "Accuracy: 9485/10000 (94.85%)\n",
      "\n",
      "Round  22, Average loss 521859.124 Test accuracy 94.850\n",
      "selected users: [1 4 7 8 9]\n",
      "\n",
      "Test set: Average loss: 1123782.4632 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  23, Average loss 1123782.463 Test accuracy 94.620\n",
      "selected users: [ 2  3  7  8 13]\n",
      "\n",
      "Test set: Average loss: 1430081.2384 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  24, Average loss 1430081.238 Test accuracy 94.710\n",
      "selected users: [ 0  1  4  9 14]\n",
      "\n",
      "Test set: Average loss: 2804152.6112 \n",
      "Accuracy: 9489/10000 (94.89%)\n",
      "\n",
      "Round  25, Average loss 2804152.611 Test accuracy 94.890\n",
      "selected users: [ 1  6  9 13 14]\n",
      "\n",
      "Test set: Average loss: 4828868.7872 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round  26, Average loss 4828868.787 Test accuracy 94.970\n",
      "selected users: [ 1  2  3  7 11]\n",
      "\n",
      "Test set: Average loss: 9103933.2096 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  27, Average loss 9103933.210 Test accuracy 94.790\n",
      "selected users: [ 4  6 11 12 14]\n",
      "\n",
      "Test set: Average loss: 18319114.6240 \n",
      "Accuracy: 9469/10000 (94.69%)\n",
      "\n",
      "Round  28, Average loss 18319114.624 Test accuracy 94.690\n",
      "selected users: [ 5  7 10 11 12]\n",
      "\n",
      "Test set: Average loss: 34271007.7952 \n",
      "Accuracy: 9444/10000 (94.44%)\n",
      "\n",
      "Round  29, Average loss 34271007.795 Test accuracy 94.440\n",
      "(m= 5 )  4 -th Trial!!\n",
      "selected users: [ 1  2  7  8 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  5 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 1 2 5 7]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 983/10000 (9.83%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.830\n",
      "selected users: [ 3  4 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1.1982 \n",
      "Accuracy: 7023/10000 (70.23%)\n",
      "\n",
      "Round   3, Average loss 1.198 Test accuracy 70.230\n",
      "selected users: [ 2  6  8  9 12]\n",
      "\n",
      "Test set: Average loss: 0.2399 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round   4, Average loss 0.240 Test accuracy 95.590\n",
      "selected users: [ 0  1  3  8 13]\n",
      "\n",
      "Test set: Average loss: 0.2286 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round   5, Average loss 0.229 Test accuracy 95.720\n",
      "selected users: [ 1  4  8 10 11]\n",
      "\n",
      "Test set: Average loss: 25.4477 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round   6, Average loss 25.448 Test accuracy 94.960\n",
      "selected users: [ 0  3  4 10 13]\n",
      "\n",
      "Test set: Average loss: 854.9243 \n",
      "Accuracy: 9323/10000 (93.23%)\n",
      "\n",
      "Round   7, Average loss 854.924 Test accuracy 93.230\n",
      "selected users: [ 3  4  9 11 13]\n",
      "\n",
      "Test set: Average loss: 590.1352 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round   8, Average loss 590.135 Test accuracy 93.880\n",
      "selected users: [ 3  5  9 12 14]\n",
      "\n",
      "Test set: Average loss: 1345.1606 \n",
      "Accuracy: 9426/10000 (94.26%)\n",
      "\n",
      "Round   9, Average loss 1345.161 Test accuracy 94.260\n",
      "selected users: [1 2 4 7 8]\n",
      "\n",
      "Test set: Average loss: 6573.6403 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round  10, Average loss 6573.640 Test accuracy 94.560\n",
      "selected users: [ 9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 23046.0969 \n",
      "Accuracy: 9394/10000 (93.94%)\n",
      "\n",
      "Round  11, Average loss 23046.097 Test accuracy 93.940\n",
      "selected users: [ 0  1  7  8 13]\n",
      "\n",
      "Test set: Average loss: 10533.9798 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  12, Average loss 10533.980 Test accuracy 95.480\n",
      "selected users: [ 0  4  6 11 13]\n",
      "\n",
      "Test set: Average loss: 33377.1414 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  13, Average loss 33377.141 Test accuracy 95.550\n",
      "selected users: [ 1  6  8 10 12]\n",
      "\n",
      "Test set: Average loss: 50893.3041 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  14, Average loss 50893.304 Test accuracy 95.660\n",
      "selected users: [ 1  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 111487.8539 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  15, Average loss 111487.854 Test accuracy 95.640\n",
      "selected users: [ 0  2  8 10 13]\n",
      "\n",
      "Test set: Average loss: 81232.7193 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  16, Average loss 81232.719 Test accuracy 95.680\n",
      "selected users: [ 1  2  5  7 11]\n",
      "\n",
      "Test set: Average loss: 177941.8884 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  17, Average loss 177941.888 Test accuracy 95.770\n",
      "selected users: [ 1  4  5  8 14]\n",
      "\n",
      "Test set: Average loss: 341709.9944 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round  18, Average loss 341709.994 Test accuracy 95.880\n",
      "selected users: [ 0  3  7  9 11]\n",
      "\n",
      "Test set: Average loss: 608036.3452 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  19, Average loss 608036.345 Test accuracy 95.810\n",
      "selected users: [ 4  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1173794.6648 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round  20, Average loss 1173794.665 Test accuracy 95.850\n",
      "selected users: [ 1  3  9 10 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1948349.2672 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round  21, Average loss 1948349.267 Test accuracy 95.820\n",
      "selected users: [ 0  2  7  8 12]\n",
      "\n",
      "Test set: Average loss: 2649047.0336 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  22, Average loss 2649047.034 Test accuracy 95.550\n",
      "selected users: [ 0  1  7 10 11]\n",
      "\n",
      "Test set: Average loss: 3986328.1824 \n",
      "Accuracy: 9598/10000 (95.98%)\n",
      "\n",
      "Round  23, Average loss 3986328.182 Test accuracy 95.980\n",
      "selected users: [ 1  5  6 10 12]\n",
      "\n",
      "Test set: Average loss: 7302074.5344 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  24, Average loss 7302074.534 Test accuracy 95.960\n",
      "selected users: [ 2  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 10295791.7696 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round  25, Average loss 10295791.770 Test accuracy 95.880\n",
      "selected users: [ 0  1  4 10 14]\n",
      "\n",
      "Test set: Average loss: 19618336.8192 \n",
      "Accuracy: 9595/10000 (95.95%)\n",
      "\n",
      "Round  26, Average loss 19618336.819 Test accuracy 95.950\n",
      "selected users: [ 1  2  8 12 14]\n",
      "\n",
      "Test set: Average loss: 31279559.7056 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  27, Average loss 31279559.706 Test accuracy 95.860\n",
      "selected users: [ 1  3  7  8 12]\n",
      "\n",
      "Test set: Average loss: 51917691.6480 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round  28, Average loss 51917691.648 Test accuracy 95.630\n",
      "selected users: [ 0  4  9 12 13]\n",
      "\n",
      "Test set: Average loss: 88551147.2128 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round  29, Average loss 88551147.213 Test accuracy 95.840\n",
      "(m= 5 )  5 -th Trial!!\n",
      "selected users: [1 2 4 5 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6398 \n",
      "Accuracy: 6120/10000 (61.20%)\n",
      "\n",
      "Round   2, Average loss 1.640 Test accuracy 61.200\n",
      "selected users: [ 2  3  5  9 11]\n",
      "\n",
      "Test set: Average loss: 31.9859 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round   3, Average loss 31.986 Test accuracy 92.470\n",
      "selected users: [ 1  3  9 11 13]\n",
      "\n",
      "Test set: Average loss: 1.2440 \n",
      "Accuracy: 7856/10000 (78.56%)\n",
      "\n",
      "Round   4, Average loss 1.244 Test accuracy 78.560\n",
      "selected users: [ 2  4  6 10 12]\n",
      "\n",
      "Test set: Average loss: 32.3505 \n",
      "Accuracy: 9223/10000 (92.23%)\n",
      "\n",
      "Round   5, Average loss 32.351 Test accuracy 92.230\n",
      "selected users: [ 0  2  3 10 11]\n",
      "\n",
      "Test set: Average loss: 715.2146 \n",
      "Accuracy: 9283/10000 (92.83%)\n",
      "\n",
      "Round   6, Average loss 715.215 Test accuracy 92.830\n",
      "selected users: [ 0  4  5 12 13]\n",
      "\n",
      "Test set: Average loss: 2415.4638 \n",
      "Accuracy: 9223/10000 (92.23%)\n",
      "\n",
      "Round   7, Average loss 2415.464 Test accuracy 92.230\n",
      "selected users: [ 4  6 10 13 14]\n",
      "\n",
      "Test set: Average loss: 8673.9255 \n",
      "Accuracy: 9250/10000 (92.50%)\n",
      "\n",
      "Round   8, Average loss 8673.926 Test accuracy 92.500\n",
      "selected users: [ 0  1  4 12 13]\n",
      "\n",
      "Test set: Average loss: 15026.3691 \n",
      "Accuracy: 9306/10000 (93.06%)\n",
      "\n",
      "Round   9, Average loss 15026.369 Test accuracy 93.060\n",
      "selected users: [2 3 6 7 8]\n",
      "\n",
      "Test set: Average loss: 17693.6531 \n",
      "Accuracy: 9361/10000 (93.61%)\n",
      "\n",
      "Round  10, Average loss 17693.653 Test accuracy 93.610\n",
      "selected users: [ 0  1  5 12 13]\n",
      "\n",
      "Test set: Average loss: 40040.6470 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round  11, Average loss 40040.647 Test accuracy 92.970\n",
      "selected users: [ 3  4  7 12 13]\n",
      "\n",
      "Test set: Average loss: 29642.5429 \n",
      "Accuracy: 9347/10000 (93.47%)\n",
      "\n",
      "Round  12, Average loss 29642.543 Test accuracy 93.470\n",
      "selected users: [ 0  7  8 12 14]\n",
      "\n",
      "Test set: Average loss: 42708.3967 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round  13, Average loss 42708.397 Test accuracy 94.060\n",
      "selected users: [ 4  6  9 11 14]\n",
      "\n",
      "Test set: Average loss: 126500.1782 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  14, Average loss 126500.178 Test accuracy 94.280\n",
      "selected users: [ 0  4  5  6 11]\n",
      "\n",
      "Test set: Average loss: 325442.6132 \n",
      "Accuracy: 9394/10000 (93.94%)\n",
      "\n",
      "Round  15, Average loss 325442.613 Test accuracy 93.940\n",
      "selected users: [ 1  3  8 11 14]\n",
      "\n",
      "Test set: Average loss: 495269.1008 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  16, Average loss 495269.101 Test accuracy 94.110\n",
      "selected users: [ 0  3  5  9 11]\n",
      "\n",
      "Test set: Average loss: 1082600.7800 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round  17, Average loss 1082600.780 Test accuracy 93.870\n",
      "selected users: [ 2  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1561034.6024 \n",
      "Accuracy: 9431/10000 (94.31%)\n",
      "\n",
      "Round  18, Average loss 1561034.602 Test accuracy 94.310\n",
      "selected users: [ 2  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2400968.6528 \n",
      "Accuracy: 9443/10000 (94.43%)\n",
      "\n",
      "Round  19, Average loss 2400968.653 Test accuracy 94.430\n",
      "selected users: [ 3  4  5  8 11]\n",
      "\n",
      "Test set: Average loss: 4363137.1392 \n",
      "Accuracy: 9412/10000 (94.12%)\n",
      "\n",
      "Round  20, Average loss 4363137.139 Test accuracy 94.120\n",
      "selected users: [ 5  6  7  9 11]\n",
      "\n",
      "Test set: Average loss: 8490519.2512 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round  21, Average loss 8490519.251 Test accuracy 93.870\n",
      "selected users: [ 0  3  8 13 14]\n",
      "\n",
      "Test set: Average loss: 13313666.5344 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round  22, Average loss 13313666.534 Test accuracy 93.810\n",
      "selected users: [ 1  2  7  8 13]\n",
      "\n",
      "Test set: Average loss: 18995617.9840 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  23, Average loss 18995617.984 Test accuracy 94.080\n",
      "selected users: [ 2  3  8 10 13]\n",
      "\n",
      "Test set: Average loss: 30243847.6032 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round  24, Average loss 30243847.603 Test accuracy 93.980\n",
      "selected users: [ 0  3 10 11 14]\n",
      "\n",
      "Test set: Average loss: 51103549.4912 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  25, Average loss 51103549.491 Test accuracy 94.110\n",
      "selected users: [ 5  6  7 13 14]\n",
      "\n",
      "Test set: Average loss: 86646866.9952 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  26, Average loss 86646866.995 Test accuracy 94.030\n",
      "selected users: [ 1  2  3  5 10]\n",
      "\n",
      "Test set: Average loss: 155556082.4832 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  27, Average loss 155556082.483 Test accuracy 94.080\n",
      "selected users: [ 1  3  9 12 14]\n",
      "\n",
      "Test set: Average loss: 261619577.4464 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round  28, Average loss 261619577.446 Test accuracy 94.200\n",
      "selected users: [ 1  7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 442689768.6528 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  29, Average loss 442689768.653 Test accuracy 94.280\n",
      "(m= 5 )  6 -th Trial!!\n",
      "selected users: [ 1  2  3  8 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  6  7 13]\n",
      "\n",
      "Test set: Average loss: 0.6284 \n",
      "Accuracy: 8501/10000 (85.01%)\n",
      "\n",
      "Round   1, Average loss 0.628 Test accuracy 85.010\n",
      "selected users: [ 0  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 18.9102 \n",
      "Accuracy: 9329/10000 (93.29%)\n",
      "\n",
      "Round   2, Average loss 18.910 Test accuracy 93.290\n",
      "selected users: [ 0  2  7  9 10]\n",
      "\n",
      "Test set: Average loss: 99.3250 \n",
      "Accuracy: 8910/10000 (89.10%)\n",
      "\n",
      "Round   3, Average loss 99.325 Test accuracy 89.100\n",
      "selected users: [ 2  4  8  9 13]\n",
      "\n",
      "Test set: Average loss: 47.4775 \n",
      "Accuracy: 9126/10000 (91.26%)\n",
      "\n",
      "Round   4, Average loss 47.478 Test accuracy 91.260\n",
      "selected users: [ 1  6  7  9 12]\n",
      "\n",
      "Test set: Average loss: 261.8278 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round   5, Average loss 261.828 Test accuracy 93.870\n",
      "selected users: [0 1 4 5 7]\n",
      "\n",
      "Test set: Average loss: 231.8586 \n",
      "Accuracy: 9417/10000 (94.17%)\n",
      "\n",
      "Round   6, Average loss 231.859 Test accuracy 94.170\n",
      "selected users: [ 0  3  9 10 12]\n",
      "\n",
      "Test set: Average loss: 11.8143 \n",
      "Accuracy: 4335/10000 (43.35%)\n",
      "\n",
      "Round   7, Average loss 11.814 Test accuracy 43.350\n",
      "selected users: [ 0  4 10 12 14]\n",
      "\n",
      "Test set: Average loss: 954.3262 \n",
      "Accuracy: 9241/10000 (92.41%)\n",
      "\n",
      "Round   8, Average loss 954.326 Test accuracy 92.410\n",
      "selected users: [ 0  3  5 11 12]\n",
      "\n",
      "Test set: Average loss: 8029.4368 \n",
      "Accuracy: 9296/10000 (92.96%)\n",
      "\n",
      "Round   9, Average loss 8029.437 Test accuracy 92.960\n",
      "selected users: [ 2  4  8 11 14]\n",
      "\n",
      "Test set: Average loss: 10302.2277 \n",
      "Accuracy: 9400/10000 (94.00%)\n",
      "\n",
      "Round  10, Average loss 10302.228 Test accuracy 94.000\n",
      "selected users: [1 3 4 5 8]\n",
      "\n",
      "Test set: Average loss: 12369.1547 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round  11, Average loss 12369.155 Test accuracy 94.390\n",
      "selected users: [2 3 4 8 9]\n",
      "\n",
      "Test set: Average loss: 45094.9307 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  12, Average loss 45094.931 Test accuracy 93.990\n",
      "selected users: [ 2  5  6 10 13]\n",
      "\n",
      "Test set: Average loss: 55601.6963 \n",
      "Accuracy: 9440/10000 (94.40%)\n",
      "\n",
      "Round  13, Average loss 55601.696 Test accuracy 94.400\n",
      "selected users: [ 0  5  7  9 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 104675.4076 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  14, Average loss 104675.408 Test accuracy 94.360\n",
      "selected users: [ 1  5  6  9 12]\n",
      "\n",
      "Test set: Average loss: 174132.4142 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round  15, Average loss 174132.414 Test accuracy 94.560\n",
      "selected users: [ 4  6  7  9 12]\n",
      "\n",
      "Test set: Average loss: 281353.6840 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round  16, Average loss 281353.684 Test accuracy 94.640\n",
      "selected users: [ 2  3  7 11 12]\n",
      "\n",
      "Test set: Average loss: 324117.9080 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  17, Average loss 324117.908 Test accuracy 94.790\n",
      "selected users: [ 3  4 10 13 14]\n",
      "\n",
      "Test set: Average loss: 739218.0952 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  18, Average loss 739218.095 Test accuracy 94.630\n",
      "selected users: [ 0  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 1584686.6520 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round  19, Average loss 1584686.652 Test accuracy 94.640\n",
      "selected users: [ 1  2  4  6 14]\n",
      "\n",
      "Test set: Average loss: 2803140.5184 \n",
      "Accuracy: 9469/10000 (94.69%)\n",
      "\n",
      "Round  20, Average loss 2803140.518 Test accuracy 94.690\n",
      "selected users: [ 3  4 10 11 12]\n",
      "\n",
      "Test set: Average loss: 4922332.8960 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  21, Average loss 4922332.896 Test accuracy 94.360\n",
      "selected users: [ 0  3  5  6 10]\n",
      "\n",
      "Test set: Average loss: 9395486.9952 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  22, Average loss 9395486.995 Test accuracy 94.280\n",
      "selected users: [ 0  3  4  5 10]\n",
      "\n",
      "Test set: Average loss: 18380193.2416 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  23, Average loss 18380193.242 Test accuracy 94.030\n",
      "selected users: [ 0  1  6 11 14]\n",
      "\n",
      "Test set: Average loss: 31371353.4208 \n",
      "Accuracy: 9447/10000 (94.47%)\n",
      "\n",
      "Round  24, Average loss 31371353.421 Test accuracy 94.470\n",
      "selected users: [ 0  6  7 10 11]\n",
      "\n",
      "Test set: Average loss: 57271775.2832 \n",
      "Accuracy: 9444/10000 (94.44%)\n",
      "\n",
      "Round  25, Average loss 57271775.283 Test accuracy 94.440\n",
      "selected users: [ 0  4  6  8 11]\n",
      "\n",
      "Test set: Average loss: 104067010.6112 \n",
      "Accuracy: 9435/10000 (94.35%)\n",
      "\n",
      "Round  26, Average loss 104067010.611 Test accuracy 94.350\n",
      "selected users: [ 1  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 170785737.9328 \n",
      "Accuracy: 9442/10000 (94.42%)\n",
      "\n",
      "Round  27, Average loss 170785737.933 Test accuracy 94.420\n",
      "selected users: [ 3  5 10 12 14]\n",
      "\n",
      "Test set: Average loss: 302571289.6000 \n",
      "Accuracy: 9429/10000 (94.29%)\n",
      "\n",
      "Round  28, Average loss 302571289.600 Test accuracy 94.290\n",
      "selected users: [ 1  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 532320807.3216 \n",
      "Accuracy: 9424/10000 (94.24%)\n",
      "\n",
      "Round  29, Average loss 532320807.322 Test accuracy 94.240\n",
      "(m= 5 )  7 -th Trial!!\n",
      "selected users: [ 1  2  6  7 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  5  6 11]\n",
      "\n",
      "Test set: Average loss: 1.0069 \n",
      "Accuracy: 7538/10000 (75.38%)\n",
      "\n",
      "Round   1, Average loss 1.007 Test accuracy 75.380\n",
      "selected users: [1 2 3 7 9]\n",
      "\n",
      "Test set: Average loss: 0.3368 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round   2, Average loss 0.337 Test accuracy 94.390\n",
      "selected users: [ 0  3  8  9 13]\n",
      "\n",
      "Test set: Average loss: 0.9530 \n",
      "Accuracy: 9197/10000 (91.97%)\n",
      "\n",
      "Round   3, Average loss 0.953 Test accuracy 91.970\n",
      "selected users: [2 3 5 7 9]\n",
      "\n",
      "Test set: Average loss: 39.4378 \n",
      "Accuracy: 9243/10000 (92.43%)\n",
      "\n",
      "Round   4, Average loss 39.438 Test accuracy 92.430\n",
      "selected users: [ 1  5  7 11 13]\n",
      "\n",
      "Test set: Average loss: 86.2167 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round   5, Average loss 86.217 Test accuracy 94.330\n",
      "selected users: [ 3  6  8  9 11]\n",
      "\n",
      "Test set: Average loss: 136.2309 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round   6, Average loss 136.231 Test accuracy 94.610\n",
      "selected users: [ 3  7 12 13 14]\n",
      "\n",
      "Test set: Average loss: 45.6391 \n",
      "Accuracy: 9385/10000 (93.85%)\n",
      "\n",
      "Round   7, Average loss 45.639 Test accuracy 93.850\n",
      "selected users: [ 1  2 10 12 13]\n",
      "\n",
      "Test set: Average loss: 99.4345 \n",
      "Accuracy: 8867/10000 (88.67%)\n",
      "\n",
      "Round   8, Average loss 99.435 Test accuracy 88.670\n",
      "selected users: [ 0  2  3  7 11]\n",
      "\n",
      "Test set: Average loss: 2172.3376 \n",
      "Accuracy: 9394/10000 (93.94%)\n",
      "\n",
      "Round   9, Average loss 2172.338 Test accuracy 93.940\n",
      "selected users: [ 1  5  9 11 12]\n",
      "\n",
      "Test set: Average loss: 4718.4597 \n",
      "Accuracy: 9395/10000 (93.95%)\n",
      "\n",
      "Round  10, Average loss 4718.460 Test accuracy 93.950\n",
      "selected users: [ 1  3  9 10 12]\n",
      "\n",
      "Test set: Average loss: 715.9559 \n",
      "Accuracy: 9322/10000 (93.22%)\n",
      "\n",
      "Round  11, Average loss 715.956 Test accuracy 93.220\n",
      "selected users: [ 3  4  7  8 14]\n",
      "\n",
      "Test set: Average loss: 3343.5539 \n",
      "Accuracy: 9485/10000 (94.85%)\n",
      "\n",
      "Round  12, Average loss 3343.554 Test accuracy 94.850\n",
      "selected users: [ 7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 25358.2709 \n",
      "Accuracy: 9425/10000 (94.25%)\n",
      "\n",
      "Round  13, Average loss 25358.271 Test accuracy 94.250\n",
      "selected users: [ 2  6 10 11 12]\n",
      "\n",
      "Test set: Average loss: 24667.6687 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  14, Average loss 24667.669 Test accuracy 94.790\n",
      "selected users: [ 1  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 44481.4996 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round  15, Average loss 44481.500 Test accuracy 95.050\n",
      "selected users: [ 0  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 130303.6602 \n",
      "Accuracy: 9483/10000 (94.83%)\n",
      "\n",
      "Round  16, Average loss 130303.660 Test accuracy 94.830\n",
      "selected users: [ 1  3  4  5 10]\n",
      "\n",
      "Test set: Average loss: 370247.9490 \n",
      "Accuracy: 9394/10000 (93.94%)\n",
      "\n",
      "Round  17, Average loss 370247.949 Test accuracy 93.940\n",
      "selected users: [ 1  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 611742.8480 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round  18, Average loss 611742.848 Test accuracy 94.450\n",
      "selected users: [ 2  5  7 13 14]\n",
      "\n",
      "Test set: Average loss: 594510.2112 \n",
      "Accuracy: 9473/10000 (94.73%)\n",
      "\n",
      "Round  19, Average loss 594510.211 Test accuracy 94.730\n",
      "selected users: [ 0  1  2  3 11]\n",
      "\n",
      "Test set: Average loss: 1107312.5248 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round  20, Average loss 1107312.525 Test accuracy 94.820\n",
      "selected users: [ 3  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 1530566.8304 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  21, Average loss 1530566.830 Test accuracy 95.060\n",
      "selected users: [ 2  5  7  9 12]\n",
      "\n",
      "Test set: Average loss: 2212944.9856 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  22, Average loss 2212944.986 Test accuracy 95.290\n",
      "selected users: [ 3  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 3057752.9984 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round  23, Average loss 3057752.998 Test accuracy 95.320\n",
      "selected users: [ 0  3  8 13 14]\n",
      "\n",
      "Test set: Average loss: 4276829.7728 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  24, Average loss 4276829.773 Test accuracy 95.100\n",
      "selected users: [ 0  2  6  8 12]\n",
      "\n",
      "Test set: Average loss: 6076491.7952 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  25, Average loss 6076491.795 Test accuracy 95.100\n",
      "selected users: [ 0  4  9 10 14]\n",
      "\n",
      "Test set: Average loss: 11997418.6368 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  26, Average loss 11997418.637 Test accuracy 95.340\n",
      "selected users: [ 0  4  5 10 11]\n",
      "\n",
      "Test set: Average loss: 25011907.9936 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  27, Average loss 25011907.994 Test accuracy 95.280\n",
      "selected users: [ 2  5  6  8 14]\n",
      "\n",
      "Test set: Average loss: 42747714.4064 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  28, Average loss 42747714.406 Test accuracy 95.310\n",
      "selected users: [ 2  4  9 12 14]\n",
      "\n",
      "Test set: Average loss: 76196276.5312 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round  29, Average loss 76196276.531 Test accuracy 95.350\n",
      "(m= 5 )  8 -th Trial!!\n",
      "selected users: [ 2  4  6  9 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5  9 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  6  9 10]\n",
      "\n",
      "Test set: Average loss: 1.3878 \n",
      "Accuracy: 7592/10000 (75.92%)\n",
      "\n",
      "Round   2, Average loss 1.388 Test accuracy 75.920\n",
      "selected users: [4 6 7 8 9]\n",
      "\n",
      "Test set: Average loss: 28.9673 \n",
      "Accuracy: 9136/10000 (91.36%)\n",
      "\n",
      "Round   3, Average loss 28.967 Test accuracy 91.360\n",
      "selected users: [ 1  2  9 11 14]\n",
      "\n",
      "Test set: Average loss: 3.4365 \n",
      "Accuracy: 8991/10000 (89.91%)\n",
      "\n",
      "Round   4, Average loss 3.436 Test accuracy 89.910\n",
      "selected users: [ 3  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1340 \n",
      "Accuracy: 3659/10000 (36.59%)\n",
      "\n",
      "Round   5, Average loss 2.134 Test accuracy 36.590\n",
      "selected users: [ 2  6  9 10 11]\n",
      "\n",
      "Test set: Average loss: 0.6338 \n",
      "Accuracy: 8459/10000 (84.59%)\n",
      "\n",
      "Round   6, Average loss 0.634 Test accuracy 84.590\n",
      "selected users: [ 3  6  8  9 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 7.4931 \n",
      "Accuracy: 8639/10000 (86.39%)\n",
      "\n",
      "Round   7, Average loss 7.493 Test accuracy 86.390\n",
      "selected users: [ 2  6  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7161 \n",
      "Accuracy: 7891/10000 (78.91%)\n",
      "\n",
      "Round   8, Average loss 0.716 Test accuracy 78.910\n",
      "selected users: [ 0  4  7 10 12]\n",
      "\n",
      "Test set: Average loss: 24.6457 \n",
      "Accuracy: 9212/10000 (92.12%)\n",
      "\n",
      "Round   9, Average loss 24.646 Test accuracy 92.120\n",
      "selected users: [ 3  4  7  8 14]\n",
      "\n",
      "Test set: Average loss: 19.8203 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  10, Average loss 19.820 Test accuracy 94.280\n",
      "selected users: [ 1  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 137.2801 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  11, Average loss 137.280 Test accuracy 95.610\n",
      "selected users: [ 2  3  6  9 12]\n",
      "\n",
      "Test set: Average loss: 71.7881 \n",
      "Accuracy: 9478/10000 (94.78%)\n",
      "\n",
      "Round  12, Average loss 71.788 Test accuracy 94.780\n",
      "selected users: [0 1 4 7 8]\n",
      "\n",
      "Test set: Average loss: 1055.4069 \n",
      "Accuracy: 9491/10000 (94.91%)\n",
      "\n",
      "Round  13, Average loss 1055.407 Test accuracy 94.910\n",
      "selected users: [ 4  6  7 13 14]\n",
      "\n",
      "Test set: Average loss: 359.8154 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round  14, Average loss 359.815 Test accuracy 93.280\n",
      "selected users: [ 2  4  5  6 13]\n",
      "\n",
      "Test set: Average loss: 417.3404 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  15, Average loss 417.340 Test accuracy 94.980\n",
      "selected users: [ 3  5  7 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5333 \n",
      "Accuracy: 979/10000 (9.79%)\n",
      "\n",
      "Round  16, Average loss 2.533 Test accuracy 9.790\n",
      "selected users: [ 0  3  4 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4083 \n",
      "Accuracy: 977/10000 (9.77%)\n",
      "\n",
      "Round  17, Average loss 2.408 Test accuracy 9.770\n",
      "selected users: [ 1  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3378 \n",
      "Accuracy: 974/10000 (9.74%)\n",
      "\n",
      "Round  18, Average loss 2.338 Test accuracy 9.740\n",
      "selected users: [ 0  4  5  8 12]\n",
      "\n",
      "Test set: Average loss: 2.3142 \n",
      "Accuracy: 975/10000 (9.75%)\n",
      "\n",
      "Round  19, Average loss 2.314 Test accuracy 9.750\n",
      "selected users: [ 0  1  2  6 14]\n",
      "\n",
      "Test set: Average loss: 2.3020 \n",
      "Accuracy: 1151/10000 (11.51%)\n",
      "\n",
      "Round  20, Average loss 2.302 Test accuracy 11.510\n",
      "selected users: [ 0  6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.2948 \n",
      "Accuracy: 1164/10000 (11.64%)\n",
      "\n",
      "Round  21, Average loss 2.295 Test accuracy 11.640\n",
      "selected users: [ 3  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3016 \n",
      "Accuracy: 1137/10000 (11.37%)\n",
      "\n",
      "Round  22, Average loss 2.302 Test accuracy 11.370\n",
      "selected users: [ 0  1 11 12 13]\n",
      "\n",
      "Test set: Average loss: 41.7995 \n",
      "Accuracy: 1291/10000 (12.91%)\n",
      "\n",
      "Round  23, Average loss 41.800 Test accuracy 12.910\n",
      "selected users: [ 1  2  3 10 11]\n",
      "\n",
      "Test set: Average loss: 6.4858 \n",
      "Accuracy: 838/10000 (8.38%)\n",
      "\n",
      "Round  24, Average loss 6.486 Test accuracy 8.380\n",
      "selected users: [ 1  3 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4  5  6 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  3  4 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  6  7  9 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  7 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "(m= 5 )  9 -th Trial!!\n",
      "selected users: [ 1  2  3  7 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  7 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  5  6 10]\n",
      "\n",
      "Test set: Average loss: 2.0932 \n",
      "Accuracy: 4651/10000 (46.51%)\n",
      "\n",
      "Round   2, Average loss 2.093 Test accuracy 46.510\n",
      "selected users: [ 1  5 11 12 13]\n",
      "\n",
      "Test set: Average loss: 38.0773 \n",
      "Accuracy: 8675/10000 (86.75%)\n",
      "\n",
      "Round   3, Average loss 38.077 Test accuracy 86.750\n",
      "selected users: [0 1 3 7 8]\n",
      "\n",
      "Test set: Average loss: 2.7522 \n",
      "Accuracy: 8094/10000 (80.94%)\n",
      "\n",
      "Round   4, Average loss 2.752 Test accuracy 80.940\n",
      "selected users: [ 1  2  3  4 14]\n",
      "\n",
      "Test set: Average loss: 149.3155 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round   5, Average loss 149.316 Test accuracy 93.870\n",
      "selected users: [ 0  2  7 10 12]\n",
      "\n",
      "Test set: Average loss: 2.0769 \n",
      "Accuracy: 1712/10000 (17.12%)\n",
      "\n",
      "Round   6, Average loss 2.077 Test accuracy 17.120\n",
      "selected users: [ 1  6 10 12 13]\n",
      "\n",
      "Test set: Average loss: 6.1166 \n",
      "Accuracy: 8552/10000 (85.52%)\n",
      "\n",
      "Round   7, Average loss 6.117 Test accuracy 85.520\n",
      "selected users: [ 0  5  7  8 14]\n",
      "\n",
      "Test set: Average loss: 96.3619 \n",
      "Accuracy: 9257/10000 (92.57%)\n",
      "\n",
      "Round   8, Average loss 96.362 Test accuracy 92.570\n",
      "selected users: [ 4  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 371.2967 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round   9, Average loss 371.297 Test accuracy 94.540\n",
      "selected users: [ 3  4  5  7 11]\n",
      "\n",
      "Test set: Average loss: 725.3615 \n",
      "Accuracy: 9415/10000 (94.15%)\n",
      "\n",
      "Round  10, Average loss 725.361 Test accuracy 94.150\n",
      "selected users: [ 2  6  9 12 14]\n",
      "\n",
      "Test set: Average loss: 582.4051 \n",
      "Accuracy: 9414/10000 (94.14%)\n",
      "\n",
      "Round  11, Average loss 582.405 Test accuracy 94.140\n",
      "selected users: [ 0  1 10 13 14]\n",
      "\n",
      "Test set: Average loss: 4893.6907 \n",
      "Accuracy: 9279/10000 (92.79%)\n",
      "\n",
      "Round  12, Average loss 4893.691 Test accuracy 92.790\n",
      "selected users: [ 0  4  7 13 14]\n",
      "\n",
      "Test set: Average loss: 2357.1395 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round  13, Average loss 2357.140 Test accuracy 94.860\n",
      "selected users: [0 2 3 6 8]\n",
      "\n",
      "Test set: Average loss: 4054.7458 \n",
      "Accuracy: 9442/10000 (94.42%)\n",
      "\n",
      "Round  14, Average loss 4054.746 Test accuracy 94.420\n",
      "selected users: [ 1 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 13105.2118 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  15, Average loss 13105.212 Test accuracy 94.620\n",
      "selected users: [ 0  3  5 10 13]\n",
      "\n",
      "Test set: Average loss: 49584.4700 \n",
      "Accuracy: 9361/10000 (93.61%)\n",
      "\n",
      "Round  16, Average loss 49584.470 Test accuracy 93.610\n",
      "selected users: [ 0  1  6  8 10]\n",
      "\n",
      "Test set: Average loss: 130686.0232 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round  17, Average loss 130686.023 Test accuracy 93.600\n",
      "selected users: [ 2  5  6 13 14]\n",
      "\n",
      "Test set: Average loss: 68279.4720 \n",
      "Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Round  18, Average loss 68279.472 Test accuracy 94.720\n",
      "selected users: [ 2  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 61024.8437 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  19, Average loss 61024.844 Test accuracy 94.900\n",
      "selected users: [ 1  4  6  8 11]\n",
      "\n",
      "Test set: Average loss: 194132.8424 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  20, Average loss 194132.842 Test accuracy 95.140\n",
      "selected users: [ 4  5  9 10 11]\n",
      "\n",
      "Test set: Average loss: 542910.3184 \n",
      "Accuracy: 9494/10000 (94.94%)\n",
      "\n",
      "Round  21, Average loss 542910.318 Test accuracy 94.940\n",
      "selected users: [2 3 5 6 8]\n",
      "\n",
      "Test set: Average loss: 777321.8376 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  22, Average loss 777321.838 Test accuracy 94.800\n",
      "selected users: [ 0  4  6  9 14]\n",
      "\n",
      "Test set: Average loss: 1636294.4544 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  23, Average loss 1636294.454 Test accuracy 94.920\n",
      "selected users: [ 4  5  7  8 12]\n",
      "\n",
      "Test set: Average loss: 2575670.9184 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round  24, Average loss 2575670.918 Test accuracy 94.880\n",
      "selected users: [ 0  1  3  8 13]\n",
      "\n",
      "Test set: Average loss: 3558804.3584 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round  25, Average loss 3558804.358 Test accuracy 95.040\n",
      "selected users: [1 2 3 8 9]\n",
      "\n",
      "Test set: Average loss: 6685303.0080 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  26, Average loss 6685303.008 Test accuracy 95.020\n",
      "selected users: [1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 14023377.6384 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round  27, Average loss 14023377.638 Test accuracy 94.550\n",
      "selected users: [ 0  6  8 11 14]\n",
      "\n",
      "Test set: Average loss: 25147430.4256 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  28, Average loss 25147430.426 Test accuracy 94.870\n",
      "selected users: [ 0  3  6  9 10]\n",
      "\n",
      "Test set: Average loss: 48213243.1360 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  29, Average loss 48213243.136 Test accuracy 94.650\n",
      "number of results: 6\n",
      "(m= 6 )  0 -th Trial!!\n",
      "selected users: [ 1  3  6  7 11 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  6 11 12 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9143 \n",
      "Accuracy: 6583/10000 (65.83%)\n",
      "\n",
      "Round   1, Average loss 1.914 Test accuracy 65.830\n",
      "selected users: [ 0  1  6  8  9 10]\n",
      "\n",
      "Test set: Average loss: 14.5255 \n",
      "Accuracy: 8103/10000 (81.03%)\n",
      "\n",
      "Round   2, Average loss 14.526 Test accuracy 81.030\n",
      "selected users: [ 0  2  4  7  8 10]\n",
      "\n",
      "Test set: Average loss: 201.8626 \n",
      "Accuracy: 8829/10000 (88.29%)\n",
      "\n",
      "Round   3, Average loss 201.863 Test accuracy 88.290\n",
      "selected users: [ 0  3  4  7  8 10]\n",
      "\n",
      "Test set: Average loss: 965.2464 \n",
      "Accuracy: 8836/10000 (88.36%)\n",
      "\n",
      "Round   4, Average loss 965.246 Test accuracy 88.360\n",
      "selected users: [ 0  3  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 31.0683 \n",
      "Accuracy: 8613/10000 (86.13%)\n",
      "\n",
      "Round   5, Average loss 31.068 Test accuracy 86.130\n",
      "selected users: [ 2  3  4  8 10 11]\n",
      "\n",
      "Test set: Average loss: 159.0862 \n",
      "Accuracy: 9231/10000 (92.31%)\n",
      "\n",
      "Round   6, Average loss 159.086 Test accuracy 92.310\n",
      "selected users: [0 1 3 5 6 9]\n",
      "\n",
      "Test set: Average loss: 730.7577 \n",
      "Accuracy: 9225/10000 (92.25%)\n",
      "\n",
      "Round   7, Average loss 730.758 Test accuracy 92.250\n",
      "selected users: [ 4  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1166.9899 \n",
      "Accuracy: 9271/10000 (92.71%)\n",
      "\n",
      "Round   8, Average loss 1166.990 Test accuracy 92.710\n",
      "selected users: [ 0  2  5  9 12 13]\n",
      "\n",
      "Test set: Average loss: 1025.2687 \n",
      "Accuracy: 9233/10000 (92.33%)\n",
      "\n",
      "Round   9, Average loss 1025.269 Test accuracy 92.330\n",
      "selected users: [ 1  4  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 1030.3193 \n",
      "Accuracy: 9301/10000 (93.01%)\n",
      "\n",
      "Round  10, Average loss 1030.319 Test accuracy 93.010\n",
      "selected users: [ 2  3  4 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1632.9541 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round  11, Average loss 1632.954 Test accuracy 92.470\n",
      "selected users: [ 0  3  5  9 13 14]\n",
      "\n",
      "Test set: Average loss: 1712.5651 \n",
      "Accuracy: 9248/10000 (92.48%)\n",
      "\n",
      "Round  12, Average loss 1712.565 Test accuracy 92.480\n",
      "selected users: [ 1  5  6  8 10 12]\n",
      "\n",
      "Test set: Average loss: 1515.7034 \n",
      "Accuracy: 9267/10000 (92.67%)\n",
      "\n",
      "Round  13, Average loss 1515.703 Test accuracy 92.670\n",
      "selected users: [ 3  5  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 831.7258 \n",
      "Accuracy: 9175/10000 (91.75%)\n",
      "\n",
      "Round  14, Average loss 831.726 Test accuracy 91.750\n",
      "selected users: [0 1 3 6 7 9]\n",
      "\n",
      "Test set: Average loss: 4747.7147 \n",
      "Accuracy: 9294/10000 (92.94%)\n",
      "\n",
      "Round  15, Average loss 4747.715 Test accuracy 92.940\n",
      "selected users: [ 2  3  5  7 10 13]\n",
      "\n",
      "Test set: Average loss: 3655.6463 \n",
      "Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Round  16, Average loss 3655.646 Test accuracy 92.690\n",
      "selected users: [ 1  3  4  9 10 11]\n",
      "\n",
      "Test set: Average loss: 7445.7230 \n",
      "Accuracy: 9319/10000 (93.19%)\n",
      "\n",
      "Round  17, Average loss 7445.723 Test accuracy 93.190\n",
      "selected users: [ 1  2  5  6 10 12]\n",
      "\n",
      "Test set: Average loss: 5706.8440 \n",
      "Accuracy: 9313/10000 (93.13%)\n",
      "\n",
      "Round  18, Average loss 5706.844 Test accuracy 93.130\n",
      "selected users: [ 1  3  4  8  9 11]\n",
      "\n",
      "Test set: Average loss: 9996.9814 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round  19, Average loss 9996.981 Test accuracy 93.240\n",
      "selected users: [ 0  1  4  7  8 14]\n",
      "\n",
      "Test set: Average loss: 12489.0050 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round  20, Average loss 12489.005 Test accuracy 93.370\n",
      "selected users: [ 1  5  6  9 11 12]\n",
      "\n",
      "Test set: Average loss: 9570.4581 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  21, Average loss 9570.458 Test accuracy 93.990\n",
      "selected users: [ 2  5  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 3439.0226 \n",
      "Accuracy: 9215/10000 (92.15%)\n",
      "\n",
      "Round  22, Average loss 3439.023 Test accuracy 92.150\n",
      "selected users: [ 2  6  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 1668.1163 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round  23, Average loss 1668.116 Test accuracy 93.520\n",
      "selected users: [ 0  5  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 6362.9544 \n",
      "Accuracy: 9317/10000 (93.17%)\n",
      "\n",
      "Round  24, Average loss 6362.954 Test accuracy 93.170\n",
      "selected users: [ 2  3  5  7  8 11]\n",
      "\n",
      "Test set: Average loss: 12497.6666 \n",
      "Accuracy: 9279/10000 (92.79%)\n",
      "\n",
      "Round  25, Average loss 12497.667 Test accuracy 92.790\n",
      "selected users: [ 0  2  3  6  7 13]\n",
      "\n",
      "Test set: Average loss: 5672.9347 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round  26, Average loss 5672.935 Test accuracy 93.760\n",
      "selected users: [ 0  2  4  7  9 13]\n",
      "\n",
      "Test set: Average loss: 7286.1009 \n",
      "Accuracy: 9364/10000 (93.64%)\n",
      "\n",
      "Round  27, Average loss 7286.101 Test accuracy 93.640\n",
      "selected users: [ 0  1  3  5 10 14]\n",
      "\n",
      "Test set: Average loss: 32109.7630 \n",
      "Accuracy: 9149/10000 (91.49%)\n",
      "\n",
      "Round  28, Average loss 32109.763 Test accuracy 91.490\n",
      "selected users: [ 0  7  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 33313.9743 \n",
      "Accuracy: 9203/10000 (92.03%)\n",
      "\n",
      "Round  29, Average loss 33313.974 Test accuracy 92.030\n",
      "(m= 6 )  1 -th Trial!!\n",
      "selected users: [ 0  1  3  9 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  5  6 12 14]\n",
      "\n",
      "Test set: Average loss: 2.2916 \n",
      "Accuracy: 1242/10000 (12.42%)\n",
      "\n",
      "Round   1, Average loss 2.292 Test accuracy 12.420\n",
      "selected users: [ 2  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 1.7732 \n",
      "Accuracy: 7722/10000 (77.22%)\n",
      "\n",
      "Round   2, Average loss 1.773 Test accuracy 77.220\n",
      "selected users: [ 0  4  5  9 12 14]\n",
      "\n",
      "Test set: Average loss: 15.0802 \n",
      "Accuracy: 9422/10000 (94.22%)\n",
      "\n",
      "Round   3, Average loss 15.080 Test accuracy 94.220\n",
      "selected users: [ 5  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 288.4174 \n",
      "Accuracy: 8999/10000 (89.99%)\n",
      "\n",
      "Round   4, Average loss 288.417 Test accuracy 89.990\n",
      "selected users: [ 1  3  5 10 11 14]\n",
      "\n",
      "Test set: Average loss: 799.9106 \n",
      "Accuracy: 9205/10000 (92.05%)\n",
      "\n",
      "Round   5, Average loss 799.911 Test accuracy 92.050\n",
      "selected users: [ 1  4  5  6  7 11]\n",
      "\n",
      "Test set: Average loss: 1325.8010 \n",
      "Accuracy: 9350/10000 (93.50%)\n",
      "\n",
      "Round   6, Average loss 1325.801 Test accuracy 93.500\n",
      "selected users: [ 1  6  7  9 12 14]\n",
      "\n",
      "Test set: Average loss: 1130.4422 \n",
      "Accuracy: 9437/10000 (94.37%)\n",
      "\n",
      "Round   7, Average loss 1130.442 Test accuracy 94.370\n",
      "selected users: [ 2  5 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4589.6106 \n",
      "Accuracy: 9281/10000 (92.81%)\n",
      "\n",
      "Round   8, Average loss 4589.611 Test accuracy 92.810\n",
      "selected users: [ 1  2  4  5  6 12]\n",
      "\n",
      "Test set: Average loss: 2276.5904 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round   9, Average loss 2276.590 Test accuracy 94.030\n",
      "selected users: [ 4  5  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 2477.3769 \n",
      "Accuracy: 9380/10000 (93.80%)\n",
      "\n",
      "Round  10, Average loss 2477.377 Test accuracy 93.800\n",
      "selected users: [ 0  3  5  9 10 13]\n",
      "\n",
      "Test set: Average loss: 3051.5921 \n",
      "Accuracy: 9334/10000 (93.34%)\n",
      "\n",
      "Round  11, Average loss 3051.592 Test accuracy 93.340\n",
      "selected users: [ 1  4  5  6 12 14]\n",
      "\n",
      "Test set: Average loss: 1407.0087 \n",
      "Accuracy: 9358/10000 (93.58%)\n",
      "\n",
      "Round  12, Average loss 1407.009 Test accuracy 93.580\n",
      "selected users: [ 0  1  3  9 13 14]\n",
      "\n",
      "Test set: Average loss: 1341.5191 \n",
      "Accuracy: 9423/10000 (94.23%)\n",
      "\n",
      "Round  13, Average loss 1341.519 Test accuracy 94.230\n",
      "selected users: [ 3  4  6  7 11 12]\n",
      "\n",
      "Test set: Average loss: 956.9701 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  14, Average loss 956.970 Test accuracy 93.380\n",
      "selected users: [0 3 5 7 8 9]\n",
      "\n",
      "Test set: Average loss: 1510.7493 \n",
      "Accuracy: 9438/10000 (94.38%)\n",
      "\n",
      "Round  15, Average loss 1510.749 Test accuracy 94.380\n",
      "selected users: [ 0  1  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1785.2300 \n",
      "Accuracy: 9053/10000 (90.53%)\n",
      "\n",
      "Round  16, Average loss 1785.230 Test accuracy 90.530\n",
      "selected users: [ 4  5  6  8 11 14]\n",
      "\n",
      "Test set: Average loss: 3117.5958 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  17, Average loss 3117.596 Test accuracy 95.750\n",
      "selected users: [ 0  5  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 5386.5952 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  18, Average loss 5386.595 Test accuracy 94.800\n",
      "selected users: [ 4  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 5827.0591 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round  19, Average loss 5827.059 Test accuracy 95.190\n",
      "selected users: [ 3  6  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2630.5378 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round  20, Average loss 2630.538 Test accuracy 94.820\n",
      "selected users: [ 1  2  3  8  9 10]\n",
      "\n",
      "Test set: Average loss: 5805.9629 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round  21, Average loss 5805.963 Test accuracy 93.760\n",
      "selected users: [ 1  3  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 551.8031 \n",
      "Accuracy: 8621/10000 (86.21%)\n",
      "\n",
      "Round  22, Average loss 551.803 Test accuracy 86.210\n",
      "selected users: [ 3  6  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 2610.3250 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  23, Average loss 2610.325 Test accuracy 94.800\n",
      "selected users: [ 1  4  7 10 12 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 6497.3402 \n",
      "Accuracy: 9458/10000 (94.58%)\n",
      "\n",
      "Round  24, Average loss 6497.340 Test accuracy 94.580\n",
      "selected users: [ 2  4  5  6 12 14]\n",
      "\n",
      "Test set: Average loss: 2541.1763 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round  25, Average loss 2541.176 Test accuracy 94.880\n",
      "selected users: [ 4  5  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 16330.3628 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round  26, Average loss 16330.363 Test accuracy 93.240\n",
      "selected users: [ 2  3  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 4784.3276 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  27, Average loss 4784.328 Test accuracy 94.080\n",
      "selected users: [ 1  6  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 7905.3829 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  28, Average loss 7905.383 Test accuracy 95.060\n",
      "selected users: [ 4  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 22003.0348 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round  29, Average loss 22003.035 Test accuracy 93.870\n",
      "(m= 6 )  2 -th Trial!!\n",
      "selected users: [ 1  4  6  7  9 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 2.2861 \n",
      "Accuracy: 4795/10000 (47.95%)\n",
      "\n",
      "Round   1, Average loss 2.286 Test accuracy 47.950\n",
      "selected users: [ 0  1  2 11 12 13]\n",
      "\n",
      "Test set: Average loss: 3.3387 \n",
      "Accuracy: 6803/10000 (68.03%)\n",
      "\n",
      "Round   2, Average loss 3.339 Test accuracy 68.030\n",
      "selected users: [ 0  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2575 \n",
      "Accuracy: 5228/10000 (52.28%)\n",
      "\n",
      "Round   3, Average loss 3.257 Test accuracy 52.280\n",
      "selected users: [ 0  1  5  6 10 14]\n",
      "\n",
      "Test set: Average loss: 2.5353 \n",
      "Accuracy: 4262/10000 (42.62%)\n",
      "\n",
      "Round   4, Average loss 2.535 Test accuracy 42.620\n",
      "selected users: [ 0  2 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 4  6  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  5  6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   7, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  8 11 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   8, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4  6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1.6330 \n",
      "Accuracy: 5061/10000 (50.61%)\n",
      "\n",
      "Round   9, Average loss 1.633 Test accuracy 50.610\n",
      "selected users: [ 2  3  5  8 10 11]\n",
      "\n",
      "Test set: Average loss: 4.0495 \n",
      "Accuracy: 9312/10000 (93.12%)\n",
      "\n",
      "Round  10, Average loss 4.050 Test accuracy 93.120\n",
      "selected users: [0 2 3 4 8 9]\n",
      "\n",
      "Test set: Average loss: 145.3341 \n",
      "Accuracy: 8869/10000 (88.69%)\n",
      "\n",
      "Round  11, Average loss 145.334 Test accuracy 88.690\n",
      "selected users: [ 0  1  4  5  9 14]\n",
      "\n",
      "Test set: Average loss: 117.8880 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round  12, Average loss 117.888 Test accuracy 95.030\n",
      "selected users: [ 2  3  7  8 12 14]\n",
      "\n",
      "Test set: Average loss: 2.0524 \n",
      "Accuracy: 2520/10000 (25.20%)\n",
      "\n",
      "Round  13, Average loss 2.052 Test accuracy 25.200\n",
      "selected users: [ 0  1  4  5  9 11]\n",
      "\n",
      "Test set: Average loss: 1.6785 \n",
      "Accuracy: 7143/10000 (71.43%)\n",
      "\n",
      "Round  14, Average loss 1.679 Test accuracy 71.430\n",
      "selected users: [ 0  2  4  7 11 14]\n",
      "\n",
      "Test set: Average loss: 0.5540 \n",
      "Accuracy: 8529/10000 (85.29%)\n",
      "\n",
      "Round  15, Average loss 0.554 Test accuracy 85.290\n",
      "selected users: [ 1  3  6 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.1912 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round  16, Average loss 1.191 Test accuracy 93.930\n",
      "selected users: [ 2  3  6  9 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4225 \n",
      "Accuracy: 8798/10000 (87.98%)\n",
      "\n",
      "Round  17, Average loss 0.423 Test accuracy 87.980\n",
      "selected users: [ 0  1  5  8  9 14]\n",
      "\n",
      "Test set: Average loss: 13.0932 \n",
      "Accuracy: 9404/10000 (94.04%)\n",
      "\n",
      "Round  18, Average loss 13.093 Test accuracy 94.040\n",
      "selected users: [ 1  2  6  9 11 12]\n",
      "\n",
      "Test set: Average loss: 0.9690 \n",
      "Accuracy: 7709/10000 (77.09%)\n",
      "\n",
      "Round  19, Average loss 0.969 Test accuracy 77.090\n",
      "selected users: [ 0  4  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 28.9947 \n",
      "Accuracy: 9266/10000 (92.66%)\n",
      "\n",
      "Round  20, Average loss 28.995 Test accuracy 92.660\n",
      "selected users: [ 0  1  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 6.1367 \n",
      "Accuracy: 8856/10000 (88.56%)\n",
      "\n",
      "Round  21, Average loss 6.137 Test accuracy 88.560\n",
      "selected users: [ 0  2  4  6 10 14]\n",
      "\n",
      "Test set: Average loss: 120.3683 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  22, Average loss 120.368 Test accuracy 93.660\n",
      "selected users: [ 0  1  3  7  8 12]\n",
      "\n",
      "Test set: Average loss: 2.1476 \n",
      "Accuracy: 8053/10000 (80.53%)\n",
      "\n",
      "Round  23, Average loss 2.148 Test accuracy 80.530\n",
      "selected users: [ 0  5  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 194.8845 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round  24, Average loss 194.885 Test accuracy 93.430\n",
      "selected users: [ 3  5  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 43.8095 \n",
      "Accuracy: 9295/10000 (92.95%)\n",
      "\n",
      "Round  25, Average loss 43.810 Test accuracy 92.950\n",
      "selected users: [ 1  2  7 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.2658 \n",
      "Accuracy: 1111/10000 (11.11%)\n",
      "\n",
      "Round  26, Average loss 2.266 Test accuracy 11.110\n",
      "selected users: [ 0  1  3  7  8 10]\n",
      "\n",
      "Test set: Average loss: 138.7321 \n",
      "Accuracy: 8789/10000 (87.89%)\n",
      "\n",
      "Round  27, Average loss 138.732 Test accuracy 87.890\n",
      "selected users: [ 1  4  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 83.3597 \n",
      "Accuracy: 9150/10000 (91.50%)\n",
      "\n",
      "Round  28, Average loss 83.360 Test accuracy 91.500\n",
      "selected users: [ 1  5 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 789.0882 \n",
      "Accuracy: 8961/10000 (89.61%)\n",
      "\n",
      "Round  29, Average loss 789.088 Test accuracy 89.610\n",
      "(m= 6 )  3 -th Trial!!\n",
      "selected users: [ 1  2  4  6  9 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  4  5 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  4  5 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8731 \n",
      "Accuracy: 8000/10000 (80.00%)\n",
      "\n",
      "Round   3, Average loss 1.873 Test accuracy 80.000\n",
      "selected users: [ 1  4  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 3.0564 \n",
      "Accuracy: 8547/10000 (85.47%)\n",
      "\n",
      "Round   4, Average loss 3.056 Test accuracy 85.470\n",
      "selected users: [ 2  3  5  7  9 12]\n",
      "\n",
      "Test set: Average loss: 8.0347 \n",
      "Accuracy: 7926/10000 (79.26%)\n",
      "\n",
      "Round   5, Average loss 8.035 Test accuracy 79.260\n",
      "selected users: [ 6  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 28.3948 \n",
      "Accuracy: 8982/10000 (89.82%)\n",
      "\n",
      "Round   6, Average loss 28.395 Test accuracy 89.820\n",
      "selected users: [ 1  5 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 757.2168 \n",
      "Accuracy: 8675/10000 (86.75%)\n",
      "\n",
      "Round   7, Average loss 757.217 Test accuracy 86.750\n",
      "selected users: [ 1  3  7  8  9 12]\n",
      "\n",
      "Test set: Average loss: 24.7316 \n",
      "Accuracy: 8633/10000 (86.33%)\n",
      "\n",
      "Round   8, Average loss 24.732 Test accuracy 86.330\n",
      "selected users: [ 1  2  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2909 \n",
      "Accuracy: 1393/10000 (13.93%)\n",
      "\n",
      "Round   9, Average loss 2.291 Test accuracy 13.930\n",
      "selected users: [ 1  3  4  7  9 14]\n",
      "\n",
      "Test set: Average loss: 2.1963 \n",
      "Accuracy: 2749/10000 (27.49%)\n",
      "\n",
      "Round  10, Average loss 2.196 Test accuracy 27.490\n",
      "selected users: [ 1  4  5 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0943 \n",
      "Accuracy: 8450/10000 (84.50%)\n",
      "\n",
      "Round  11, Average loss 1.094 Test accuracy 84.500\n",
      "selected users: [ 3  6  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.5501 \n",
      "Accuracy: 8585/10000 (85.85%)\n",
      "\n",
      "Round  12, Average loss 0.550 Test accuracy 85.850\n",
      "selected users: [ 0  5  6  7  9 12]\n",
      "\n",
      "Test set: Average loss: 8.2831 \n",
      "Accuracy: 9026/10000 (90.26%)\n",
      "\n",
      "Round  13, Average loss 8.283 Test accuracy 90.260\n",
      "selected users: [ 1  2  4  8  9 12]\n",
      "\n",
      "Test set: Average loss: 3.9143 \n",
      "Accuracy: 8657/10000 (86.57%)\n",
      "\n",
      "Round  14, Average loss 3.914 Test accuracy 86.570\n",
      "selected users: [ 0  3  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1.7266 \n",
      "Accuracy: 5396/10000 (53.96%)\n",
      "\n",
      "Round  15, Average loss 1.727 Test accuracy 53.960\n",
      "selected users: [ 5  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6665 \n",
      "Accuracy: 8740/10000 (87.40%)\n",
      "\n",
      "Round  16, Average loss 1.666 Test accuracy 87.400\n",
      "selected users: [ 0  1  2  9 10 11]\n",
      "\n",
      "Test set: Average loss: 0.7613 \n",
      "Accuracy: 8365/10000 (83.65%)\n",
      "\n",
      "Round  17, Average loss 0.761 Test accuracy 83.650\n",
      "selected users: [ 0  1  2  9 11 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2775 \n",
      "Accuracy: 9233/10000 (92.33%)\n",
      "\n",
      "Round  18, Average loss 0.277 Test accuracy 92.330\n",
      "selected users: [ 3  4  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3066 \n",
      "Accuracy: 9016/10000 (90.16%)\n",
      "\n",
      "Round  19, Average loss 2.307 Test accuracy 90.160\n",
      "selected users: [0 2 4 5 6 9]\n",
      "\n",
      "Test set: Average loss: 6.0558 \n",
      "Accuracy: 9363/10000 (93.63%)\n",
      "\n",
      "Round  20, Average loss 6.056 Test accuracy 93.630\n",
      "selected users: [ 0  1  2  5  9 13]\n",
      "\n",
      "Test set: Average loss: 35.7748 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round  21, Average loss 35.775 Test accuracy 92.380\n",
      "selected users: [ 1  4  5  7 10 14]\n",
      "\n",
      "Test set: Average loss: 172.6942 \n",
      "Accuracy: 9326/10000 (93.26%)\n",
      "\n",
      "Round  22, Average loss 172.694 Test accuracy 93.260\n",
      "selected users: [ 0  2  5  6 10 14]\n",
      "\n",
      "Test set: Average loss: 397.3466 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round  23, Average loss 397.347 Test accuracy 92.490\n",
      "selected users: [0 1 2 3 8 9]\n",
      "\n",
      "Test set: Average loss: 274.7862 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  24, Average loss 274.786 Test accuracy 93.860\n",
      "selected users: [ 0  5  6  9 12 13]\n",
      "\n",
      "Test set: Average loss: 514.3327 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  25, Average loss 514.333 Test accuracy 94.490\n",
      "selected users: [ 1  3  5  8 13 14]\n",
      "\n",
      "Test set: Average loss: 12.8967 \n",
      "Accuracy: 7691/10000 (76.91%)\n",
      "\n",
      "Round  26, Average loss 12.897 Test accuracy 76.910\n",
      "selected users: [ 1  4  5  7 12 13]\n",
      "\n",
      "Test set: Average loss: 10.6491 \n",
      "Accuracy: 8325/10000 (83.25%)\n",
      "\n",
      "Round  27, Average loss 10.649 Test accuracy 83.250\n",
      "selected users: [ 1  3  5  7  8 11]\n",
      "\n",
      "Test set: Average loss: 445.3200 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round  28, Average loss 445.320 Test accuracy 93.710\n",
      "selected users: [ 0  1  4  6 12 14]\n",
      "\n",
      "Test set: Average loss: 54.0873 \n",
      "Accuracy: 9292/10000 (92.92%)\n",
      "\n",
      "Round  29, Average loss 54.087 Test accuracy 92.920\n",
      "(m= 6 )  4 -th Trial!!\n",
      "selected users: [ 2  6  7  8  9 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  5 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2994 \n",
      "Accuracy: 1044/10000 (10.44%)\n",
      "\n",
      "Round   1, Average loss 2.299 Test accuracy 10.440\n",
      "selected users: [ 1  2  6  7 12 13]\n",
      "\n",
      "Test set: Average loss: 1.4923 \n",
      "Accuracy: 8285/10000 (82.85%)\n",
      "\n",
      "Round   2, Average loss 1.492 Test accuracy 82.850\n",
      "selected users: [0 1 2 4 8 9]\n",
      "\n",
      "Test set: Average loss: 12.7668 \n",
      "Accuracy: 9079/10000 (90.79%)\n",
      "\n",
      "Round   3, Average loss 12.767 Test accuracy 90.790\n",
      "selected users: [ 5  6  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 192.9149 \n",
      "Accuracy: 9182/10000 (91.82%)\n",
      "\n",
      "Round   4, Average loss 192.915 Test accuracy 91.820\n",
      "selected users: [ 0  3  4  6 11 12]\n",
      "\n",
      "Test set: Average loss: 91.5217 \n",
      "Accuracy: 9448/10000 (94.48%)\n",
      "\n",
      "Round   5, Average loss 91.522 Test accuracy 94.480\n",
      "selected users: [ 1  4  6  8 10 14]\n",
      "\n",
      "Test set: Average loss: 419.8525 \n",
      "Accuracy: 9421/10000 (94.21%)\n",
      "\n",
      "Round   6, Average loss 419.853 Test accuracy 94.210\n",
      "selected users: [ 3  4  6  8 12 13]\n",
      "\n",
      "Test set: Average loss: 17.4766 \n",
      "Accuracy: 8969/10000 (89.69%)\n",
      "\n",
      "Round   7, Average loss 17.477 Test accuracy 89.690\n",
      "selected users: [0 1 3 5 6 9]\n",
      "\n",
      "Test set: Average loss: 504.4722 \n",
      "Accuracy: 9429/10000 (94.29%)\n",
      "\n",
      "Round   8, Average loss 504.472 Test accuracy 94.290\n",
      "selected users: [ 1  3  6  7  9 14]\n",
      "\n",
      "Test set: Average loss: 498.2055 \n",
      "Accuracy: 9522/10000 (95.22%)\n",
      "\n",
      "Round   9, Average loss 498.205 Test accuracy 95.220\n",
      "selected users: [ 1  2  3  5  9 14]\n",
      "\n",
      "Test set: Average loss: 1462.2485 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  10, Average loss 1462.248 Test accuracy 94.360\n",
      "selected users: [ 3  4  5  6  9 10]\n",
      "\n",
      "Test set: Average loss: 3957.4525 \n",
      "Accuracy: 9282/10000 (92.82%)\n",
      "\n",
      "Round  11, Average loss 3957.452 Test accuracy 92.820\n",
      "selected users: [ 1  3  5  6 10 14]\n",
      "\n",
      "Test set: Average loss: 4612.9049 \n",
      "Accuracy: 9342/10000 (93.42%)\n",
      "\n",
      "Round  12, Average loss 4612.905 Test accuracy 93.420\n",
      "selected users: [ 0  1  5  6  7 10]\n",
      "\n",
      "Test set: Average loss: 8814.5518 \n",
      "Accuracy: 9233/10000 (92.33%)\n",
      "\n",
      "Round  13, Average loss 8814.552 Test accuracy 92.330\n",
      "selected users: [ 4  5  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 9197.9840 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  14, Average loss 9197.984 Test accuracy 93.380\n",
      "selected users: [ 1  4  5  7 10 12]\n",
      "\n",
      "Test set: Average loss: 6713.3813 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round  15, Average loss 6713.381 Test accuracy 93.760\n",
      "selected users: [ 0  4  6 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10086.5728 \n",
      "Accuracy: 9413/10000 (94.13%)\n",
      "\n",
      "Round  16, Average loss 10086.573 Test accuracy 94.130\n",
      "selected users: [ 1  5  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 5770.8306 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round  17, Average loss 5770.831 Test accuracy 93.510\n",
      "selected users: [ 0  1  3  5  8 10]\n",
      "\n",
      "Test set: Average loss: 23081.1005 \n",
      "Accuracy: 9206/10000 (92.06%)\n",
      "\n",
      "Round  18, Average loss 23081.101 Test accuracy 92.060\n",
      "selected users: [ 0  1  3  4  5 12]\n",
      "\n",
      "Test set: Average loss: 13580.5454 \n",
      "Accuracy: 9313/10000 (93.13%)\n",
      "\n",
      "Round  19, Average loss 13580.545 Test accuracy 93.130\n",
      "selected users: [ 2  5  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 10135.7177 \n",
      "Accuracy: 9309/10000 (93.09%)\n",
      "\n",
      "Round  20, Average loss 10135.718 Test accuracy 93.090\n",
      "selected users: [ 1  4  6 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12484.3450 \n",
      "Accuracy: 9413/10000 (94.13%)\n",
      "\n",
      "Round  21, Average loss 12484.345 Test accuracy 94.130\n",
      "selected users: [ 4  7  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 13595.9196 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  22, Average loss 13595.920 Test accuracy 93.990\n",
      "selected users: [ 2  3  5 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16259.6554 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  23, Average loss 16259.655 Test accuracy 93.660\n",
      "selected users: [ 1  3  6 10 12 13]\n",
      "\n",
      "Test set: Average loss: 14657.2475 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round  24, Average loss 14657.247 Test accuracy 93.760\n",
      "selected users: [ 0  2  3  4  9 14]\n",
      "\n",
      "Test set: Average loss: 25866.7418 \n",
      "Accuracy: 9390/10000 (93.90%)\n",
      "\n",
      "Round  25, Average loss 25866.742 Test accuracy 93.900\n",
      "selected users: [ 3  6  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 12276.2421 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  26, Average loss 12276.242 Test accuracy 94.790\n",
      "selected users: [ 0  2  3  5 11 12]\n",
      "\n",
      "Test set: Average loss: 33188.6741 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round  27, Average loss 33188.674 Test accuracy 93.110\n",
      "selected users: [ 4  5  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 25642.9444 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round  28, Average loss 25642.944 Test accuracy 93.960\n",
      "selected users: [ 1  2  5  7 10 11]\n",
      "\n",
      "Test set: Average loss: 22163.8217 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  29, Average loss 22163.822 Test accuracy 94.300\n",
      "(m= 6 )  5 -th Trial!!\n",
      "selected users: [ 3  4  5  7 10 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  4  5  8 12]\n",
      "\n",
      "Test set: Average loss: 2.2639 \n",
      "Accuracy: 3997/10000 (39.97%)\n",
      "\n",
      "Round   1, Average loss 2.264 Test accuracy 39.970\n",
      "selected users: [ 0  5  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 15.3991 \n",
      "Accuracy: 8825/10000 (88.25%)\n",
      "\n",
      "Round   2, Average loss 15.399 Test accuracy 88.250\n",
      "selected users: [ 3  4 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 321.4677 \n",
      "Accuracy: 8891/10000 (88.91%)\n",
      "\n",
      "Round   3, Average loss 321.468 Test accuracy 88.910\n",
      "selected users: [ 0  1  6  9 11 14]\n",
      "\n",
      "Test set: Average loss: 81.8452 \n",
      "Accuracy: 9389/10000 (93.89%)\n",
      "\n",
      "Round   4, Average loss 81.845 Test accuracy 93.890\n",
      "selected users: [ 1  3  5  6  7 14]\n",
      "\n",
      "Test set: Average loss: 125.9850 \n",
      "Accuracy: 9341/10000 (93.41%)\n",
      "\n",
      "Round   5, Average loss 125.985 Test accuracy 93.410\n",
      "selected users: [ 0  1  4  5  8 12]\n",
      "\n",
      "Test set: Average loss: 52.0324 \n",
      "Accuracy: 9214/10000 (92.14%)\n",
      "\n",
      "Round   6, Average loss 52.032 Test accuracy 92.140\n",
      "selected users: [ 0  2  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 14.4813 \n",
      "Accuracy: 3736/10000 (37.36%)\n",
      "\n",
      "Round   7, Average loss 14.481 Test accuracy 37.360\n",
      "selected users: [ 0  5  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 412.4632 \n",
      "Accuracy: 8733/10000 (87.33%)\n",
      "\n",
      "Round   8, Average loss 412.463 Test accuracy 87.330\n",
      "selected users: [ 0  1  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 18.5410 \n",
      "Accuracy: 8406/10000 (84.06%)\n",
      "\n",
      "Round   9, Average loss 18.541 Test accuracy 84.060\n",
      "selected users: [ 1  2  3  6 11 13]\n",
      "\n",
      "Test set: Average loss: 105.0877 \n",
      "Accuracy: 9419/10000 (94.19%)\n",
      "\n",
      "Round  10, Average loss 105.088 Test accuracy 94.190\n",
      "selected users: [ 2  4  9 11 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 270.7898 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  11, Average loss 270.790 Test accuracy 94.510\n",
      "selected users: [ 0  2  3  7 12 14]\n",
      "\n",
      "Test set: Average loss: 18.5153 \n",
      "Accuracy: 8923/10000 (89.23%)\n",
      "\n",
      "Round  12, Average loss 18.515 Test accuracy 89.230\n",
      "selected users: [ 0  4  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 423.7074 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  13, Average loss 423.707 Test accuracy 94.300\n",
      "selected users: [ 0  2  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 8.0694 \n",
      "Accuracy: 3478/10000 (34.78%)\n",
      "\n",
      "Round  14, Average loss 8.069 Test accuracy 34.780\n",
      "selected users: [ 1  4  5  8 10 12]\n",
      "\n",
      "Test set: Average loss: 5.2885 \n",
      "Accuracy: 6577/10000 (65.77%)\n",
      "\n",
      "Round  15, Average loss 5.289 Test accuracy 65.770\n",
      "selected users: [ 0  1  5  7  8 12]\n",
      "\n",
      "Test set: Average loss: 16.8365 \n",
      "Accuracy: 7482/10000 (74.82%)\n",
      "\n",
      "Round  16, Average loss 16.836 Test accuracy 74.820\n",
      "selected users: [ 0  1  6  9 11 13]\n",
      "\n",
      "Test set: Average loss: 28.4078 \n",
      "Accuracy: 7509/10000 (75.09%)\n",
      "\n",
      "Round  17, Average loss 28.408 Test accuracy 75.090\n",
      "selected users: [ 1  2  3 10 12 13]\n",
      "\n",
      "Test set: Average loss: 114.4400 \n",
      "Accuracy: 9146/10000 (91.46%)\n",
      "\n",
      "Round  18, Average loss 114.440 Test accuracy 91.460\n",
      "selected users: [0 1 3 4 5 7]\n",
      "\n",
      "Test set: Average loss: 107.3272 \n",
      "Accuracy: 2035/10000 (20.35%)\n",
      "\n",
      "Round  19, Average loss 107.327 Test accuracy 20.350\n",
      "selected users: [ 1  3  5  6 13 14]\n",
      "\n",
      "Test set: Average loss: 6.7693 \n",
      "Accuracy: 1867/10000 (18.67%)\n",
      "\n",
      "Round  20, Average loss 6.769 Test accuracy 18.670\n",
      "selected users: [ 0  3  5  7 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4  5  7 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  4  5  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  6  7  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  5  6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  28, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "(m= 6 )  6 -th Trial!!\n",
      "selected users: [ 0  3  4 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2886 \n",
      "Accuracy: 2412/10000 (24.12%)\n",
      "\n",
      "Round   1, Average loss 2.289 Test accuracy 24.120\n",
      "selected users: [ 6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3276 \n",
      "Accuracy: 8989/10000 (89.89%)\n",
      "\n",
      "Round   2, Average loss 0.328 Test accuracy 89.890\n",
      "selected users: [ 0  6  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 16.1542 \n",
      "Accuracy: 9378/10000 (93.78%)\n",
      "\n",
      "Round   3, Average loss 16.154 Test accuracy 93.780\n",
      "selected users: [ 1  6  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 9.1086 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round   4, Average loss 9.109 Test accuracy 94.820\n",
      "selected users: [ 1  3  6  7 10 13]\n",
      "\n",
      "Test set: Average loss: 25.4952 \n",
      "Accuracy: 9284/10000 (92.84%)\n",
      "\n",
      "Round   5, Average loss 25.495 Test accuracy 92.840\n",
      "selected users: [ 0  1  2  3  5 11]\n",
      "\n",
      "Test set: Average loss: 382.6872 \n",
      "Accuracy: 9306/10000 (93.06%)\n",
      "\n",
      "Round   6, Average loss 382.687 Test accuracy 93.060\n",
      "selected users: [ 1  2  4  6  7 11]\n",
      "\n",
      "Test set: Average loss: 723.6773 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round   7, Average loss 723.677 Test accuracy 93.540\n",
      "selected users: [ 1  3  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 360.8423 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round   8, Average loss 360.842 Test accuracy 93.990\n",
      "selected users: [ 5  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 1290.9759 \n",
      "Accuracy: 9098/10000 (90.98%)\n",
      "\n",
      "Round   9, Average loss 1290.976 Test accuracy 90.980\n",
      "selected users: [ 0  2  7  8 11 14]\n",
      "\n",
      "Test set: Average loss: 81.2505 \n",
      "Accuracy: 8708/10000 (87.08%)\n",
      "\n",
      "Round  10, Average loss 81.250 Test accuracy 87.080\n",
      "selected users: [ 0  4  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 947.9738 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round  11, Average loss 947.974 Test accuracy 92.910\n",
      "selected users: [ 2  3  4  5  9 10]\n",
      "\n",
      "Test set: Average loss: 7005.3265 \n",
      "Accuracy: 8953/10000 (89.53%)\n",
      "\n",
      "Round  12, Average loss 7005.326 Test accuracy 89.530\n",
      "selected users: [ 0  1  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 24.5432 \n",
      "Accuracy: 2257/10000 (22.57%)\n",
      "\n",
      "Round  13, Average loss 24.543 Test accuracy 22.570\n",
      "selected users: [ 4  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3013 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  14, Average loss 2.301 Test accuracy 11.350\n",
      "selected users: [ 2  6  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3012 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  15, Average loss 2.301 Test accuracy 11.350\n",
      "selected users: [ 0  4  5  7  9 10]\n",
      "\n",
      "Test set: Average loss: 1.8373 \n",
      "Accuracy: 3265/10000 (32.65%)\n",
      "\n",
      "Round  16, Average loss 1.837 Test accuracy 32.650\n",
      "selected users: [ 0  5  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 1.8101 \n",
      "Accuracy: 3140/10000 (31.40%)\n",
      "\n",
      "Round  17, Average loss 1.810 Test accuracy 31.400\n",
      "selected users: [ 0  2  3  4 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2624 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.262 Test accuracy 9.800\n",
      "selected users: [ 3  5  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  4  6 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  3  6  8 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  5  6  7  9 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [1 2 3 5 8 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4  5 11 13]\n",
      "\n",
      "Test set: Average loss: 2.2452 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.245 Test accuracy 9.800\n",
      "selected users: [ 1  3  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  4  7 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7122 \n",
      "Accuracy: 5805/10000 (58.05%)\n",
      "\n",
      "Round  27, Average loss 1.712 Test accuracy 58.050\n",
      "selected users: [2 3 4 5 7 9]\n",
      "\n",
      "Test set: Average loss: 10.0032 \n",
      "Accuracy: 8785/10000 (87.85%)\n",
      "\n",
      "Round  28, Average loss 10.003 Test accuracy 87.850\n",
      "selected users: [ 1  2  3 11 12 14]\n",
      "\n",
      "Test set: Average loss: 19.7698 \n",
      "Accuracy: 9413/10000 (94.13%)\n",
      "\n",
      "Round  29, Average loss 19.770 Test accuracy 94.130\n",
      "(m= 6 )  7 -th Trial!!\n",
      "selected users: [ 0  1  5  8 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  5  7  8 11]\n",
      "\n",
      "Test set: Average loss: 2.0057 \n",
      "Accuracy: 4731/10000 (47.31%)\n",
      "\n",
      "Round   1, Average loss 2.006 Test accuracy 47.310\n",
      "selected users: [ 1  4  5  6 11 12]\n",
      "\n",
      "Test set: Average loss: 2.2297 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round   2, Average loss 2.230 Test accuracy 93.760\n",
      "selected users: [ 1  5  6  8  9 10]\n",
      "\n",
      "Test set: Average loss: 150.7829 \n",
      "Accuracy: 9020/10000 (90.20%)\n",
      "\n",
      "Round   3, Average loss 150.783 Test accuracy 90.200\n",
      "selected users: [ 1  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 42.2723 \n",
      "Accuracy: 9306/10000 (93.06%)\n",
      "\n",
      "Round   4, Average loss 42.272 Test accuracy 93.060\n",
      "selected users: [ 2  5  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 84.5183 \n",
      "Accuracy: 9181/10000 (91.81%)\n",
      "\n",
      "Round   5, Average loss 84.518 Test accuracy 91.810\n",
      "selected users: [ 1  5  6 10 11 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 562.6416 \n",
      "Accuracy: 9349/10000 (93.49%)\n",
      "\n",
      "Round   6, Average loss 562.642 Test accuracy 93.490\n",
      "selected users: [ 2  5  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 697.0615 \n",
      "Accuracy: 9322/10000 (93.22%)\n",
      "\n",
      "Round   7, Average loss 697.062 Test accuracy 93.220\n",
      "selected users: [ 2  4  6  8  9 12]\n",
      "\n",
      "Test set: Average loss: 185.9890 \n",
      "Accuracy: 9362/10000 (93.62%)\n",
      "\n",
      "Round   8, Average loss 185.989 Test accuracy 93.620\n",
      "selected users: [ 0  2  3  4  9 11]\n",
      "\n",
      "Test set: Average loss: 2090.0213 \n",
      "Accuracy: 9341/10000 (93.41%)\n",
      "\n",
      "Round   9, Average loss 2090.021 Test accuracy 93.410\n",
      "selected users: [ 1  6  7  8 12 13]\n",
      "\n",
      "Test set: Average loss: 923.2736 \n",
      "Accuracy: 9440/10000 (94.40%)\n",
      "\n",
      "Round  10, Average loss 923.274 Test accuracy 94.400\n",
      "selected users: [ 2  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 418.7234 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round  11, Average loss 418.723 Test accuracy 93.750\n",
      "selected users: [ 1  4  7  9 11 14]\n",
      "\n",
      "Test set: Average loss: 2165.0066 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round  12, Average loss 2165.007 Test accuracy 94.200\n",
      "selected users: [ 2  5  6  7 11 13]\n",
      "\n",
      "Test set: Average loss: 1501.6437 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round  13, Average loss 1501.644 Test accuracy 93.710\n",
      "selected users: [ 4  5  6  8 11 12]\n",
      "\n",
      "Test set: Average loss: 1861.7495 \n",
      "Accuracy: 9434/10000 (94.34%)\n",
      "\n",
      "Round  14, Average loss 1861.749 Test accuracy 94.340\n",
      "selected users: [ 4  5  7  8  9 14]\n",
      "\n",
      "Test set: Average loss: 4657.9818 \n",
      "Accuracy: 9412/10000 (94.12%)\n",
      "\n",
      "Round  15, Average loss 4657.982 Test accuracy 94.120\n",
      "selected users: [ 0  1  2  9 10 13]\n",
      "\n",
      "Test set: Average loss: 1171.4945 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  16, Average loss 1171.495 Test accuracy 94.790\n",
      "selected users: [ 0  5  6  8 12 14]\n",
      "\n",
      "Test set: Average loss: 2437.3178 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round  17, Average loss 2437.318 Test accuracy 93.600\n",
      "selected users: [ 2  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1516.8103 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  18, Average loss 1516.810 Test accuracy 94.110\n",
      "selected users: [ 0  4  5  9 10 11]\n",
      "\n",
      "Test set: Average loss: 8579.3809 \n",
      "Accuracy: 9416/10000 (94.16%)\n",
      "\n",
      "Round  19, Average loss 8579.381 Test accuracy 94.160\n",
      "selected users: [ 0  1  5  7 11 13]\n",
      "\n",
      "Test set: Average loss: 7823.6129 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  20, Average loss 7823.613 Test accuracy 94.410\n",
      "selected users: [ 0  3  5  8 11 13]\n",
      "\n",
      "Test set: Average loss: 6065.2165 \n",
      "Accuracy: 9413/10000 (94.13%)\n",
      "\n",
      "Round  21, Average loss 6065.216 Test accuracy 94.130\n",
      "selected users: [ 2  3  5  6  7 14]\n",
      "\n",
      "Test set: Average loss: 5443.4105 \n",
      "Accuracy: 9412/10000 (94.12%)\n",
      "\n",
      "Round  22, Average loss 5443.411 Test accuracy 94.120\n",
      "selected users: [ 0  4  6  8 10 11]\n",
      "\n",
      "Test set: Average loss: 11503.8441 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  23, Average loss 11503.844 Test accuracy 94.360\n",
      "selected users: [ 5  6  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 18193.1855 \n",
      "Accuracy: 9230/10000 (92.30%)\n",
      "\n",
      "Round  24, Average loss 18193.186 Test accuracy 92.300\n",
      "selected users: [ 2  4  5  6  8 14]\n",
      "\n",
      "Test set: Average loss: 10720.3585 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round  25, Average loss 10720.359 Test accuracy 94.090\n",
      "selected users: [ 1  5  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 17688.2649 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round  26, Average loss 17688.265 Test accuracy 93.370\n",
      "selected users: [ 5  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 28356.7212 \n",
      "Accuracy: 9288/10000 (92.88%)\n",
      "\n",
      "Round  27, Average loss 28356.721 Test accuracy 92.880\n",
      "selected users: [ 0  2  5  7  8 13]\n",
      "\n",
      "Test set: Average loss: 17847.3437 \n",
      "Accuracy: 9300/10000 (93.00%)\n",
      "\n",
      "Round  28, Average loss 17847.344 Test accuracy 93.000\n",
      "selected users: [ 1  5  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 37370.7517 \n",
      "Accuracy: 9285/10000 (92.85%)\n",
      "\n",
      "Round  29, Average loss 37370.752 Test accuracy 92.850\n",
      "(m= 6 )  8 -th Trial!!\n",
      "selected users: [ 0  1  2  6  7 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4  7 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.0371 \n",
      "Accuracy: 2997/10000 (29.97%)\n",
      "\n",
      "Round   1, Average loss 2.037 Test accuracy 29.970\n",
      "selected users: [ 3  6  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5126 \n",
      "Accuracy: 9362/10000 (93.62%)\n",
      "\n",
      "Round   2, Average loss 0.513 Test accuracy 93.620\n",
      "selected users: [ 1  2  4  5  7 14]\n",
      "\n",
      "Test set: Average loss: 5.3863 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round   3, Average loss 5.386 Test accuracy 95.380\n",
      "selected users: [ 0  6  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 68.2242 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round   4, Average loss 68.224 Test accuracy 94.960\n",
      "selected users: [ 3  4  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 4.3706 \n",
      "Accuracy: 9071/10000 (90.71%)\n",
      "\n",
      "Round   5, Average loss 4.371 Test accuracy 90.710\n",
      "selected users: [ 3  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 1.4507 \n",
      "Accuracy: 5287/10000 (52.87%)\n",
      "\n",
      "Round   6, Average loss 1.451 Test accuracy 52.870\n",
      "selected users: [ 0  3  6  9 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7454 \n",
      "Accuracy: 9285/10000 (92.85%)\n",
      "\n",
      "Round   7, Average loss 4.745 Test accuracy 92.850\n",
      "selected users: [ 0  1  2  6  7 12]\n",
      "\n",
      "Test set: Average loss: 1.4113 \n",
      "Accuracy: 5597/10000 (55.97%)\n",
      "\n",
      "Round   8, Average loss 1.411 Test accuracy 55.970\n",
      "selected users: [ 2  4  5  6  8 10]\n",
      "\n",
      "Test set: Average loss: 144.0080 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round   9, Average loss 144.008 Test accuracy 92.210\n",
      "selected users: [ 6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 270.3197 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round  10, Average loss 270.320 Test accuracy 94.090\n",
      "selected users: [ 2  4  5  7 11 12]\n",
      "\n",
      "Test set: Average loss: 45.0290 \n",
      "Accuracy: 9357/10000 (93.57%)\n",
      "\n",
      "Round  11, Average loss 45.029 Test accuracy 93.570\n",
      "selected users: [ 0  1  4  5  6 11]\n",
      "\n",
      "Test set: Average loss: 561.6492 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  12, Average loss 561.649 Test accuracy 94.990\n",
      "selected users: [ 0  3  4  5 10 13]\n",
      "\n",
      "Test set: Average loss: 1310.9439 \n",
      "Accuracy: 9285/10000 (92.85%)\n",
      "\n",
      "Round  13, Average loss 1310.944 Test accuracy 92.850\n",
      "selected users: [ 0  5  6  8 10 13]\n",
      "\n",
      "Test set: Average loss: 1500.4382 \n",
      "Accuracy: 9325/10000 (93.25%)\n",
      "\n",
      "Round  14, Average loss 1500.438 Test accuracy 93.250\n",
      "selected users: [ 0  1  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 78.8560 \n",
      "Accuracy: 2165/10000 (21.65%)\n",
      "\n",
      "Round  15, Average loss 78.856 Test accuracy 21.650\n",
      "selected users: [0 1 2 3 6 7]\n",
      "\n",
      "Test set: Average loss: 3.4236 \n",
      "Accuracy: 990/10000 (9.90%)\n",
      "\n",
      "Round  16, Average loss 3.424 Test accuracy 9.900\n",
      "selected users: [ 0  4  5  7  8 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  17, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  5  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  18, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  19, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  6  8 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  20, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  4  8 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  21, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [1 3 4 5 7 8]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  22, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  4  5  7  8 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  23, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  4  5  9 10 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  24, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  4  5  9 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  25, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4  9 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  26, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  6  7 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  27, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 7.1985 \n",
      "Accuracy: 1848/10000 (18.48%)\n",
      "\n",
      "Round  28, Average loss 7.199 Test accuracy 18.480\n",
      "selected users: [ 1  2  6  9 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  29, Average loss 2.303 Test accuracy 9.800\n",
      "(m= 6 )  9 -th Trial!!\n",
      "selected users: [1 2 5 6 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0102 \n",
      "Accuracy: 2620/10000 (26.20%)\n",
      "\n",
      "Round   0, Average loss 2.010 Test accuracy 26.200\n",
      "selected users: [ 5  6  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  4  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 2.1498 \n",
      "Accuracy: 1841/10000 (18.41%)\n",
      "\n",
      "Round   2, Average loss 2.150 Test accuracy 18.410\n",
      "selected users: [ 1  2  4  8 11 14]\n",
      "\n",
      "Test set: Average loss: 1.1384 \n",
      "Accuracy: 7014/10000 (70.14%)\n",
      "\n",
      "Round   3, Average loss 1.138 Test accuracy 70.140\n",
      "selected users: [ 0  4  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.6016 \n",
      "Accuracy: 3949/10000 (39.49%)\n",
      "\n",
      "Round   4, Average loss 1.602 Test accuracy 39.490\n",
      "selected users: [ 0  1  6  8  9 14]\n",
      "\n",
      "Test set: Average loss: 1.8277 \n",
      "Accuracy: 3196/10000 (31.96%)\n",
      "\n",
      "Round   5, Average loss 1.828 Test accuracy 31.960\n",
      "selected users: [ 3  4  6  9 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   6, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  4  8 11 14]\n",
      "\n",
      "Test set: Average loss: 2.1094 \n",
      "Accuracy: 4393/10000 (43.93%)\n",
      "\n",
      "Round   7, Average loss 2.109 Test accuracy 43.930\n",
      "selected users: [ 2  4  6  9 10 12]\n",
      "\n",
      "Test set: Average loss: 2.2821 \n",
      "Accuracy: 1071/10000 (10.71%)\n",
      "\n",
      "Round   8, Average loss 2.282 Test accuracy 10.710\n",
      "selected users: [ 0  2  5  7 10 14]\n",
      "\n",
      "Test set: Average loss: 2.0468 \n",
      "Accuracy: 1960/10000 (19.60%)\n",
      "\n",
      "Round   9, Average loss 2.047 Test accuracy 19.600\n",
      "selected users: [ 1  2  4  8 10 14]\n",
      "\n",
      "Test set: Average loss: 2.6808 \n",
      "Accuracy: 4232/10000 (42.32%)\n",
      "\n",
      "Round  10, Average loss 2.681 Test accuracy 42.320\n",
      "selected users: [ 2  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  11, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  5  8 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  12, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  5  9 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  13, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  14, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  4  5 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.7127 \n",
      "Accuracy: 3460/10000 (34.60%)\n",
      "\n",
      "Round  15, Average loss 1.713 Test accuracy 34.600\n",
      "selected users: [ 0  1  2  6  9 14]\n",
      "\n",
      "Test set: Average loss: 0.5200 \n",
      "Accuracy: 8535/10000 (85.35%)\n",
      "\n",
      "Round  16, Average loss 0.520 Test accuracy 85.350\n",
      "selected users: [ 6  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3322 \n",
      "Accuracy: 9440/10000 (94.40%)\n",
      "\n",
      "Round  17, Average loss 0.332 Test accuracy 94.400\n",
      "selected users: [ 0  2  4  6 10 14]\n",
      "\n",
      "Test set: Average loss: 12.2760 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  18, Average loss 12.276 Test accuracy 93.860\n",
      "selected users: [ 2  3  5  7  8 12]\n",
      "\n",
      "Test set: Average loss: 4.8189 \n",
      "Accuracy: 7698/10000 (76.98%)\n",
      "\n",
      "Round  19, Average loss 4.819 Test accuracy 76.980\n",
      "selected users: [ 1  5  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 47.0304 \n",
      "Accuracy: 9098/10000 (90.98%)\n",
      "\n",
      "Round  20, Average loss 47.030 Test accuracy 90.980\n",
      "selected users: [ 0  2  4  7  8 12]\n",
      "\n",
      "Test set: Average loss: 29.3748 \n",
      "Accuracy: 9102/10000 (91.02%)\n",
      "\n",
      "Round  21, Average loss 29.375 Test accuracy 91.020\n",
      "selected users: [ 1  4  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 81.8624 \n",
      "Accuracy: 9320/10000 (93.20%)\n",
      "\n",
      "Round  22, Average loss 81.862 Test accuracy 93.200\n",
      "selected users: [ 2  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 25.6467 \n",
      "Accuracy: 8790/10000 (87.90%)\n",
      "\n",
      "Round  23, Average loss 25.647 Test accuracy 87.900\n",
      "selected users: [ 1  3  4  8 12 14]\n",
      "\n",
      "Test set: Average loss: 62.1854 \n",
      "Accuracy: 9267/10000 (92.67%)\n",
      "\n",
      "Round  24, Average loss 62.185 Test accuracy 92.670\n",
      "selected users: [ 2  4  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 120.3755 \n",
      "Accuracy: 9275/10000 (92.75%)\n",
      "\n",
      "Round  25, Average loss 120.375 Test accuracy 92.750\n",
      "selected users: [ 4  5  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 387.7945 \n",
      "Accuracy: 9287/10000 (92.87%)\n",
      "\n",
      "Round  26, Average loss 387.794 Test accuracy 92.870\n",
      "selected users: [ 0  5  6  7  8 13]\n",
      "\n",
      "Test set: Average loss: 533.0459 \n",
      "Accuracy: 9224/10000 (92.24%)\n",
      "\n",
      "Round  27, Average loss 533.046 Test accuracy 92.240\n",
      "selected users: [ 0  1  3  5  7 14]\n",
      "\n",
      "Test set: Average loss: 556.2243 \n",
      "Accuracy: 9364/10000 (93.64%)\n",
      "\n",
      "Round  28, Average loss 556.224 Test accuracy 93.640\n",
      "selected users: [ 3  4  6  7  8 14]\n",
      "\n",
      "Test set: Average loss: 306.3608 \n",
      "Accuracy: 9419/10000 (94.19%)\n",
      "\n",
      "Round  29, Average loss 306.361 Test accuracy 94.190\n",
      "number of results: 7\n",
      "(m= 7 )  0 -th Trial!!\n",
      "selected users: [ 0  2  4  5  8  9 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.0665 \n",
      "Accuracy: 3793/10000 (37.93%)\n",
      "\n",
      "Round   1, Average loss 2.067 Test accuracy 37.930\n",
      "selected users: [ 0  3  4  5  6 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9568 \n",
      "Accuracy: 9123/10000 (91.23%)\n",
      "\n",
      "Round   2, Average loss 1.957 Test accuracy 91.230\n",
      "selected users: [ 1  2  6  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 2.0178 \n",
      "Accuracy: 9407/10000 (94.07%)\n",
      "\n",
      "Round   3, Average loss 2.018 Test accuracy 94.070\n",
      "selected users: [ 0  2  3  4  6  8 12]\n",
      "\n",
      "Test set: Average loss: 2.7880 \n",
      "Accuracy: 9031/10000 (90.31%)\n",
      "\n",
      "Round   4, Average loss 2.788 Test accuracy 90.310\n",
      "selected users: [ 0  4  5  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 47.8922 \n",
      "Accuracy: 9212/10000 (92.12%)\n",
      "\n",
      "Round   5, Average loss 47.892 Test accuracy 92.120\n",
      "selected users: [ 1  2  4  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 27.4373 \n",
      "Accuracy: 9309/10000 (93.09%)\n",
      "\n",
      "Round   6, Average loss 27.437 Test accuracy 93.090\n",
      "selected users: [ 0  1  2  4  8  9 13]\n",
      "\n",
      "Test set: Average loss: 16.7032 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round   7, Average loss 16.703 Test accuracy 93.980\n",
      "selected users: [ 0  1  6  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 30.1875 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round   8, Average loss 30.188 Test accuracy 95.310\n",
      "selected users: [ 1  2  6  7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 13.1396 \n",
      "Accuracy: 9201/10000 (92.01%)\n",
      "\n",
      "Round   9, Average loss 13.140 Test accuracy 92.010\n",
      "selected users: [ 2  3  5  6 11 12 13]\n",
      "\n",
      "Test set: Average loss: 52.9895 \n",
      "Accuracy: 9326/10000 (93.26%)\n",
      "\n",
      "Round  10, Average loss 52.990 Test accuracy 93.260\n",
      "selected users: [ 1  2  5  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 71.3049 \n",
      "Accuracy: 9177/10000 (91.77%)\n",
      "\n",
      "Round  11, Average loss 71.305 Test accuracy 91.770\n",
      "selected users: [ 2  4  6  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 91.6976 \n",
      "Accuracy: 9202/10000 (92.02%)\n",
      "\n",
      "Round  12, Average loss 91.698 Test accuracy 92.020\n",
      "selected users: [ 0  5  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 318.1294 \n",
      "Accuracy: 9255/10000 (92.55%)\n",
      "\n",
      "Round  13, Average loss 318.129 Test accuracy 92.550\n",
      "selected users: [ 0  2  3  4  6 13 14]\n",
      "\n",
      "Test set: Average loss: 46.5358 \n",
      "Accuracy: 9139/10000 (91.39%)\n",
      "\n",
      "Round  14, Average loss 46.536 Test accuracy 91.390\n",
      "selected users: [ 3  5  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 30.2486 \n",
      "Accuracy: 8988/10000 (89.88%)\n",
      "\n",
      "Round  15, Average loss 30.249 Test accuracy 89.880\n",
      "selected users: [ 5  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 678.4883 \n",
      "Accuracy: 9186/10000 (91.86%)\n",
      "\n",
      "Round  16, Average loss 678.488 Test accuracy 91.860\n",
      "selected users: [ 1  2  3  7  8 11 14]\n",
      "\n",
      "Test set: Average loss: 295.7240 \n",
      "Accuracy: 9364/10000 (93.64%)\n",
      "\n",
      "Round  17, Average loss 295.724 Test accuracy 93.640\n",
      "selected users: [ 0  4  6  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 376.3119 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round  18, Average loss 376.312 Test accuracy 92.910\n",
      "selected users: [ 4  5  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 241.5425 \n",
      "Accuracy: 9300/10000 (93.00%)\n",
      "\n",
      "Round  19, Average loss 241.542 Test accuracy 93.000\n",
      "selected users: [ 0  1  2  5  8 10 13]\n",
      "\n",
      "Test set: Average loss: 260.9227 \n",
      "Accuracy: 9160/10000 (91.60%)\n",
      "\n",
      "Round  20, Average loss 260.923 Test accuracy 91.600\n",
      "selected users: [ 0  1  2  6 10 12 14]\n",
      "\n",
      "Test set: Average loss: 406.1875 \n",
      "Accuracy: 9306/10000 (93.06%)\n",
      "\n",
      "Round  21, Average loss 406.187 Test accuracy 93.060\n",
      "selected users: [ 3  5  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 210.7336 \n",
      "Accuracy: 9124/10000 (91.24%)\n",
      "\n",
      "Round  22, Average loss 210.734 Test accuracy 91.240\n",
      "selected users: [ 1  6  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 400.2306 \n",
      "Accuracy: 9421/10000 (94.21%)\n",
      "\n",
      "Round  23, Average loss 400.231 Test accuracy 94.210\n",
      "selected users: [ 2  3  4  6  8 10 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 115.4048 \n",
      "Accuracy: 9172/10000 (91.72%)\n",
      "\n",
      "Round  24, Average loss 115.405 Test accuracy 91.720\n",
      "selected users: [ 1  4  6  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 508.1647 \n",
      "Accuracy: 9364/10000 (93.64%)\n",
      "\n",
      "Round  25, Average loss 508.165 Test accuracy 93.640\n",
      "selected users: [ 5  6  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 821.0079 \n",
      "Accuracy: 9146/10000 (91.46%)\n",
      "\n",
      "Round  26, Average loss 821.008 Test accuracy 91.460\n",
      "selected users: [ 0  3  5  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 437.6991 \n",
      "Accuracy: 9222/10000 (92.22%)\n",
      "\n",
      "Round  27, Average loss 437.699 Test accuracy 92.220\n",
      "selected users: [ 0  3  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 111.5519 \n",
      "Accuracy: 9209/10000 (92.09%)\n",
      "\n",
      "Round  28, Average loss 111.552 Test accuracy 92.090\n",
      "selected users: [ 1  2  3  4 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1354.2234 \n",
      "Accuracy: 9157/10000 (91.57%)\n",
      "\n",
      "Round  29, Average loss 1354.223 Test accuracy 91.570\n",
      "(m= 7 )  1 -th Trial!!\n",
      "selected users: [ 1  4  5  6 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.9189 \n",
      "Accuracy: 7494/10000 (74.94%)\n",
      "\n",
      "Round   1, Average loss 1.919 Test accuracy 74.940\n",
      "selected users: [ 0  1  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 9.5416 \n",
      "Accuracy: 198/10000 (1.98%)\n",
      "\n",
      "Round   2, Average loss 9.542 Test accuracy 1.980\n",
      "selected users: [ 3  4  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3052 \n",
      "Accuracy: 9193/10000 (91.93%)\n",
      "\n",
      "Round   3, Average loss 0.305 Test accuracy 91.930\n",
      "selected users: [ 2  4  5  6  7  8 12]\n",
      "\n",
      "Test set: Average loss: 0.1733 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round   4, Average loss 0.173 Test accuracy 94.840\n",
      "selected users: [ 0  4  5  7 11 13 14]\n",
      "\n",
      "Test set: Average loss: 10.6401 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round   5, Average loss 10.640 Test accuracy 94.770\n",
      "selected users: [ 1  2  5 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 132.6742 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round   6, Average loss 132.674 Test accuracy 93.180\n",
      "selected users: [ 1  2  3  5 11 12 13]\n",
      "\n",
      "Test set: Average loss: 315.3727 \n",
      "Accuracy: 9279/10000 (92.79%)\n",
      "\n",
      "Round   7, Average loss 315.373 Test accuracy 92.790\n",
      "selected users: [ 0  4  5  7  8 11 14]\n",
      "\n",
      "Test set: Average loss: 512.9424 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round   8, Average loss 512.942 Test accuracy 93.510\n",
      "selected users: [ 0  5  6  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 527.5166 \n",
      "Accuracy: 9252/10000 (92.52%)\n",
      "\n",
      "Round   9, Average loss 527.517 Test accuracy 92.520\n",
      "selected users: [ 3  4  5  6  8 10 14]\n",
      "\n",
      "Test set: Average loss: 323.0087 \n",
      "Accuracy: 9293/10000 (92.93%)\n",
      "\n",
      "Round  10, Average loss 323.009 Test accuracy 92.930\n",
      "selected users: [ 0  1  2  6  7 10 12]\n",
      "\n",
      "Test set: Average loss: 165.8604 \n",
      "Accuracy: 9106/10000 (91.06%)\n",
      "\n",
      "Round  11, Average loss 165.860 Test accuracy 91.060\n",
      "selected users: [ 0  3  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 107.3736 \n",
      "Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Round  12, Average loss 107.374 Test accuracy 92.690\n",
      "selected users: [ 2  5  6 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 251.7447 \n",
      "Accuracy: 9201/10000 (92.01%)\n",
      "\n",
      "Round  13, Average loss 251.745 Test accuracy 92.010\n",
      "selected users: [ 0  1  5  6  8 12 13]\n",
      "\n",
      "Test set: Average loss: 106.4546 \n",
      "Accuracy: 8884/10000 (88.84%)\n",
      "\n",
      "Round  14, Average loss 106.455 Test accuracy 88.840\n",
      "selected users: [ 1  3  5  7  8  9 12]\n",
      "\n",
      "Test set: Average loss: 116.9468 \n",
      "Accuracy: 9070/10000 (90.70%)\n",
      "\n",
      "Round  15, Average loss 116.947 Test accuracy 90.700\n",
      "selected users: [ 2  3  4  6 10 11 12]\n",
      "\n",
      "Test set: Average loss: 166.6873 \n",
      "Accuracy: 9005/10000 (90.05%)\n",
      "\n",
      "Round  16, Average loss 166.687 Test accuracy 90.050\n",
      "selected users: [ 2  3  4  7 10 13 14]\n",
      "\n",
      "Test set: Average loss: 385.4433 \n",
      "Accuracy: 8914/10000 (89.14%)\n",
      "\n",
      "Round  17, Average loss 385.443 Test accuracy 89.140\n",
      "selected users: [ 3  4  6  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 100.5439 \n",
      "Accuracy: 9301/10000 (93.01%)\n",
      "\n",
      "Round  18, Average loss 100.544 Test accuracy 93.010\n",
      "selected users: [ 1  3  4  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 413.4684 \n",
      "Accuracy: 9410/10000 (94.10%)\n",
      "\n",
      "Round  19, Average loss 413.468 Test accuracy 94.100\n",
      "selected users: [ 0  1  4  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 235.4847 \n",
      "Accuracy: 9308/10000 (93.08%)\n",
      "\n",
      "Round  20, Average loss 235.485 Test accuracy 93.080\n",
      "selected users: [ 0  1  6 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 333.9874 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round  21, Average loss 333.987 Test accuracy 93.880\n",
      "selected users: [ 0  2  4  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 179.6549 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round  22, Average loss 179.655 Test accuracy 92.490\n",
      "selected users: [ 0  1  3  4  7  8 10]\n",
      "\n",
      "Test set: Average loss: 1047.6817 \n",
      "Accuracy: 9162/10000 (91.62%)\n",
      "\n",
      "Round  23, Average loss 1047.682 Test accuracy 91.620\n",
      "selected users: [ 0  4  5  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 981.2359 \n",
      "Accuracy: 9236/10000 (92.36%)\n",
      "\n",
      "Round  24, Average loss 981.236 Test accuracy 92.360\n",
      "selected users: [ 2  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 137.6167 \n",
      "Accuracy: 9148/10000 (91.48%)\n",
      "\n",
      "Round  25, Average loss 137.617 Test accuracy 91.480\n",
      "selected users: [ 0  3  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 156.8914 \n",
      "Accuracy: 9145/10000 (91.45%)\n",
      "\n",
      "Round  26, Average loss 156.891 Test accuracy 91.450\n",
      "selected users: [0 1 2 3 5 7 9]\n",
      "\n",
      "Test set: Average loss: 986.0838 \n",
      "Accuracy: 9218/10000 (92.18%)\n",
      "\n",
      "Round  27, Average loss 986.084 Test accuracy 92.180\n",
      "selected users: [ 0  4  7 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1160.7772 \n",
      "Accuracy: 9242/10000 (92.42%)\n",
      "\n",
      "Round  28, Average loss 1160.777 Test accuracy 92.420\n",
      "selected users: [ 5  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1816.7447 \n",
      "Accuracy: 9155/10000 (91.55%)\n",
      "\n",
      "Round  29, Average loss 1816.745 Test accuracy 91.550\n",
      "(m= 7 )  2 -th Trial!!\n",
      "selected users: [ 0  1  4  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 983/10000 (9.83%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.830\n",
      "selected users: [ 2  3  4  5  7  8 11]\n",
      "\n",
      "Test set: Average loss: 1.1988 \n",
      "Accuracy: 6502/10000 (65.02%)\n",
      "\n",
      "Round   1, Average loss 1.199 Test accuracy 65.020\n",
      "selected users: [ 0  4  5  6  9 11 12]\n",
      "\n",
      "Test set: Average loss: 1.7181 \n",
      "Accuracy: 3183/10000 (31.83%)\n",
      "\n",
      "Round   2, Average loss 1.718 Test accuracy 31.830\n",
      "selected users: [ 1  2  3  6 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3286 \n",
      "Accuracy: 4951/10000 (49.51%)\n",
      "\n",
      "Round   3, Average loss 1.329 Test accuracy 49.510\n",
      "selected users: [ 3  5  6  7 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8216 \n",
      "Accuracy: 2749/10000 (27.49%)\n",
      "\n",
      "Round   4, Average loss 1.822 Test accuracy 27.490\n",
      "selected users: [ 0  3  4  5 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7709 \n",
      "Accuracy: 2889/10000 (28.89%)\n",
      "\n",
      "Round   5, Average loss 1.771 Test accuracy 28.890\n",
      "selected users: [ 0  6  7  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8681 \n",
      "Accuracy: 2454/10000 (24.54%)\n",
      "\n",
      "Round   6, Average loss 1.868 Test accuracy 24.540\n",
      "selected users: [ 2  4  5  6 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.5565 \n",
      "Accuracy: 4210/10000 (42.10%)\n",
      "\n",
      "Round   7, Average loss 1.556 Test accuracy 42.100\n",
      "selected users: [ 1  2  3  6  8  9 12]\n",
      "\n",
      "Test set: Average loss: 2.1821 \n",
      "Accuracy: 1426/10000 (14.26%)\n",
      "\n",
      "Round   8, Average loss 2.182 Test accuracy 14.260\n",
      "selected users: [ 0  1  3  7 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0198 \n",
      "Accuracy: 1911/10000 (19.11%)\n",
      "\n",
      "Round   9, Average loss 2.020 Test accuracy 19.110\n",
      "selected users: [ 0  1  3  5  8 11 12]\n",
      "\n",
      "Test set: Average loss: 1.7125 \n",
      "Accuracy: 3321/10000 (33.21%)\n",
      "\n",
      "Round  10, Average loss 1.713 Test accuracy 33.210\n",
      "selected users: [ 0  5  6  7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 1.1977 \n",
      "Accuracy: 5992/10000 (59.92%)\n",
      "\n",
      "Round  11, Average loss 1.198 Test accuracy 59.920\n",
      "selected users: [ 1  5  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8065 \n",
      "Accuracy: 2759/10000 (27.59%)\n",
      "\n",
      "Round  12, Average loss 1.806 Test accuracy 27.590\n",
      "selected users: [ 0  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.6634 \n",
      "Accuracy: 4969/10000 (49.69%)\n",
      "\n",
      "Round  13, Average loss 1.663 Test accuracy 49.690\n",
      "selected users: [ 1  3  4  6 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.6721 \n",
      "Accuracy: 5130/10000 (51.30%)\n",
      "\n",
      "Round  14, Average loss 2.672 Test accuracy 51.300\n",
      "selected users: [ 2  5  6  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round  15, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8283 \n",
      "Accuracy: 5145/10000 (51.45%)\n",
      "\n",
      "Round  16, Average loss 1.828 Test accuracy 51.450\n",
      "selected users: [ 0  2  3  6  8 10 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8979 \n",
      "Accuracy: 4000/10000 (40.00%)\n",
      "\n",
      "Round  17, Average loss 1.898 Test accuracy 40.000\n",
      "selected users: [ 0  1  3  4 11 13 14]\n",
      "\n",
      "Test set: Average loss: 66.2370 \n",
      "Accuracy: 5722/10000 (57.22%)\n",
      "\n",
      "Round  18, Average loss 66.237 Test accuracy 57.220\n",
      "selected users: [ 0  1  6  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 21.8441 \n",
      "Accuracy: 5622/10000 (56.22%)\n",
      "\n",
      "Round  19, Average loss 21.844 Test accuracy 56.220\n",
      "selected users: [ 2  3  5  6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3233 \n",
      "Accuracy: 3600/10000 (36.00%)\n",
      "\n",
      "Round  20, Average loss 2.323 Test accuracy 36.000\n",
      "selected users: [ 0  1  4  6  8 11 12]\n",
      "\n",
      "Test set: Average loss: 2.8616 \n",
      "Accuracy: 3568/10000 (35.68%)\n",
      "\n",
      "Round  21, Average loss 2.862 Test accuracy 35.680\n",
      "selected users: [ 0  4  5  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8335 \n",
      "Accuracy: 4873/10000 (48.73%)\n",
      "\n",
      "Round  22, Average loss 5.834 Test accuracy 48.730\n",
      "selected users: [ 0  2  4  6  8 11 13]\n",
      "\n",
      "Test set: Average loss: 2.8177 \n",
      "Accuracy: 4065/10000 (40.65%)\n",
      "\n",
      "Round  23, Average loss 2.818 Test accuracy 40.650\n",
      "selected users: [ 3  4  5  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0221 \n",
      "Accuracy: 2536/10000 (25.36%)\n",
      "\n",
      "Round  24, Average loss 2.022 Test accuracy 25.360\n",
      "selected users: [ 0  1  3  4  7 11 12]\n",
      "\n",
      "Test set: Average loss: 1.8799 \n",
      "Accuracy: 2717/10000 (27.17%)\n",
      "\n",
      "Round  25, Average loss 1.880 Test accuracy 27.170\n",
      "selected users: [ 0  4  5  6  8 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8312 \n",
      "Accuracy: 2635/10000 (26.35%)\n",
      "\n",
      "Round  26, Average loss 1.831 Test accuracy 26.350\n",
      "selected users: [ 1  3  4  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 2.0280 \n",
      "Accuracy: 3430/10000 (34.30%)\n",
      "\n",
      "Round  27, Average loss 2.028 Test accuracy 34.300\n",
      "selected users: [ 0  1  3  5  7  9 10]\n",
      "\n",
      "Test set: Average loss: 1.9954 \n",
      "Accuracy: 2058/10000 (20.58%)\n",
      "\n",
      "Round  28, Average loss 1.995 Test accuracy 20.580\n",
      "selected users: [ 1  4  5  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8453 \n",
      "Accuracy: 3002/10000 (30.02%)\n",
      "\n",
      "Round  29, Average loss 1.845 Test accuracy 30.020\n",
      "(m= 7 )  3 -th Trial!!\n",
      "selected users: [ 0  2  3  5  7 10 13]\n",
      "\n",
      "Test set: Average loss: 2.2409 \n",
      "Accuracy: 3072/10000 (30.72%)\n",
      "\n",
      "Round   0, Average loss 2.241 Test accuracy 30.720\n",
      "selected users: [ 0  1  3  6  8 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1075 \n",
      "Accuracy: 8207/10000 (82.07%)\n",
      "\n",
      "Round   1, Average loss 1.107 Test accuracy 82.070\n",
      "selected users: [ 0  1  3  4  8  9 10]\n",
      "\n",
      "Test set: Average loss: 31.5872 \n",
      "Accuracy: 8734/10000 (87.34%)\n",
      "\n",
      "Round   2, Average loss 31.587 Test accuracy 87.340\n",
      "selected users: [ 3  4  5  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 21.2075 \n",
      "Accuracy: 8571/10000 (85.71%)\n",
      "\n",
      "Round   3, Average loss 21.208 Test accuracy 85.710\n",
      "selected users: [ 1  4  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 19.4286 \n",
      "Accuracy: 9112/10000 (91.12%)\n",
      "\n",
      "Round   4, Average loss 19.429 Test accuracy 91.120\n",
      "selected users: [ 2  3  6  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 17.8728 \n",
      "Accuracy: 9264/10000 (92.64%)\n",
      "\n",
      "Round   5, Average loss 17.873 Test accuracy 92.640\n",
      "selected users: [ 1  3  5  6  7 12 14]\n",
      "\n",
      "Test set: Average loss: 5.0820 \n",
      "Accuracy: 8711/10000 (87.11%)\n",
      "\n",
      "Round   6, Average loss 5.082 Test accuracy 87.110\n",
      "selected users: [ 3  4  5  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 40.5252 \n",
      "Accuracy: 9245/10000 (92.45%)\n",
      "\n",
      "Round   7, Average loss 40.525 Test accuracy 92.450\n",
      "selected users: [1 2 4 5 6 8 9]\n",
      "\n",
      "Test set: Average loss: 217.0205 \n",
      "Accuracy: 9177/10000 (91.77%)\n",
      "\n",
      "Round   8, Average loss 217.020 Test accuracy 91.770\n",
      "selected users: [ 1  2  5  6 10 13 14]\n",
      "\n",
      "Test set: Average loss: 288.0948 \n",
      "Accuracy: 9179/10000 (91.79%)\n",
      "\n",
      "Round   9, Average loss 288.095 Test accuracy 91.790\n",
      "selected users: [ 0  4  7  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 157.2256 \n",
      "Accuracy: 9298/10000 (92.98%)\n",
      "\n",
      "Round  10, Average loss 157.226 Test accuracy 92.980\n",
      "selected users: [ 1  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 336.0756 \n",
      "Accuracy: 9363/10000 (93.63%)\n",
      "\n",
      "Round  11, Average loss 336.076 Test accuracy 93.630\n",
      "selected users: [ 1  4  5  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 439.5969 \n",
      "Accuracy: 9355/10000 (93.55%)\n",
      "\n",
      "Round  12, Average loss 439.597 Test accuracy 93.550\n",
      "selected users: [ 0  1  3  4  9 10 13]\n",
      "\n",
      "Test set: Average loss: 184.9501 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  13, Average loss 184.950 Test accuracy 94.410\n",
      "selected users: [ 0  3  5  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 557.0802 \n",
      "Accuracy: 9379/10000 (93.79%)\n",
      "\n",
      "Round  14, Average loss 557.080 Test accuracy 93.790\n",
      "selected users: [ 2  4  5  6  8 12 14]\n",
      "\n",
      "Test set: Average loss: 55.1934 \n",
      "Accuracy: 9126/10000 (91.26%)\n",
      "\n",
      "Round  15, Average loss 55.193 Test accuracy 91.260\n",
      "selected users: [ 0  1  4  5  6 10 14]\n",
      "\n",
      "Test set: Average loss: 612.0409 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  16, Average loss 612.041 Test accuracy 93.660\n",
      "selected users: [ 1  2  5  7  8 11 14]\n",
      "\n",
      "Test set: Average loss: 719.9388 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round  17, Average loss 719.939 Test accuracy 92.740\n",
      "selected users: [ 2  4  5  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 1114.3234 \n",
      "Accuracy: 8956/10000 (89.56%)\n",
      "\n",
      "Round  18, Average loss 1114.323 Test accuracy 89.560\n",
      "selected users: [ 0  4  6  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1081.1772 \n",
      "Accuracy: 9248/10000 (92.48%)\n",
      "\n",
      "Round  19, Average loss 1081.177 Test accuracy 92.480\n",
      "selected users: [ 1  3  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 143.3536 \n",
      "Accuracy: 9134/10000 (91.34%)\n",
      "\n",
      "Round  20, Average loss 143.354 Test accuracy 91.340\n",
      "selected users: [1 2 3 4 6 8 9]\n",
      "\n",
      "Test set: Average loss: 785.2062 \n",
      "Accuracy: 9323/10000 (93.23%)\n",
      "\n",
      "Round  21, Average loss 785.206 Test accuracy 93.230\n",
      "selected users: [ 0  2  5  6 10 12 14]\n",
      "\n",
      "Test set: Average loss: 628.9140 \n",
      "Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Round  22, Average loss 628.914 Test accuracy 92.690\n",
      "selected users: [ 0  1  2  5  9 10 12]\n",
      "\n",
      "Test set: Average loss: 319.8348 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round  23, Average loss 319.835 Test accuracy 92.470\n",
      "selected users: [ 0  2  3  5  6 13 14]\n",
      "\n",
      "Test set: Average loss: 25.4499 \n",
      "Accuracy: 8105/10000 (81.05%)\n",
      "\n",
      "Round  24, Average loss 25.450 Test accuracy 81.050\n",
      "selected users: [ 0  5  6 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1003.9980 \n",
      "Accuracy: 9133/10000 (91.33%)\n",
      "\n",
      "Round  25, Average loss 1003.998 Test accuracy 91.330\n",
      "selected users: [ 0  1  3  6  8 10 14]\n",
      "\n",
      "Test set: Average loss: 540.3032 \n",
      "Accuracy: 9308/10000 (93.08%)\n",
      "\n",
      "Round  26, Average loss 540.303 Test accuracy 93.080\n",
      "selected users: [ 0  1  2  3  7 10 13]\n",
      "\n",
      "Test set: Average loss: 59.6619 \n",
      "Accuracy: 9020/10000 (90.20%)\n",
      "\n",
      "Round  27, Average loss 59.662 Test accuracy 90.200\n",
      "selected users: [ 0  1  2  5  7  8 10]\n",
      "\n",
      "Test set: Average loss: 984.0132 \n",
      "Accuracy: 9034/10000 (90.34%)\n",
      "\n",
      "Round  28, Average loss 984.013 Test accuracy 90.340\n",
      "selected users: [ 3  4  6  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 285.9976 \n",
      "Accuracy: 9304/10000 (93.04%)\n",
      "\n",
      "Round  29, Average loss 285.998 Test accuracy 93.040\n",
      "(m= 7 )  4 -th Trial!!\n",
      "selected users: [ 1  2  4  6  9 10 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  5  8 10 13]\n",
      "\n",
      "Test set: Average loss: 5.0364 \n",
      "Accuracy: 7566/10000 (75.66%)\n",
      "\n",
      "Round   1, Average loss 5.036 Test accuracy 75.660\n",
      "selected users: [ 4  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 5.1136 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round   2, Average loss 5.114 Test accuracy 94.020\n",
      "selected users: [ 0  3  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6951 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round   3, Average loss 2.695 Test accuracy 92.470\n",
      "selected users: [ 2  3  5  6 10 12 14]\n",
      "\n",
      "Test set: Average loss: 43.5034 \n",
      "Accuracy: 9087/10000 (90.87%)\n",
      "\n",
      "Round   4, Average loss 43.503 Test accuracy 90.870\n",
      "selected users: [ 2  3  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 38.0649 \n",
      "Accuracy: 9002/10000 (90.02%)\n",
      "\n",
      "Round   5, Average loss 38.065 Test accuracy 90.020\n",
      "selected users: [ 1  3  4  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 96.6530 \n",
      "Accuracy: 9100/10000 (91.00%)\n",
      "\n",
      "Round   6, Average loss 96.653 Test accuracy 91.000\n",
      "selected users: [ 1  2  4  5  9 12 13]\n",
      "\n",
      "Test set: Average loss: 90.5238 \n",
      "Accuracy: 9169/10000 (91.69%)\n",
      "\n",
      "Round   7, Average loss 90.524 Test accuracy 91.690\n",
      "selected users: [ 0  1  4  6  8 10 13]\n",
      "\n",
      "Test set: Average loss: 89.4169 \n",
      "Accuracy: 9137/10000 (91.37%)\n",
      "\n",
      "Round   8, Average loss 89.417 Test accuracy 91.370\n",
      "selected users: [ 3  5  6  7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 13.5159 \n",
      "Accuracy: 8753/10000 (87.53%)\n",
      "\n",
      "Round   9, Average loss 13.516 Test accuracy 87.530\n",
      "selected users: [ 1  7  8 10 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 148.2630 \n",
      "Accuracy: 9284/10000 (92.84%)\n",
      "\n",
      "Round  10, Average loss 148.263 Test accuracy 92.840\n",
      "selected users: [ 2  3  6  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 104.6585 \n",
      "Accuracy: 9098/10000 (90.98%)\n",
      "\n",
      "Round  11, Average loss 104.659 Test accuracy 90.980\n",
      "selected users: [ 1  2  3  4  8 10 13]\n",
      "\n",
      "Test set: Average loss: 108.1032 \n",
      "Accuracy: 8685/10000 (86.85%)\n",
      "\n",
      "Round  12, Average loss 108.103 Test accuracy 86.850\n",
      "selected users: [ 0  2  5  7 10 11 14]\n",
      "\n",
      "Test set: Average loss: 248.9887 \n",
      "Accuracy: 9096/10000 (90.96%)\n",
      "\n",
      "Round  13, Average loss 248.989 Test accuracy 90.960\n",
      "selected users: [ 0  1  2  7 10 11 14]\n",
      "\n",
      "Test set: Average loss: 125.2438 \n",
      "Accuracy: 9226/10000 (92.26%)\n",
      "\n",
      "Round  14, Average loss 125.244 Test accuracy 92.260\n",
      "selected users: [ 1  4  5  6 12 13 14]\n",
      "\n",
      "Test set: Average loss: 203.6906 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  15, Average loss 203.691 Test accuracy 93.380\n",
      "selected users: [ 1  4  5  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 316.9859 \n",
      "Accuracy: 9294/10000 (92.94%)\n",
      "\n",
      "Round  16, Average loss 316.986 Test accuracy 92.940\n",
      "selected users: [ 0  2  4  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 595.9880 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round  17, Average loss 595.988 Test accuracy 93.960\n",
      "selected users: [ 0  2  5  6  8 11 14]\n",
      "\n",
      "Test set: Average loss: 383.5126 \n",
      "Accuracy: 9242/10000 (92.42%)\n",
      "\n",
      "Round  18, Average loss 383.513 Test accuracy 92.420\n",
      "selected users: [ 0  4  5  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 626.8529 \n",
      "Accuracy: 9121/10000 (91.21%)\n",
      "\n",
      "Round  19, Average loss 626.853 Test accuracy 91.210\n",
      "selected users: [ 0  1  2  7 12 13 14]\n",
      "\n",
      "Test set: Average loss: 79.5970 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round  20, Average loss 79.597 Test accuracy 92.210\n",
      "selected users: [ 0  1  2  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 84.1144 \n",
      "Accuracy: 8947/10000 (89.47%)\n",
      "\n",
      "Round  21, Average loss 84.114 Test accuracy 89.470\n",
      "selected users: [ 3  6  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 82.3500 \n",
      "Accuracy: 9287/10000 (92.87%)\n",
      "\n",
      "Round  22, Average loss 82.350 Test accuracy 92.870\n",
      "selected users: [ 2  4  6  7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 89.6273 \n",
      "Accuracy: 8959/10000 (89.59%)\n",
      "\n",
      "Round  23, Average loss 89.627 Test accuracy 89.590\n",
      "selected users: [ 0  1  3  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 18.0684 \n",
      "Accuracy: 8806/10000 (88.06%)\n",
      "\n",
      "Round  24, Average loss 18.068 Test accuracy 88.060\n",
      "selected users: [ 0  4  6  7 10 11 12]\n",
      "\n",
      "Test set: Average loss: 249.7725 \n",
      "Accuracy: 9088/10000 (90.88%)\n",
      "\n",
      "Round  25, Average loss 249.772 Test accuracy 90.880\n",
      "selected users: [ 1  3  6  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 97.2457 \n",
      "Accuracy: 9089/10000 (90.89%)\n",
      "\n",
      "Round  26, Average loss 97.246 Test accuracy 90.890\n",
      "selected users: [ 4  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 294.8659 \n",
      "Accuracy: 9062/10000 (90.62%)\n",
      "\n",
      "Round  27, Average loss 294.866 Test accuracy 90.620\n",
      "selected users: [ 0  4  5  7  8 10 11]\n",
      "\n",
      "Test set: Average loss: 921.7724 \n",
      "Accuracy: 9209/10000 (92.09%)\n",
      "\n",
      "Round  28, Average loss 921.772 Test accuracy 92.090\n",
      "selected users: [ 0  3  6  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 555.9654 \n",
      "Accuracy: 9168/10000 (91.68%)\n",
      "\n",
      "Round  29, Average loss 555.965 Test accuracy 91.680\n",
      "(m= 7 )  5 -th Trial!!\n",
      "selected users: [ 1  2  5  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  5  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 2.2593 \n",
      "Accuracy: 2869/10000 (28.69%)\n",
      "\n",
      "Round   1, Average loss 2.259 Test accuracy 28.690\n",
      "selected users: [ 0  2  4  7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 1.1409 \n",
      "Accuracy: 8906/10000 (89.06%)\n",
      "\n",
      "Round   2, Average loss 1.141 Test accuracy 89.060\n",
      "selected users: [ 1  2  4  6  7  9 11]\n",
      "\n",
      "Test set: Average loss: 12.2947 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round   3, Average loss 12.295 Test accuracy 94.900\n",
      "selected users: [ 0  2  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.2477 \n",
      "Accuracy: 6157/10000 (61.57%)\n",
      "\n",
      "Round   4, Average loss 1.248 Test accuracy 61.570\n",
      "selected users: [ 0  1  2  6  9 11 14]\n",
      "\n",
      "Test set: Average loss: 0.7860 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round   5, Average loss 0.786 Test accuracy 93.980\n",
      "selected users: [ 1  2  3  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 0.5744 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round   6, Average loss 0.574 Test accuracy 93.370\n",
      "selected users: [ 0  3  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.6072 \n",
      "Accuracy: 8244/10000 (82.44%)\n",
      "\n",
      "Round   7, Average loss 0.607 Test accuracy 82.440\n",
      "selected users: [ 1  4  5  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 7.7834 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round   8, Average loss 7.783 Test accuracy 94.870\n",
      "selected users: [ 0  1  4  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 14.8005 \n",
      "Accuracy: 9405/10000 (94.05%)\n",
      "\n",
      "Round   9, Average loss 14.800 Test accuracy 94.050\n",
      "selected users: [ 1  3  6  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 9.6715 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round  10, Average loss 9.671 Test accuracy 93.960\n",
      "selected users: [ 0  1  3  4  5  6 14]\n",
      "\n",
      "Test set: Average loss: 35.0922 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  11, Average loss 35.092 Test accuracy 95.680\n",
      "selected users: [ 0  1  6  7  9 11 12]\n",
      "\n",
      "Test set: Average loss: 9.5808 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  12, Average loss 9.581 Test accuracy 95.280\n",
      "selected users: [ 1  2  5  7  8 12 14]\n",
      "\n",
      "Test set: Average loss: 24.0493 \n",
      "Accuracy: 9258/10000 (92.58%)\n",
      "\n",
      "Round  13, Average loss 24.049 Test accuracy 92.580\n",
      "selected users: [ 3  4  5  6  9 13 14]\n",
      "\n",
      "Test set: Average loss: 13.0061 \n",
      "Accuracy: 9256/10000 (92.56%)\n",
      "\n",
      "Round  14, Average loss 13.006 Test accuracy 92.560\n",
      "selected users: [ 1  2  3  6  9 10 13]\n",
      "\n",
      "Test set: Average loss: 25.4044 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  15, Average loss 25.404 Test accuracy 94.360\n",
      "selected users: [ 0  3  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 10.2842 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round  16, Average loss 10.284 Test accuracy 92.380\n",
      "selected users: [ 1  5  7  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 150.5228 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round  17, Average loss 150.523 Test accuracy 94.770\n",
      "selected users: [ 3  6  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 55.5273 \n",
      "Accuracy: 9390/10000 (93.90%)\n",
      "\n",
      "Round  18, Average loss 55.527 Test accuracy 93.900\n",
      "selected users: [ 2  3  4  5 10 12 13]\n",
      "\n",
      "Test set: Average loss: 317.0635 \n",
      "Accuracy: 9120/10000 (91.20%)\n",
      "\n",
      "Round  19, Average loss 317.064 Test accuracy 91.200\n",
      "selected users: [ 4  5  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 130.7466 \n",
      "Accuracy: 9321/10000 (93.21%)\n",
      "\n",
      "Round  20, Average loss 130.747 Test accuracy 93.210\n",
      "selected users: [ 0  2  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 14.1547 \n",
      "Accuracy: 8918/10000 (89.18%)\n",
      "\n",
      "Round  21, Average loss 14.155 Test accuracy 89.180\n",
      "selected users: [ 0  3  6  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 90.6519 \n",
      "Accuracy: 9415/10000 (94.15%)\n",
      "\n",
      "Round  22, Average loss 90.652 Test accuracy 94.150\n",
      "selected users: [ 0  1  5  6 10 12 14]\n",
      "\n",
      "Test set: Average loss: 326.8430 \n",
      "Accuracy: 9377/10000 (93.77%)\n",
      "\n",
      "Round  23, Average loss 326.843 Test accuracy 93.770\n",
      "selected users: [ 2  3  5  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 87.8280 \n",
      "Accuracy: 9292/10000 (92.92%)\n",
      "\n",
      "Round  24, Average loss 87.828 Test accuracy 92.920\n",
      "selected users: [ 0  2  4  6 11 13 14]\n",
      "\n",
      "Test set: Average loss: 314.3174 \n",
      "Accuracy: 9421/10000 (94.21%)\n",
      "\n",
      "Round  25, Average loss 314.317 Test accuracy 94.210\n",
      "selected users: [ 2  4  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 192.6880 \n",
      "Accuracy: 9299/10000 (92.99%)\n",
      "\n",
      "Round  26, Average loss 192.688 Test accuracy 92.990\n",
      "selected users: [ 1  2  3  5  9 10 14]\n",
      "\n",
      "Test set: Average loss: 650.4755 \n",
      "Accuracy: 9332/10000 (93.32%)\n",
      "\n",
      "Round  27, Average loss 650.475 Test accuracy 93.320\n",
      "selected users: [ 1  5  6  7 11 12 14]\n",
      "\n",
      "Test set: Average loss: 655.8115 \n",
      "Accuracy: 9394/10000 (93.94%)\n",
      "\n",
      "Round  28, Average loss 655.812 Test accuracy 93.940\n",
      "selected users: [ 0  1  2  6  7 11 12]\n",
      "\n",
      "Test set: Average loss: 146.1564 \n",
      "Accuracy: 9276/10000 (92.76%)\n",
      "\n",
      "Round  29, Average loss 146.156 Test accuracy 92.760\n",
      "(m= 7 )  6 -th Trial!!\n",
      "selected users: [ 3  5  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  3  4  5  6 11]\n",
      "\n",
      "Test set: Average loss: 1.0197 \n",
      "Accuracy: 6300/10000 (63.00%)\n",
      "\n",
      "Round   1, Average loss 1.020 Test accuracy 63.000\n",
      "selected users: [ 1  4  5  6  7 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6682 \n",
      "Accuracy: 9159/10000 (91.59%)\n",
      "\n",
      "Round   2, Average loss 0.668 Test accuracy 91.590\n",
      "selected users: [ 0  2  5  7  8 11 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 17.9389 \n",
      "Accuracy: 8974/10000 (89.74%)\n",
      "\n",
      "Round   3, Average loss 17.939 Test accuracy 89.740\n",
      "selected users: [ 2  3  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 14.3718 \n",
      "Accuracy: 9053/10000 (90.53%)\n",
      "\n",
      "Round   4, Average loss 14.372 Test accuracy 90.530\n",
      "selected users: [ 0  1  2  3 11 12 13]\n",
      "\n",
      "Test set: Average loss: 13.7149 \n",
      "Accuracy: 8945/10000 (89.45%)\n",
      "\n",
      "Round   5, Average loss 13.715 Test accuracy 89.450\n",
      "selected users: [ 2  5  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 17.9882 \n",
      "Accuracy: 8604/10000 (86.04%)\n",
      "\n",
      "Round   6, Average loss 17.988 Test accuracy 86.040\n",
      "selected users: [ 0  1  4 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 239.0829 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round   7, Average loss 239.083 Test accuracy 92.380\n",
      "selected users: [ 1  2  3  4  9 12 13]\n",
      "\n",
      "Test set: Average loss: 129.1175 \n",
      "Accuracy: 9412/10000 (94.12%)\n",
      "\n",
      "Round   8, Average loss 129.118 Test accuracy 94.120\n",
      "selected users: [ 1  2  4  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 92.3590 \n",
      "Accuracy: 9330/10000 (93.30%)\n",
      "\n",
      "Round   9, Average loss 92.359 Test accuracy 93.300\n",
      "selected users: [ 3  5  6  7  8  9 12]\n",
      "\n",
      "Test set: Average loss: 3.1995 \n",
      "Accuracy: 7508/10000 (75.08%)\n",
      "\n",
      "Round  10, Average loss 3.200 Test accuracy 75.080\n",
      "selected users: [ 1  5  6  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 37.5429 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round  11, Average loss 37.543 Test accuracy 93.180\n",
      "selected users: [ 2  3  4  7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 23.9173 \n",
      "Accuracy: 9294/10000 (92.94%)\n",
      "\n",
      "Round  12, Average loss 23.917 Test accuracy 92.940\n",
      "selected users: [ 2  3  5  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 80.8145 \n",
      "Accuracy: 9090/10000 (90.90%)\n",
      "\n",
      "Round  13, Average loss 80.814 Test accuracy 90.900\n",
      "selected users: [ 0  1  5  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 102.0341 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round  14, Average loss 102.034 Test accuracy 93.180\n",
      "selected users: [ 1  4  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 181.9407 \n",
      "Accuracy: 9348/10000 (93.48%)\n",
      "\n",
      "Round  15, Average loss 181.941 Test accuracy 93.480\n",
      "selected users: [ 1  3  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 55.3205 \n",
      "Accuracy: 9368/10000 (93.68%)\n",
      "\n",
      "Round  16, Average loss 55.320 Test accuracy 93.680\n",
      "selected users: [ 0  2  6  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8539 \n",
      "Accuracy: 6906/10000 (69.06%)\n",
      "\n",
      "Round  17, Average loss 5.854 Test accuracy 69.060\n",
      "selected users: [ 1  4  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 27.2717 \n",
      "Accuracy: 9377/10000 (93.77%)\n",
      "\n",
      "Round  18, Average loss 27.272 Test accuracy 93.770\n",
      "selected users: [ 0  2  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.6683 \n",
      "Accuracy: 7719/10000 (77.19%)\n",
      "\n",
      "Round  19, Average loss 1.668 Test accuracy 77.190\n",
      "selected users: [ 3  4  5  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 49.7655 \n",
      "Accuracy: 8887/10000 (88.87%)\n",
      "\n",
      "Round  20, Average loss 49.765 Test accuracy 88.870\n",
      "selected users: [ 2  6  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 14.4796 \n",
      "Accuracy: 8920/10000 (89.20%)\n",
      "\n",
      "Round  21, Average loss 14.480 Test accuracy 89.200\n",
      "selected users: [ 2  4  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 10.0884 \n",
      "Accuracy: 9035/10000 (90.35%)\n",
      "\n",
      "Round  22, Average loss 10.088 Test accuracy 90.350\n",
      "selected users: [ 3  4  5  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 40.1930 \n",
      "Accuracy: 8678/10000 (86.78%)\n",
      "\n",
      "Round  23, Average loss 40.193 Test accuracy 86.780\n",
      "selected users: [ 0  2  4  5  7 12 14]\n",
      "\n",
      "Test set: Average loss: 11.9190 \n",
      "Accuracy: 8632/10000 (86.32%)\n",
      "\n",
      "Round  24, Average loss 11.919 Test accuracy 86.320\n",
      "selected users: [ 0  2  3  5  6  8 10]\n",
      "\n",
      "Test set: Average loss: 563.3273 \n",
      "Accuracy: 8987/10000 (89.87%)\n",
      "\n",
      "Round  25, Average loss 563.327 Test accuracy 89.870\n",
      "selected users: [ 1  3  4  5 10 12 14]\n",
      "\n",
      "Test set: Average loss: 889.6455 \n",
      "Accuracy: 9013/10000 (90.13%)\n",
      "\n",
      "Round  26, Average loss 889.645 Test accuracy 90.130\n",
      "selected users: [ 0  4  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 611.1688 \n",
      "Accuracy: 9210/10000 (92.10%)\n",
      "\n",
      "Round  27, Average loss 611.169 Test accuracy 92.100\n",
      "selected users: [ 0  2  4  5  6 11 12]\n",
      "\n",
      "Test set: Average loss: 573.2478 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round  28, Average loss 573.248 Test accuracy 93.370\n",
      "selected users: [ 3  5  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 545.5244 \n",
      "Accuracy: 9309/10000 (93.09%)\n",
      "\n",
      "Round  29, Average loss 545.524 Test accuracy 93.090\n",
      "(m= 7 )  7 -th Trial!!\n",
      "selected users: [ 1  2  3  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  5  6  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 2.0636 \n",
      "Accuracy: 6681/10000 (66.81%)\n",
      "\n",
      "Round   1, Average loss 2.064 Test accuracy 66.810\n",
      "selected users: [ 1  2  6  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1895 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round   2, Average loss 0.190 Test accuracy 95.670\n",
      "selected users: [ 1  3  4  5  6  8 10]\n",
      "\n",
      "Test set: Average loss: 33.6854 \n",
      "Accuracy: 9220/10000 (92.20%)\n",
      "\n",
      "Round   3, Average loss 33.685 Test accuracy 92.200\n",
      "selected users: [ 1  2  4  6 11 12 13]\n",
      "\n",
      "Test set: Average loss: 32.5773 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round   4, Average loss 32.577 Test accuracy 94.410\n",
      "selected users: [ 0  2  4  6  8 13 14]\n",
      "\n",
      "Test set: Average loss: 8.2924 \n",
      "Accuracy: 8990/10000 (89.90%)\n",
      "\n",
      "Round   5, Average loss 8.292 Test accuracy 89.900\n",
      "selected users: [ 0  2  6  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 5.1425 \n",
      "Accuracy: 9384/10000 (93.84%)\n",
      "\n",
      "Round   6, Average loss 5.143 Test accuracy 93.840\n",
      "selected users: [ 0  1  6 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 31.9330 \n",
      "Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Round   7, Average loss 31.933 Test accuracy 95.120\n",
      "selected users: [ 2  5  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 14.8984 \n",
      "Accuracy: 8986/10000 (89.86%)\n",
      "\n",
      "Round   8, Average loss 14.898 Test accuracy 89.860\n",
      "selected users: [ 0  1  5  6  9 10 11]\n",
      "\n",
      "Test set: Average loss: 95.0212 \n",
      "Accuracy: 9466/10000 (94.66%)\n",
      "\n",
      "Round   9, Average loss 95.021 Test accuracy 94.660\n",
      "selected users: [ 0  1  6  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 58.1742 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  10, Average loss 58.174 Test accuracy 95.610\n",
      "selected users: [0 1 2 4 5 7 9]\n",
      "\n",
      "Test set: Average loss: 160.0850 \n",
      "Accuracy: 9438/10000 (94.38%)\n",
      "\n",
      "Round  11, Average loss 160.085 Test accuracy 94.380\n",
      "selected users: [ 1  5  6  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 119.8287 \n",
      "Accuracy: 9431/10000 (94.31%)\n",
      "\n",
      "Round  12, Average loss 119.829 Test accuracy 94.310\n",
      "selected users: [ 2  3  4  5  7  8 13]\n",
      "\n",
      "Test set: Average loss: 13.5011 \n",
      "Accuracy: 8821/10000 (88.21%)\n",
      "\n",
      "Round  13, Average loss 13.501 Test accuracy 88.210\n",
      "selected users: [ 2  3  6  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 23.2874 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  14, Average loss 23.287 Test accuracy 93.990\n",
      "selected users: [ 3  4  6  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 63.3321 \n",
      "Accuracy: 9422/10000 (94.22%)\n",
      "\n",
      "Round  15, Average loss 63.332 Test accuracy 94.220\n",
      "selected users: [ 0  1  2  4 11 13 14]\n",
      "\n",
      "Test set: Average loss: 539.5875 \n",
      "Accuracy: 9323/10000 (93.23%)\n",
      "\n",
      "Round  16, Average loss 539.588 Test accuracy 93.230\n",
      "selected users: [ 1  2  3  5  6 10 11]\n",
      "\n",
      "Test set: Average loss: 386.4432 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  17, Average loss 386.443 Test accuracy 94.900\n",
      "selected users: [ 1  2  3  5  7 13 14]\n",
      "\n",
      "Test set: Average loss: 6.3718 \n",
      "Accuracy: 7928/10000 (79.28%)\n",
      "\n",
      "Round  18, Average loss 6.372 Test accuracy 79.280\n",
      "selected users: [ 3  5  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 9.3437 \n",
      "Accuracy: 8151/10000 (81.51%)\n",
      "\n",
      "Round  19, Average loss 9.344 Test accuracy 81.510\n",
      "selected users: [ 1  2  5  6  7 10 12]\n",
      "\n",
      "Test set: Average loss: 39.3465 \n",
      "Accuracy: 8996/10000 (89.96%)\n",
      "\n",
      "Round  20, Average loss 39.346 Test accuracy 89.960\n",
      "selected users: [ 0  1  5  6  7  9 11]\n",
      "\n",
      "Test set: Average loss: 192.2869 \n",
      "Accuracy: 9295/10000 (92.95%)\n",
      "\n",
      "Round  21, Average loss 192.287 Test accuracy 92.950\n",
      "selected users: [ 0  1  4  5  9 10 11]\n",
      "\n",
      "Test set: Average loss: 242.2989 \n",
      "Accuracy: 9473/10000 (94.73%)\n",
      "\n",
      "Round  22, Average loss 242.299 Test accuracy 94.730\n",
      "selected users: [ 0  1  3  6  7 10 12]\n",
      "\n",
      "Test set: Average loss: 70.6938 \n",
      "Accuracy: 9330/10000 (93.30%)\n",
      "\n",
      "Round  23, Average loss 70.694 Test accuracy 93.300\n",
      "selected users: [ 3  5  7  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 18.6166 \n",
      "Accuracy: 8984/10000 (89.84%)\n",
      "\n",
      "Round  24, Average loss 18.617 Test accuracy 89.840\n",
      "selected users: [ 1  2  5  6  7  9 13]\n",
      "\n",
      "Test set: Average loss: 22.5193 \n",
      "Accuracy: 8973/10000 (89.73%)\n",
      "\n",
      "Round  25, Average loss 22.519 Test accuracy 89.730\n",
      "selected users: [ 2  3  4  6  9 10 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 19.5157 \n",
      "Accuracy: 9292/10000 (92.92%)\n",
      "\n",
      "Round  26, Average loss 19.516 Test accuracy 92.920\n",
      "selected users: [ 3  6  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 16.2906 \n",
      "Accuracy: 8946/10000 (89.46%)\n",
      "\n",
      "Round  27, Average loss 16.291 Test accuracy 89.460\n",
      "selected users: [ 1  3  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 13.0769 \n",
      "Accuracy: 9123/10000 (91.23%)\n",
      "\n",
      "Round  28, Average loss 13.077 Test accuracy 91.230\n",
      "selected users: [ 3  4  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 22.5077 \n",
      "Accuracy: 9096/10000 (90.96%)\n",
      "\n",
      "Round  29, Average loss 22.508 Test accuracy 90.960\n",
      "(m= 7 )  8 -th Trial!!\n",
      "selected users: [ 0  2  4  6  8  9 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  6 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2380 \n",
      "Accuracy: 2484/10000 (24.84%)\n",
      "\n",
      "Round   1, Average loss 2.238 Test accuracy 24.840\n",
      "selected users: [ 0  3  4  5  8 10 14]\n",
      "\n",
      "Test set: Average loss: 5.7438 \n",
      "Accuracy: 8865/10000 (88.65%)\n",
      "\n",
      "Round   2, Average loss 5.744 Test accuracy 88.650\n",
      "selected users: [ 1  2  3  5  6 12 14]\n",
      "\n",
      "Test set: Average loss: 2.1718 \n",
      "Accuracy: 3225/10000 (32.25%)\n",
      "\n",
      "Round   3, Average loss 2.172 Test accuracy 32.250\n",
      "selected users: [ 0  2  3  5  7 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9053 \n",
      "Accuracy: 9098/10000 (90.98%)\n",
      "\n",
      "Round   4, Average loss 0.905 Test accuracy 90.980\n",
      "selected users: [ 1  3  4  6 10 11 13]\n",
      "\n",
      "Test set: Average loss: 4.9796 \n",
      "Accuracy: 9268/10000 (92.68%)\n",
      "\n",
      "Round   5, Average loss 4.980 Test accuracy 92.680\n",
      "selected users: [ 0  5  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 60.0679 \n",
      "Accuracy: 9201/10000 (92.01%)\n",
      "\n",
      "Round   6, Average loss 60.068 Test accuracy 92.010\n",
      "selected users: [ 0  1  2  6  7 11 13]\n",
      "\n",
      "Test set: Average loss: 24.2134 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round   7, Average loss 24.213 Test accuracy 93.110\n",
      "selected users: [ 0  2  4  5  8 12 14]\n",
      "\n",
      "Test set: Average loss: 16.2939 \n",
      "Accuracy: 8971/10000 (89.71%)\n",
      "\n",
      "Round   8, Average loss 16.294 Test accuracy 89.710\n",
      "selected users: [ 0  4  6  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 375.8965 \n",
      "Accuracy: 9171/10000 (91.71%)\n",
      "\n",
      "Round   9, Average loss 375.896 Test accuracy 91.710\n",
      "selected users: [ 0  1  2  3  9 10 14]\n",
      "\n",
      "Test set: Average loss: 50.6604 \n",
      "Accuracy: 9426/10000 (94.26%)\n",
      "\n",
      "Round  10, Average loss 50.660 Test accuracy 94.260\n",
      "selected users: [ 1  2  5  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 243.2701 \n",
      "Accuracy: 9167/10000 (91.67%)\n",
      "\n",
      "Round  11, Average loss 243.270 Test accuracy 91.670\n",
      "selected users: [ 2  3  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 25.9007 \n",
      "Accuracy: 9181/10000 (91.81%)\n",
      "\n",
      "Round  12, Average loss 25.901 Test accuracy 91.810\n",
      "selected users: [ 1  2  6  7  8 10 11]\n",
      "\n",
      "Test set: Average loss: 86.4411 \n",
      "Accuracy: 9421/10000 (94.21%)\n",
      "\n",
      "Round  13, Average loss 86.441 Test accuracy 94.210\n",
      "selected users: [ 1  2  4  6  9 11 14]\n",
      "\n",
      "Test set: Average loss: 220.2230 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  14, Average loss 220.223 Test accuracy 94.710\n",
      "selected users: [ 0  3  4  6 11 12 13]\n",
      "\n",
      "Test set: Average loss: 257.3120 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  15, Average loss 257.312 Test accuracy 94.300\n",
      "selected users: [ 2  3  4  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 116.4959 \n",
      "Accuracy: 9285/10000 (92.85%)\n",
      "\n",
      "Round  16, Average loss 116.496 Test accuracy 92.850\n",
      "selected users: [ 4  6  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 414.5434 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  17, Average loss 414.543 Test accuracy 94.080\n",
      "selected users: [ 2  3  4  6  7  9 11]\n",
      "\n",
      "Test set: Average loss: 466.7422 \n",
      "Accuracy: 9400/10000 (94.00%)\n",
      "\n",
      "Round  18, Average loss 466.742 Test accuracy 94.000\n",
      "selected users: [ 0  2  3  6  7 11 14]\n",
      "\n",
      "Test set: Average loss: 581.0648 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round  19, Average loss 581.065 Test accuracy 93.930\n",
      "selected users: [ 0  3  4  5  8 10 13]\n",
      "\n",
      "Test set: Average loss: 307.3502 \n",
      "Accuracy: 9163/10000 (91.63%)\n",
      "\n",
      "Round  20, Average loss 307.350 Test accuracy 91.630\n",
      "selected users: [1 2 3 4 5 6 8]\n",
      "\n",
      "Test set: Average loss: 172.3853 \n",
      "Accuracy: 9217/10000 (92.17%)\n",
      "\n",
      "Round  21, Average loss 172.385 Test accuracy 92.170\n",
      "selected users: [ 1  5  6  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 199.3607 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  22, Average loss 199.361 Test accuracy 93.380\n",
      "selected users: [ 1  2  4  6  7 11 14]\n",
      "\n",
      "Test set: Average loss: 469.2688 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round  23, Average loss 469.269 Test accuracy 93.960\n",
      "selected users: [ 1  6  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 446.5032 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round  24, Average loss 446.503 Test accuracy 94.550\n",
      "selected users: [ 0  2  3  4  6  7 12]\n",
      "\n",
      "Test set: Average loss: 130.7583 \n",
      "Accuracy: 9173/10000 (91.73%)\n",
      "\n",
      "Round  25, Average loss 130.758 Test accuracy 91.730\n",
      "selected users: [0 1 3 4 5 6 9]\n",
      "\n",
      "Test set: Average loss: 348.4445 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  26, Average loss 348.445 Test accuracy 94.410\n",
      "selected users: [ 3  4  5  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 263.8026 \n",
      "Accuracy: 9303/10000 (93.03%)\n",
      "\n",
      "Round  27, Average loss 263.803 Test accuracy 93.030\n",
      "selected users: [ 0  2  5  6  7 12 14]\n",
      "\n",
      "Test set: Average loss: 99.0542 \n",
      "Accuracy: 8810/10000 (88.10%)\n",
      "\n",
      "Round  28, Average loss 99.054 Test accuracy 88.100\n",
      "selected users: [ 0  2  3  4  9 12 13]\n",
      "\n",
      "Test set: Average loss: 248.8327 \n",
      "Accuracy: 9330/10000 (93.30%)\n",
      "\n",
      "Round  29, Average loss 248.833 Test accuracy 93.300\n",
      "(m= 7 )  9 -th Trial!!\n",
      "selected users: [ 3  4  5  6  8 10 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  5  9 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1414 \n",
      "Accuracy: 3755/10000 (37.55%)\n",
      "\n",
      "Round   1, Average loss 2.141 Test accuracy 37.550\n",
      "selected users: [ 3  5  6  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 1.2254 \n",
      "Accuracy: 8973/10000 (89.73%)\n",
      "\n",
      "Round   2, Average loss 1.225 Test accuracy 89.730\n",
      "selected users: [ 0  5  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 8.8051 \n",
      "Accuracy: 9251/10000 (92.51%)\n",
      "\n",
      "Round   3, Average loss 8.805 Test accuracy 92.510\n",
      "selected users: [ 0  4  5  6  8 11 12]\n",
      "\n",
      "Test set: Average loss: 8.8207 \n",
      "Accuracy: 9370/10000 (93.70%)\n",
      "\n",
      "Round   4, Average loss 8.821 Test accuracy 93.700\n",
      "selected users: [ 0  3  5  7  9 11 14]\n",
      "\n",
      "Test set: Average loss: 46.6679 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round   5, Average loss 46.668 Test accuracy 93.520\n",
      "selected users: [ 0  3  4  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 100.2335 \n",
      "Accuracy: 9326/10000 (93.26%)\n",
      "\n",
      "Round   6, Average loss 100.233 Test accuracy 93.260\n",
      "selected users: [ 1  4  5  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 84.8837 \n",
      "Accuracy: 9326/10000 (93.26%)\n",
      "\n",
      "Round   7, Average loss 84.884 Test accuracy 93.260\n",
      "selected users: [ 0  1  5  7  8 10 11]\n",
      "\n",
      "Test set: Average loss: 305.1660 \n",
      "Accuracy: 9336/10000 (93.36%)\n",
      "\n",
      "Round   8, Average loss 305.166 Test accuracy 93.360\n",
      "selected users: [ 4  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 291.7148 \n",
      "Accuracy: 9425/10000 (94.25%)\n",
      "\n",
      "Round   9, Average loss 291.715 Test accuracy 94.250\n",
      "selected users: [ 0  5  6  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 364.6500 \n",
      "Accuracy: 9312/10000 (93.12%)\n",
      "\n",
      "Round  10, Average loss 364.650 Test accuracy 93.120\n",
      "selected users: [ 0  5  6  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 1109.9584 \n",
      "Accuracy: 9224/10000 (92.24%)\n",
      "\n",
      "Round  11, Average loss 1109.958 Test accuracy 92.240\n",
      "selected users: [ 1  4  6  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 940.0937 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round  12, Average loss 940.094 Test accuracy 93.180\n",
      "selected users: [ 1  3  6  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 380.9632 \n",
      "Accuracy: 9288/10000 (92.88%)\n",
      "\n",
      "Round  13, Average loss 380.963 Test accuracy 92.880\n",
      "selected users: [ 0  1  2  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 115.8829 \n",
      "Accuracy: 9050/10000 (90.50%)\n",
      "\n",
      "Round  14, Average loss 115.883 Test accuracy 90.500\n",
      "selected users: [ 2  4  6  7  9 11 12]\n",
      "\n",
      "Test set: Average loss: 58.8286 \n",
      "Accuracy: 8901/10000 (89.01%)\n",
      "\n",
      "Round  15, Average loss 58.829 Test accuracy 89.010\n",
      "selected users: [ 0  4  5  6  9 13 14]\n",
      "\n",
      "Test set: Average loss: 297.1752 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round  16, Average loss 297.175 Test accuracy 93.180\n",
      "selected users: [ 0  2  4  5  8 11 13]\n",
      "\n",
      "Test set: Average loss: 159.8130 \n",
      "Accuracy: 9196/10000 (91.96%)\n",
      "\n",
      "Round  17, Average loss 159.813 Test accuracy 91.960\n",
      "selected users: [ 0  1  3  4  6 11 12]\n",
      "\n",
      "Test set: Average loss: 182.2767 \n",
      "Accuracy: 9331/10000 (93.31%)\n",
      "\n",
      "Round  18, Average loss 182.277 Test accuracy 93.310\n",
      "selected users: [ 0  1  4 10 11 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 743.3543 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round  19, Average loss 743.354 Test accuracy 92.490\n",
      "selected users: [ 0  1  4  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 893.3472 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round  20, Average loss 893.347 Test accuracy 93.710\n",
      "selected users: [1 2 4 5 7 8 9]\n",
      "\n",
      "Test set: Average loss: 897.9828 \n",
      "Accuracy: 9426/10000 (94.26%)\n",
      "\n",
      "Round  21, Average loss 897.983 Test accuracy 94.260\n",
      "selected users: [ 3  4  5 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 687.4632 \n",
      "Accuracy: 9072/10000 (90.72%)\n",
      "\n",
      "Round  22, Average loss 687.463 Test accuracy 90.720\n",
      "selected users: [ 0  1  2  5  9 12 13]\n",
      "\n",
      "Test set: Average loss: 481.5670 \n",
      "Accuracy: 9278/10000 (92.78%)\n",
      "\n",
      "Round  23, Average loss 481.567 Test accuracy 92.780\n",
      "selected users: [ 0  1  3  4  7  9 10]\n",
      "\n",
      "Test set: Average loss: 882.6590 \n",
      "Accuracy: 9140/10000 (91.40%)\n",
      "\n",
      "Round  24, Average loss 882.659 Test accuracy 91.400\n",
      "selected users: [ 0  3  4  5  8 11 14]\n",
      "\n",
      "Test set: Average loss: 776.1674 \n",
      "Accuracy: 9227/10000 (92.27%)\n",
      "\n",
      "Round  25, Average loss 776.167 Test accuracy 92.270\n",
      "selected users: [ 0  1  4  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 396.3190 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round  26, Average loss 396.319 Test accuracy 93.370\n",
      "selected users: [ 1  3  4  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 361.9635 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round  27, Average loss 361.964 Test accuracy 93.240\n",
      "selected users: [ 1  3  4  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 715.5107 \n",
      "Accuracy: 9384/10000 (93.84%)\n",
      "\n",
      "Round  28, Average loss 715.511 Test accuracy 93.840\n",
      "selected users: [ 0  4  5  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 2747.5988 \n",
      "Accuracy: 9098/10000 (90.98%)\n",
      "\n",
      "Round  29, Average loss 2747.599 Test accuracy 90.980\n",
      "number of results: 8\n",
      "(m= 8 )  0 -th Trial!!\n",
      "selected users: [ 0  1  3  5  6  7  9 10]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  4  5  6  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.2981 \n",
      "Accuracy: 1905/10000 (19.05%)\n",
      "\n",
      "Round   1, Average loss 2.298 Test accuracy 19.050\n",
      "selected users: [ 0  1  2  6  7  8 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5529 \n",
      "Accuracy: 8999/10000 (89.99%)\n",
      "\n",
      "Round   2, Average loss 0.553 Test accuracy 89.990\n",
      "selected users: [ 1  3  5  6  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 1.7421 \n",
      "Accuracy: 9164/10000 (91.64%)\n",
      "\n",
      "Round   3, Average loss 1.742 Test accuracy 91.640\n",
      "selected users: [ 0  1  2  3  5  6 13 14]\n",
      "\n",
      "Test set: Average loss: 178.3406 \n",
      "Accuracy: 27/10000 (0.27%)\n",
      "\n",
      "Round   4, Average loss 178.341 Test accuracy 0.270\n",
      "selected users: [ 0  2  4  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 2.2867 \n",
      "Accuracy: 1207/10000 (12.07%)\n",
      "\n",
      "Round   5, Average loss 2.287 Test accuracy 12.070\n",
      "selected users: [ 0  1  2  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 2.0349 \n",
      "Accuracy: 8246/10000 (82.46%)\n",
      "\n",
      "Round   6, Average loss 2.035 Test accuracy 82.460\n",
      "selected users: [ 3  4  5  6  7  9 11 12]\n",
      "\n",
      "Test set: Average loss: 0.1789 \n",
      "Accuracy: 9516/10000 (95.16%)\n",
      "\n",
      "Round   7, Average loss 0.179 Test accuracy 95.160\n",
      "selected users: [ 0  1  3  7  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 0.1647 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round   8, Average loss 0.165 Test accuracy 95.750\n",
      "selected users: [ 1  3  4  6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 4.5748 \n",
      "Accuracy: 9316/10000 (93.16%)\n",
      "\n",
      "Round   9, Average loss 4.575 Test accuracy 93.160\n",
      "selected users: [ 0  3  5  6 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0931 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  10, Average loss 2.093 Test accuracy 95.080\n",
      "selected users: [ 7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.4436 \n",
      "Accuracy: 6013/10000 (60.13%)\n",
      "\n",
      "Round  11, Average loss 10.444 Test accuracy 60.130\n",
      "selected users: [ 6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8441 \n",
      "Accuracy: 9241/10000 (92.41%)\n",
      "\n",
      "Round  12, Average loss 1.844 Test accuracy 92.410\n",
      "selected users: [ 1  2  3  4  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 8.4533 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round  13, Average loss 8.453 Test accuracy 94.840\n",
      "selected users: [ 1  4  5  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 16.0744 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round  14, Average loss 16.074 Test accuracy 95.040\n",
      "selected users: [ 2  3  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5884 \n",
      "Accuracy: 9405/10000 (94.05%)\n",
      "\n",
      "Round  15, Average loss 1.588 Test accuracy 94.050\n",
      "selected users: [ 2  4  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 13.6138 \n",
      "Accuracy: 9327/10000 (93.27%)\n",
      "\n",
      "Round  16, Average loss 13.614 Test accuracy 93.270\n",
      "selected users: [ 0  2  5  6  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 5.8526 \n",
      "Accuracy: 9147/10000 (91.47%)\n",
      "\n",
      "Round  17, Average loss 5.853 Test accuracy 91.470\n",
      "selected users: [ 0  2  3  5  6  9 13 14]\n",
      "\n",
      "Test set: Average loss: 16.6475 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round  18, Average loss 16.648 Test accuracy 93.240\n",
      "selected users: [ 2  3  4  6  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 16.2163 \n",
      "Accuracy: 9192/10000 (91.92%)\n",
      "\n",
      "Round  19, Average loss 16.216 Test accuracy 91.920\n",
      "selected users: [ 0  1  2  4  5 10 11 14]\n",
      "\n",
      "Test set: Average loss: 108.4253 \n",
      "Accuracy: 9284/10000 (92.84%)\n",
      "\n",
      "Round  20, Average loss 108.425 Test accuracy 92.840\n",
      "selected users: [ 0  3  5  6  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 54.5088 \n",
      "Accuracy: 9135/10000 (91.35%)\n",
      "\n",
      "Round  21, Average loss 54.509 Test accuracy 91.350\n",
      "selected users: [ 0  1  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.4955 \n",
      "Accuracy: 4874/10000 (48.74%)\n",
      "\n",
      "Round  22, Average loss 2.496 Test accuracy 48.740\n",
      "selected users: [ 1  4  5  6  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2471 \n",
      "Accuracy: 8109/10000 (81.09%)\n",
      "\n",
      "Round  23, Average loss 1.247 Test accuracy 81.090\n",
      "selected users: [ 0  1  3  4  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3431 \n",
      "Accuracy: 9194/10000 (91.94%)\n",
      "\n",
      "Round  24, Average loss 0.343 Test accuracy 91.940\n",
      "selected users: [ 1  3  5  6 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8493 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  25, Average loss 0.849 Test accuracy 94.020\n",
      "selected users: [ 1  2  3  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9937 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  26, Average loss 0.994 Test accuracy 94.960\n",
      "selected users: [ 1  2  5  6  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8281 \n",
      "Accuracy: 9117/10000 (91.17%)\n",
      "\n",
      "Round  27, Average loss 2.828 Test accuracy 91.170\n",
      "selected users: [ 3  4  5  6  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.7984 \n",
      "Accuracy: 9494/10000 (94.94%)\n",
      "\n",
      "Round  28, Average loss 2.798 Test accuracy 94.940\n",
      "selected users: [ 0  4  5  6  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 40.8522 \n",
      "Accuracy: 9425/10000 (94.25%)\n",
      "\n",
      "Round  29, Average loss 40.852 Test accuracy 94.250\n",
      "(m= 8 )  1 -th Trial!!\n",
      "selected users: [ 1  2  3  5  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  4  5  7  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1.8178 \n",
      "Accuracy: 7077/10000 (70.77%)\n",
      "\n",
      "Round   1, Average loss 1.818 Test accuracy 70.770\n",
      "selected users: [ 2  3  5  6  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.2536 \n",
      "Accuracy: 8602/10000 (86.02%)\n",
      "\n",
      "Round   2, Average loss 1.254 Test accuracy 86.020\n",
      "selected users: [ 0  1  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 400.1250 \n",
      "Accuracy: 186/10000 (1.86%)\n",
      "\n",
      "Round   3, Average loss 400.125 Test accuracy 1.860\n",
      "selected users: [ 0  2  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 2 3 4 5 6 7 9]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   5, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2279 \n",
      "Accuracy: 4098/10000 (40.98%)\n",
      "\n",
      "Round   6, Average loss 2.228 Test accuracy 40.980\n",
      "selected users: [ 0  1  4  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.5202 \n",
      "Accuracy: 9363/10000 (93.63%)\n",
      "\n",
      "Round   7, Average loss 0.520 Test accuracy 93.630\n",
      "selected users: [ 1  2  5  6  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 9.3100 \n",
      "Accuracy: 8875/10000 (88.75%)\n",
      "\n",
      "Round   8, Average loss 9.310 Test accuracy 88.750\n",
      "selected users: [ 0  2  4  5  6  7  8 12]\n",
      "\n",
      "Test set: Average loss: 1.2200 \n",
      "Accuracy: 8770/10000 (87.70%)\n",
      "\n",
      "Round   9, Average loss 1.220 Test accuracy 87.700\n",
      "selected users: [ 1  4  5  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 2.2798 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round  10, Average loss 2.280 Test accuracy 92.740\n",
      "selected users: [ 0  3  4  5  6  9 10 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 24.5883 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  11, Average loss 24.588 Test accuracy 94.810\n",
      "selected users: [ 0  1  3  4 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 339.6837 \n",
      "Accuracy: 9099/10000 (90.99%)\n",
      "\n",
      "Round  12, Average loss 339.684 Test accuracy 90.990\n",
      "selected users: [ 0  1  4  6  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 48.4704 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round  13, Average loss 48.470 Test accuracy 94.880\n",
      "selected users: [ 2  3  4  6  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 66.4203 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  14, Average loss 66.420 Test accuracy 94.630\n",
      "selected users: [ 1  2  3  6  7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 23.1312 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  15, Average loss 23.131 Test accuracy 94.280\n",
      "selected users: [ 0  2  3  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 29.9469 \n",
      "Accuracy: 9365/10000 (93.65%)\n",
      "\n",
      "Round  16, Average loss 29.947 Test accuracy 93.650\n",
      "selected users: [ 1  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 58.1991 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  17, Average loss 58.199 Test accuracy 94.920\n",
      "selected users: [ 0  1  2  4  5  6 11 14]\n",
      "\n",
      "Test set: Average loss: 89.2081 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  18, Average loss 89.208 Test accuracy 95.390\n",
      "selected users: [ 0  1  3  4  6  9 10 11]\n",
      "\n",
      "Test set: Average loss: 90.7529 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  19, Average loss 90.753 Test accuracy 95.390\n",
      "selected users: [ 1  4  5  6  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 142.7098 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  20, Average loss 142.710 Test accuracy 95.080\n",
      "selected users: [ 4  5  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 155.9779 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  21, Average loss 155.978 Test accuracy 94.490\n",
      "selected users: [ 2  3  6  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 65.4741 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round  22, Average loss 65.474 Test accuracy 93.930\n",
      "selected users: [ 0  4  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 170.9443 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round  23, Average loss 170.944 Test accuracy 94.750\n",
      "selected users: [ 2  3  5  6  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 59.2884 \n",
      "Accuracy: 9342/10000 (93.42%)\n",
      "\n",
      "Round  24, Average loss 59.288 Test accuracy 93.420\n",
      "selected users: [ 5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 462.0853 \n",
      "Accuracy: 9154/10000 (91.54%)\n",
      "\n",
      "Round  25, Average loss 462.085 Test accuracy 91.540\n",
      "selected users: [ 0  3  4  5  7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 82.8121 \n",
      "Accuracy: 9245/10000 (92.45%)\n",
      "\n",
      "Round  26, Average loss 82.812 Test accuracy 92.450\n",
      "selected users: [ 1  3  5  6  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 35.5663 \n",
      "Accuracy: 9111/10000 (91.11%)\n",
      "\n",
      "Round  27, Average loss 35.566 Test accuracy 91.110\n",
      "selected users: [ 1  2  3  4  6  9 10 11]\n",
      "\n",
      "Test set: Average loss: 85.9374 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  28, Average loss 85.937 Test accuracy 94.960\n",
      "selected users: [ 0  1  2  5  6 10 11 14]\n",
      "\n",
      "Test set: Average loss: 106.4588 \n",
      "Accuracy: 9417/10000 (94.17%)\n",
      "\n",
      "Round  29, Average loss 106.459 Test accuracy 94.170\n",
      "(m= 8 )  2 -th Trial!!\n",
      "selected users: [ 0  3  5  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  4  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.2693 \n",
      "Accuracy: 5038/10000 (50.38%)\n",
      "\n",
      "Round   1, Average loss 2.269 Test accuracy 50.380\n",
      "selected users: [ 2  3  4  6  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2932 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round   2, Average loss 0.293 Test accuracy 93.810\n",
      "selected users: [ 0  2  3  4  6  7  9 11]\n",
      "\n",
      "Test set: Average loss: 9.2666 \n",
      "Accuracy: 9444/10000 (94.44%)\n",
      "\n",
      "Round   3, Average loss 9.267 Test accuracy 94.440\n",
      "selected users: [ 1  2  3  4  6 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.8858 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round   4, Average loss 6.886 Test accuracy 95.290\n",
      "selected users: [ 0  1  2  3  5  9 10 11]\n",
      "\n",
      "Test set: Average loss: 15.2541 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round   5, Average loss 15.254 Test accuracy 95.100\n",
      "selected users: [ 0  1  2  3  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.9013 \n",
      "Accuracy: 7110/10000 (71.10%)\n",
      "\n",
      "Round   6, Average loss 0.901 Test accuracy 71.100\n",
      "selected users: [ 2  4  5  6  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 3.9368 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round   7, Average loss 3.937 Test accuracy 92.210\n",
      "selected users: [ 1  3  4  6  7 10 11 12]\n",
      "\n",
      "Test set: Average loss: 4.8797 \n",
      "Accuracy: 9217/10000 (92.17%)\n",
      "\n",
      "Round   8, Average loss 4.880 Test accuracy 92.170\n",
      "selected users: [ 1  2  3  5  6  7 11 12]\n",
      "\n",
      "Test set: Average loss: 5.7165 \n",
      "Accuracy: 8900/10000 (89.00%)\n",
      "\n",
      "Round   9, Average loss 5.716 Test accuracy 89.000\n",
      "selected users: [ 1  2  4  6  7  8  9 12]\n",
      "\n",
      "Test set: Average loss: 3.1102 \n",
      "Accuracy: 9315/10000 (93.15%)\n",
      "\n",
      "Round  10, Average loss 3.110 Test accuracy 93.150\n",
      "selected users: [ 0  3  6  7  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 0.8066 \n",
      "Accuracy: 8335/10000 (83.35%)\n",
      "\n",
      "Round  11, Average loss 0.807 Test accuracy 83.350\n",
      "selected users: [ 0  4  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 15.3210 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round  12, Average loss 15.321 Test accuracy 93.100\n",
      "selected users: [ 0  1  3  4  5  6 10 11]\n",
      "\n",
      "Test set: Average loss: 25.8929 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  13, Average loss 25.893 Test accuracy 95.060\n",
      "selected users: [ 2  4  6  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 12.9132 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round  14, Average loss 12.913 Test accuracy 93.110\n",
      "selected users: [ 0  2  6  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0194 \n",
      "Accuracy: 7252/10000 (72.52%)\n",
      "\n",
      "Round  15, Average loss 1.019 Test accuracy 72.520\n",
      "selected users: [ 0  4  5  7  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 27.2383 \n",
      "Accuracy: 9373/10000 (93.73%)\n",
      "\n",
      "Round  16, Average loss 27.238 Test accuracy 93.730\n",
      "selected users: [ 2  3  5  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 21.5325 \n",
      "Accuracy: 9103/10000 (91.03%)\n",
      "\n",
      "Round  17, Average loss 21.532 Test accuracy 91.030\n",
      "selected users: [ 2  3  4  6  7  8 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8745 \n",
      "Accuracy: 8111/10000 (81.11%)\n",
      "\n",
      "Round  18, Average loss 1.875 Test accuracy 81.110\n",
      "selected users: [ 0  2  3  6  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 4.7268 \n",
      "Accuracy: 9157/10000 (91.57%)\n",
      "\n",
      "Round  19, Average loss 4.727 Test accuracy 91.570\n",
      "selected users: [ 3  4  6  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 1.0987 \n",
      "Accuracy: 7938/10000 (79.38%)\n",
      "\n",
      "Round  20, Average loss 1.099 Test accuracy 79.380\n",
      "selected users: [ 0  5  6  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 76.9698 \n",
      "Accuracy: 9164/10000 (91.64%)\n",
      "\n",
      "Round  21, Average loss 76.970 Test accuracy 91.640\n",
      "selected users: [ 0  5  6  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 102.7406 \n",
      "Accuracy: 9142/10000 (91.42%)\n",
      "\n",
      "Round  22, Average loss 102.741 Test accuracy 91.420\n",
      "selected users: [ 0  1  3  6  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 16.3414 \n",
      "Accuracy: 9344/10000 (93.44%)\n",
      "\n",
      "Round  23, Average loss 16.341 Test accuracy 93.440\n",
      "selected users: [ 0  1  4  6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 51.9752 \n",
      "Accuracy: 9345/10000 (93.45%)\n",
      "\n",
      "Round  24, Average loss 51.975 Test accuracy 93.450\n",
      "selected users: [ 0  3  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 50.1827 \n",
      "Accuracy: 9405/10000 (94.05%)\n",
      "\n",
      "Round  25, Average loss 50.183 Test accuracy 94.050\n",
      "selected users: [ 0  2  3  5  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 98.5837 \n",
      "Accuracy: 9148/10000 (91.48%)\n",
      "\n",
      "Round  26, Average loss 98.584 Test accuracy 91.480\n",
      "selected users: [ 3  4  5  6  7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 11.6558 \n",
      "Accuracy: 9120/10000 (91.20%)\n",
      "\n",
      "Round  27, Average loss 11.656 Test accuracy 91.200\n",
      "selected users: [ 2  3  5  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 47.9652 \n",
      "Accuracy: 9152/10000 (91.52%)\n",
      "\n",
      "Round  28, Average loss 47.965 Test accuracy 91.520\n",
      "selected users: [ 0  3  4  5  6  7  9 10]\n",
      "\n",
      "Test set: Average loss: 462.7358 \n",
      "Accuracy: 8421/10000 (84.21%)\n",
      "\n",
      "Round  29, Average loss 462.736 Test accuracy 84.210\n",
      "(m= 8 )  3 -th Trial!!\n",
      "selected users: [ 0  2  5  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  4  6  7  9 14]\n",
      "\n",
      "Test set: Average loss: 1.4386 \n",
      "Accuracy: 8270/10000 (82.70%)\n",
      "\n",
      "Round   1, Average loss 1.439 Test accuracy 82.700\n",
      "selected users: [ 1  2  3 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6218 \n",
      "Accuracy: 8976/10000 (89.76%)\n",
      "\n",
      "Round   2, Average loss 3.622 Test accuracy 89.760\n",
      "selected users: [ 0  4  6  7  8 10 11 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 7.5832 \n",
      "Accuracy: 9216/10000 (92.16%)\n",
      "\n",
      "Round   3, Average loss 7.583 Test accuracy 92.160\n",
      "selected users: [ 0  1  2  4  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 16.2889 \n",
      "Accuracy: 9313/10000 (93.13%)\n",
      "\n",
      "Round   4, Average loss 16.289 Test accuracy 93.130\n",
      "selected users: [ 0  1  2  5  6  7 11 14]\n",
      "\n",
      "Test set: Average loss: 23.0270 \n",
      "Accuracy: 9319/10000 (93.19%)\n",
      "\n",
      "Round   5, Average loss 23.027 Test accuracy 93.190\n",
      "selected users: [ 0  5  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 98.7699 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round   6, Average loss 98.770 Test accuracy 92.210\n",
      "selected users: [ 0  1  2  4  5 11 12 14]\n",
      "\n",
      "Test set: Average loss: 163.0338 \n",
      "Accuracy: 9277/10000 (92.77%)\n",
      "\n",
      "Round   7, Average loss 163.034 Test accuracy 92.770\n",
      "selected users: [ 1  2  4  6  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 83.3827 \n",
      "Accuracy: 9380/10000 (93.80%)\n",
      "\n",
      "Round   8, Average loss 83.383 Test accuracy 93.800\n",
      "selected users: [ 3  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 35.0349 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round   9, Average loss 35.035 Test accuracy 93.750\n",
      "selected users: [ 0  1  4  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 95.1057 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round  10, Average loss 95.106 Test accuracy 94.750\n",
      "selected users: [ 0  2  4  5  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 103.6162 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round  11, Average loss 103.616 Test accuracy 93.430\n",
      "selected users: [ 1  2  3  4  5  7  9 13]\n",
      "\n",
      "Test set: Average loss: 30.9737 \n",
      "Accuracy: 9242/10000 (92.42%)\n",
      "\n",
      "Round  12, Average loss 30.974 Test accuracy 92.420\n",
      "selected users: [ 1  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 74.8309 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  13, Average loss 74.831 Test accuracy 94.870\n",
      "selected users: [ 1  2  5  6  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 13.5949 \n",
      "Accuracy: 9002/10000 (90.02%)\n",
      "\n",
      "Round  14, Average loss 13.595 Test accuracy 90.020\n",
      "selected users: [ 0  1  2  4  5  6 11 14]\n",
      "\n",
      "Test set: Average loss: 59.4292 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  15, Average loss 59.429 Test accuracy 95.420\n",
      "selected users: [ 4  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 114.2634 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round  16, Average loss 114.263 Test accuracy 94.680\n",
      "selected users: [ 0  2  3  4  5  7  8 13]\n",
      "\n",
      "Test set: Average loss: 40.4799 \n",
      "Accuracy: 9125/10000 (91.25%)\n",
      "\n",
      "Round  17, Average loss 40.480 Test accuracy 91.250\n",
      "selected users: [ 2  4  5  6  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 5.1546 \n",
      "Accuracy: 8452/10000 (84.52%)\n",
      "\n",
      "Round  18, Average loss 5.155 Test accuracy 84.520\n",
      "selected users: [ 0  4  5  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 105.4330 \n",
      "Accuracy: 9361/10000 (93.61%)\n",
      "\n",
      "Round  19, Average loss 105.433 Test accuracy 93.610\n",
      "selected users: [ 2  4  5  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 3.7930 \n",
      "Accuracy: 8474/10000 (84.74%)\n",
      "\n",
      "Round  20, Average loss 3.793 Test accuracy 84.740\n",
      "selected users: [ 0  1  2  5  6  8  9 10]\n",
      "\n",
      "Test set: Average loss: 223.0995 \n",
      "Accuracy: 8795/10000 (87.95%)\n",
      "\n",
      "Round  21, Average loss 223.099 Test accuracy 87.950\n",
      "selected users: [ 0  1  3  5  6 11 12 14]\n",
      "\n",
      "Test set: Average loss: 64.7977 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round  22, Average loss 64.798 Test accuracy 93.510\n",
      "selected users: [ 2  4  5  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 90.5589 \n",
      "Accuracy: 8935/10000 (89.35%)\n",
      "\n",
      "Round  23, Average loss 90.559 Test accuracy 89.350\n",
      "selected users: [ 0  2  3  6  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 22.9955 \n",
      "Accuracy: 8990/10000 (89.90%)\n",
      "\n",
      "Round  24, Average loss 22.996 Test accuracy 89.900\n",
      "selected users: [ 2  3  4  5  6  7  9 11]\n",
      "\n",
      "Test set: Average loss: 72.2489 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round  25, Average loss 72.249 Test accuracy 92.740\n",
      "selected users: [ 0  3  4  5  6  9 11 14]\n",
      "\n",
      "Test set: Average loss: 121.6042 \n",
      "Accuracy: 9429/10000 (94.29%)\n",
      "\n",
      "Round  26, Average loss 121.604 Test accuracy 94.290\n",
      "selected users: [ 2  3  4  5  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 51.1348 \n",
      "Accuracy: 8928/10000 (89.28%)\n",
      "\n",
      "Round  27, Average loss 51.135 Test accuracy 89.280\n",
      "selected users: [ 1  2  3  4  6  7 11 14]\n",
      "\n",
      "Test set: Average loss: 85.9712 \n",
      "Accuracy: 9350/10000 (93.50%)\n",
      "\n",
      "Round  28, Average loss 85.971 Test accuracy 93.500\n",
      "selected users: [ 0  1  5  6  7 11 13 14]\n",
      "\n",
      "Test set: Average loss: 104.5200 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round  29, Average loss 104.520 Test accuracy 92.470\n",
      "(m= 8 )  4 -th Trial!!\n",
      "selected users: [ 1  3  4  5  6 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  3  5  6  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 2.2753 \n",
      "Accuracy: 2716/10000 (27.16%)\n",
      "\n",
      "Round   1, Average loss 2.275 Test accuracy 27.160\n",
      "selected users: [ 0  1  3  6  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2422 \n",
      "Accuracy: 9357/10000 (93.57%)\n",
      "\n",
      "Round   2, Average loss 0.242 Test accuracy 93.570\n",
      "selected users: [ 0  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 6.2945 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round   3, Average loss 6.294 Test accuracy 94.840\n",
      "selected users: [ 0  2  3  4  5  6  9 12]\n",
      "\n",
      "Test set: Average loss: 3.0131 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round   4, Average loss 3.013 Test accuracy 94.800\n",
      "selected users: [ 0  2  3  5  6  8 10 12]\n",
      "\n",
      "Test set: Average loss: 4.3398 \n",
      "Accuracy: 9107/10000 (91.07%)\n",
      "\n",
      "Round   5, Average loss 4.340 Test accuracy 91.070\n",
      "selected users: [ 2  4  5  6  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 11.1906 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round   6, Average loss 11.191 Test accuracy 94.300\n",
      "selected users: [ 0  1  3 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.5130 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round   7, Average loss 24.513 Test accuracy 93.280\n",
      "selected users: [ 0  2  3  5  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 472.0973 \n",
      "Accuracy: 8750/10000 (87.50%)\n",
      "\n",
      "Round   8, Average loss 472.097 Test accuracy 87.500\n",
      "selected users: [ 1  3  5  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 80.1700 \n",
      "Accuracy: 9064/10000 (90.64%)\n",
      "\n",
      "Round   9, Average loss 80.170 Test accuracy 90.640\n",
      "selected users: [ 2  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 23.5431 \n",
      "Accuracy: 9133/10000 (91.33%)\n",
      "\n",
      "Round  10, Average loss 23.543 Test accuracy 91.330\n",
      "selected users: [ 0  2  3  4  5  8  9 13]\n",
      "\n",
      "Test set: Average loss: 39.4093 \n",
      "Accuracy: 9048/10000 (90.48%)\n",
      "\n",
      "Round  11, Average loss 39.409 Test accuracy 90.480\n",
      "selected users: [ 3  4  5  6  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 6.2567 \n",
      "Accuracy: 8837/10000 (88.37%)\n",
      "\n",
      "Round  12, Average loss 6.257 Test accuracy 88.370\n",
      "selected users: [ 0  2  3  4  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 63.2760 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round  13, Average loss 63.276 Test accuracy 93.830\n",
      "selected users: [ 0  4  5  6  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 128.2918 \n",
      "Accuracy: 9422/10000 (94.22%)\n",
      "\n",
      "Round  14, Average loss 128.292 Test accuracy 94.220\n",
      "selected users: [ 0  1  4  5  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 34.0332 \n",
      "Accuracy: 9293/10000 (92.93%)\n",
      "\n",
      "Round  15, Average loss 34.033 Test accuracy 92.930\n",
      "selected users: [ 1  2  3  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 10.7640 \n",
      "Accuracy: 9091/10000 (90.91%)\n",
      "\n",
      "Round  16, Average loss 10.764 Test accuracy 90.910\n",
      "selected users: [ 0  1  4  5 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 326.1025 \n",
      "Accuracy: 8922/10000 (89.22%)\n",
      "\n",
      "Round  17, Average loss 326.103 Test accuracy 89.220\n",
      "selected users: [ 0  2  4  6  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 283.3585 \n",
      "Accuracy: 9045/10000 (90.45%)\n",
      "\n",
      "Round  18, Average loss 283.359 Test accuracy 90.450\n",
      "selected users: [ 0  1  2  3  7 10 12 13]\n",
      "\n",
      "Test set: Average loss: 10.7418 \n",
      "Accuracy: 8863/10000 (88.63%)\n",
      "\n",
      "Round  19, Average loss 10.742 Test accuracy 88.630\n",
      "selected users: [ 1  2  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.2912 \n",
      "Accuracy: 9284/10000 (92.84%)\n",
      "\n",
      "Round  20, Average loss 22.291 Test accuracy 92.840\n",
      "selected users: [ 0  2  4  5  6  9 10 12]\n",
      "\n",
      "Test set: Average loss: 11.7383 \n",
      "Accuracy: 9107/10000 (91.07%)\n",
      "\n",
      "Round  21, Average loss 11.738 Test accuracy 91.070\n",
      "selected users: [ 1  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 29.9390 \n",
      "Accuracy: 9364/10000 (93.64%)\n",
      "\n",
      "Round  22, Average loss 29.939 Test accuracy 93.640\n",
      "selected users: [ 0  3  5  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 23.6672 \n",
      "Accuracy: 9006/10000 (90.06%)\n",
      "\n",
      "Round  23, Average loss 23.667 Test accuracy 90.060\n",
      "selected users: [ 0  2  4  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 10.1826 \n",
      "Accuracy: 8907/10000 (89.07%)\n",
      "\n",
      "Round  24, Average loss 10.183 Test accuracy 89.070\n",
      "selected users: [ 4  5  6 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 56.8131 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  25, Average loss 56.813 Test accuracy 94.080\n",
      "selected users: [ 0  1  2  5  6  8 11 12]\n",
      "\n",
      "Test set: Average loss: 5.2906 \n",
      "Accuracy: 8778/10000 (87.78%)\n",
      "\n",
      "Round  26, Average loss 5.291 Test accuracy 87.780\n",
      "selected users: [ 2  3  5  6  7  9 11 14]\n",
      "\n",
      "Test set: Average loss: 28.1057 \n",
      "Accuracy: 9327/10000 (93.27%)\n",
      "\n",
      "Round  27, Average loss 28.106 Test accuracy 93.270\n",
      "selected users: [ 2  3  4  5  7  9 10 13]\n",
      "\n",
      "Test set: Average loss: 13.0462 \n",
      "Accuracy: 8331/10000 (83.31%)\n",
      "\n",
      "Round  28, Average loss 13.046 Test accuracy 83.310\n",
      "selected users: [ 1  3  4  5  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 12.8784 \n",
      "Accuracy: 9219/10000 (92.19%)\n",
      "\n",
      "Round  29, Average loss 12.878 Test accuracy 92.190\n",
      "(m= 8 )  5 -th Trial!!\n",
      "selected users: [ 1  2  5  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  4  5  6  7 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2552 \n",
      "Accuracy: 1905/10000 (19.05%)\n",
      "\n",
      "Round   1, Average loss 2.255 Test accuracy 19.050\n",
      "selected users: [ 2  3  4 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6844 \n",
      "Accuracy: 9128/10000 (91.28%)\n",
      "\n",
      "Round   2, Average loss 0.684 Test accuracy 91.280\n",
      "selected users: [ 1  2  6  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3764 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round   3, Average loss 0.376 Test accuracy 94.200\n",
      "selected users: [ 1  4  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.8091 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round   4, Average loss 3.809 Test accuracy 94.410\n",
      "selected users: [ 0  3  4  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 15.1304 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round   5, Average loss 15.130 Test accuracy 94.200\n",
      "selected users: [ 0  1  3  4  7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 3.8795 \n",
      "Accuracy: 9419/10000 (94.19%)\n",
      "\n",
      "Round   6, Average loss 3.879 Test accuracy 94.190\n",
      "selected users: [ 1  3  4  5  6  8 10 12]\n",
      "\n",
      "Test set: Average loss: 3.4929 \n",
      "Accuracy: 9196/10000 (91.96%)\n",
      "\n",
      "Round   7, Average loss 3.493 Test accuracy 91.960\n",
      "selected users: [ 1  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 31.1148 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round   8, Average loss 31.115 Test accuracy 94.650\n",
      "selected users: [ 0  1  2  4  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 9.8382 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round   9, Average loss 9.838 Test accuracy 94.280\n",
      "selected users: [ 0  1  2  5  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 59.9195 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round  10, Average loss 59.920 Test accuracy 94.330\n",
      "selected users: [ 1  2  3  6  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 56.1069 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round  11, Average loss 56.107 Test accuracy 94.640\n",
      "selected users: [ 2  4  5  6  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 36.6454 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  12, Average loss 36.645 Test accuracy 93.660\n",
      "selected users: [ 0  2  4  5  7 11 12 13]\n",
      "\n",
      "Test set: Average loss: 44.7998 \n",
      "Accuracy: 9196/10000 (91.96%)\n",
      "\n",
      "Round  13, Average loss 44.800 Test accuracy 91.960\n",
      "selected users: [ 0  2  4  7  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 23.3526 \n",
      "Accuracy: 9060/10000 (90.60%)\n",
      "\n",
      "Round  14, Average loss 23.353 Test accuracy 90.600\n",
      "selected users: [ 2  3  4  5  7  8 12 13]\n",
      "\n",
      "Test set: Average loss: 3.6808 \n",
      "Accuracy: 7901/10000 (79.01%)\n",
      "\n",
      "Round  15, Average loss 3.681 Test accuracy 79.010\n",
      "selected users: [ 0  4  5  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 42.9286 \n",
      "Accuracy: 9230/10000 (92.30%)\n",
      "\n",
      "Round  16, Average loss 42.929 Test accuracy 92.300\n",
      "selected users: [ 0  1  2  3  4  5  9 10]\n",
      "\n",
      "Test set: Average loss: 696.8636 \n",
      "Accuracy: 8568/10000 (85.68%)\n",
      "\n",
      "Round  17, Average loss 696.864 Test accuracy 85.680\n",
      "selected users: [ 0  1  5  6 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 177.4129 \n",
      "Accuracy: 8974/10000 (89.74%)\n",
      "\n",
      "Round  18, Average loss 177.413 Test accuracy 89.740\n",
      "selected users: [ 2  3  5  6  7  9 12 13]\n",
      "\n",
      "Test set: Average loss: 12.8178 \n",
      "Accuracy: 8893/10000 (88.93%)\n",
      "\n",
      "Round  19, Average loss 12.818 Test accuracy 88.930\n",
      "selected users: [ 1  5  6  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 45.9337 \n",
      "Accuracy: 9296/10000 (92.96%)\n",
      "\n",
      "Round  20, Average loss 45.934 Test accuracy 92.960\n",
      "selected users: [ 1  3  4  5  7  8  9 12]\n",
      "\n",
      "Test set: Average loss: 15.2315 \n",
      "Accuracy: 9134/10000 (91.34%)\n",
      "\n",
      "Round  21, Average loss 15.232 Test accuracy 91.340\n",
      "selected users: [ 0  2  3  5  6  8 11 12]\n",
      "\n",
      "Test set: Average loss: 9.0698 \n",
      "Accuracy: 8666/10000 (86.66%)\n",
      "\n",
      "Round  22, Average loss 9.070 Test accuracy 86.660\n",
      "selected users: [ 0  1  2  3  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3014 \n",
      "Accuracy: 1144/10000 (11.44%)\n",
      "\n",
      "Round  23, Average loss 2.301 Test accuracy 11.440\n",
      "selected users: [ 0  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.6649 \n",
      "Accuracy: 7630/10000 (76.30%)\n",
      "\n",
      "Round  24, Average loss 1.665 Test accuracy 76.300\n",
      "selected users: [ 0  1  3  6  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7412 \n",
      "Accuracy: 9423/10000 (94.23%)\n",
      "\n",
      "Round  25, Average loss 0.741 Test accuracy 94.230\n",
      "selected users: [ 1  3  6  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2355 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  26, Average loss 0.235 Test accuracy 95.540\n",
      "selected users: [ 0  3  5  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 1.7449 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round  27, Average loss 1.745 Test accuracy 92.740\n",
      "selected users: [ 1  3  4  5  6  7  8 11]\n",
      "\n",
      "Test set: Average loss: 8.7544 \n",
      "Accuracy: 9444/10000 (94.44%)\n",
      "\n",
      "Round  28, Average loss 8.754 Test accuracy 94.440\n",
      "selected users: [ 0  1  2  4  5  6  8 11]\n",
      "\n",
      "Test set: Average loss: 21.8018 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  29, Average loss 21.802 Test accuracy 94.800\n",
      "(m= 8 )  6 -th Trial!!\n",
      "selected users: [ 1  2  3  4  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 2.2951 \n",
      "Accuracy: 1411/10000 (14.11%)\n",
      "\n",
      "Round   0, Average loss 2.295 Test accuracy 14.110\n",
      "selected users: [ 2  4  6  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 0.8716 \n",
      "Accuracy: 8529/10000 (85.29%)\n",
      "\n",
      "Round   1, Average loss 0.872 Test accuracy 85.290\n",
      "selected users: [ 0  1  3  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3801 \n",
      "Accuracy: 9275/10000 (92.75%)\n",
      "\n",
      "Round   2, Average loss 0.380 Test accuracy 92.750\n",
      "selected users: [ 1  3  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3169 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round   3, Average loss 0.317 Test accuracy 94.790\n",
      "selected users: [ 1  3  6  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.6541 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round   4, Average loss 0.654 Test accuracy 95.620\n",
      "selected users: [ 0  1  4  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9819 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round   5, Average loss 4.982 Test accuracy 95.170\n",
      "selected users: [ 2  3  5  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 10.1278 \n",
      "Accuracy: 9203/10000 (92.03%)\n",
      "\n",
      "Round   6, Average loss 10.128 Test accuracy 92.030\n",
      "selected users: [ 0  1  3  4  5 10 12 13]\n",
      "\n",
      "Test set: Average loss: 54.1620 \n",
      "Accuracy: 9109/10000 (91.09%)\n",
      "\n",
      "Round   7, Average loss 54.162 Test accuracy 91.090\n",
      "selected users: [ 1  3  6  7 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 36.1442 \n",
      "Accuracy: 9217/10000 (92.17%)\n",
      "\n",
      "Round   8, Average loss 36.144 Test accuracy 92.170\n",
      "selected users: [ 0  2  3  5  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 122.0296 \n",
      "Accuracy: 9061/10000 (90.61%)\n",
      "\n",
      "Round   9, Average loss 122.030 Test accuracy 90.610\n",
      "selected users: [ 1  3  4  6 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 157.6669 \n",
      "Accuracy: 9135/10000 (91.35%)\n",
      "\n",
      "Round  10, Average loss 157.667 Test accuracy 91.350\n",
      "selected users: [ 0  3  4  5  6  8  9 12]\n",
      "\n",
      "Test set: Average loss: 29.6284 \n",
      "Accuracy: 9196/10000 (91.96%)\n",
      "\n",
      "Round  11, Average loss 29.628 Test accuracy 91.960\n",
      "selected users: [ 0  4  5  6  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 159.5320 \n",
      "Accuracy: 9299/10000 (92.99%)\n",
      "\n",
      "Round  12, Average loss 159.532 Test accuracy 92.990\n",
      "selected users: [ 3  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 23.3505 \n",
      "Accuracy: 9250/10000 (92.50%)\n",
      "\n",
      "Round  13, Average loss 23.351 Test accuracy 92.500\n",
      "selected users: [ 1  2  3  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 5.8744 \n",
      "Accuracy: 9005/10000 (90.05%)\n",
      "\n",
      "Round  14, Average loss 5.874 Test accuracy 90.050\n",
      "selected users: [ 2  4  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 9.7648 \n",
      "Accuracy: 9270/10000 (92.70%)\n",
      "\n",
      "Round  15, Average loss 9.765 Test accuracy 92.700\n",
      "selected users: [ 2  4  5  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 1.1580 \n",
      "Accuracy: 7016/10000 (70.16%)\n",
      "\n",
      "Round  16, Average loss 1.158 Test accuracy 70.160\n",
      "selected users: [ 0  1  5  6  8 10 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 22.1661 \n",
      "Accuracy: 8792/10000 (87.92%)\n",
      "\n",
      "Round  17, Average loss 22.166 Test accuracy 87.920\n",
      "selected users: [ 0  1  4  5  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 27.6537 \n",
      "Accuracy: 9041/10000 (90.41%)\n",
      "\n",
      "Round  18, Average loss 27.654 Test accuracy 90.410\n",
      "selected users: [ 3  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.6947 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round  19, Average loss 3.695 Test accuracy 92.210\n",
      "selected users: [ 1  5  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 85.6631 \n",
      "Accuracy: 9102/10000 (91.02%)\n",
      "\n",
      "Round  20, Average loss 85.663 Test accuracy 91.020\n",
      "selected users: [ 0  1  3  5  7  9 11 14]\n",
      "\n",
      "Test set: Average loss: 49.1276 \n",
      "Accuracy: 9304/10000 (93.04%)\n",
      "\n",
      "Round  21, Average loss 49.128 Test accuracy 93.040\n",
      "selected users: [ 0  3  5  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 30.6816 \n",
      "Accuracy: 9177/10000 (91.77%)\n",
      "\n",
      "Round  22, Average loss 30.682 Test accuracy 91.770\n",
      "selected users: [ 0  2  3  5  6  9 12 14]\n",
      "\n",
      "Test set: Average loss: 44.5546 \n",
      "Accuracy: 9220/10000 (92.20%)\n",
      "\n",
      "Round  23, Average loss 44.555 Test accuracy 92.200\n",
      "selected users: [ 2  3  4  6  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 58.9435 \n",
      "Accuracy: 9305/10000 (93.05%)\n",
      "\n",
      "Round  24, Average loss 58.944 Test accuracy 93.050\n",
      "selected users: [ 0  1  4  5  6  7 12 13]\n",
      "\n",
      "Test set: Average loss: 1.7928 \n",
      "Accuracy: 7846/10000 (78.46%)\n",
      "\n",
      "Round  25, Average loss 1.793 Test accuracy 78.460\n",
      "selected users: [ 0  1  2  3  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 1.9809 \n",
      "Accuracy: 3718/10000 (37.18%)\n",
      "\n",
      "Round  26, Average loss 1.981 Test accuracy 37.180\n",
      "selected users: [ 1  3  5  6  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4863 \n",
      "Accuracy: 8808/10000 (88.08%)\n",
      "\n",
      "Round  27, Average loss 0.486 Test accuracy 88.080\n",
      "selected users: [ 0  3  4  6 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.2776 \n",
      "Accuracy: 8930/10000 (89.30%)\n",
      "\n",
      "Round  28, Average loss 1.278 Test accuracy 89.300\n",
      "selected users: [ 2  5  6  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.1298 \n",
      "Accuracy: 8803/10000 (88.03%)\n",
      "\n",
      "Round  29, Average loss 2.130 Test accuracy 88.030\n",
      "(m= 8 )  7 -th Trial!!\n",
      "selected users: [ 0  1  3  5  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  5  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1188 \n",
      "Accuracy: 7515/10000 (75.15%)\n",
      "\n",
      "Round   1, Average loss 2.119 Test accuracy 75.150\n",
      "selected users: [ 1  2  5  6  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 1.4780 \n",
      "Accuracy: 9268/10000 (92.68%)\n",
      "\n",
      "Round   2, Average loss 1.478 Test accuracy 92.680\n",
      "selected users: [ 0  3  4  5  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2373 \n",
      "Accuracy: 9239/10000 (92.39%)\n",
      "\n",
      "Round   3, Average loss 5.237 Test accuracy 92.390\n",
      "selected users: [ 0  1  3  6  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 0.4139 \n",
      "Accuracy: 8898/10000 (88.98%)\n",
      "\n",
      "Round   4, Average loss 0.414 Test accuracy 88.980\n",
      "selected users: [ 2  3  5  6  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 1.2020 \n",
      "Accuracy: 9022/10000 (90.22%)\n",
      "\n",
      "Round   5, Average loss 1.202 Test accuracy 90.220\n",
      "selected users: [ 0  2  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3188 \n",
      "Accuracy: 5190/10000 (51.90%)\n",
      "\n",
      "Round   6, Average loss 1.319 Test accuracy 51.900\n",
      "selected users: [ 1  3  4  5  6 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5958 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round   7, Average loss 0.596 Test accuracy 94.670\n",
      "selected users: [ 2  5  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 7.4333 \n",
      "Accuracy: 8960/10000 (89.60%)\n",
      "\n",
      "Round   8, Average loss 7.433 Test accuracy 89.600\n",
      "selected users: [ 4  5  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 6.1986 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round   9, Average loss 6.199 Test accuracy 93.750\n",
      "selected users: [ 0  1  2  4  6  9 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3213 \n",
      "Accuracy: 9349/10000 (93.49%)\n",
      "\n",
      "Round  10, Average loss 4.321 Test accuracy 93.490\n",
      "selected users: [ 2  3  6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 3.7802 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  11, Average loss 3.780 Test accuracy 93.380\n",
      "selected users: [ 4  5  6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 13.9975 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  12, Average loss 13.998 Test accuracy 94.300\n",
      "selected users: [ 1  2  3  4  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 5.0609 \n",
      "Accuracy: 9191/10000 (91.91%)\n",
      "\n",
      "Round  13, Average loss 5.061 Test accuracy 91.910\n",
      "selected users: [ 0  2  4  6  7  9 12 14]\n",
      "\n",
      "Test set: Average loss: 13.2933 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round  14, Average loss 13.293 Test accuracy 93.520\n",
      "selected users: [ 0  4  5  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 44.8417 \n",
      "Accuracy: 9341/10000 (93.41%)\n",
      "\n",
      "Round  15, Average loss 44.842 Test accuracy 93.410\n",
      "selected users: [ 2  3  5  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 35.4559 \n",
      "Accuracy: 8874/10000 (88.74%)\n",
      "\n",
      "Round  16, Average loss 35.456 Test accuracy 88.740\n",
      "selected users: [ 0  1  2  3  6  8 11 12]\n",
      "\n",
      "Test set: Average loss: 1.4828 \n",
      "Accuracy: 5223/10000 (52.23%)\n",
      "\n",
      "Round  17, Average loss 1.483 Test accuracy 52.230\n",
      "selected users: [ 0  1  5  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 14.4019 \n",
      "Accuracy: 8689/10000 (86.89%)\n",
      "\n",
      "Round  18, Average loss 14.402 Test accuracy 86.890\n",
      "selected users: [ 1  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3155 \n",
      "Accuracy: 9495/10000 (94.95%)\n",
      "\n",
      "Round  19, Average loss 4.315 Test accuracy 94.950\n",
      "selected users: [ 2  3  5  6  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 2.5117 \n",
      "Accuracy: 9060/10000 (90.60%)\n",
      "\n",
      "Round  20, Average loss 2.512 Test accuracy 90.600\n",
      "selected users: [ 3  4  6  7  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.6387 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round  21, Average loss 2.639 Test accuracy 93.430\n",
      "selected users: [ 0  1  3  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 15.1774 \n",
      "Accuracy: 9142/10000 (91.42%)\n",
      "\n",
      "Round  22, Average loss 15.177 Test accuracy 91.420\n",
      "selected users: [ 0  4  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 42.2306 \n",
      "Accuracy: 9282/10000 (92.82%)\n",
      "\n",
      "Round  23, Average loss 42.231 Test accuracy 92.820\n",
      "selected users: [ 0  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 80.3989 \n",
      "Accuracy: 9372/10000 (93.72%)\n",
      "\n",
      "Round  24, Average loss 80.399 Test accuracy 93.720\n",
      "selected users: [ 0  3  5  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 62.0696 \n",
      "Accuracy: 9307/10000 (93.07%)\n",
      "\n",
      "Round  25, Average loss 62.070 Test accuracy 93.070\n",
      "selected users: [ 0  3  4  6  7  8  9 12]\n",
      "\n",
      "Test set: Average loss: 21.2080 \n",
      "Accuracy: 9211/10000 (92.11%)\n",
      "\n",
      "Round  26, Average loss 21.208 Test accuracy 92.110\n",
      "selected users: [ 0  2  5  6  7 10 11 14]\n",
      "\n",
      "Test set: Average loss: 64.5875 \n",
      "Accuracy: 9085/10000 (90.85%)\n",
      "\n",
      "Round  27, Average loss 64.587 Test accuracy 90.850\n",
      "selected users: [ 0  3  5  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 16.0358 \n",
      "Accuracy: 8827/10000 (88.27%)\n",
      "\n",
      "Round  28, Average loss 16.036 Test accuracy 88.270\n",
      "selected users: [ 3  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 14.6296 \n",
      "Accuracy: 9235/10000 (92.35%)\n",
      "\n",
      "Round  29, Average loss 14.630 Test accuracy 92.350\n",
      "(m= 8 )  8 -th Trial!!\n",
      "selected users: [ 2  3  5  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  4  6  7  8 13]\n",
      "\n",
      "Test set: Average loss: 2.1171 \n",
      "Accuracy: 6512/10000 (65.12%)\n",
      "\n",
      "Round   1, Average loss 2.117 Test accuracy 65.120\n",
      "selected users: [ 1  2  4  6  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.9147 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round   2, Average loss 0.915 Test accuracy 94.510\n",
      "selected users: [ 2  3  4  5  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 7.0924 \n",
      "Accuracy: 9391/10000 (93.91%)\n",
      "\n",
      "Round   3, Average loss 7.092 Test accuracy 93.910\n",
      "selected users: [ 0  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 36.1017 \n",
      "Accuracy: 9419/10000 (94.19%)\n",
      "\n",
      "Round   4, Average loss 36.102 Test accuracy 94.190\n",
      "selected users: [ 2  5  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 13.0391 \n",
      "Accuracy: 9253/10000 (92.53%)\n",
      "\n",
      "Round   5, Average loss 13.039 Test accuracy 92.530\n",
      "selected users: [ 0  2  4  5  6  8 10 12]\n",
      "\n",
      "Test set: Average loss: 6.9295 \n",
      "Accuracy: 9110/10000 (91.10%)\n",
      "\n",
      "Round   6, Average loss 6.929 Test accuracy 91.100\n",
      "selected users: [ 0  4  6  7  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 35.3996 \n",
      "Accuracy: 9208/10000 (92.08%)\n",
      "\n",
      "Round   7, Average loss 35.400 Test accuracy 92.080\n",
      "selected users: [ 0  4  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 83.3181 \n",
      "Accuracy: 9359/10000 (93.59%)\n",
      "\n",
      "Round   8, Average loss 83.318 Test accuracy 93.590\n",
      "selected users: [ 2  5  6  7  8 10 11 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 31.2370 \n",
      "Accuracy: 9313/10000 (93.13%)\n",
      "\n",
      "Round   9, Average loss 31.237 Test accuracy 93.130\n",
      "selected users: [ 0  2  3  6  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 21.0080 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round  10, Average loss 21.008 Test accuracy 92.970\n",
      "selected users: [ 1  2  4  5  6 10 12 13]\n",
      "\n",
      "Test set: Average loss: 66.0326 \n",
      "Accuracy: 9240/10000 (92.40%)\n",
      "\n",
      "Round  11, Average loss 66.033 Test accuracy 92.400\n",
      "selected users: [ 1  5  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 95.1308 \n",
      "Accuracy: 9330/10000 (93.30%)\n",
      "\n",
      "Round  12, Average loss 95.131 Test accuracy 93.300\n",
      "selected users: [ 0  2  4  5  6  8 10 11]\n",
      "\n",
      "Test set: Average loss: 47.7050 \n",
      "Accuracy: 9330/10000 (93.30%)\n",
      "\n",
      "Round  13, Average loss 47.705 Test accuracy 93.300\n",
      "selected users: [ 1  2  4  5  6  7  8 14]\n",
      "\n",
      "Test set: Average loss: 47.2436 \n",
      "Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Round  14, Average loss 47.244 Test accuracy 94.720\n",
      "selected users: [ 0  1  3  4  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 331.8391 \n",
      "Accuracy: 9066/10000 (90.66%)\n",
      "\n",
      "Round  15, Average loss 331.839 Test accuracy 90.660\n",
      "selected users: [ 0  3  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.5074 \n",
      "Accuracy: 8665/10000 (86.65%)\n",
      "\n",
      "Round  16, Average loss 6.507 Test accuracy 86.650\n",
      "selected users: [ 2  4  6  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 2.6230 \n",
      "Accuracy: 8322/10000 (83.22%)\n",
      "\n",
      "Round  17, Average loss 2.623 Test accuracy 83.220\n",
      "selected users: [ 0  1  2  4  5  6  8 11]\n",
      "\n",
      "Test set: Average loss: 33.4802 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round  18, Average loss 33.480 Test accuracy 94.680\n",
      "selected users: [ 0  2  3  5  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 27.5524 \n",
      "Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Round  19, Average loss 27.552 Test accuracy 91.980\n",
      "selected users: [ 0  3  4  5 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 153.5424 \n",
      "Accuracy: 8636/10000 (86.36%)\n",
      "\n",
      "Round  20, Average loss 153.542 Test accuracy 86.360\n",
      "selected users: [ 2  3  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.0694 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round  21, Average loss 24.069 Test accuracy 92.970\n",
      "selected users: [ 0  1  2  4  6  8 10 13]\n",
      "\n",
      "Test set: Average loss: 29.4733 \n",
      "Accuracy: 9050/10000 (90.50%)\n",
      "\n",
      "Round  22, Average loss 29.473 Test accuracy 90.500\n",
      "selected users: [ 1  2  5  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 44.9416 \n",
      "Accuracy: 8779/10000 (87.79%)\n",
      "\n",
      "Round  23, Average loss 44.942 Test accuracy 87.790\n",
      "selected users: [ 2  4  5  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 41.0231 \n",
      "Accuracy: 8611/10000 (86.11%)\n",
      "\n",
      "Round  24, Average loss 41.023 Test accuracy 86.110\n",
      "selected users: [ 0  2  3  4  5  9 10 11]\n",
      "\n",
      "Test set: Average loss: 76.3660 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round  25, Average loss 76.366 Test accuracy 93.100\n",
      "selected users: [ 3  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 26.5133 \n",
      "Accuracy: 8861/10000 (88.61%)\n",
      "\n",
      "Round  26, Average loss 26.513 Test accuracy 88.610\n",
      "selected users: [ 0  1  4  6  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 20.3815 \n",
      "Accuracy: 9168/10000 (91.68%)\n",
      "\n",
      "Round  27, Average loss 20.381 Test accuracy 91.680\n",
      "selected users: [ 0  1  3  4  5  6  7 11]\n",
      "\n",
      "Test set: Average loss: 67.9718 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round  28, Average loss 67.972 Test accuracy 93.540\n",
      "selected users: [ 0  1  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 10.6259 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round  29, Average loss 10.626 Test accuracy 93.760\n",
      "(m= 8 )  9 -th Trial!!\n",
      "selected users: [ 2  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  4  5  6  7 10 11]\n",
      "\n",
      "Test set: Average loss: 1.9999 \n",
      "Accuracy: 5782/10000 (57.82%)\n",
      "\n",
      "Round   1, Average loss 2.000 Test accuracy 57.820\n",
      "selected users: [ 3  4  6  7  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.6018 \n",
      "Accuracy: 9165/10000 (91.65%)\n",
      "\n",
      "Round   2, Average loss 0.602 Test accuracy 91.650\n",
      "selected users: [ 0  3  4  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.5145 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round   3, Average loss 3.515 Test accuracy 94.550\n",
      "selected users: [ 0  2  3  5  6  7  9 11]\n",
      "\n",
      "Test set: Average loss: 24.4722 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round   4, Average loss 24.472 Test accuracy 94.200\n",
      "selected users: [ 0  5  6  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 61.2542 \n",
      "Accuracy: 9362/10000 (93.62%)\n",
      "\n",
      "Round   5, Average loss 61.254 Test accuracy 93.620\n",
      "selected users: [0 1 2 3 5 6 8 9]\n",
      "\n",
      "Test set: Average loss: 60.0929 \n",
      "Accuracy: 8895/10000 (88.95%)\n",
      "\n",
      "Round   6, Average loss 60.093 Test accuracy 88.950\n",
      "selected users: [ 0  1  2  5  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 7.2891 \n",
      "Accuracy: 9367/10000 (93.67%)\n",
      "\n",
      "Round   7, Average loss 7.289 Test accuracy 93.670\n",
      "selected users: [ 3  4  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 5.0956 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round   8, Average loss 5.096 Test accuracy 94.110\n",
      "selected users: [ 0  3  4  5  7  8  9 14]\n",
      "\n",
      "Test set: Average loss: 34.1922 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round   9, Average loss 34.192 Test accuracy 94.810\n",
      "selected users: [ 1  2  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2308 \n",
      "Accuracy: 7038/10000 (70.38%)\n",
      "\n",
      "Round  10, Average loss 5.231 Test accuracy 70.380\n",
      "selected users: [ 0  2  3  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 34.0512 \n",
      "Accuracy: 9068/10000 (90.68%)\n",
      "\n",
      "Round  11, Average loss 34.051 Test accuracy 90.680\n",
      "selected users: [ 1  2  6  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.3220 \n",
      "Accuracy: 8371/10000 (83.71%)\n",
      "\n",
      "Round  12, Average loss 9.322 Test accuracy 83.710\n",
      "selected users: [ 1  2  3  4  5  6 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3004 \n",
      "Accuracy: 893/10000 (8.93%)\n",
      "\n",
      "Round  13, Average loss 2.300 Test accuracy 8.930\n",
      "selected users: [ 0  2  3  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2997 \n",
      "Accuracy: 1195/10000 (11.95%)\n",
      "\n",
      "Round  14, Average loss 2.300 Test accuracy 11.950\n",
      "selected users: [ 0  1  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7676 \n",
      "Accuracy: 5406/10000 (54.06%)\n",
      "\n",
      "Round  15, Average loss 1.768 Test accuracy 54.060\n",
      "selected users: [ 2  3  4  6  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 0.5470 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round  16, Average loss 0.547 Test accuracy 94.770\n",
      "selected users: [ 0  2  3  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3221 \n",
      "Accuracy: 9401/10000 (94.01%)\n",
      "\n",
      "Round  17, Average loss 2.322 Test accuracy 94.010\n",
      "selected users: [ 1  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 5.3859 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  18, Average loss 5.386 Test accuracy 95.610\n",
      "selected users: [ 0  3  4  6  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 16.8284 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  19, Average loss 16.828 Test accuracy 94.760\n",
      "selected users: [ 1  3  5  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 2.7250 \n",
      "Accuracy: 9144/10000 (91.44%)\n",
      "\n",
      "Round  20, Average loss 2.725 Test accuracy 91.440\n",
      "selected users: [ 1  2  4  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 8.8657 \n",
      "Accuracy: 9175/10000 (91.75%)\n",
      "\n",
      "Round  21, Average loss 8.866 Test accuracy 91.750\n",
      "selected users: [ 0  3  4  5  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 39.2698 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round  22, Average loss 39.270 Test accuracy 93.540\n",
      "selected users: [ 0  1  2  6  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 27.4160 \n",
      "Accuracy: 9457/10000 (94.57%)\n",
      "\n",
      "Round  23, Average loss 27.416 Test accuracy 94.570\n",
      "selected users: [ 2  5  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.0634 \n",
      "Accuracy: 9161/10000 (91.61%)\n",
      "\n",
      "Round  24, Average loss 21.063 Test accuracy 91.610\n",
      "selected users: [ 0  3  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 5.3040 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round  25, Average loss 5.304 Test accuracy 93.750\n",
      "selected users: [ 0  1  3  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 12.2594 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  26, Average loss 12.259 Test accuracy 94.410\n",
      "selected users: [ 0  3  4  5  6  7 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3017 \n",
      "Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Round  27, Average loss 2.302 Test accuracy 11.350\n",
      "selected users: [ 2  3  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2552 \n",
      "Accuracy: 2167/10000 (21.67%)\n",
      "\n",
      "Round  28, Average loss 2.255 Test accuracy 21.670\n",
      "selected users: [ 0  2  3  6  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 0.2962 \n",
      "Accuracy: 9169/10000 (91.69%)\n",
      "\n",
      "Round  29, Average loss 0.296 Test accuracy 91.690\n",
      "number of results: 9\n",
      "(m= 9 )  0 -th Trial!!\n",
      "selected users: [ 1  2  3  4  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4  5  8 10 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6039 \n",
      "Accuracy: 7041/10000 (70.41%)\n",
      "\n",
      "Round   1, Average loss 1.604 Test accuracy 70.410\n",
      "selected users: [ 0  1  3  5  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4160 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round   2, Average loss 0.416 Test accuracy 92.210\n",
      "selected users: [ 1  2  3  4  5  6  7 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3271 \n",
      "Accuracy: 9368/10000 (93.68%)\n",
      "\n",
      "Round   3, Average loss 2.327 Test accuracy 93.680\n",
      "selected users: [ 2  3  5  6  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 1.4760 \n",
      "Accuracy: 8896/10000 (88.96%)\n",
      "\n",
      "Round   4, Average loss 1.476 Test accuracy 88.960\n",
      "selected users: [ 0  2  3  4  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 3.5782 \n",
      "Accuracy: 9011/10000 (90.11%)\n",
      "\n",
      "Round   5, Average loss 3.578 Test accuracy 90.110\n",
      "selected users: [ 1  2  3  5  6 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2147 \n",
      "Accuracy: 9432/10000 (94.32%)\n",
      "\n",
      "Round   6, Average loss 4.215 Test accuracy 94.320\n",
      "selected users: [ 0  1  3  5  6  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3784 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round   7, Average loss 2.378 Test accuracy 95.070\n",
      "selected users: [ 0  3  5  6  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7535 \n",
      "Accuracy: 9346/10000 (93.46%)\n",
      "\n",
      "Round   8, Average loss 2.754 Test accuracy 93.460\n",
      "selected users: [ 0  1  3  4  5  6  7 11 13]\n",
      "\n",
      "Test set: Average loss: 3.1089 \n",
      "Accuracy: 9392/10000 (93.92%)\n",
      "\n",
      "Round   9, Average loss 3.109 Test accuracy 93.920\n",
      "selected users: [ 2  3  5  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 4.4157 \n",
      "Accuracy: 9392/10000 (93.92%)\n",
      "\n",
      "Round  10, Average loss 4.416 Test accuracy 93.920\n",
      "selected users: [ 0  3  4  5  6  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 16.0963 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round  11, Average loss 16.096 Test accuracy 92.910\n",
      "selected users: [ 0  2  3  5  6  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 5.0311 \n",
      "Accuracy: 9242/10000 (92.42%)\n",
      "\n",
      "Round  12, Average loss 5.031 Test accuracy 92.420\n",
      "selected users: [ 0  1  3  4  6  7  8 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7440 \n",
      "Accuracy: 8554/10000 (85.54%)\n",
      "\n",
      "Round  13, Average loss 0.744 Test accuracy 85.540\n",
      "selected users: [ 0  1  2  4  6  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 11.9270 \n",
      "Accuracy: 9349/10000 (93.49%)\n",
      "\n",
      "Round  14, Average loss 11.927 Test accuracy 93.490\n",
      "selected users: [ 1  2  3  5  6  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 2.5078 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round  15, Average loss 2.508 Test accuracy 92.970\n",
      "selected users: [ 0  1  2  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.0629 \n",
      "Accuracy: 8847/10000 (88.47%)\n",
      "\n",
      "Round  16, Average loss 1.063 Test accuracy 88.470\n",
      "selected users: [ 1  2  5  6  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.0046 \n",
      "Accuracy: 9438/10000 (94.38%)\n",
      "\n",
      "Round  17, Average loss 5.005 Test accuracy 94.380\n",
      "selected users: [ 0  1  2  3  5  6  8 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7334 \n",
      "Accuracy: 7773/10000 (77.73%)\n",
      "\n",
      "Round  18, Average loss 0.733 Test accuracy 77.730\n",
      "selected users: [ 0  1  3  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6385 \n",
      "Accuracy: 9425/10000 (94.25%)\n",
      "\n",
      "Round  19, Average loss 0.639 Test accuracy 94.250\n",
      "selected users: [ 0  1  3  4  5  6 10 12 13]\n",
      "\n",
      "Test set: Average loss: 5.7080 \n",
      "Accuracy: 9287/10000 (92.87%)\n",
      "\n",
      "Round  20, Average loss 5.708 Test accuracy 92.870\n",
      "selected users: [ 0  1  3  5 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 52.0140 \n",
      "Accuracy: 8919/10000 (89.19%)\n",
      "\n",
      "Round  21, Average loss 52.014 Test accuracy 89.190\n",
      "selected users: [ 2  4  5  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 9.1873 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round  22, Average loss 9.187 Test accuracy 93.520\n",
      "selected users: [ 3  5  6  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1126 \n",
      "Accuracy: 9160/10000 (91.60%)\n",
      "\n",
      "Round  23, Average loss 3.113 Test accuracy 91.600\n",
      "selected users: [ 0  2  4  5  6  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 6.6570 \n",
      "Accuracy: 9254/10000 (92.54%)\n",
      "\n",
      "Round  24, Average loss 6.657 Test accuracy 92.540\n",
      "selected users: [ 0  1  3  6  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 3.3713 \n",
      "Accuracy: 9250/10000 (92.50%)\n",
      "\n",
      "Round  25, Average loss 3.371 Test accuracy 92.500\n",
      "selected users: [ 1  3  5  6  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.4289 \n",
      "Accuracy: 9349/10000 (93.49%)\n",
      "\n",
      "Round  26, Average loss 5.429 Test accuracy 93.490\n",
      "selected users: [ 1  3  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7174 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  27, Average loss 4.717 Test accuracy 94.510\n",
      "selected users: [ 0  1  5  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.2481 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round  28, Average loss 6.248 Test accuracy 94.670\n",
      "selected users: [ 2  3  4  5  7  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 1.1065 \n",
      "Accuracy: 8201/10000 (82.01%)\n",
      "\n",
      "Round  29, Average loss 1.106 Test accuracy 82.010\n",
      "(m= 9 )  1 -th Trial!!\n",
      "selected users: [ 1  2  3  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2778 \n",
      "Accuracy: 4406/10000 (44.06%)\n",
      "\n",
      "Round   0, Average loss 2.278 Test accuracy 44.060\n",
      "selected users: [ 1  4  5  6  7  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.4250 \n",
      "Accuracy: 8904/10000 (89.04%)\n",
      "\n",
      "Round   1, Average loss 0.425 Test accuracy 89.040\n",
      "selected users: [ 0  2  3  4  5  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 0.8942 \n",
      "Accuracy: 9429/10000 (94.29%)\n",
      "\n",
      "Round   2, Average loss 0.894 Test accuracy 94.290\n",
      "selected users: [ 0  1  3  5  6  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 0.8343 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round   3, Average loss 0.834 Test accuracy 92.970\n",
      "selected users: [ 1  2  3  4  5  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 3.6442 \n",
      "Accuracy: 9057/10000 (90.57%)\n",
      "\n",
      "Round   4, Average loss 3.644 Test accuracy 90.570\n",
      "selected users: [ 1  3  4  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.1058 \n",
      "Accuracy: 9446/10000 (94.46%)\n",
      "\n",
      "Round   5, Average loss 6.106 Test accuracy 94.460\n",
      "selected users: [ 0  1  2  4  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 11.2070 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round   6, Average loss 11.207 Test accuracy 95.240\n",
      "selected users: [ 0  3  4  5  6  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.2851 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round   7, Average loss 6.285 Test accuracy 93.660\n",
      "selected users: [ 0  3  5  6  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 11.0728 \n",
      "Accuracy: 9362/10000 (93.62%)\n",
      "\n",
      "Round   8, Average loss 11.073 Test accuracy 93.620\n",
      "selected users: [ 1  2  3  4  6  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 21.1168 \n",
      "Accuracy: 9290/10000 (92.90%)\n",
      "\n",
      "Round   9, Average loss 21.117 Test accuracy 92.900\n",
      "selected users: [ 0  1  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.2536 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  10, Average loss 6.254 Test accuracy 94.800\n",
      "selected users: [ 3  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6836 \n",
      "Accuracy: 9203/10000 (92.03%)\n",
      "\n",
      "Round  11, Average loss 1.684 Test accuracy 92.030\n",
      "selected users: [ 0  2  4  5  7  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 10.2872 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round  12, Average loss 10.287 Test accuracy 94.610\n",
      "selected users: [ 1  2  3  4  5  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 20.9629 \n",
      "Accuracy: 9174/10000 (91.74%)\n",
      "\n",
      "Round  13, Average loss 20.963 Test accuracy 91.740\n",
      "selected users: [ 1  4  5  6  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 6.1614 \n",
      "Accuracy: 9364/10000 (93.64%)\n",
      "\n",
      "Round  14, Average loss 6.161 Test accuracy 93.640\n",
      "selected users: [ 3  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8807 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round  15, Average loss 3.881 Test accuracy 92.910\n",
      "selected users: [ 1  2  3  5  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 14.7575 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round  16, Average loss 14.758 Test accuracy 92.740\n",
      "selected users: [ 0  1  3  4  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 7.9456 \n",
      "Accuracy: 9209/10000 (92.09%)\n",
      "\n",
      "Round  17, Average loss 7.946 Test accuracy 92.090\n",
      "selected users: [ 2  4  5  6  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 6.3061 \n",
      "Accuracy: 9340/10000 (93.40%)\n",
      "\n",
      "Round  18, Average loss 6.306 Test accuracy 93.400\n",
      "selected users: [ 1  3  4  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 11.1625 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round  19, Average loss 11.162 Test accuracy 94.670\n",
      "selected users: [ 1  4  5  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 11.8231 \n",
      "Accuracy: 9353/10000 (93.53%)\n",
      "\n",
      "Round  20, Average loss 11.823 Test accuracy 93.530\n",
      "selected users: [ 3  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.2635 \n",
      "Accuracy: 9025/10000 (90.25%)\n",
      "\n",
      "Round  21, Average loss 4.264 Test accuracy 90.250\n",
      "selected users: [ 0  1  4  5  7  8 11 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 16.2096 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round  22, Average loss 16.210 Test accuracy 94.820\n",
      "selected users: [ 0  2  5  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 31.2672 \n",
      "Accuracy: 9279/10000 (92.79%)\n",
      "\n",
      "Round  23, Average loss 31.267 Test accuracy 92.790\n",
      "selected users: [ 1  2  3  4  6  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 24.8781 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  24, Average loss 24.878 Test accuracy 94.800\n",
      "selected users: [ 0  1  3  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.3111 \n",
      "Accuracy: 9257/10000 (92.57%)\n",
      "\n",
      "Round  25, Average loss 5.311 Test accuracy 92.570\n",
      "selected users: [ 0  1  2  4  5  7 11 12 14]\n",
      "\n",
      "Test set: Average loss: 12.5126 \n",
      "Accuracy: 9440/10000 (94.40%)\n",
      "\n",
      "Round  26, Average loss 12.513 Test accuracy 94.400\n",
      "selected users: [ 2  4  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 11.2211 \n",
      "Accuracy: 9123/10000 (91.23%)\n",
      "\n",
      "Round  27, Average loss 11.221 Test accuracy 91.230\n",
      "selected users: [ 0  1  2  5  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 28.0659 \n",
      "Accuracy: 9426/10000 (94.26%)\n",
      "\n",
      "Round  28, Average loss 28.066 Test accuracy 94.260\n",
      "selected users: [ 2  3  4  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 18.9035 \n",
      "Accuracy: 8930/10000 (89.30%)\n",
      "\n",
      "Round  29, Average loss 18.904 Test accuracy 89.300\n",
      "(m= 9 )  2 -th Trial!!\n",
      "selected users: [ 1  2  3  4  6  7  8 10 11]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  4  6 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7484 \n",
      "Accuracy: 5671/10000 (56.71%)\n",
      "\n",
      "Round   1, Average loss 1.748 Test accuracy 56.710\n",
      "selected users: [ 0  1  2  3  5  6  9 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4843 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round   2, Average loss 0.484 Test accuracy 94.560\n",
      "selected users: [ 0  1  4  5  6  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.6033 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round   3, Average loss 0.603 Test accuracy 95.130\n",
      "selected users: [ 1  3  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5396 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round   4, Average loss 0.540 Test accuracy 95.920\n",
      "selected users: [ 0  1  4  6  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3276 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round   5, Average loss 2.328 Test accuracy 94.330\n",
      "selected users: [ 0  1  2  4  5  7  9 11 14]\n",
      "\n",
      "Test set: Average loss: 5.1468 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round   6, Average loss 5.147 Test accuracy 95.050\n",
      "selected users: [ 0  4  5  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 16.5364 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round   7, Average loss 16.536 Test accuracy 95.150\n",
      "selected users: [ 2  4  5  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 9.5263 \n",
      "Accuracy: 9256/10000 (92.56%)\n",
      "\n",
      "Round   8, Average loss 9.526 Test accuracy 92.560\n",
      "selected users: [ 0  1  2  3  5  7  9 12 14]\n",
      "\n",
      "Test set: Average loss: 6.0568 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round   9, Average loss 6.057 Test accuracy 93.100\n",
      "selected users: [ 0  2  4  6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 7.1107 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round  10, Average loss 7.111 Test accuracy 92.910\n",
      "selected users: [ 0  1  5  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 24.1859 \n",
      "Accuracy: 9391/10000 (93.91%)\n",
      "\n",
      "Round  11, Average loss 24.186 Test accuracy 93.910\n",
      "selected users: [ 2  3  5  6  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 7.4025 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round  12, Average loss 7.402 Test accuracy 92.210\n",
      "selected users: [ 1  5  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 15.0387 \n",
      "Accuracy: 9452/10000 (94.52%)\n",
      "\n",
      "Round  13, Average loss 15.039 Test accuracy 94.520\n",
      "selected users: [ 0  2  3  6  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 3.2485 \n",
      "Accuracy: 9188/10000 (91.88%)\n",
      "\n",
      "Round  14, Average loss 3.249 Test accuracy 91.880\n",
      "selected users: [ 2  3  4  5  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 3.2336 \n",
      "Accuracy: 8861/10000 (88.61%)\n",
      "\n",
      "Round  15, Average loss 3.234 Test accuracy 88.610\n",
      "selected users: [ 0  3  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 2.7113 \n",
      "Accuracy: 9082/10000 (90.82%)\n",
      "\n",
      "Round  16, Average loss 2.711 Test accuracy 90.820\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 5.2676 \n",
      "Accuracy: 9087/10000 (90.87%)\n",
      "\n",
      "Round  17, Average loss 5.268 Test accuracy 90.870\n",
      "selected users: [ 2  3  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6563 \n",
      "Accuracy: 9200/10000 (92.00%)\n",
      "\n",
      "Round  18, Average loss 1.656 Test accuracy 92.000\n",
      "selected users: [ 0  1  2  4  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2444 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round  19, Average loss 5.244 Test accuracy 93.600\n",
      "selected users: [ 1  2  3  6  7  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.5279 \n",
      "Accuracy: 9161/10000 (91.61%)\n",
      "\n",
      "Round  20, Average loss 2.528 Test accuracy 91.610\n",
      "selected users: [ 0  1  3  4  6  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 1.8369 \n",
      "Accuracy: 9153/10000 (91.53%)\n",
      "\n",
      "Round  21, Average loss 1.837 Test accuracy 91.530\n",
      "selected users: [ 0  1  3  5  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 3.1820 \n",
      "Accuracy: 8944/10000 (89.44%)\n",
      "\n",
      "Round  22, Average loss 3.182 Test accuracy 89.440\n",
      "selected users: [ 0  3  4  6  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 9.7368 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  23, Average loss 9.737 Test accuracy 94.650\n",
      "selected users: [ 1  2  3  6  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 3.5135 \n",
      "Accuracy: 9429/10000 (94.29%)\n",
      "\n",
      "Round  24, Average loss 3.513 Test accuracy 94.290\n",
      "selected users: [ 1  4  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 7.3638 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  25, Average loss 7.364 Test accuracy 94.360\n",
      "selected users: [ 2  3  4  5  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 8.3077 \n",
      "Accuracy: 8721/10000 (87.21%)\n",
      "\n",
      "Round  26, Average loss 8.308 Test accuracy 87.210\n",
      "selected users: [ 3  4  5  6  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 3.2945 \n",
      "Accuracy: 8693/10000 (86.93%)\n",
      "\n",
      "Round  27, Average loss 3.294 Test accuracy 86.930\n",
      "selected users: [ 0  1  2  4  6  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 4.6213 \n",
      "Accuracy: 9344/10000 (93.44%)\n",
      "\n",
      "Round  28, Average loss 4.621 Test accuracy 93.440\n",
      "selected users: [ 0  4  5  6  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 4.6972 \n",
      "Accuracy: 9281/10000 (92.81%)\n",
      "\n",
      "Round  29, Average loss 4.697 Test accuracy 92.810\n",
      "(m= 9 )  3 -th Trial!!\n",
      "selected users: [ 3  4  5  6  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3021 \n",
      "Accuracy: 1293/10000 (12.93%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 12.930\n",
      "selected users: [ 0  2  3  4  5  7 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.9557 \n",
      "Accuracy: 7358/10000 (73.58%)\n",
      "\n",
      "Round   1, Average loss 0.956 Test accuracy 73.580\n",
      "selected users: [ 0  3  5  6  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.8616 \n",
      "Accuracy: 9274/10000 (92.74%)\n",
      "\n",
      "Round   2, Average loss 0.862 Test accuracy 92.740\n",
      "selected users: [ 0  1  2  5  6  7 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4241 \n",
      "Accuracy: 9253/10000 (92.53%)\n",
      "\n",
      "Round   3, Average loss 2.424 Test accuracy 92.530\n",
      "selected users: [ 0  1  2  4  5  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.6079 \n",
      "Accuracy: 8998/10000 (89.98%)\n",
      "\n",
      "Round   4, Average loss 2.608 Test accuracy 89.980\n",
      "selected users: [ 0  2  4  6  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 3.6420 \n",
      "Accuracy: 9384/10000 (93.84%)\n",
      "\n",
      "Round   5, Average loss 3.642 Test accuracy 93.840\n",
      "selected users: [ 0  1  2  3  4  7 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.0259 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round   6, Average loss 4.026 Test accuracy 94.450\n",
      "selected users: [ 0  1  2  4  5 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 52.0147 \n",
      "Accuracy: 8989/10000 (89.89%)\n",
      "\n",
      "Round   7, Average loss 52.015 Test accuracy 89.890\n",
      "selected users: [ 0  4  5  6  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 27.8420 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round   8, Average loss 27.842 Test accuracy 93.930\n",
      "selected users: [ 0  1  4  5  7  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 28.5215 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round   9, Average loss 28.522 Test accuracy 93.510\n",
      "selected users: [ 0  1  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 7.5620 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round  10, Average loss 7.562 Test accuracy 94.680\n",
      "selected users: [ 0  1  3  4  5  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 12.2815 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  11, Average loss 12.281 Test accuracy 94.410\n",
      "selected users: [ 0  3  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.7438 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round  12, Average loss 8.744 Test accuracy 93.830\n",
      "selected users: [ 0  1  3  6  7 10 11 12 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.9688 \n",
      "Accuracy: 9197/10000 (91.97%)\n",
      "\n",
      "Round  13, Average loss 3.969 Test accuracy 91.970\n",
      "selected users: [ 1  2  5  6 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 22.6671 \n",
      "Accuracy: 8966/10000 (89.66%)\n",
      "\n",
      "Round  14, Average loss 22.667 Test accuracy 89.660\n",
      "selected users: [ 0  1  3  5  6  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 8.5546 \n",
      "Accuracy: 8947/10000 (89.47%)\n",
      "\n",
      "Round  15, Average loss 8.555 Test accuracy 89.470\n",
      "selected users: [ 1  2  4  5  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 7.0204 \n",
      "Accuracy: 8963/10000 (89.63%)\n",
      "\n",
      "Round  16, Average loss 7.020 Test accuracy 89.630\n",
      "selected users: [ 1  3  4  6  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 2.9943 \n",
      "Accuracy: 9149/10000 (91.49%)\n",
      "\n",
      "Round  17, Average loss 2.994 Test accuracy 91.490\n",
      "selected users: [ 2  3  5  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 18.6106 \n",
      "Accuracy: 8696/10000 (86.96%)\n",
      "\n",
      "Round  18, Average loss 18.611 Test accuracy 86.960\n",
      "selected users: [ 1  3  5  6  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 14.5848 \n",
      "Accuracy: 8779/10000 (87.79%)\n",
      "\n",
      "Round  19, Average loss 14.585 Test accuracy 87.790\n",
      "selected users: [ 2  3  4  5  6  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 20.5287 \n",
      "Accuracy: 8695/10000 (86.95%)\n",
      "\n",
      "Round  20, Average loss 20.529 Test accuracy 86.950\n",
      "selected users: [ 2  3  4  6  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 8.7660 \n",
      "Accuracy: 8901/10000 (89.01%)\n",
      "\n",
      "Round  21, Average loss 8.766 Test accuracy 89.010\n",
      "selected users: [ 0  1  2  5  6 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 19.6075 \n",
      "Accuracy: 9034/10000 (90.34%)\n",
      "\n",
      "Round  22, Average loss 19.607 Test accuracy 90.340\n",
      "selected users: [ 0  1  2  3  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6795 \n",
      "Accuracy: 9187/10000 (91.87%)\n",
      "\n",
      "Round  23, Average loss 2.680 Test accuracy 91.870\n",
      "selected users: [ 2  3  4  5  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 7.3504 \n",
      "Accuracy: 9271/10000 (92.71%)\n",
      "\n",
      "Round  24, Average loss 7.350 Test accuracy 92.710\n",
      "selected users: [ 1  2  3  5  6  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 1.7908 \n",
      "Accuracy: 8704/10000 (87.04%)\n",
      "\n",
      "Round  25, Average loss 1.791 Test accuracy 87.040\n",
      "selected users: [ 1  2  3  5  6  7 11 13 14]\n",
      "\n",
      "Test set: Average loss: 12.2469 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round  26, Average loss 12.247 Test accuracy 93.510\n",
      "selected users: [ 0  4  5  6  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 31.1754 \n",
      "Accuracy: 9109/10000 (91.09%)\n",
      "\n",
      "Round  27, Average loss 31.175 Test accuracy 91.090\n",
      "selected users: [ 0  2  3  4  6  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 12.9257 \n",
      "Accuracy: 8790/10000 (87.90%)\n",
      "\n",
      "Round  28, Average loss 12.926 Test accuracy 87.900\n",
      "selected users: [ 2  4  5  6  7  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8606 \n",
      "Accuracy: 7923/10000 (79.23%)\n",
      "\n",
      "Round  29, Average loss 2.861 Test accuracy 79.230\n",
      "(m= 9 )  4 -th Trial!!\n",
      "selected users: [ 0  2  4  5  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2555 \n",
      "Accuracy: 6150/10000 (61.50%)\n",
      "\n",
      "Round   1, Average loss 2.256 Test accuracy 61.500\n",
      "selected users: [ 0  2  3  4  5  6  9 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3315 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round   2, Average loss 0.331 Test accuracy 94.090\n",
      "selected users: [ 1  4  5  6  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.2407 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round   3, Average loss 0.241 Test accuracy 94.640\n",
      "selected users: [ 2  4  5  6  7  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3472 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round   4, Average loss 0.347 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  4  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7595 \n",
      "Accuracy: 9474/10000 (94.74%)\n",
      "\n",
      "Round   5, Average loss 0.760 Test accuracy 94.740\n",
      "selected users: [ 0  1  2  4  5  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.3232 \n",
      "Accuracy: 9437/10000 (94.37%)\n",
      "\n",
      "Round   6, Average loss 4.323 Test accuracy 94.370\n",
      "selected users: [ 0  1  2  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3499 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round   7, Average loss 3.350 Test accuracy 95.350\n",
      "selected users: [ 1  2  3  6  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.8006 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round   8, Average loss 3.801 Test accuracy 95.480\n",
      "selected users: [ 1  2  4  5  6  7 11 12 13]\n",
      "\n",
      "Test set: Average loss: 7.1977 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round   9, Average loss 7.198 Test accuracy 93.880\n",
      "selected users: [ 0  2  3  4  5  6 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.8073 \n",
      "Accuracy: 9407/10000 (94.07%)\n",
      "\n",
      "Round  10, Average loss 6.807 Test accuracy 94.070\n",
      "selected users: [ 3  4  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6569 \n",
      "Accuracy: 9390/10000 (93.90%)\n",
      "\n",
      "Round  11, Average loss 2.657 Test accuracy 93.900\n",
      "selected users: [ 0  1  3  4  5  7  9 11 14]\n",
      "\n",
      "Test set: Average loss: 7.5605 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round  12, Average loss 7.560 Test accuracy 94.970\n",
      "selected users: [ 0  1  2  3  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.8303 \n",
      "Accuracy: 7521/10000 (75.21%)\n",
      "\n",
      "Round  13, Average loss 0.830 Test accuracy 75.210\n",
      "selected users: [ 4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7183 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round  14, Average loss 4.718 Test accuracy 94.330\n",
      "selected users: [ 1  2  5  6  7  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 5.5012 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round  15, Average loss 5.501 Test accuracy 94.090\n",
      "selected users: [ 0  3  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2986 \n",
      "Accuracy: 9372/10000 (93.72%)\n",
      "\n",
      "Round  16, Average loss 3.299 Test accuracy 93.720\n",
      "selected users: [ 1  3  4  5  6  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.3620 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  17, Average loss 5.362 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  5  6  8 11 14]\n",
      "\n",
      "Test set: Average loss: 5.0641 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  18, Average loss 5.064 Test accuracy 94.920\n",
      "selected users: [ 1  2  3  4  5  6  7  8 12]\n",
      "\n",
      "Test set: Average loss: 1.4257 \n",
      "Accuracy: 8396/10000 (83.96%)\n",
      "\n",
      "Round  19, Average loss 1.426 Test accuracy 83.960\n",
      "selected users: [ 0  1  4  6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 3.1651 \n",
      "Accuracy: 9365/10000 (93.65%)\n",
      "\n",
      "Round  20, Average loss 3.165 Test accuracy 93.650\n",
      "selected users: [ 3  4  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.0666 \n",
      "Accuracy: 8917/10000 (89.17%)\n",
      "\n",
      "Round  21, Average loss 3.067 Test accuracy 89.170\n",
      "selected users: [ 3  4  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8096 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  22, Average loss 1.810 Test accuracy 93.380\n",
      "selected users: [ 2  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.4156 \n",
      "Accuracy: 9051/10000 (90.51%)\n",
      "\n",
      "Round  23, Average loss 4.416 Test accuracy 90.510\n",
      "selected users: [ 0  1  3  4  6  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 1.3398 \n",
      "Accuracy: 9309/10000 (93.09%)\n",
      "\n",
      "Round  24, Average loss 1.340 Test accuracy 93.090\n",
      "selected users: [ 5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 65.0697 \n",
      "Accuracy: 9006/10000 (90.06%)\n",
      "\n",
      "Round  25, Average loss 65.070 Test accuracy 90.060\n",
      "selected users: [ 1  3  4  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 17.6189 \n",
      "Accuracy: 9397/10000 (93.97%)\n",
      "\n",
      "Round  26, Average loss 17.619 Test accuracy 93.970\n",
      "selected users: [ 0  1  2  3  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8604 \n",
      "Accuracy: 7564/10000 (75.64%)\n",
      "\n",
      "Round  27, Average loss 0.860 Test accuracy 75.640\n",
      "selected users: [ 1  2  4  6  7  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 3.8174 \n",
      "Accuracy: 9446/10000 (94.46%)\n",
      "\n",
      "Round  28, Average loss 3.817 Test accuracy 94.460\n",
      "selected users: [ 0  3  4  5  6  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 2.9194 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round  29, Average loss 2.919 Test accuracy 93.100\n",
      "(m= 9 )  5 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  4  6  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1420 \n",
      "Accuracy: 5845/10000 (58.45%)\n",
      "\n",
      "Round   1, Average loss 2.142 Test accuracy 58.450\n",
      "selected users: [ 0  1  4  5  6 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1714 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round   2, Average loss 1.171 Test accuracy 94.360\n",
      "selected users: [ 0  3  4  5  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9087 \n",
      "Accuracy: 9279/10000 (92.79%)\n",
      "\n",
      "Round   3, Average loss 2.909 Test accuracy 92.790\n",
      "selected users: [ 0  1  3  6 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.2518 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round   4, Average loss 4.252 Test accuracy 94.670\n",
      "selected users: [ 0  1  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 2.9074 \n",
      "Accuracy: 9333/10000 (93.33%)\n",
      "\n",
      "Round   5, Average loss 2.907 Test accuracy 93.330\n",
      "selected users: [ 1  2  3  4  5  7  8  9 11]\n",
      "\n",
      "Test set: Average loss: 16.7900 \n",
      "Accuracy: 9339/10000 (93.39%)\n",
      "\n",
      "Round   6, Average loss 16.790 Test accuracy 93.390\n",
      "selected users: [ 0  1  3  4  6  7  9 10 14]\n",
      "\n",
      "Test set: Average loss: 15.2061 \n",
      "Accuracy: 9446/10000 (94.46%)\n",
      "\n",
      "Round   7, Average loss 15.206 Test accuracy 94.460\n",
      "selected users: [ 0  1  5  6  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 6.3985 \n",
      "Accuracy: 9208/10000 (92.08%)\n",
      "\n",
      "Round   8, Average loss 6.398 Test accuracy 92.080\n",
      "selected users: [ 0  3  5  6  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 1.3891 \n",
      "Accuracy: 8896/10000 (88.96%)\n",
      "\n",
      "Round   9, Average loss 1.389 Test accuracy 88.960\n",
      "selected users: [ 1  2  3  4  5  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 9.8542 \n",
      "Accuracy: 9145/10000 (91.45%)\n",
      "\n",
      "Round  10, Average loss 9.854 Test accuracy 91.450\n",
      "selected users: [ 0  4  5  6  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.3051 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  11, Average loss 12.305 Test accuracy 94.500\n",
      "selected users: [ 1  2  4  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.5091 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  12, Average loss 10.509 Test accuracy 94.990\n",
      "selected users: [ 2  3  4  5  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 9.6553 \n",
      "Accuracy: 9227/10000 (92.27%)\n",
      "\n",
      "Round  13, Average loss 9.655 Test accuracy 92.270\n",
      "selected users: [ 0  1  2  3  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5369 \n",
      "Accuracy: 8723/10000 (87.23%)\n",
      "\n",
      "Round  14, Average loss 0.537 Test accuracy 87.230\n",
      "selected users: [ 0  2  3  6  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 6.8063 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  15, Average loss 6.806 Test accuracy 94.080\n",
      "selected users: [ 0  3  5  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.2931 \n",
      "Accuracy: 9303/10000 (93.03%)\n",
      "\n",
      "Round  16, Average loss 9.293 Test accuracy 93.030\n",
      "selected users: [ 0  2  3  5  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 22.7566 \n",
      "Accuracy: 8913/10000 (89.13%)\n",
      "\n",
      "Round  17, Average loss 22.757 Test accuracy 89.130\n",
      "selected users: [ 0  3  4  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 18.7941 \n",
      "Accuracy: 9179/10000 (91.79%)\n",
      "\n",
      "Round  18, Average loss 18.794 Test accuracy 91.790\n",
      "selected users: [ 0  1  2  4  6  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 16.5389 \n",
      "Accuracy: 9392/10000 (93.92%)\n",
      "\n",
      "Round  19, Average loss 16.539 Test accuracy 93.920\n",
      "selected users: [ 1  4  5  6  7  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 8.7926 \n",
      "Accuracy: 9256/10000 (92.56%)\n",
      "\n",
      "Round  20, Average loss 8.793 Test accuracy 92.560\n",
      "selected users: [ 0  2  3  4  6  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 12.0529 \n",
      "Accuracy: 9288/10000 (92.88%)\n",
      "\n",
      "Round  21, Average loss 12.053 Test accuracy 92.880\n",
      "selected users: [ 0  2  3  4  6  7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 16.4063 \n",
      "Accuracy: 9272/10000 (92.72%)\n",
      "\n",
      "Round  22, Average loss 16.406 Test accuracy 92.720\n",
      "selected users: [ 0  1  3  4  6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 23.5128 \n",
      "Accuracy: 9335/10000 (93.35%)\n",
      "\n",
      "Round  23, Average loss 23.513 Test accuracy 93.350\n",
      "selected users: [ 0  1  3  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1.2110 \n",
      "Accuracy: 8107/10000 (81.07%)\n",
      "\n",
      "Round  24, Average loss 1.211 Test accuracy 81.070\n",
      "selected users: [ 0  1  2  3  5  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 14.6957 \n",
      "Accuracy: 9191/10000 (91.91%)\n",
      "\n",
      "Round  25, Average loss 14.696 Test accuracy 91.910\n",
      "selected users: [ 1  2  3  5  6  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 12.0954 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round  26, Average loss 12.095 Test accuracy 93.600\n",
      "selected users: [ 1  3  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.1199 \n",
      "Accuracy: 9382/10000 (93.82%)\n",
      "\n",
      "Round  27, Average loss 7.120 Test accuracy 93.820\n",
      "selected users: [ 2  3  4  5  6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 18.8851 \n",
      "Accuracy: 9202/10000 (92.02%)\n",
      "\n",
      "Round  28, Average loss 18.885 Test accuracy 92.020\n",
      "selected users: [ 1  3  4  5  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 21.7968 \n",
      "Accuracy: 9317/10000 (93.17%)\n",
      "\n",
      "Round  29, Average loss 21.797 Test accuracy 93.170\n",
      "(m= 9 )  6 -th Trial!!\n",
      "selected users: [ 1  2  3  6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 1.9686 \n",
      "Accuracy: 7658/10000 (76.58%)\n",
      "\n",
      "Round   1, Average loss 1.969 Test accuracy 76.580\n",
      "selected users: [ 0  1  3  6  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2307 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round   2, Average loss 0.231 Test accuracy 95.640\n",
      "selected users: [ 0  1  3  4  5 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 15.0368 \n",
      "Accuracy: 9276/10000 (92.76%)\n",
      "\n",
      "Round   3, Average loss 15.037 Test accuracy 92.760\n",
      "selected users: [ 1  2  4  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 9.2525 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round   4, Average loss 9.253 Test accuracy 94.610\n",
      "selected users: [ 1  2  3  5  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 22.5227 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round   5, Average loss 22.523 Test accuracy 93.430\n",
      "selected users: [ 0  2  4  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 14.3111 \n",
      "Accuracy: 9437/10000 (94.37%)\n",
      "\n",
      "Round   6, Average loss 14.311 Test accuracy 94.370\n",
      "selected users: [ 0  1  2  4  6 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 17.8423 \n",
      "Accuracy: 9306/10000 (93.06%)\n",
      "\n",
      "Round   7, Average loss 17.842 Test accuracy 93.060\n",
      "selected users: [ 1  4  5  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.0516 \n",
      "Accuracy: 9356/10000 (93.56%)\n",
      "\n",
      "Round   8, Average loss 20.052 Test accuracy 93.560\n",
      "selected users: [ 0  1  4  5  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 19.9943 \n",
      "Accuracy: 9427/10000 (94.27%)\n",
      "\n",
      "Round   9, Average loss 19.994 Test accuracy 94.270\n",
      "selected users: [ 1  2  3  5  6  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 6.7580 \n",
      "Accuracy: 9415/10000 (94.15%)\n",
      "\n",
      "Round  10, Average loss 6.758 Test accuracy 94.150\n",
      "selected users: [ 0  2  3  4  5  6  7  8 10]\n",
      "\n",
      "Test set: Average loss: 131.3948 \n",
      "Accuracy: 9035/10000 (90.35%)\n",
      "\n",
      "Round  11, Average loss 131.395 Test accuracy 90.350\n",
      "selected users: [ 1  2  4  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.9858 \n",
      "Accuracy: 9325/10000 (93.25%)\n",
      "\n",
      "Round  12, Average loss 31.986 Test accuracy 93.250\n",
      "selected users: [ 0  1  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 8.5412 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round  13, Average loss 8.541 Test accuracy 95.520\n",
      "selected users: [ 3  4  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8505 \n",
      "Accuracy: 9246/10000 (92.46%)\n",
      "\n",
      "Round  14, Average loss 3.851 Test accuracy 92.460\n",
      "selected users: [ 0  2  4  5  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.5426 \n",
      "Accuracy: 9384/10000 (93.84%)\n",
      "\n",
      "Round  15, Average loss 13.543 Test accuracy 93.840\n",
      "selected users: [ 0  2  4  5  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 15.3804 \n",
      "Accuracy: 9169/10000 (91.69%)\n",
      "\n",
      "Round  16, Average loss 15.380 Test accuracy 91.690\n",
      "selected users: [ 1  2  3  6  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 3.9312 \n",
      "Accuracy: 9224/10000 (92.24%)\n",
      "\n",
      "Round  17, Average loss 3.931 Test accuracy 92.240\n",
      "selected users: [ 0  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 33.5484 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  18, Average loss 33.548 Test accuracy 93.860\n",
      "selected users: [ 0  2  4  5  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 16.2338 \n",
      "Accuracy: 9229/10000 (92.29%)\n",
      "\n",
      "Round  19, Average loss 16.234 Test accuracy 92.290\n",
      "selected users: [ 2  3  4  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 17.1826 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round  20, Average loss 17.183 Test accuracy 93.880\n",
      "selected users: [ 1  4  5  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 13.1171 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round  21, Average loss 13.117 Test accuracy 93.600\n",
      "selected users: [ 0  3  5  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 42.4286 \n",
      "Accuracy: 9194/10000 (91.94%)\n",
      "\n",
      "Round  22, Average loss 42.429 Test accuracy 91.940\n",
      "selected users: [ 0  2  5  6  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 1.3898 \n",
      "Accuracy: 7587/10000 (75.87%)\n",
      "\n",
      "Round  23, Average loss 1.390 Test accuracy 75.870\n",
      "selected users: [ 1  4  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 6.4273 \n",
      "Accuracy: 9336/10000 (93.36%)\n",
      "\n",
      "Round  24, Average loss 6.427 Test accuracy 93.360\n",
      "selected users: [ 1  2  3  7  8 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 6.0878 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round  25, Average loss 6.088 Test accuracy 92.970\n",
      "selected users: [ 0  1  2  4  5  7  8 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8824 \n",
      "Accuracy: 8537/10000 (85.37%)\n",
      "\n",
      "Round  26, Average loss 1.882 Test accuracy 85.370\n",
      "selected users: [ 0  1  2  3  5  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 28.5104 \n",
      "Accuracy: 9164/10000 (91.64%)\n",
      "\n",
      "Round  27, Average loss 28.510 Test accuracy 91.640\n",
      "selected users: [ 2  3  4  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 13.2565 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round  28, Average loss 13.257 Test accuracy 93.430\n",
      "selected users: [ 2  3  4  6  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 16.6129 \n",
      "Accuracy: 8785/10000 (87.85%)\n",
      "\n",
      "Round  29, Average loss 16.613 Test accuracy 87.850\n",
      "(m= 9 )  7 -th Trial!!\n",
      "selected users: [ 0  4  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  4  5  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4836 \n",
      "Accuracy: 8327/10000 (83.27%)\n",
      "\n",
      "Round   1, Average loss 0.484 Test accuracy 83.270\n",
      "selected users: [ 0  2  4  5  6  7  9 11 13]\n",
      "\n",
      "Test set: Average loss: 0.7926 \n",
      "Accuracy: 9363/10000 (93.63%)\n",
      "\n",
      "Round   2, Average loss 0.793 Test accuracy 93.630\n",
      "selected users: [ 0  1  2  5  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 12.2753 \n",
      "Accuracy: 8860/10000 (88.60%)\n",
      "\n",
      "Round   3, Average loss 12.275 Test accuracy 88.600\n",
      "selected users: [ 1  3  4  6  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.9727 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round   4, Average loss 4.973 Test accuracy 94.110\n",
      "selected users: [ 2  3  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2182 \n",
      "Accuracy: 9192/10000 (91.92%)\n",
      "\n",
      "Round   5, Average loss 2.218 Test accuracy 91.920\n",
      "selected users: [ 0  3  5  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 5.9543 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round   6, Average loss 5.954 Test accuracy 93.760\n",
      "selected users: [ 0  1  5  6  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 8.8159 \n",
      "Accuracy: 9194/10000 (91.94%)\n",
      "\n",
      "Round   7, Average loss 8.816 Test accuracy 91.940\n",
      "selected users: [ 3  4  5  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 3.8829 \n",
      "Accuracy: 8929/10000 (89.29%)\n",
      "\n",
      "Round   8, Average loss 3.883 Test accuracy 89.290\n",
      "selected users: [ 0  3  5  6  7 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 20.5900 \n",
      "Accuracy: 9135/10000 (91.35%)\n",
      "\n",
      "Round   9, Average loss 20.590 Test accuracy 91.350\n",
      "selected users: [ 0  2  3  5  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 4.1777 \n",
      "Accuracy: 9083/10000 (90.83%)\n",
      "\n",
      "Round  10, Average loss 4.178 Test accuracy 90.830\n",
      "selected users: [ 1  2  3  4  5  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 12.6717 \n",
      "Accuracy: 9176/10000 (91.76%)\n",
      "\n",
      "Round  11, Average loss 12.672 Test accuracy 91.760\n",
      "selected users: [ 0  2  4  5  7  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 18.6105 \n",
      "Accuracy: 8114/10000 (81.14%)\n",
      "\n",
      "Round  12, Average loss 18.611 Test accuracy 81.140\n",
      "selected users: [ 3  4  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6428 \n",
      "Accuracy: 8647/10000 (86.47%)\n",
      "\n",
      "Round  13, Average loss 2.643 Test accuracy 86.470\n",
      "selected users: [ 1  2  3  6  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 13.8764 \n",
      "Accuracy: 9109/10000 (91.09%)\n",
      "\n",
      "Round  14, Average loss 13.876 Test accuracy 91.090\n",
      "selected users: [ 0  2  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3020 \n",
      "Accuracy: 1138/10000 (11.38%)\n",
      "\n",
      "Round  15, Average loss 2.302 Test accuracy 11.380\n",
      "selected users: [ 0  1  2  3  5  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.3951 \n",
      "Accuracy: 8149/10000 (81.49%)\n",
      "\n",
      "Round  16, Average loss 1.395 Test accuracy 81.490\n",
      "selected users: [ 1  3  4  5  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.7079 \n",
      "Accuracy: 8942/10000 (89.42%)\n",
      "\n",
      "Round  17, Average loss 0.708 Test accuracy 89.420\n",
      "selected users: [ 1  3  5  6  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0140 \n",
      "Accuracy: 8882/10000 (88.82%)\n",
      "\n",
      "Round  18, Average loss 2.014 Test accuracy 88.820\n",
      "selected users: [ 3  5  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5801 \n",
      "Accuracy: 8046/10000 (80.46%)\n",
      "\n",
      "Round  19, Average loss 0.580 Test accuracy 80.460\n",
      "selected users: [ 0  1  2  4  5  6  7  8 14]\n",
      "\n",
      "Test set: Average loss: 0.1772 \n",
      "Accuracy: 9483/10000 (94.83%)\n",
      "\n",
      "Round  20, Average loss 0.177 Test accuracy 94.830\n",
      "selected users: [ 0  1  2  4  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.5092 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round  21, Average loss 1.509 Test accuracy 94.330\n",
      "selected users: [ 0  3  4  5  6  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3617 \n",
      "Accuracy: 9491/10000 (94.91%)\n",
      "\n",
      "Round  22, Average loss 2.362 Test accuracy 94.910\n",
      "selected users: [ 0  1  2  3  6  7 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5507 \n",
      "Accuracy: 8498/10000 (84.98%)\n",
      "\n",
      "Round  23, Average loss 0.551 Test accuracy 84.980\n",
      "selected users: [ 0  4  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.2609 \n",
      "Accuracy: 9457/10000 (94.57%)\n",
      "\n",
      "Round  24, Average loss 5.261 Test accuracy 94.570\n",
      "selected users: [ 0  1  2  4  6  7  8  9 13]\n",
      "\n",
      "Test set: Average loss: 1.0865 \n",
      "Accuracy: 9379/10000 (93.79%)\n",
      "\n",
      "Round  25, Average loss 1.087 Test accuracy 93.790\n",
      "selected users: [ 1  3  4  5  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 1.5512 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round  26, Average loss 1.551 Test accuracy 93.110\n",
      "selected users: [ 2  3  4  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 5.9084 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  27, Average loss 5.908 Test accuracy 94.620\n",
      "selected users: [ 0  1  3  5  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 4.6420 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round  28, Average loss 4.642 Test accuracy 93.520\n",
      "selected users: [ 1  3  5  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.0433 \n",
      "Accuracy: 9344/10000 (93.44%)\n",
      "\n",
      "Round  29, Average loss 9.043 Test accuracy 93.440\n",
      "(m= 9 )  8 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  9 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  4  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1414 \n",
      "Accuracy: 7858/10000 (78.58%)\n",
      "\n",
      "Round   1, Average loss 1.141 Test accuracy 78.580\n",
      "selected users: [ 2  3  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 0.4783 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round   2, Average loss 0.478 Test accuracy 94.620\n",
      "selected users: [ 1  2  3  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9738 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round   3, Average loss 0.974 Test accuracy 94.980\n",
      "selected users: [ 1  4  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6139 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round   4, Average loss 3.614 Test accuracy 95.250\n",
      "selected users: [ 0  1  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6462 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round   5, Average loss 0.646 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  5  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 5.6001 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round   6, Average loss 5.600 Test accuracy 95.050\n",
      "selected users: [ 2  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5991 \n",
      "Accuracy: 8680/10000 (86.80%)\n",
      "\n",
      "Round   7, Average loss 0.599 Test accuracy 86.800\n",
      "selected users: [ 0  2  5  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6196 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round   8, Average loss 3.620 Test accuracy 94.770\n",
      "selected users: [ 0  1  2  4  5  6  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.6027 \n",
      "Accuracy: 9270/10000 (92.70%)\n",
      "\n",
      "Round   9, Average loss 0.603 Test accuracy 92.700\n",
      "selected users: [ 0  1  4  5  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.0309 \n",
      "Accuracy: 9298/10000 (92.98%)\n",
      "\n",
      "Round  10, Average loss 2.031 Test accuracy 92.980\n",
      "selected users: [ 1  2  3  4  5  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 7.0725 \n",
      "Accuracy: 9329/10000 (93.29%)\n",
      "\n",
      "Round  11, Average loss 7.072 Test accuracy 93.290\n",
      "selected users: [ 0  1  2  4  6  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 6.8619 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round  12, Average loss 6.862 Test accuracy 95.330\n",
      "selected users: [ 2  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.5234 \n",
      "Accuracy: 9143/10000 (91.43%)\n",
      "\n",
      "Round  13, Average loss 3.523 Test accuracy 91.430\n",
      "selected users: [ 1  3  5  6  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 4.2806 \n",
      "Accuracy: 9370/10000 (93.70%)\n",
      "\n",
      "Round  14, Average loss 4.281 Test accuracy 93.700\n",
      "selected users: [ 2  4  5  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 9.2239 \n",
      "Accuracy: 8887/10000 (88.87%)\n",
      "\n",
      "Round  15, Average loss 9.224 Test accuracy 88.870\n",
      "selected users: [ 2  6  7  8  9 10 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.8416 \n",
      "Accuracy: 9285/10000 (92.85%)\n",
      "\n",
      "Round  16, Average loss 2.842 Test accuracy 92.850\n",
      "selected users: [ 0  1  2  3  4  6  8  9 13]\n",
      "\n",
      "Test set: Average loss: 1.2755 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round  17, Average loss 1.275 Test accuracy 93.110\n",
      "selected users: [ 0  2  4  5  6  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 6.4159 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  18, Average loss 6.416 Test accuracy 94.810\n",
      "selected users: [ 1  2  4  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 15.3404 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round  19, Average loss 15.340 Test accuracy 94.560\n",
      "selected users: [ 0  3  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 7.2207 \n",
      "Accuracy: 9226/10000 (92.26%)\n",
      "\n",
      "Round  20, Average loss 7.221 Test accuracy 92.260\n",
      "selected users: [ 0  2  3  5  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 24.8773 \n",
      "Accuracy: 9252/10000 (92.52%)\n",
      "\n",
      "Round  21, Average loss 24.877 Test accuracy 92.520\n",
      "selected users: [ 0  2  5  6  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 12.6633 \n",
      "Accuracy: 8768/10000 (87.68%)\n",
      "\n",
      "Round  22, Average loss 12.663 Test accuracy 87.680\n",
      "selected users: [ 1  2  3  5  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 34.2767 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round  23, Average loss 34.277 Test accuracy 93.240\n",
      "selected users: [ 0  1  2  4  5  6  9 10 14]\n",
      "\n",
      "Test set: Average loss: 20.3595 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  24, Average loss 20.360 Test accuracy 94.960\n",
      "selected users: [ 0  2  3  4  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 28.4099 \n",
      "Accuracy: 9314/10000 (93.14%)\n",
      "\n",
      "Round  25, Average loss 28.410 Test accuracy 93.140\n",
      "selected users: [ 0  1  2  3  5  6  9 12 14]\n",
      "\n",
      "Test set: Average loss: 6.8007 \n",
      "Accuracy: 9444/10000 (94.44%)\n",
      "\n",
      "Round  26, Average loss 6.801 Test accuracy 94.440\n",
      "selected users: [ 0  1  3  4  6  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 17.9761 \n",
      "Accuracy: 9320/10000 (93.20%)\n",
      "\n",
      "Round  27, Average loss 17.976 Test accuracy 93.200\n",
      "selected users: [ 0  1  3  4  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 12.2808 \n",
      "Accuracy: 9243/10000 (92.43%)\n",
      "\n",
      "Round  28, Average loss 12.281 Test accuracy 92.430\n",
      "selected users: [ 0  2  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.3570 \n",
      "Accuracy: 8811/10000 (88.11%)\n",
      "\n",
      "Round  29, Average loss 5.357 Test accuracy 88.110\n",
      "(m= 9 )  9 -th Trial!!\n",
      "selected users: [ 1  2  3  4  5  6  8 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 2  3  5  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 1.6865 \n",
      "Accuracy: 8250/10000 (82.50%)\n",
      "\n",
      "Round   1, Average loss 1.686 Test accuracy 82.500\n",
      "selected users: [ 0  2  3  6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.5982 \n",
      "Accuracy: 9305/10000 (93.05%)\n",
      "\n",
      "Round   2, Average loss 1.598 Test accuracy 93.050\n",
      "selected users: [ 1  2  4  6  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9498 \n",
      "Accuracy: 9282/10000 (92.82%)\n",
      "\n",
      "Round   3, Average loss 2.950 Test accuracy 92.820\n",
      "selected users: [ 0  1  3  4  5  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7360 \n",
      "Accuracy: 8923/10000 (89.23%)\n",
      "\n",
      "Round   4, Average loss 1.736 Test accuracy 89.230\n",
      "selected users: [ 1  2  4  5  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.8710 \n",
      "Accuracy: 9322/10000 (93.22%)\n",
      "\n",
      "Round   5, Average loss 0.871 Test accuracy 93.220\n",
      "selected users: [ 3  4  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.3331 \n",
      "Accuracy: 8990/10000 (89.90%)\n",
      "\n",
      "Round   6, Average loss 1.333 Test accuracy 89.900\n",
      "selected users: [ 1  2  3  4 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 31.9079 \n",
      "Accuracy: 9179/10000 (91.79%)\n",
      "\n",
      "Round   7, Average loss 31.908 Test accuracy 91.790\n",
      "selected users: [ 1  3  5  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 12.9339 \n",
      "Accuracy: 9385/10000 (93.85%)\n",
      "\n",
      "Round   8, Average loss 12.934 Test accuracy 93.850\n",
      "selected users: [ 0  4  5  6  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 27.7926 \n",
      "Accuracy: 9431/10000 (94.31%)\n",
      "\n",
      "Round   9, Average loss 27.793 Test accuracy 94.310\n",
      "selected users: [ 1  3  4  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 20.6643 \n",
      "Accuracy: 9437/10000 (94.37%)\n",
      "\n",
      "Round  10, Average loss 20.664 Test accuracy 94.370\n",
      "selected users: [ 0  4  5  6  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 29.4033 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  11, Average loss 29.403 Test accuracy 94.630\n",
      "selected users: [ 1  2  3  6  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 19.6816 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round  12, Average loss 19.682 Test accuracy 94.680\n",
      "selected users: [ 0  1  2  6  7  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 12.3003 \n",
      "Accuracy: 9148/10000 (91.48%)\n",
      "\n",
      "Round  13, Average loss 12.300 Test accuracy 91.480\n",
      "selected users: [ 1  2  4  5  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 25.5258 \n",
      "Accuracy: 9377/10000 (93.77%)\n",
      "\n",
      "Round  14, Average loss 25.526 Test accuracy 93.770\n",
      "selected users: [ 2  3  5  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 23.1874 \n",
      "Accuracy: 9066/10000 (90.66%)\n",
      "\n",
      "Round  15, Average loss 23.187 Test accuracy 90.660\n",
      "selected users: [ 1  2  4  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 24.3314 \n",
      "Accuracy: 9412/10000 (94.12%)\n",
      "\n",
      "Round  16, Average loss 24.331 Test accuracy 94.120\n",
      "selected users: [ 0  1  4  5  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 9.8564 \n",
      "Accuracy: 9267/10000 (92.67%)\n",
      "\n",
      "Round  17, Average loss 9.856 Test accuracy 92.670\n",
      "selected users: [ 0  1  2  3  4  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 24.4718 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  18, Average loss 24.472 Test accuracy 94.030\n",
      "selected users: [ 4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 20.4201 \n",
      "Accuracy: 9347/10000 (93.47%)\n",
      "\n",
      "Round  19, Average loss 20.420 Test accuracy 93.470\n",
      "selected users: [ 1  2  4  5  7  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 27.1346 \n",
      "Accuracy: 9093/10000 (90.93%)\n",
      "\n",
      "Round  20, Average loss 27.135 Test accuracy 90.930\n",
      "selected users: [ 3  4  5  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 12.8127 \n",
      "Accuracy: 9323/10000 (93.23%)\n",
      "\n",
      "Round  21, Average loss 12.813 Test accuracy 93.230\n",
      "selected users: [ 0  2  4  6  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 16.2464 \n",
      "Accuracy: 9120/10000 (91.20%)\n",
      "\n",
      "Round  22, Average loss 16.246 Test accuracy 91.200\n",
      "selected users: [ 1  2  5  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 20.2457 \n",
      "Accuracy: 9216/10000 (92.16%)\n",
      "\n",
      "Round  23, Average loss 20.246 Test accuracy 92.160\n",
      "selected users: [ 0  1  4  5  6 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 25.0667 \n",
      "Accuracy: 9444/10000 (94.44%)\n",
      "\n",
      "Round  24, Average loss 25.067 Test accuracy 94.440\n",
      "selected users: [ 0  3  4  6  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 21.6035 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  25, Average loss 21.604 Test accuracy 94.030\n",
      "selected users: [ 0  1  3  4  6  7 11 13 14]\n",
      "\n",
      "Test set: Average loss: 26.4979 \n",
      "Accuracy: 9440/10000 (94.40%)\n",
      "\n",
      "Round  26, Average loss 26.498 Test accuracy 94.400\n",
      "selected users: [ 0  2  3  6  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 26.4222 \n",
      "Accuracy: 9297/10000 (92.97%)\n",
      "\n",
      "Round  27, Average loss 26.422 Test accuracy 92.970\n",
      "selected users: [ 0  1  2  4  5  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 35.4968 \n",
      "Accuracy: 9181/10000 (91.81%)\n",
      "\n",
      "Round  28, Average loss 35.497 Test accuracy 91.810\n",
      "selected users: [ 0  2  3  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 21.4372 \n",
      "Accuracy: 9094/10000 (90.94%)\n",
      "\n",
      "Round  29, Average loss 21.437 Test accuracy 90.940\n",
      "number of results: 10\n",
      "(m= 10 )  0 -th Trial!!\n",
      "selected users: [ 2  3  4  5  6  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2911 \n",
      "Accuracy: 3568/10000 (35.68%)\n",
      "\n",
      "Round   0, Average loss 2.291 Test accuracy 35.680\n",
      "selected users: [ 3  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3966 \n",
      "Accuracy: 9114/10000 (91.14%)\n",
      "\n",
      "Round   1, Average loss 1.397 Test accuracy 91.140\n",
      "selected users: [ 0  1  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.2279 \n",
      "Accuracy: 9323/10000 (93.23%)\n",
      "\n",
      "Round   2, Average loss 0.228 Test accuracy 93.230\n",
      "selected users: [ 2  3  4  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5650 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round   3, Average loss 1.565 Test accuracy 93.810\n",
      "selected users: [ 1  3  4  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3051 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round   4, Average loss 1.305 Test accuracy 95.140\n",
      "selected users: [ 0  3  4  5  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.7530 \n",
      "Accuracy: 9267/10000 (92.67%)\n",
      "\n",
      "Round   5, Average loss 2.753 Test accuracy 92.670\n",
      "selected users: [ 0  1  2  3  4  5  7  8 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6765 \n",
      "Accuracy: 7758/10000 (77.58%)\n",
      "\n",
      "Round   6, Average loss 0.676 Test accuracy 77.580\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3368 \n",
      "Accuracy: 8891/10000 (88.91%)\n",
      "\n",
      "Round   7, Average loss 2.337 Test accuracy 88.910\n",
      "selected users: [ 0  2  4  5  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.9570 \n",
      "Accuracy: 8513/10000 (85.13%)\n",
      "\n",
      "Round   8, Average loss 5.957 Test accuracy 85.130\n",
      "selected users: [ 0  3  4  5  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.4657 \n",
      "Accuracy: 9013/10000 (90.13%)\n",
      "\n",
      "Round   9, Average loss 4.466 Test accuracy 90.130\n",
      "selected users: [ 0  1  4  5  6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 3.1184 \n",
      "Accuracy: 9317/10000 (93.17%)\n",
      "\n",
      "Round  10, Average loss 3.118 Test accuracy 93.170\n",
      "selected users: [ 0  1  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4682 \n",
      "Accuracy: 9187/10000 (91.87%)\n",
      "\n",
      "Round  11, Average loss 0.468 Test accuracy 91.870\n",
      "selected users: [ 0  2  3  4  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 3.9574 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round  12, Average loss 3.957 Test accuracy 95.050\n",
      "selected users: [ 0  1  2  3  4  6 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.8005 \n",
      "Accuracy: 9303/10000 (93.03%)\n",
      "\n",
      "Round  13, Average loss 10.800 Test accuracy 93.030\n",
      "selected users: [ 1  2  3  4  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 9.7663 \n",
      "Accuracy: 9337/10000 (93.37%)\n",
      "\n",
      "Round  14, Average loss 9.766 Test accuracy 93.370\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 14]\n",
      "\n",
      "Test set: Average loss: 3.7250 \n",
      "Accuracy: 9495/10000 (94.95%)\n",
      "\n",
      "Round  15, Average loss 3.725 Test accuracy 94.950\n",
      "selected users: [ 0  1  2  5  6  7 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.8415 \n",
      "Accuracy: 9158/10000 (91.58%)\n",
      "\n",
      "Round  16, Average loss 10.841 Test accuracy 91.580\n",
      "selected users: [ 0  1  2  5  6  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 1.1234 \n",
      "Accuracy: 8539/10000 (85.39%)\n",
      "\n",
      "Round  17, Average loss 1.123 Test accuracy 85.390\n",
      "selected users: [ 0  1  2  3  6  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7364 \n",
      "Accuracy: 8747/10000 (87.47%)\n",
      "\n",
      "Round  18, Average loss 0.736 Test accuracy 87.470\n",
      "selected users: [ 0  1  5  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3738 \n",
      "Accuracy: 9253/10000 (92.53%)\n",
      "\n",
      "Round  19, Average loss 0.374 Test accuracy 92.530\n",
      "selected users: [ 3  4  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2770 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  20, Average loss 0.277 Test accuracy 95.240\n",
      "selected users: [ 0  2  3  5  6  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 3.3483 \n",
      "Accuracy: 9183/10000 (91.83%)\n",
      "\n",
      "Round  21, Average loss 3.348 Test accuracy 91.830\n",
      "selected users: [ 0  1  2  4  6  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8232 \n",
      "Accuracy: 9372/10000 (93.72%)\n",
      "\n",
      "Round  22, Average loss 1.823 Test accuracy 93.720\n",
      "selected users: [ 0  1  2  4  6  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 0.8107 \n",
      "Accuracy: 9410/10000 (94.10%)\n",
      "\n",
      "Round  23, Average loss 0.811 Test accuracy 94.100\n",
      "selected users: [ 1  2  4  5  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1169 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  24, Average loss 3.117 Test accuracy 95.210\n",
      "selected users: [ 0  1  3  4  5  6  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2676 \n",
      "Accuracy: 2087/10000 (20.87%)\n",
      "\n",
      "Round  25, Average loss 2.268 Test accuracy 20.870\n",
      "selected users: [ 0  3  4  5  6  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2057 \n",
      "Accuracy: 9392/10000 (93.92%)\n",
      "\n",
      "Round  26, Average loss 0.206 Test accuracy 93.920\n",
      "selected users: [ 0  2  4  5  6  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9007 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round  27, Average loss 0.901 Test accuracy 94.200\n",
      "selected users: [ 0  1  3  5  6  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8796 \n",
      "Accuracy: 9305/10000 (93.05%)\n",
      "\n",
      "Round  28, Average loss 0.880 Test accuracy 93.050\n",
      "selected users: [ 0  1  2  3  4  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.6163 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round  29, Average loss 1.616 Test accuracy 93.110\n",
      "(m= 10 )  1 -th Trial!!\n",
      "selected users: [ 1  2  3  4  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4  5  6  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.1539 \n",
      "Accuracy: 7823/10000 (78.23%)\n",
      "\n",
      "Round   1, Average loss 2.154 Test accuracy 78.230\n",
      "selected users: [ 1  2  3  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3137 \n",
      "Accuracy: 9241/10000 (92.41%)\n",
      "\n",
      "Round   2, Average loss 0.314 Test accuracy 92.410\n",
      "selected users: [ 2  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3336 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round   3, Average loss 0.334 Test accuracy 95.020\n",
      "selected users: [ 0  1  2  3  5  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7823 \n",
      "Accuracy: 9277/10000 (92.77%)\n",
      "\n",
      "Round   4, Average loss 0.782 Test accuracy 92.770\n",
      "selected users: [ 0  1  3  5  6  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5126 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round   5, Average loss 0.513 Test accuracy 94.080\n",
      "selected users: [ 0  1  2  3  6  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.7171 \n",
      "Accuracy: 9373/10000 (93.73%)\n",
      "\n",
      "Round   6, Average loss 0.717 Test accuracy 93.730\n",
      "selected users: [ 0  2  3  4  5  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.4782 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round   7, Average loss 3.478 Test accuracy 93.710\n",
      "selected users: [ 0  1  2  5  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.5722 \n",
      "Accuracy: 9204/10000 (92.04%)\n",
      "\n",
      "Round   8, Average loss 3.572 Test accuracy 92.040\n",
      "selected users: [ 0  1  2  4  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2055 \n",
      "Accuracy: 9169/10000 (91.69%)\n",
      "\n",
      "Round   9, Average loss 4.206 Test accuracy 91.690\n",
      "selected users: [ 1  2  3  4  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 3.6563 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  10, Average loss 3.656 Test accuracy 95.020\n",
      "selected users: [ 2  3  5  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.7021 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round  11, Average loss 2.702 Test accuracy 92.490\n",
      "selected users: [ 1  2  3  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6825 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  12, Average loss 1.683 Test accuracy 94.810\n",
      "selected users: [ 2  3  4  5  6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 1.2408 \n",
      "Accuracy: 8982/10000 (89.82%)\n",
      "\n",
      "Round  13, Average loss 1.241 Test accuracy 89.820\n",
      "selected users: [ 2  3  4  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.5828 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  14, Average loss 2.583 Test accuracy 95.140\n",
      "selected users: [ 0  1  2  3  4  5  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.3067 \n",
      "Accuracy: 9188/10000 (91.88%)\n",
      "\n",
      "Round  15, Average loss 1.307 Test accuracy 91.880\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 3.2077 \n",
      "Accuracy: 9452/10000 (94.52%)\n",
      "\n",
      "Round  16, Average loss 3.208 Test accuracy 94.520\n",
      "selected users: [ 3  4  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7302 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round  17, Average loss 0.730 Test accuracy 93.710\n",
      "selected users: [ 0  1  2  3  4  5  7 10 11 12]\n",
      "\n",
      "Test set: Average loss: 3.7478 \n",
      "Accuracy: 7885/10000 (78.85%)\n",
      "\n",
      "Round  18, Average loss 3.748 Test accuracy 78.850\n",
      "selected users: [ 0  1  2  3  5  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.0729 \n",
      "Accuracy: 9201/10000 (92.01%)\n",
      "\n",
      "Round  19, Average loss 3.073 Test accuracy 92.010\n",
      "selected users: [ 0  1  3  4  5  6  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3629 \n",
      "Accuracy: 9277/10000 (92.77%)\n",
      "\n",
      "Round  20, Average loss 0.363 Test accuracy 92.770\n",
      "selected users: [ 0  1  4  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8962 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round  21, Average loss 1.896 Test accuracy 95.400\n",
      "selected users: [ 0  1  2  3  4  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8649 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round  22, Average loss 2.865 Test accuracy 94.930\n",
      "selected users: [ 0  1  2  3  5  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 6.9366 \n",
      "Accuracy: 9073/10000 (90.73%)\n",
      "\n",
      "Round  23, Average loss 6.937 Test accuracy 90.730\n",
      "selected users: [ 1  3  4  5  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 6.1467 \n",
      "Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Round  24, Average loss 6.147 Test accuracy 94.720\n",
      "selected users: [ 1  2  4  5  6  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9591 \n",
      "Accuracy: 9278/10000 (92.78%)\n",
      "\n",
      "Round  25, Average loss 4.959 Test accuracy 92.780\n",
      "selected users: [ 0  1  2  3  4  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 4.3596 \n",
      "Accuracy: 9094/10000 (90.94%)\n",
      "\n",
      "Round  26, Average loss 4.360 Test accuracy 90.940\n",
      "selected users: [ 1  3  4  5  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 5.5753 \n",
      "Accuracy: 9385/10000 (93.85%)\n",
      "\n",
      "Round  27, Average loss 5.575 Test accuracy 93.850\n",
      "selected users: [ 0  2  4  5  6  7  9 11 12 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 7.5718 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round  28, Average loss 7.572 Test accuracy 93.870\n",
      "selected users: [ 2  3  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3926 \n",
      "Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Round  29, Average loss 2.393 Test accuracy 91.980\n",
      "(m= 10 )  2 -th Trial!!\n",
      "selected users: [ 1  3  4  5  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3019 \n",
      "Accuracy: 1770/10000 (17.70%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 17.700\n",
      "selected users: [ 1  3  4  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.7569 \n",
      "Accuracy: 8065/10000 (80.65%)\n",
      "\n",
      "Round   1, Average loss 1.757 Test accuracy 80.650\n",
      "selected users: [ 1  2  3  4  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8913 \n",
      "Accuracy: 9251/10000 (92.51%)\n",
      "\n",
      "Round   2, Average loss 0.891 Test accuracy 92.510\n",
      "selected users: [ 1  2  3  4  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6227 \n",
      "Accuracy: 9385/10000 (93.85%)\n",
      "\n",
      "Round   3, Average loss 0.623 Test accuracy 93.850\n",
      "selected users: [ 3  4  5  6  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2784 \n",
      "Accuracy: 9363/10000 (93.63%)\n",
      "\n",
      "Round   4, Average loss 0.278 Test accuracy 93.630\n",
      "selected users: [ 1  2  3  4  5  6 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0745 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round   5, Average loss 2.075 Test accuracy 94.200\n",
      "selected users: [ 1  2  3  4  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.4834 \n",
      "Accuracy: 9415/10000 (94.15%)\n",
      "\n",
      "Round   6, Average loss 1.483 Test accuracy 94.150\n",
      "selected users: [ 0  1  2  4  5  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.6522 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round   7, Average loss 3.652 Test accuracy 94.880\n",
      "selected users: [ 0  2  3  4  6  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 1.9336 \n",
      "Accuracy: 9379/10000 (93.79%)\n",
      "\n",
      "Round   8, Average loss 1.934 Test accuracy 93.790\n",
      "selected users: [ 1  3  4  5  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 4.6562 \n",
      "Accuracy: 9215/10000 (92.15%)\n",
      "\n",
      "Round   9, Average loss 4.656 Test accuracy 92.150\n",
      "selected users: [ 1  2  3  5  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 3.4319 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  10, Average loss 3.432 Test accuracy 94.650\n",
      "selected users: [ 0  2  3  4  6  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.9183 \n",
      "Accuracy: 9418/10000 (94.18%)\n",
      "\n",
      "Round  11, Average loss 4.918 Test accuracy 94.180\n",
      "selected users: [ 3  4  5  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.2125 \n",
      "Accuracy: 8677/10000 (86.77%)\n",
      "\n",
      "Round  12, Average loss 1.212 Test accuracy 86.770\n",
      "selected users: [ 1  2  3  4  5  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.2871 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round  13, Average loss 4.287 Test accuracy 94.390\n",
      "selected users: [ 0  1  4  5  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9320 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  14, Average loss 2.932 Test accuracy 94.870\n",
      "selected users: [ 1  2  3  4  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.0401 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  15, Average loss 5.040 Test accuracy 95.100\n",
      "selected users: [ 0  1  2  4  6  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6947 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round  16, Average loss 2.695 Test accuracy 95.030\n",
      "selected users: [ 0  1  2  5  6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 1.3156 \n",
      "Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Round  17, Average loss 1.316 Test accuracy 91.980\n",
      "selected users: [ 1  3  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6010 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round  18, Average loss 0.601 Test accuracy 93.810\n",
      "selected users: [ 0  4  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.7853 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round  19, Average loss 6.785 Test accuracy 94.610\n",
      "selected users: [ 0  1  3  4  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 2.7692 \n",
      "Accuracy: 9197/10000 (91.97%)\n",
      "\n",
      "Round  20, Average loss 2.769 Test accuracy 91.970\n",
      "selected users: [ 0  1  2  4  5  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 6.0749 \n",
      "Accuracy: 9064/10000 (90.64%)\n",
      "\n",
      "Round  21, Average loss 6.075 Test accuracy 90.640\n",
      "selected users: [ 0  1  3  4  5  6  7  9 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6483 \n",
      "Accuracy: 8847/10000 (88.47%)\n",
      "\n",
      "Round  22, Average loss 0.648 Test accuracy 88.470\n",
      "selected users: [ 0  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.2305 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  23, Average loss 6.231 Test accuracy 94.960\n",
      "selected users: [ 0  3  4  5  6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 10.0176 \n",
      "Accuracy: 9397/10000 (93.97%)\n",
      "\n",
      "Round  24, Average loss 10.018 Test accuracy 93.970\n",
      "selected users: [ 0  1  3  4  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 6.1498 \n",
      "Accuracy: 9522/10000 (95.22%)\n",
      "\n",
      "Round  25, Average loss 6.150 Test accuracy 95.220\n",
      "selected users: [ 1  2  3  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.5130 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  26, Average loss 3.513 Test accuracy 94.760\n",
      "selected users: [ 0  1  2  4  5  6  7 10 11 13]\n",
      "\n",
      "Test set: Average loss: 3.6581 \n",
      "Accuracy: 9118/10000 (91.18%)\n",
      "\n",
      "Round  27, Average loss 3.658 Test accuracy 91.180\n",
      "selected users: [ 0  3  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 3.5298 \n",
      "Accuracy: 9474/10000 (94.74%)\n",
      "\n",
      "Round  28, Average loss 3.530 Test accuracy 94.740\n",
      "selected users: [ 2  3  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6171 \n",
      "Accuracy: 8518/10000 (85.18%)\n",
      "\n",
      "Round  29, Average loss 0.617 Test accuracy 85.180\n",
      "(m= 10 )  3 -th Trial!!\n",
      "selected users: [ 0  1  3  4  5 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  6 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.1839 \n",
      "Accuracy: 6227/10000 (62.27%)\n",
      "\n",
      "Round   1, Average loss 2.184 Test accuracy 62.270\n",
      "selected users: [ 1  2  3  5  6  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6934 \n",
      "Accuracy: 8872/10000 (88.72%)\n",
      "\n",
      "Round   2, Average loss 1.693 Test accuracy 88.720\n",
      "selected users: [ 0  1  3  4  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.2466 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round   3, Average loss 0.247 Test accuracy 95.090\n",
      "selected users: [ 0  1  3  5  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2254 \n",
      "Accuracy: 9291/10000 (92.91%)\n",
      "\n",
      "Round   4, Average loss 1.225 Test accuracy 92.910\n",
      "selected users: [ 1  2  3  5  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.5334 \n",
      "Accuracy: 9248/10000 (92.48%)\n",
      "\n",
      "Round   5, Average loss 4.533 Test accuracy 92.480\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 0.6145 \n",
      "Accuracy: 9345/10000 (93.45%)\n",
      "\n",
      "Round   6, Average loss 0.615 Test accuracy 93.450\n",
      "selected users: [ 0  1  2  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.9880 \n",
      "Accuracy: 9119/10000 (91.19%)\n",
      "\n",
      "Round   7, Average loss 2.988 Test accuracy 91.190\n",
      "selected users: [ 1  2  3  5  6  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.9218 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round   8, Average loss 1.922 Test accuracy 94.280\n",
      "selected users: [ 1  2  3  6  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1572 \n",
      "Accuracy: 9435/10000 (94.35%)\n",
      "\n",
      "Round   9, Average loss 3.157 Test accuracy 94.350\n",
      "selected users: [ 0  2  3  5  6  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 5.9671 \n",
      "Accuracy: 9466/10000 (94.66%)\n",
      "\n",
      "Round  10, Average loss 5.967 Test accuracy 94.660\n",
      "selected users: [ 0  1  2  3  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8779 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round  11, Average loss 1.878 Test accuracy 95.000\n",
      "selected users: [ 0  1  2  4  6  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6840 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round  12, Average loss 3.684 Test accuracy 94.670\n",
      "selected users: [ 0  3  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5349 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round  13, Average loss 2.535 Test accuracy 94.750\n",
      "selected users: [ 0  1  3  4  5  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.5213 \n",
      "Accuracy: 9178/10000 (91.78%)\n",
      "\n",
      "Round  14, Average loss 1.521 Test accuracy 91.780\n",
      "selected users: [ 2  3  4  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8096 \n",
      "Accuracy: 9418/10000 (94.18%)\n",
      "\n",
      "Round  15, Average loss 2.810 Test accuracy 94.180\n",
      "selected users: [ 0  1  2  3  4  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 6.3544 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  16, Average loss 6.354 Test accuracy 95.250\n",
      "selected users: [ 0  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 16.3785 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round  17, Average loss 16.379 Test accuracy 94.390\n",
      "selected users: [ 1  2  4  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 13.2643 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  18, Average loss 13.264 Test accuracy 94.620\n",
      "selected users: [ 2  3  4  5  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9327 \n",
      "Accuracy: 9322/10000 (93.22%)\n",
      "\n",
      "Round  19, Average loss 6.933 Test accuracy 93.220\n",
      "selected users: [ 0  1  2  3  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8122 \n",
      "Accuracy: 7553/10000 (75.53%)\n",
      "\n",
      "Round  20, Average loss 0.812 Test accuracy 75.530\n",
      "selected users: [ 0  1  2  4  6  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7610 \n",
      "Accuracy: 9338/10000 (93.38%)\n",
      "\n",
      "Round  21, Average loss 1.761 Test accuracy 93.380\n",
      "selected users: [ 0  2  3  4  5  6  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 4.0116 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round  22, Average loss 4.012 Test accuracy 92.380\n",
      "selected users: [ 0  1  3  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3020 \n",
      "Accuracy: 9148/10000 (91.48%)\n",
      "\n",
      "Round  23, Average loss 0.302 Test accuracy 91.480\n",
      "selected users: [ 0  3  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 10.7956 \n",
      "Accuracy: 9210/10000 (92.10%)\n",
      "\n",
      "Round  24, Average loss 10.796 Test accuracy 92.100\n",
      "selected users: [ 0  1  2  3  4  6  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 1.5528 \n",
      "Accuracy: 9394/10000 (93.94%)\n",
      "\n",
      "Round  25, Average loss 1.553 Test accuracy 93.940\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.3856 \n",
      "Accuracy: 8781/10000 (87.81%)\n",
      "\n",
      "Round  26, Average loss 0.386 Test accuracy 87.810\n",
      "selected users: [ 0  3  4  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2180 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round  27, Average loss 2.218 Test accuracy 93.830\n",
      "selected users: [ 1  3  4  5  6  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7880 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  28, Average loss 0.788 Test accuracy 94.960\n",
      "selected users: [ 0  3  4  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3382 \n",
      "Accuracy: 9213/10000 (92.13%)\n",
      "\n",
      "Round  29, Average loss 2.338 Test accuracy 92.130\n",
      "(m= 10 )  4 -th Trial!!\n",
      "selected users: [ 0  2  4  5  6  7  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  4  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2356 \n",
      "Accuracy: 7262/10000 (72.62%)\n",
      "\n",
      "Round   1, Average loss 1.236 Test accuracy 72.620\n",
      "selected users: [ 2  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3198 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round   2, Average loss 0.320 Test accuracy 93.710\n",
      "selected users: [ 0  1  3  5  6  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5230 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round   3, Average loss 0.523 Test accuracy 95.090\n",
      "selected users: [ 0  1  3  5  6  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6526 \n",
      "Accuracy: 9294/10000 (92.94%)\n",
      "\n",
      "Round   4, Average loss 0.653 Test accuracy 92.940\n",
      "selected users: [ 0  1  2  3  5  6  7  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.5775 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round   5, Average loss 0.577 Test accuracy 94.030\n",
      "selected users: [ 0  1  2  4  5  6  7 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1.1082 \n",
      "Accuracy: 9199/10000 (91.99%)\n",
      "\n",
      "Round   6, Average loss 1.108 Test accuracy 91.990\n",
      "selected users: [ 1  3  4  5  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0744 \n",
      "Accuracy: 9249/10000 (92.49%)\n",
      "\n",
      "Round   7, Average loss 2.074 Test accuracy 92.490\n",
      "selected users: [ 0  1  2  3  4  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8524 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round   8, Average loss 1.852 Test accuracy 93.930\n",
      "selected users: [ 2  3  4  5  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.7965 \n",
      "Accuracy: 9130/10000 (91.30%)\n",
      "\n",
      "Round   9, Average loss 2.797 Test accuracy 91.300\n",
      "selected users: [ 4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.0996 \n",
      "Accuracy: 9474/10000 (94.74%)\n",
      "\n",
      "Round  10, Average loss 3.100 Test accuracy 94.740\n",
      "selected users: [ 0  1  2  4  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.8341 \n",
      "Accuracy: 9275/10000 (92.75%)\n",
      "\n",
      "Round  11, Average loss 1.834 Test accuracy 92.750\n",
      "selected users: [ 0  1  2  4  5  6  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5253 \n",
      "Accuracy: 9427/10000 (94.27%)\n",
      "\n",
      "Round  12, Average loss 0.525 Test accuracy 94.270\n",
      "selected users: [ 0  2  3  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.9372 \n",
      "Accuracy: 9429/10000 (94.29%)\n",
      "\n",
      "Round  13, Average loss 3.937 Test accuracy 94.290\n",
      "selected users: [ 0  3  5  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.0834 \n",
      "Accuracy: 8944/10000 (89.44%)\n",
      "\n",
      "Round  14, Average loss 1.083 Test accuracy 89.440\n",
      "selected users: [ 1  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2673 \n",
      "Accuracy: 9355/10000 (93.55%)\n",
      "\n",
      "Round  15, Average loss 3.267 Test accuracy 93.550\n",
      "selected users: [ 0  1  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.9726 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  16, Average loss 3.973 Test accuracy 94.500\n",
      "selected users: [ 0  2  3  4  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 10.0098 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round  17, Average loss 10.010 Test accuracy 94.560\n",
      "selected users: [ 0  1  2  4  5  6  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 6.3975 \n",
      "Accuracy: 9432/10000 (94.32%)\n",
      "\n",
      "Round  18, Average loss 6.397 Test accuracy 94.320\n",
      "selected users: [ 0  2  3  4  6  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 9.4029 \n",
      "Accuracy: 9321/10000 (93.21%)\n",
      "\n",
      "Round  19, Average loss 9.403 Test accuracy 93.210\n",
      "selected users: [ 1  2  4  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 5.7506 \n",
      "Accuracy: 9303/10000 (93.03%)\n",
      "\n",
      "Round  20, Average loss 5.751 Test accuracy 93.030\n",
      "selected users: [ 1  3  4  5  6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 3.7080 \n",
      "Accuracy: 9252/10000 (92.52%)\n",
      "\n",
      "Round  21, Average loss 3.708 Test accuracy 92.520\n",
      "selected users: [ 3  4  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8782 \n",
      "Accuracy: 9137/10000 (91.37%)\n",
      "\n",
      "Round  22, Average loss 0.878 Test accuracy 91.370\n",
      "selected users: [ 1  2  3  4  5  6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 6.8796 \n",
      "Accuracy: 9360/10000 (93.60%)\n",
      "\n",
      "Round  23, Average loss 6.880 Test accuracy 93.600\n",
      "selected users: [ 0  1  3  4  5  6  7  9 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1731 \n",
      "Accuracy: 9361/10000 (93.61%)\n",
      "\n",
      "Round  24, Average loss 1.173 Test accuracy 93.610\n",
      "selected users: [ 1  2  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7086 \n",
      "Accuracy: 9321/10000 (93.21%)\n",
      "\n",
      "Round  25, Average loss 3.709 Test accuracy 93.210\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 13]\n",
      "\n",
      "Test set: Average loss: 2.6049 \n",
      "Accuracy: 9298/10000 (92.98%)\n",
      "\n",
      "Round  26, Average loss 2.605 Test accuracy 92.980\n",
      "selected users: [ 0  1  3  4  5  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.5305 \n",
      "Accuracy: 9404/10000 (94.04%)\n",
      "\n",
      "Round  27, Average loss 3.531 Test accuracy 94.040\n",
      "selected users: [ 0  2  3  4  5  6  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 1.4523 \n",
      "Accuracy: 9060/10000 (90.60%)\n",
      "\n",
      "Round  28, Average loss 1.452 Test accuracy 90.600\n",
      "selected users: [ 1  2  3  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1430 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  29, Average loss 2.143 Test accuracy 95.020\n",
      "(m= 10 )  5 -th Trial!!\n",
      "selected users: [ 1  2  3  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1293 \n",
      "Accuracy: 6343/10000 (63.43%)\n",
      "\n",
      "Round   1, Average loss 2.129 Test accuracy 63.430\n",
      "selected users: [ 0  2  4  5  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.2175 \n",
      "Accuracy: 9170/10000 (91.70%)\n",
      "\n",
      "Round   2, Average loss 1.217 Test accuracy 91.700\n",
      "selected users: [ 0  3  4  5  6  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9278 \n",
      "Accuracy: 9245/10000 (92.45%)\n",
      "\n",
      "Round   3, Average loss 2.928 Test accuracy 92.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 13]\n",
      "\n",
      "Test set: Average loss: 2.3606 \n",
      "Accuracy: 9190/10000 (91.90%)\n",
      "\n",
      "Round   4, Average loss 2.361 Test accuracy 91.900\n",
      "selected users: [ 0  2  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9412 \n",
      "Accuracy: 9263/10000 (92.63%)\n",
      "\n",
      "Round   5, Average loss 4.941 Test accuracy 92.630\n",
      "selected users: [ 0  1  2  4  5  6  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2357 \n",
      "Accuracy: 3080/10000 (30.80%)\n",
      "\n",
      "Round   6, Average loss 2.236 Test accuracy 30.800\n",
      "selected users: [ 0  1  2  3  5  6  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 0.2913 \n",
      "Accuracy: 9314/10000 (93.14%)\n",
      "\n",
      "Round   7, Average loss 0.291 Test accuracy 93.140\n",
      "selected users: [ 0  3  4  5  6  7 10 11 12 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8326 \n",
      "Accuracy: 9194/10000 (91.94%)\n",
      "\n",
      "Round   8, Average loss 1.833 Test accuracy 91.940\n",
      "selected users: [ 0  1  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.9493 \n",
      "Accuracy: 9068/10000 (90.68%)\n",
      "\n",
      "Round   9, Average loss 0.949 Test accuracy 90.680\n",
      "selected users: [ 1  2  4  5  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8394 \n",
      "Accuracy: 8792/10000 (87.92%)\n",
      "\n",
      "Round  10, Average loss 5.839 Test accuracy 87.920\n",
      "selected users: [ 0  2  3  4  5  6  7  8 11 13]\n",
      "\n",
      "Test set: Average loss: 1.0981 \n",
      "Accuracy: 9303/10000 (93.03%)\n",
      "\n",
      "Round  11, Average loss 1.098 Test accuracy 93.030\n",
      "selected users: [ 0  3  4  5  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.0493 \n",
      "Accuracy: 9012/10000 (90.12%)\n",
      "\n",
      "Round  12, Average loss 13.049 Test accuracy 90.120\n",
      "selected users: [ 2  3  4  5  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.2054 \n",
      "Accuracy: 9021/10000 (90.21%)\n",
      "\n",
      "Round  13, Average loss 1.205 Test accuracy 90.210\n",
      "selected users: [ 1  2  3  4  5  6  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6973 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round  14, Average loss 0.697 Test accuracy 94.200\n",
      "selected users: [ 1  2  3  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.5437 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  15, Average loss 1.544 Test accuracy 94.510\n",
      "selected users: [ 0  1  2  3  5  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5512 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round  16, Average loss 0.551 Test accuracy 93.810\n",
      "selected users: [ 1  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5721 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  17, Average loss 2.572 Test accuracy 95.140\n",
      "selected users: [ 1  2  3  4  5  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 3.6579 \n",
      "Accuracy: 9211/10000 (92.11%)\n",
      "\n",
      "Round  18, Average loss 3.658 Test accuracy 92.110\n",
      "selected users: [ 0  1  3  4  6  7  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1.4171 \n",
      "Accuracy: 9223/10000 (92.23%)\n",
      "\n",
      "Round  19, Average loss 1.417 Test accuracy 92.230\n",
      "selected users: [ 1  2  3  4  5  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 5.5605 \n",
      "Accuracy: 8980/10000 (89.80%)\n",
      "\n",
      "Round  20, Average loss 5.561 Test accuracy 89.800\n",
      "selected users: [ 0  2  4  5  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 6.3533 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round  21, Average loss 6.353 Test accuracy 93.830\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 13]\n",
      "\n",
      "Test set: Average loss: 0.7334 \n",
      "Accuracy: 9055/10000 (90.55%)\n",
      "\n",
      "Round  22, Average loss 0.733 Test accuracy 90.550\n",
      "selected users: [ 2  3  4  5  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3902 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round  23, Average loss 2.390 Test accuracy 95.150\n",
      "selected users: [ 0  1  2  3  5  6  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 0.4278 \n",
      "Accuracy: 8894/10000 (88.94%)\n",
      "\n",
      "Round  24, Average loss 0.428 Test accuracy 88.940\n",
      "selected users: [ 0  1  2  4  6  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.5831 \n",
      "Accuracy: 9289/10000 (92.89%)\n",
      "\n",
      "Round  25, Average loss 3.583 Test accuracy 92.890\n",
      "selected users: [ 0  1  2  3  5  6  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 2.2053 \n",
      "Accuracy: 4348/10000 (43.48%)\n",
      "\n",
      "Round  26, Average loss 2.205 Test accuracy 43.480\n",
      "selected users: [ 0  1  2  3  4  5  6 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6137 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round  27, Average loss 0.614 Test accuracy 95.030\n",
      "selected users: [ 1  2  4  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1147 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round  28, Average loss 1.115 Test accuracy 95.130\n",
      "selected users: [ 0  1  4  5  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1098 \n",
      "Accuracy: 9501/10000 (95.01%)\n",
      "\n",
      "Round  29, Average loss 1.110 Test accuracy 95.010\n",
      "(m= 10 )  6 -th Trial!!\n",
      "selected users: [ 0  1  3  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 3  4  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2628 \n",
      "Accuracy: 5233/10000 (52.33%)\n",
      "\n",
      "Round   1, Average loss 2.263 Test accuracy 52.330\n",
      "selected users: [ 1  2  3  4  5  6  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4620 \n",
      "Accuracy: 9478/10000 (94.78%)\n",
      "\n",
      "Round   2, Average loss 0.462 Test accuracy 94.780\n",
      "selected users: [ 0  1  2  5  6  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.8770 \n",
      "Accuracy: 9178/10000 (91.78%)\n",
      "\n",
      "Round   3, Average loss 2.877 Test accuracy 91.780\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 21.1504 \n",
      "Accuracy: 8710/10000 (87.10%)\n",
      "\n",
      "Round   4, Average loss 21.150 Test accuracy 87.100\n",
      "selected users: [ 0  2  4  5  6  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0894 \n",
      "Accuracy: 9320/10000 (93.20%)\n",
      "\n",
      "Round   5, Average loss 2.089 Test accuracy 93.200\n",
      "selected users: [ 0  3  4  5  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.7946 \n",
      "Accuracy: 9322/10000 (93.22%)\n",
      "\n",
      "Round   6, Average loss 4.795 Test accuracy 93.220\n",
      "selected users: [ 0  1  2  3  4  6  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 6.5876 \n",
      "Accuracy: 9218/10000 (92.18%)\n",
      "\n",
      "Round   7, Average loss 6.588 Test accuracy 92.180\n",
      "selected users: [ 1  3  4  5  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 8.2349 \n",
      "Accuracy: 9060/10000 (90.60%)\n",
      "\n",
      "Round   8, Average loss 8.235 Test accuracy 90.600\n",
      "selected users: [ 0  1  2  3  5  6  7 10 11 14]\n",
      "\n",
      "Test set: Average loss: 6.0359 \n",
      "Accuracy: 9265/10000 (92.65%)\n",
      "\n",
      "Round   9, Average loss 6.036 Test accuracy 92.650\n",
      "selected users: [ 0  2  4  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 8.6379 \n",
      "Accuracy: 9097/10000 (90.97%)\n",
      "\n",
      "Round  10, Average loss 8.638 Test accuracy 90.970\n",
      "selected users: [ 0  2  3  4  6  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.5870 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  11, Average loss 6.587 Test accuracy 93.990\n",
      "selected users: [ 0  1  3  4  5  7  8 11 12 13]\n",
      "\n",
      "Test set: Average loss: 6.3764 \n",
      "Accuracy: 9185/10000 (91.85%)\n",
      "\n",
      "Round  12, Average loss 6.376 Test accuracy 91.850\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 12]\n",
      "\n",
      "Test set: Average loss: 0.4527 \n",
      "Accuracy: 8855/10000 (88.55%)\n",
      "\n",
      "Round  13, Average loss 0.453 Test accuracy 88.550\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 34.1995 \n",
      "Accuracy: 9065/10000 (90.65%)\n",
      "\n",
      "Round  14, Average loss 34.200 Test accuracy 90.650\n",
      "selected users: [ 0  1  2  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0646 \n",
      "Accuracy: 9302/10000 (93.02%)\n",
      "\n",
      "Round  15, Average loss 2.065 Test accuracy 93.020\n",
      "selected users: [ 1  2  3  4  5  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 11.3265 \n",
      "Accuracy: 9265/10000 (92.65%)\n",
      "\n",
      "Round  16, Average loss 11.327 Test accuracy 92.650\n",
      "selected users: [ 0  1  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 4.4083 \n",
      "Accuracy: 8778/10000 (87.78%)\n",
      "\n",
      "Round  17, Average loss 4.408 Test accuracy 87.780\n",
      "selected users: [ 0  1  2  3  4  7 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.2444 \n",
      "Accuracy: 9263/10000 (92.63%)\n",
      "\n",
      "Round  18, Average loss 7.244 Test accuracy 92.630\n",
      "selected users: [ 0  1  3  4  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 3.0652 \n",
      "Accuracy: 9483/10000 (94.83%)\n",
      "\n",
      "Round  19, Average loss 3.065 Test accuracy 94.830\n",
      "selected users: [ 0  1  3  4  5  6  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 0.5093 \n",
      "Accuracy: 8661/10000 (86.61%)\n",
      "\n",
      "Round  20, Average loss 0.509 Test accuracy 86.610\n",
      "selected users: [ 4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1555 \n",
      "Accuracy: 9474/10000 (94.74%)\n",
      "\n",
      "Round  21, Average loss 4.155 Test accuracy 94.740\n",
      "selected users: [ 0  3  4  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9370 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  22, Average loss 4.937 Test accuracy 94.710\n",
      "selected users: [ 0  1  2  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.3916 \n",
      "Accuracy: 9489/10000 (94.89%)\n",
      "\n",
      "Round  23, Average loss 3.392 Test accuracy 94.890\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 7.1213 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  24, Average loss 7.121 Test accuracy 95.500\n",
      "selected users: [ 2  3  4  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.6487 \n",
      "Accuracy: 9427/10000 (94.27%)\n",
      "\n",
      "Round  25, Average loss 4.649 Test accuracy 94.270\n",
      "selected users: [ 1  2  3  4  5  6 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 10.3945 \n",
      "Accuracy: 9391/10000 (93.91%)\n",
      "\n",
      "Round  26, Average loss 10.395 Test accuracy 93.910\n",
      "selected users: [ 0  2  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.1896 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round  27, Average loss 7.190 Test accuracy 92.380\n",
      "selected users: [ 0  2  3  5  6  7  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 6.7221 \n",
      "Accuracy: 8742/10000 (87.42%)\n",
      "\n",
      "Round  28, Average loss 6.722 Test accuracy 87.420\n",
      "selected users: [ 0  1  3  5  7  8  9 10 11 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.2809 \n",
      "Accuracy: 9312/10000 (93.12%)\n",
      "\n",
      "Round  29, Average loss 3.281 Test accuracy 93.120\n",
      "(m= 10 )  7 -th Trial!!\n",
      "selected users: [ 3  4  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4  5  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2974 \n",
      "Accuracy: 1657/10000 (16.57%)\n",
      "\n",
      "Round   1, Average loss 2.297 Test accuracy 16.570\n",
      "selected users: [ 0  1  2  3  4  5  7  8 10 14]\n",
      "\n",
      "Test set: Average loss: 1.4171 \n",
      "Accuracy: 8704/10000 (87.04%)\n",
      "\n",
      "Round   2, Average loss 1.417 Test accuracy 87.040\n",
      "selected users: [ 1  3  4  5  6  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1920 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round   3, Average loss 0.192 Test accuracy 94.390\n",
      "selected users: [ 0  1  3  4  6  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4981 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round   4, Average loss 0.498 Test accuracy 95.840\n",
      "selected users: [ 1  3  4  5  6  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.7147 \n",
      "Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Round   5, Average loss 0.715 Test accuracy 95.120\n",
      "selected users: [ 1  2  4  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.1583 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round   6, Average loss 1.158 Test accuracy 94.670\n",
      "selected users: [ 2  3  5  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1488 \n",
      "Accuracy: 9308/10000 (93.08%)\n",
      "\n",
      "Round   7, Average loss 1.149 Test accuracy 93.080\n",
      "selected users: [ 0  1  4  5  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1304 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round   8, Average loss 2.130 Test accuracy 94.640\n",
      "selected users: [ 0  1  3  4  6  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.2586 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round   9, Average loss 1.259 Test accuracy 95.000\n",
      "selected users: [ 0  1  4  5  6  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6760 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round  10, Average loss 0.676 Test accuracy 94.390\n",
      "selected users: [ 1  2  3  4  5  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.3756 \n",
      "Accuracy: 9276/10000 (92.76%)\n",
      "\n",
      "Round  11, Average loss 3.376 Test accuracy 92.760\n",
      "selected users: [ 0  1  3  5  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.0155 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round  12, Average loss 2.016 Test accuracy 92.210\n",
      "selected users: [ 1  2  3  4  5  6  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.8799 \n",
      "Accuracy: 9438/10000 (94.38%)\n",
      "\n",
      "Round  13, Average loss 0.880 Test accuracy 94.380\n",
      "selected users: [ 0  1  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.5411 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round  14, Average loss 0.541 Test accuracy 93.510\n",
      "selected users: [ 0  1  3  4  6  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 1.1720 \n",
      "Accuracy: 9361/10000 (93.61%)\n",
      "\n",
      "Round  15, Average loss 1.172 Test accuracy 93.610\n",
      "selected users: [ 1  3  4  5  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0140 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  16, Average loss 3.014 Test accuracy 95.060\n",
      "selected users: [ 3  4  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0032 \n",
      "Accuracy: 9272/10000 (92.72%)\n",
      "\n",
      "Round  17, Average loss 1.003 Test accuracy 92.720\n",
      "selected users: [ 1  2  3  5  6  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 6.5280 \n",
      "Accuracy: 8981/10000 (89.81%)\n",
      "\n",
      "Round  18, Average loss 6.528 Test accuracy 89.810\n",
      "selected users: [ 1  2  3  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8178 \n",
      "Accuracy: 9434/10000 (94.34%)\n",
      "\n",
      "Round  19, Average loss 2.818 Test accuracy 94.340\n",
      "selected users: [ 0  1  2  3  5  6  7  8 10 12]\n",
      "\n",
      "Test set: Average loss: 0.4028 \n",
      "Accuracy: 8760/10000 (87.60%)\n",
      "\n",
      "Round  20, Average loss 0.403 Test accuracy 87.600\n",
      "selected users: [ 0  1  3  4  6  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7230 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round  21, Average loss 1.723 Test accuracy 94.670\n",
      "selected users: [ 2  3  4  5  6  7  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.6060 \n",
      "Accuracy: 8416/10000 (84.16%)\n",
      "\n",
      "Round  22, Average loss 0.606 Test accuracy 84.160\n",
      "selected users: [ 0  2  3  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 3.1800 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round  23, Average loss 3.180 Test accuracy 93.510\n",
      "selected users: [ 0  2  3  4  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 8.1242 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round  24, Average loss 8.124 Test accuracy 92.210\n",
      "selected users: [ 2  4  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7199 \n",
      "Accuracy: 9238/10000 (92.38%)\n",
      "\n",
      "Round  25, Average loss 2.720 Test accuracy 92.380\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 5.7673 \n",
      "Accuracy: 9432/10000 (94.32%)\n",
      "\n",
      "Round  26, Average loss 5.767 Test accuracy 94.320\n",
      "selected users: [ 0  1  2  3  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.9224 \n",
      "Accuracy: 7086/10000 (70.86%)\n",
      "\n",
      "Round  27, Average loss 0.922 Test accuracy 70.860\n",
      "selected users: [ 0  1  2  3  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2941 \n",
      "Accuracy: 9283/10000 (92.83%)\n",
      "\n",
      "Round  28, Average loss 0.294 Test accuracy 92.830\n",
      "selected users: [ 0  1  2  4  5  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.4049 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round  29, Average loss 1.405 Test accuracy 94.750\n",
      "(m= 10 )  8 -th Trial!!\n",
      "selected users: [ 0  1  4  5  6  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  3  4  5  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2815 \n",
      "Accuracy: 8693/10000 (86.93%)\n",
      "\n",
      "Round   1, Average loss 1.282 Test accuracy 86.930\n",
      "selected users: [ 1  3  4  5  6  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.4575 \n",
      "Accuracy: 9063/10000 (90.63%)\n",
      "\n",
      "Round   2, Average loss 1.458 Test accuracy 90.630\n",
      "selected users: [ 1  2  4  5  6  7 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.4822 \n",
      "Accuracy: 9056/10000 (90.56%)\n",
      "\n",
      "Round   3, Average loss 2.482 Test accuracy 90.560\n",
      "selected users: [ 2  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3952 \n",
      "Accuracy: 9221/10000 (92.21%)\n",
      "\n",
      "Round   4, Average loss 0.395 Test accuracy 92.210\n",
      "selected users: [ 0  1  2  3  6  7 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8624 \n",
      "Accuracy: 9154/10000 (91.54%)\n",
      "\n",
      "Round   5, Average loss 0.862 Test accuracy 91.540\n",
      "selected users: [ 0  1  2  3  4  6  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2324 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round   6, Average loss 0.232 Test accuracy 94.640\n",
      "selected users: [ 2  3  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5354 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round   7, Average loss 0.535 Test accuracy 95.140\n",
      "selected users: [ 0  1  2  3  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2393 \n",
      "Accuracy: 9219/10000 (92.19%)\n",
      "\n",
      "Round   8, Average loss 0.239 Test accuracy 92.190\n",
      "selected users: [ 1  2  3  4  6  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8678 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round   9, Average loss 0.868 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  4  6  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3055 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  10, Average loss 2.306 Test accuracy 94.300\n",
      "selected users: [ 0  1  2  4  6  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8905 \n",
      "Accuracy: 9453/10000 (94.53%)\n",
      "\n",
      "Round  11, Average loss 1.891 Test accuracy 94.530\n",
      "selected users: [ 0  1  3  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5928 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  12, Average loss 0.593 Test accuracy 94.080\n",
      "selected users: [ 0  1  2  3  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.6779 \n",
      "Accuracy: 8742/10000 (87.42%)\n",
      "\n",
      "Round  13, Average loss 0.678 Test accuracy 87.420\n",
      "selected users: [ 0  1  2  4  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6367 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  14, Average loss 0.637 Test accuracy 95.290\n",
      "selected users: [ 0  2  3  4  5  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 5.0047 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round  15, Average loss 5.005 Test accuracy 94.610\n",
      "selected users: [ 2  4  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2589 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round  16, Average loss 2.259 Test accuracy 94.560\n",
      "selected users: [ 0  1  2  4  5  6  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.4843 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round  17, Average loss 2.484 Test accuracy 95.150\n",
      "selected users: [ 0  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 8.9810 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round  18, Average loss 8.981 Test accuracy 94.700\n",
      "selected users: [ 0  1  3  5  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.9462 \n",
      "Accuracy: 9358/10000 (93.58%)\n",
      "\n",
      "Round  19, Average loss 1.946 Test accuracy 93.580\n",
      "selected users: [ 0  1  2  3  5  7 10 11 12 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2811 \n",
      "Accuracy: 9320/10000 (93.20%)\n",
      "\n",
      "Round  20, Average loss 2.281 Test accuracy 93.200\n",
      "selected users: [ 0  2  3  4  6  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 6.7938 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round  21, Average loss 6.794 Test accuracy 93.280\n",
      "selected users: [ 0  2  4  5  6  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2688 \n",
      "Accuracy: 9189/10000 (91.89%)\n",
      "\n",
      "Round  22, Average loss 2.269 Test accuracy 91.890\n",
      "selected users: [ 1  2  3  5  6  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.5298 \n",
      "Accuracy: 9277/10000 (92.77%)\n",
      "\n",
      "Round  23, Average loss 2.530 Test accuracy 92.770\n",
      "selected users: [ 0  2  3  4  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 4.0271 \n",
      "Accuracy: 9233/10000 (92.33%)\n",
      "\n",
      "Round  24, Average loss 4.027 Test accuracy 92.330\n",
      "selected users: [ 0  3  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.9704 \n",
      "Accuracy: 8363/10000 (83.63%)\n",
      "\n",
      "Round  25, Average loss 0.970 Test accuracy 83.630\n",
      "selected users: [ 1  2  3  5  6  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 1.5738 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round  26, Average loss 1.574 Test accuracy 93.430\n",
      "selected users: [ 0  2  4  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.8778 \n",
      "Accuracy: 9442/10000 (94.42%)\n",
      "\n",
      "Round  27, Average loss 5.878 Test accuracy 94.420\n",
      "selected users: [ 0  2  4  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 1.9009 \n",
      "Accuracy: 9035/10000 (90.35%)\n",
      "\n",
      "Round  28, Average loss 1.901 Test accuracy 90.350\n",
      "selected users: [ 0  2  3  4  5  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 5.0601 \n",
      "Accuracy: 9389/10000 (93.89%)\n",
      "\n",
      "Round  29, Average loss 5.060 Test accuracy 93.890\n",
      "(m= 10 )  9 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  3  4  5  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.2806 \n",
      "Accuracy: 4770/10000 (47.70%)\n",
      "\n",
      "Round   1, Average loss 2.281 Test accuracy 47.700\n",
      "selected users: [ 2  3  4  5  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7354 \n",
      "Accuracy: 8963/10000 (89.63%)\n",
      "\n",
      "Round   2, Average loss 1.735 Test accuracy 89.630\n",
      "selected users: [ 0  2  3  4  5  6 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.6358 \n",
      "Accuracy: 9236/10000 (92.36%)\n",
      "\n",
      "Round   3, Average loss 2.636 Test accuracy 92.360\n",
      "selected users: [ 0  1  4  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3851 \n",
      "Accuracy: 9495/10000 (94.95%)\n",
      "\n",
      "Round   4, Average loss 1.385 Test accuracy 94.950\n",
      "selected users: [ 1  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4701 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round   5, Average loss 2.470 Test accuracy 95.050\n",
      "selected users: [ 0  1  2  3  6  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3412 \n",
      "Accuracy: 9144/10000 (91.44%)\n",
      "\n",
      "Round   6, Average loss 0.341 Test accuracy 91.440\n",
      "selected users: [ 0  1  2  4  6  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.8318 \n",
      "Accuracy: 9418/10000 (94.18%)\n",
      "\n",
      "Round   7, Average loss 0.832 Test accuracy 94.180\n",
      "selected users: [ 1  2  3  4  5  6  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.9701 \n",
      "Accuracy: 9442/10000 (94.42%)\n",
      "\n",
      "Round   8, Average loss 0.970 Test accuracy 94.420\n",
      "selected users: [ 0  3  4  5  6  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 1.5642 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round   9, Average loss 1.564 Test accuracy 94.610\n",
      "selected users: [ 1  2  3  4  5  7  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2185 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  10, Average loss 2.219 Test accuracy 94.630\n",
      "selected users: [ 2  3  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8159 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  11, Average loss 0.816 Test accuracy 94.360\n",
      "selected users: [ 0  1  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5220 \n",
      "Accuracy: 9404/10000 (94.04%)\n",
      "\n",
      "Round  12, Average loss 0.522 Test accuracy 94.040\n",
      "selected users: [ 0  1  4  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8200 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  13, Average loss 1.820 Test accuracy 95.830\n",
      "selected users: [ 0  1  3  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4051 \n",
      "Accuracy: 9331/10000 (93.31%)\n",
      "\n",
      "Round  14, Average loss 0.405 Test accuracy 93.310\n",
      "selected users: [ 0  1  2  3  4  5  6  8 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3374 \n",
      "Accuracy: 9040/10000 (90.40%)\n",
      "\n",
      "Round  15, Average loss 0.337 Test accuracy 90.400\n",
      "selected users: [ 0  1  2  4  5  7  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.6100 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  16, Average loss 1.610 Test accuracy 95.200\n",
      "selected users: [ 0  2  3  4  5  6  7  8 10 11]\n",
      "\n",
      "Test set: Average loss: 3.6341 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  17, Average loss 3.634 Test accuracy 94.110\n",
      "selected users: [ 1  2  3  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.4713 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  18, Average loss 3.471 Test accuracy 95.450\n",
      "selected users: [ 0  2  3  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 5.0403 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  19, Average loss 5.040 Test accuracy 94.800\n",
      "selected users: [ 0  1  2  4  6  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.7994 \n",
      "Accuracy: 9288/10000 (92.88%)\n",
      "\n",
      "Round  20, Average loss 2.799 Test accuracy 92.880\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10]\n",
      "\n",
      "Test set: Average loss: 29.7291 \n",
      "Accuracy: 9186/10000 (91.86%)\n",
      "\n",
      "Round  21, Average loss 29.729 Test accuracy 91.860\n",
      "selected users: [ 1  3  4  5  6  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.4414 \n",
      "Accuracy: 9316/10000 (93.16%)\n",
      "\n",
      "Round  22, Average loss 2.441 Test accuracy 93.160\n",
      "selected users: [ 0  1  2  3  5  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.7165 \n",
      "Accuracy: 9273/10000 (92.73%)\n",
      "\n",
      "Round  23, Average loss 1.716 Test accuracy 92.730\n",
      "selected users: [ 1  2  3  4  5  6  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8347 \n",
      "Accuracy: 6031/10000 (60.31%)\n",
      "\n",
      "Round  24, Average loss 1.835 Test accuracy 60.310\n",
      "selected users: [ 1  2  3  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2487 \n",
      "Accuracy: 9246/10000 (92.46%)\n",
      "\n",
      "Round  25, Average loss 0.249 Test accuracy 92.460\n",
      "selected users: [ 1  2  3  4  5  6  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 0.5750 \n",
      "Accuracy: 9263/10000 (92.63%)\n",
      "\n",
      "Round  26, Average loss 0.575 Test accuracy 92.630\n",
      "selected users: [ 0  1  2  4  5  6  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1765 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  27, Average loss 0.176 Test accuracy 95.490\n",
      "selected users: [ 1  2  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6892 \n",
      "Accuracy: 9457/10000 (94.57%)\n",
      "\n",
      "Round  28, Average loss 0.689 Test accuracy 94.570\n",
      "selected users: [ 0  2  4  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4414 \n",
      "Accuracy: 9437/10000 (94.37%)\n",
      "\n",
      "Round  29, Average loss 1.441 Test accuracy 94.370\n",
      "number of results: 11\n",
      "(m= 11 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.2544 \n",
      "Accuracy: 6621/10000 (66.21%)\n",
      "\n",
      "Round   1, Average loss 2.254 Test accuracy 66.210\n",
      "selected users: [ 0  1  2  3  4  5  6  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.2128 \n",
      "Accuracy: 9372/10000 (93.72%)\n",
      "\n",
      "Round   2, Average loss 0.213 Test accuracy 93.720\n",
      "selected users: [ 0  1  2  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3333 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round   3, Average loss 0.333 Test accuracy 94.390\n",
      "selected users: [ 1  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4016 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round   4, Average loss 0.402 Test accuracy 94.700\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3579 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round   5, Average loss 0.358 Test accuracy 94.330\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.5142 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round   6, Average loss 0.514 Test accuracy 95.610\n",
      "selected users: [ 1  3  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6837 \n",
      "Accuracy: 9362/10000 (93.62%)\n",
      "\n",
      "Round   7, Average loss 0.684 Test accuracy 93.620\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5165 \n",
      "Accuracy: 9336/10000 (93.36%)\n",
      "\n",
      "Round   8, Average loss 1.517 Test accuracy 93.360\n",
      "selected users: [ 1  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6378 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round   9, Average loss 0.638 Test accuracy 95.390\n",
      "selected users: [ 0  1  4  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.2870 \n",
      "Accuracy: 9452/10000 (94.52%)\n",
      "\n",
      "Round  10, Average loss 1.287 Test accuracy 94.520\n",
      "selected users: [ 0  1  2  3  4  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.2989 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  11, Average loss 1.299 Test accuracy 95.240\n",
      "selected users: [ 0  1  2  3  5  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.6107 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round  12, Average loss 1.611 Test accuracy 93.930\n",
      "selected users: [ 0  2  3  4  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8015 \n",
      "Accuracy: 9359/10000 (93.59%)\n",
      "\n",
      "Round  13, Average loss 1.802 Test accuracy 93.590\n",
      "selected users: [ 1  2  3  4  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8695 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round  14, Average loss 1.870 Test accuracy 94.820\n",
      "selected users: [ 0  1  3  5  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.3365 \n",
      "Accuracy: 9239/10000 (92.39%)\n",
      "\n",
      "Round  15, Average loss 1.336 Test accuracy 92.390\n",
      "selected users: [ 1  2  3  4  5  6  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7398 \n",
      "Accuracy: 9489/10000 (94.89%)\n",
      "\n",
      "Round  16, Average loss 1.740 Test accuracy 94.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.8744 \n",
      "Accuracy: 9422/10000 (94.22%)\n",
      "\n",
      "Round  17, Average loss 2.874 Test accuracy 94.220\n",
      "selected users: [ 0  1  3  4  5  6  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.2897 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  18, Average loss 1.290 Test accuracy 95.300\n",
      "selected users: [ 1  2  3  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0433 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  19, Average loss 1.043 Test accuracy 95.310\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6804 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round  20, Average loss 2.680 Test accuracy 93.710\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2601 \n",
      "Accuracy: 9247/10000 (92.47%)\n",
      "\n",
      "Round  21, Average loss 0.260 Test accuracy 92.470\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 1.2376 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  22, Average loss 1.238 Test accuracy 95.140\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 1.2978 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  23, Average loss 1.298 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0583 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  24, Average loss 1.058 Test accuracy 93.860\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 2.3878 \n",
      "Accuracy: 9246/10000 (92.46%)\n",
      "\n",
      "Round  25, Average loss 2.388 Test accuracy 92.460\n",
      "selected users: [ 0  1  2  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0091 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  26, Average loss 2.009 Test accuracy 93.860\n",
      "selected users: [ 0  2  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3540 \n",
      "Accuracy: 9425/10000 (94.25%)\n",
      "\n",
      "Round  27, Average loss 3.354 Test accuracy 94.250\n",
      "selected users: [ 0  1  2  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1301 \n",
      "Accuracy: 9248/10000 (92.48%)\n",
      "\n",
      "Round  28, Average loss 3.130 Test accuracy 92.480\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 3.0696 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round  29, Average loss 3.070 Test accuracy 93.180\n",
      "(m= 11 )  1 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 2.2417 \n",
      "Accuracy: 6593/10000 (65.93%)\n",
      "\n",
      "Round   1, Average loss 2.242 Test accuracy 65.930\n",
      "selected users: [ 1  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2605 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round   2, Average loss 0.261 Test accuracy 94.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6335 \n",
      "Accuracy: 9301/10000 (93.01%)\n",
      "\n",
      "Round   3, Average loss 1.633 Test accuracy 93.010\n",
      "selected users: [ 0  3  4  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5388 \n",
      "Accuracy: 9434/10000 (94.34%)\n",
      "\n",
      "Round   4, Average loss 1.539 Test accuracy 94.340\n",
      "selected users: [ 0  1  2  3  4  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1.0907 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round   5, Average loss 1.091 Test accuracy 95.080\n",
      "selected users: [ 0  2  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2215 \n",
      "Accuracy: 9375/10000 (93.75%)\n",
      "\n",
      "Round   6, Average loss 2.221 Test accuracy 93.750\n",
      "selected users: [ 0  1  2  4  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3905 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round   7, Average loss 1.390 Test accuracy 94.450\n",
      "selected users: [ 0  1  2  3  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3431 \n",
      "Accuracy: 9019/10000 (90.19%)\n",
      "\n",
      "Round   8, Average loss 0.343 Test accuracy 90.190\n",
      "selected users: [ 0  1  3  4  5  6  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4987 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round   9, Average loss 0.499 Test accuracy 94.990\n",
      "selected users: [ 0  1  2  3  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1714 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  10, Average loss 0.171 Test accuracy 95.390\n",
      "selected users: [ 0  1  3  4  5  6  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3048 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  11, Average loss 0.305 Test accuracy 95.020\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1.7020 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  12, Average loss 1.702 Test accuracy 95.510\n",
      "selected users: [ 0  3  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.4974 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round  13, Average loss 3.497 Test accuracy 94.860\n",
      "selected users: [ 0  1  4  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8596 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  14, Average loss 2.860 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5345 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  15, Average loss 1.534 Test accuracy 95.810\n",
      "selected users: [ 2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2651 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  16, Average loss 1.265 Test accuracy 94.920\n",
      "selected users: [ 1  2  3  4  5  6  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7952 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  17, Average loss 0.795 Test accuracy 95.470\n",
      "selected users: [ 1  2  3  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5119 \n",
      "Accuracy: 9473/10000 (94.73%)\n",
      "\n",
      "Round  18, Average loss 1.512 Test accuracy 94.730\n",
      "selected users: [ 0  1  2  3  4  5  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.0234 \n",
      "Accuracy: 9320/10000 (93.20%)\n",
      "\n",
      "Round  19, Average loss 1.023 Test accuracy 93.200\n",
      "selected users: [ 0  2  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5236 \n",
      "Accuracy: 9234/10000 (92.34%)\n",
      "\n",
      "Round  20, Average loss 1.524 Test accuracy 92.340\n",
      "selected users: [ 0  1  2  4  5  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7908 \n",
      "Accuracy: 9418/10000 (94.18%)\n",
      "\n",
      "Round  21, Average loss 1.791 Test accuracy 94.180\n",
      "selected users: [ 0  1  4  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1448 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  22, Average loss 1.145 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  5  6  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.9676 \n",
      "Accuracy: 9474/10000 (94.74%)\n",
      "\n",
      "Round  23, Average loss 0.968 Test accuracy 94.740\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1963 \n",
      "Accuracy: 9339/10000 (93.39%)\n",
      "\n",
      "Round  24, Average loss 3.196 Test accuracy 93.390\n",
      "selected users: [ 0  1  3  4  5  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.6217 \n",
      "Accuracy: 9321/10000 (93.21%)\n",
      "\n",
      "Round  25, Average loss 3.622 Test accuracy 93.210\n",
      "selected users: [ 0  2  3  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.1347 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round  26, Average loss 7.135 Test accuracy 93.100\n",
      "selected users: [ 0  1  2  3  4  5  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.7266 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round  27, Average loss 3.727 Test accuracy 95.000\n",
      "selected users: [ 1  2  3  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0063 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round  28, Average loss 4.006 Test accuracy 94.330\n",
      "selected users: [ 0  1  2  4  5  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0425 \n",
      "Accuracy: 9334/10000 (93.34%)\n",
      "\n",
      "Round  29, Average loss 4.042 Test accuracy 93.340\n",
      "(m= 11 )  2 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  9 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2155 \n",
      "Accuracy: 6428/10000 (64.28%)\n",
      "\n",
      "Round   1, Average loss 2.216 Test accuracy 64.280\n",
      "selected users: [ 0  1  3  4  5  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4081 \n",
      "Accuracy: 8394/10000 (83.94%)\n",
      "\n",
      "Round   2, Average loss 1.408 Test accuracy 83.940\n",
      "selected users: [ 0  1  2  4  5  6  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2128 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round   3, Average loss 0.213 Test accuracy 94.330\n",
      "selected users: [ 0  1  2  4  5  6  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3685 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round   4, Average loss 0.369 Test accuracy 94.540\n",
      "selected users: [ 0  1  2  4  5  6  7  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4080 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round   5, Average loss 0.408 Test accuracy 95.320\n",
      "selected users: [ 2  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6348 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round   6, Average loss 0.635 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  5  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3553 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round   7, Average loss 1.355 Test accuracy 94.020\n",
      "selected users: [ 1  2  3  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0687 \n",
      "Accuracy: 9170/10000 (91.70%)\n",
      "\n",
      "Round   8, Average loss 1.069 Test accuracy 91.700\n",
      "selected users: [ 1  2  3  4  5  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0830 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round   9, Average loss 1.083 Test accuracy 94.060\n",
      "selected users: [ 0  2  4  5  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3419 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round  10, Average loss 1.342 Test accuracy 94.880\n",
      "selected users: [ 0  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0784 \n",
      "Accuracy: 9353/10000 (93.53%)\n",
      "\n",
      "Round  11, Average loss 1.078 Test accuracy 93.530\n",
      "selected users: [ 0  1  4  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1099 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round  12, Average loss 1.110 Test accuracy 95.370\n",
      "selected users: [ 1  2  3  4  5  6  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4573 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  13, Average loss 1.457 Test accuracy 94.900\n",
      "selected users: [ 2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.8813 \n",
      "Accuracy: 9319/10000 (93.19%)\n",
      "\n",
      "Round  14, Average loss 0.881 Test accuracy 93.190\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5115 \n",
      "Accuracy: 9335/10000 (93.35%)\n",
      "\n",
      "Round  15, Average loss 0.512 Test accuracy 93.350\n",
      "selected users: [ 2  3  4  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7319 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  16, Average loss 0.732 Test accuracy 95.460\n",
      "selected users: [ 1  2  4  5  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9322 \n",
      "Accuracy: 9511/10000 (95.11%)\n",
      "\n",
      "Round  17, Average loss 0.932 Test accuracy 95.110\n",
      "selected users: [ 1  2  3  4  5  6  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3282 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  18, Average loss 1.328 Test accuracy 95.020\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1.4274 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  19, Average loss 1.427 Test accuracy 95.420\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.4478 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round  20, Average loss 0.448 Test accuracy 93.240\n",
      "selected users: [ 0  1  2  3  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3715 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  21, Average loss 0.371 Test accuracy 94.920\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 0.5570 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  22, Average loss 0.557 Test accuracy 95.380\n",
      "selected users: [ 0  1  3  4  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6247 \n",
      "Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Round  23, Average loss 1.625 Test accuracy 94.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 1.8615 \n",
      "Accuracy: 9485/10000 (94.85%)\n",
      "\n",
      "Round  24, Average loss 1.862 Test accuracy 94.850\n",
      "selected users: [ 0  2  3  4  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7781 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  25, Average loss 3.778 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: 3.3619 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  26, Average loss 3.362 Test accuracy 94.960\n",
      "selected users: [ 0  2  3  4  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 3.3746 \n",
      "Accuracy: 9305/10000 (93.05%)\n",
      "\n",
      "Round  27, Average loss 3.375 Test accuracy 93.050\n",
      "selected users: [ 0  1  3  4  5  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.5510 \n",
      "Accuracy: 9307/10000 (93.07%)\n",
      "\n",
      "Round  28, Average loss 1.551 Test accuracy 93.070\n",
      "selected users: [ 0  1  2  3  4  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.0842 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round  29, Average loss 4.084 Test accuracy 93.430\n",
      "(m= 11 )  3 -th Trial!!\n",
      "selected users: [ 0  1  4  5  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  5  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2822 \n",
      "Accuracy: 6534/10000 (65.34%)\n",
      "\n",
      "Round   1, Average loss 2.282 Test accuracy 65.340\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.2418 \n",
      "Accuracy: 9280/10000 (92.80%)\n",
      "\n",
      "Round   2, Average loss 0.242 Test accuracy 92.800\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 0.5503 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round   3, Average loss 0.550 Test accuracy 93.280\n",
      "selected users: [ 1  2  3  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8771 \n",
      "Accuracy: 9313/10000 (93.13%)\n",
      "\n",
      "Round   4, Average loss 0.877 Test accuracy 93.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 0.2020 \n",
      "Accuracy: 9397/10000 (93.97%)\n",
      "\n",
      "Round   5, Average loss 0.202 Test accuracy 93.970\n",
      "selected users: [ 0  1  2  3  5  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2531 \n",
      "Accuracy: 9345/10000 (93.45%)\n",
      "\n",
      "Round   6, Average loss 0.253 Test accuracy 93.450\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.4383 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round   7, Average loss 0.438 Test accuracy 95.560\n",
      "selected users: [ 1  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0999 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round   8, Average loss 1.100 Test accuracy 95.200\n",
      "selected users: [ 1  2  3  4  5  6  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1391 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   9, Average loss 1.139 Test accuracy 95.340\n",
      "selected users: [ 0  1  3  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4224 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  10, Average loss 0.422 Test accuracy 95.640\n",
      "selected users: [ 1  2  3  4  5  6  7  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1818 \n",
      "Accuracy: 9367/10000 (93.67%)\n",
      "\n",
      "Round  11, Average loss 1.182 Test accuracy 93.670\n",
      "selected users: [ 0  1  3  4  5  6  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3672 \n",
      "Accuracy: 9351/10000 (93.51%)\n",
      "\n",
      "Round  12, Average loss 0.367 Test accuracy 93.510\n",
      "selected users: [ 1  2  3  5  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6442 \n",
      "Accuracy: 9442/10000 (94.42%)\n",
      "\n",
      "Round  13, Average loss 0.644 Test accuracy 94.420\n",
      "selected users: [ 0  1  2  3  5  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.1572 \n",
      "Accuracy: 9235/10000 (92.35%)\n",
      "\n",
      "Round  14, Average loss 2.157 Test accuracy 92.350\n",
      "selected users: [ 1  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5714 \n",
      "Accuracy: 9432/10000 (94.32%)\n",
      "\n",
      "Round  15, Average loss 0.571 Test accuracy 94.320\n",
      "selected users: [ 1  2  3  4  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2293 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round  16, Average loss 1.229 Test accuracy 95.070\n",
      "selected users: [ 0  1  2  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9800 \n",
      "Accuracy: 9422/10000 (94.22%)\n",
      "\n",
      "Round  17, Average loss 1.980 Test accuracy 94.220\n",
      "selected users: [ 0  1  2  3  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.5563 \n",
      "Accuracy: 9280/10000 (92.80%)\n",
      "\n",
      "Round  18, Average loss 1.556 Test accuracy 92.800\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.6932 \n",
      "Accuracy: 9157/10000 (91.57%)\n",
      "\n",
      "Round  19, Average loss 1.693 Test accuracy 91.570\n",
      "selected users: [ 2  3  4  6  7  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1353 \n",
      "Accuracy: 9391/10000 (93.91%)\n",
      "\n",
      "Round  20, Average loss 1.135 Test accuracy 93.910\n",
      "selected users: [ 0  1  2  3  4  5  6  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3883 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round  21, Average loss 0.388 Test accuracy 94.390\n",
      "selected users: [ 0  1  2  3  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3064 \n",
      "Accuracy: 9066/10000 (90.66%)\n",
      "\n",
      "Round  22, Average loss 0.306 Test accuracy 90.660\n",
      "selected users: [ 1  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0375 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  23, Average loss 1.038 Test accuracy 95.290\n",
      "selected users: [ 0  2  3  4  5  6  7  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 3.3782 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  24, Average loss 3.378 Test accuracy 94.500\n",
      "selected users: [ 1  2  3  4  5  6  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1303 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round  25, Average loss 2.130 Test accuracy 95.090\n",
      "selected users: [ 1  2  3  5  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0280 \n",
      "Accuracy: 9443/10000 (94.43%)\n",
      "\n",
      "Round  26, Average loss 2.028 Test accuracy 94.430\n",
      "selected users: [ 0  1  2  4  5  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1128 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round  27, Average loss 4.113 Test accuracy 94.540\n",
      "selected users: [ 0  1  2  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7765 \n",
      "Accuracy: 9368/10000 (93.68%)\n",
      "\n",
      "Round  28, Average loss 1.776 Test accuracy 93.680\n",
      "selected users: [ 0  1  2  3  4  5  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.9944 \n",
      "Accuracy: 9208/10000 (92.08%)\n",
      "\n",
      "Round  29, Average loss 0.994 Test accuracy 92.080\n",
      "(m= 11 )  4 -th Trial!!\n",
      "selected users: [ 2  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9348 \n",
      "Accuracy: 7554/10000 (75.54%)\n",
      "\n",
      "Round   1, Average loss 1.935 Test accuracy 75.540\n",
      "selected users: [ 0  2  3  4  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.8526 \n",
      "Accuracy: 9335/10000 (93.35%)\n",
      "\n",
      "Round   2, Average loss 0.853 Test accuracy 93.350\n",
      "selected users: [ 1  2  3  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2485 \n",
      "Accuracy: 9485/10000 (94.85%)\n",
      "\n",
      "Round   3, Average loss 0.249 Test accuracy 94.850\n",
      "selected users: [ 0  1  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3847 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round   4, Average loss 0.385 Test accuracy 95.150\n",
      "selected users: [ 0  1  3  4  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5548 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round   5, Average loss 0.555 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0527 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round   6, Average loss 1.053 Test accuracy 95.620\n",
      "selected users: [ 0  1  2  3  4  6  7  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7151 \n",
      "Accuracy: 9442/10000 (94.42%)\n",
      "\n",
      "Round   7, Average loss 0.715 Test accuracy 94.420\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1.0441 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round   8, Average loss 1.044 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3794 \n",
      "Accuracy: 9362/10000 (93.62%)\n",
      "\n",
      "Round   9, Average loss 0.379 Test accuracy 93.620\n",
      "selected users: [ 0  1  2  3  4  5  6 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7301 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round  10, Average loss 1.730 Test accuracy 95.040\n",
      "selected users: [ 0  1  3  4  5  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.8206 \n",
      "Accuracy: 9436/10000 (94.36%)\n",
      "\n",
      "Round  11, Average loss 0.821 Test accuracy 94.360\n",
      "selected users: [ 0  2  3  4  5  6  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8883 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round  12, Average loss 1.888 Test accuracy 94.750\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2647 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  13, Average loss 2.265 Test accuracy 94.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.6423 \n",
      "Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Round  14, Average loss 2.642 Test accuracy 94.720\n",
      "selected users: [ 0  1  3  4  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5280 \n",
      "Accuracy: 9473/10000 (94.73%)\n",
      "\n",
      "Round  15, Average loss 1.528 Test accuracy 94.730\n",
      "selected users: [ 1  3  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6802 \n",
      "Accuracy: 9444/10000 (94.44%)\n",
      "\n",
      "Round  16, Average loss 2.680 Test accuracy 94.440\n",
      "selected users: [ 0  1  3  4  5  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.0599 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round  17, Average loss 3.060 Test accuracy 94.700\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.8242 \n",
      "Accuracy: 9413/10000 (94.13%)\n",
      "\n",
      "Round  18, Average loss 0.824 Test accuracy 94.130\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1.9843 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  19, Average loss 1.984 Test accuracy 95.490\n",
      "selected users: [ 2  3  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1275 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  20, Average loss 1.128 Test accuracy 94.510\n",
      "selected users: [ 0  2  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3811 \n",
      "Accuracy: 9373/10000 (93.73%)\n",
      "\n",
      "Round  21, Average loss 1.381 Test accuracy 93.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12]\n",
      "\n",
      "Test set: Average loss: 0.3590 \n",
      "Accuracy: 9170/10000 (91.70%)\n",
      "\n",
      "Round  22, Average loss 0.359 Test accuracy 91.700\n",
      "selected users: [ 0  2  3  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2166 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  23, Average loss 3.217 Test accuracy 94.500\n",
      "selected users: [ 0  1  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.6692 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  24, Average loss 1.669 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  4  5  6 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3984 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  25, Average loss 2.398 Test accuracy 94.810\n",
      "selected users: [ 0  2  3  4  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 4.3357 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round  26, Average loss 4.336 Test accuracy 94.860\n",
      "selected users: [ 0  1  2  3  4  6  7  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.9563 \n",
      "Accuracy: 9296/10000 (92.96%)\n",
      "\n",
      "Round  27, Average loss 2.956 Test accuracy 92.960\n",
      "selected users: [ 0  1  2  3  5  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 4.3083 \n",
      "Accuracy: 9180/10000 (91.80%)\n",
      "\n",
      "Round  28, Average loss 4.308 Test accuracy 91.800\n",
      "selected users: [ 1  2  4  5  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0831 \n",
      "Accuracy: 9281/10000 (92.81%)\n",
      "\n",
      "Round  29, Average loss 2.083 Test accuracy 92.810\n",
      "(m= 11 )  5 -th Trial!!\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  4  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1764 \n",
      "Accuracy: 8534/10000 (85.34%)\n",
      "\n",
      "Round   1, Average loss 1.176 Test accuracy 85.340\n",
      "selected users: [ 0  2  3  4  5  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5391 \n",
      "Accuracy: 9395/10000 (93.95%)\n",
      "\n",
      "Round   2, Average loss 0.539 Test accuracy 93.950\n",
      "selected users: [ 0  1  2  4  5  6  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3660 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round   3, Average loss 0.366 Test accuracy 94.800\n",
      "selected users: [ 0  1  2  4  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4336 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round   4, Average loss 0.434 Test accuracy 95.090\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6394 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round   5, Average loss 0.639 Test accuracy 93.960\n",
      "selected users: [ 0  2  3  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4630 \n",
      "Accuracy: 9332/10000 (93.32%)\n",
      "\n",
      "Round   6, Average loss 2.463 Test accuracy 93.320\n",
      "selected users: [ 1  2  3  4  5  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5247 \n",
      "Accuracy: 9460/10000 (94.60%)\n",
      "\n",
      "Round   7, Average loss 1.525 Test accuracy 94.600\n",
      "selected users: [ 0  1  2  3  4  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4039 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round   8, Average loss 2.404 Test accuracy 94.110\n",
      "selected users: [ 0  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9151 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round   9, Average loss 4.915 Test accuracy 94.800\n",
      "selected users: [ 0  4  5  6  7  8  9 10 11 12 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 5.0708 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  10, Average loss 5.071 Test accuracy 94.020\n",
      "selected users: [ 1  2  3  4  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.5114 \n",
      "Accuracy: 9329/10000 (93.29%)\n",
      "\n",
      "Round  11, Average loss 2.511 Test accuracy 93.290\n",
      "selected users: [ 1  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5158 \n",
      "Accuracy: 9438/10000 (94.38%)\n",
      "\n",
      "Round  12, Average loss 1.516 Test accuracy 94.380\n",
      "selected users: [ 0  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.5606 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round  13, Average loss 7.561 Test accuracy 94.610\n",
      "selected users: [ 0  1  2  4  5  6  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.1940 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round  14, Average loss 5.194 Test accuracy 93.180\n",
      "selected users: [ 0  1  2  3  4  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.2288 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round  15, Average loss 3.229 Test accuracy 94.860\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.7767 \n",
      "Accuracy: 9174/10000 (91.74%)\n",
      "\n",
      "Round  16, Average loss 0.777 Test accuracy 91.740\n",
      "selected users: [ 0  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9656 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  17, Average loss 6.966 Test accuracy 94.490\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2065 \n",
      "Accuracy: 9331/10000 (93.31%)\n",
      "\n",
      "Round  18, Average loss 2.207 Test accuracy 93.310\n",
      "selected users: [ 0  1  3  4  5  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.4983 \n",
      "Accuracy: 9271/10000 (92.71%)\n",
      "\n",
      "Round  19, Average loss 5.498 Test accuracy 92.710\n",
      "selected users: [ 0  2  3  4  5  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 8.3996 \n",
      "Accuracy: 9312/10000 (93.12%)\n",
      "\n",
      "Round  20, Average loss 8.400 Test accuracy 93.120\n",
      "selected users: [ 0  1  3  4  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.3543 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round  21, Average loss 5.354 Test accuracy 93.280\n",
      "selected users: [ 1  2  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0777 \n",
      "Accuracy: 9308/10000 (93.08%)\n",
      "\n",
      "Round  22, Average loss 2.078 Test accuracy 93.080\n",
      "selected users: [ 0  2  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0800 \n",
      "Accuracy: 9283/10000 (92.83%)\n",
      "\n",
      "Round  23, Average loss 2.080 Test accuracy 92.830\n",
      "selected users: [ 1  2  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.5140 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  24, Average loss 1.514 Test accuracy 94.020\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.1873 \n",
      "Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Round  25, Average loss 2.187 Test accuracy 93.100\n",
      "selected users: [ 0  1  4  5  6  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.5148 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  26, Average loss 1.515 Test accuracy 94.810\n",
      "selected users: [ 0  2  3  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.9113 \n",
      "Accuracy: 9378/10000 (93.78%)\n",
      "\n",
      "Round  27, Average loss 4.911 Test accuracy 93.780\n",
      "selected users: [ 0  1  2  4  5  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.7615 \n",
      "Accuracy: 9356/10000 (93.56%)\n",
      "\n",
      "Round  28, Average loss 2.762 Test accuracy 93.560\n",
      "selected users: [ 1  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5990 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  29, Average loss 2.599 Test accuracy 94.490\n",
      "(m= 11 )  6 -th Trial!!\n",
      "selected users: [ 0  1  2  4  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2628 \n",
      "Accuracy: 4064/10000 (40.64%)\n",
      "\n",
      "Round   1, Average loss 2.263 Test accuracy 40.640\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.5336 \n",
      "Accuracy: 9328/10000 (93.28%)\n",
      "\n",
      "Round   2, Average loss 0.534 Test accuracy 93.280\n",
      "selected users: [ 0  1  2  3  5  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3342 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round   3, Average loss 0.334 Test accuracy 93.520\n",
      "selected users: [ 0  1  2  3  5  6  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1602 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round   4, Average loss 0.160 Test accuracy 95.440\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5001 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round   5, Average loss 0.500 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3253 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round   6, Average loss 0.325 Test accuracy 95.370\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 1.9449 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round   7, Average loss 1.945 Test accuracy 95.350\n",
      "selected users: [ 0  2  3  4  5  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7267 \n",
      "Accuracy: 9414/10000 (94.14%)\n",
      "\n",
      "Round   8, Average loss 4.727 Test accuracy 94.140\n",
      "selected users: [ 0  1  3  4  5  6  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 1.1519 \n",
      "Accuracy: 9258/10000 (92.58%)\n",
      "\n",
      "Round   9, Average loss 1.152 Test accuracy 92.580\n",
      "selected users: [ 0  2  3  4  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.5573 \n",
      "Accuracy: 9325/10000 (93.25%)\n",
      "\n",
      "Round  10, Average loss 5.557 Test accuracy 93.250\n",
      "selected users: [ 1  2  3  4  5  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8380 \n",
      "Accuracy: 9217/10000 (92.17%)\n",
      "\n",
      "Round  11, Average loss 5.838 Test accuracy 92.170\n",
      "selected users: [ 0  1  2  4  6  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8651 \n",
      "Accuracy: 9414/10000 (94.14%)\n",
      "\n",
      "Round  12, Average loss 1.865 Test accuracy 94.140\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 3.9526 \n",
      "Accuracy: 9321/10000 (93.21%)\n",
      "\n",
      "Round  13, Average loss 3.953 Test accuracy 93.210\n",
      "selected users: [ 1  2  3  4  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3162 \n",
      "Accuracy: 9395/10000 (93.95%)\n",
      "\n",
      "Round  14, Average loss 2.316 Test accuracy 93.950\n",
      "selected users: [ 1  2  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.4511 \n",
      "Accuracy: 9478/10000 (94.78%)\n",
      "\n",
      "Round  15, Average loss 3.451 Test accuracy 94.780\n",
      "selected users: [ 0  1  2  3  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1594 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round  16, Average loss 1.159 Test accuracy 93.980\n",
      "selected users: [ 0  2  3  4  6  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 7.7400 \n",
      "Accuracy: 9373/10000 (93.73%)\n",
      "\n",
      "Round  17, Average loss 7.740 Test accuracy 93.730\n",
      "selected users: [ 0  2  3  4  5  6  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 5.6155 \n",
      "Accuracy: 9340/10000 (93.40%)\n",
      "\n",
      "Round  18, Average loss 5.615 Test accuracy 93.400\n",
      "selected users: [ 0  1  2  3  4  5  6  8 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.9706 \n",
      "Accuracy: 9369/10000 (93.69%)\n",
      "\n",
      "Round  19, Average loss 2.971 Test accuracy 93.690\n",
      "selected users: [ 0  2  3  4  5  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.8335 \n",
      "Accuracy: 9334/10000 (93.34%)\n",
      "\n",
      "Round  20, Average loss 4.834 Test accuracy 93.340\n",
      "selected users: [ 0  2  3  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 13.6121 \n",
      "Accuracy: 9227/10000 (92.27%)\n",
      "\n",
      "Round  21, Average loss 13.612 Test accuracy 92.270\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 6.9666 \n",
      "Accuracy: 9232/10000 (92.32%)\n",
      "\n",
      "Round  22, Average loss 6.967 Test accuracy 92.320\n",
      "selected users: [ 0  1  3  4  5  6  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.4994 \n",
      "Accuracy: 9271/10000 (92.71%)\n",
      "\n",
      "Round  23, Average loss 1.499 Test accuracy 92.710\n",
      "selected users: [ 0  1  3  4  5  6  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7301 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round  24, Average loss 1.730 Test accuracy 95.000\n",
      "selected users: [ 2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.2581 \n",
      "Accuracy: 9255/10000 (92.55%)\n",
      "\n",
      "Round  25, Average loss 1.258 Test accuracy 92.550\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 1.6086 \n",
      "Accuracy: 9184/10000 (91.84%)\n",
      "\n",
      "Round  26, Average loss 1.609 Test accuracy 91.840\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 7.2772 \n",
      "Accuracy: 9104/10000 (91.04%)\n",
      "\n",
      "Round  27, Average loss 7.277 Test accuracy 91.040\n",
      "selected users: [ 0  1  3  4  5  6  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8390 \n",
      "Accuracy: 9344/10000 (93.44%)\n",
      "\n",
      "Round  28, Average loss 2.839 Test accuracy 93.440\n",
      "selected users: [ 2  3  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.4530 \n",
      "Accuracy: 9354/10000 (93.54%)\n",
      "\n",
      "Round  29, Average loss 2.453 Test accuracy 93.540\n",
      "(m= 11 )  7 -th Trial!!\n",
      "selected users: [ 1  2  4  5  6  7  8 10 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  4  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8184 \n",
      "Accuracy: 6672/10000 (66.72%)\n",
      "\n",
      "Round   1, Average loss 1.818 Test accuracy 66.720\n",
      "selected users: [ 0  1  4  5  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3302 \n",
      "Accuracy: 9372/10000 (93.72%)\n",
      "\n",
      "Round   2, Average loss 0.330 Test accuracy 93.720\n",
      "selected users: [ 0  3  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5464 \n",
      "Accuracy: 9128/10000 (91.28%)\n",
      "\n",
      "Round   3, Average loss 1.546 Test accuracy 91.280\n",
      "selected users: [ 0  1  2  3  4  6  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1899 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round   4, Average loss 0.190 Test accuracy 94.500\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4377 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   5, Average loss 0.438 Test accuracy 95.340\n",
      "selected users: [ 0  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8222 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round   6, Average loss 2.822 Test accuracy 95.040\n",
      "selected users: [ 1  2  3  4  5  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.3779 \n",
      "Accuracy: 9363/10000 (93.63%)\n",
      "\n",
      "Round   7, Average loss 3.378 Test accuracy 93.630\n",
      "selected users: [ 0  3  4  5  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.8669 \n",
      "Accuracy: 9378/10000 (93.78%)\n",
      "\n",
      "Round   8, Average loss 3.867 Test accuracy 93.780\n",
      "selected users: [ 1  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7617 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round   9, Average loss 1.762 Test accuracy 94.970\n",
      "selected users: [ 0  1  2  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2256 \n",
      "Accuracy: 9425/10000 (94.25%)\n",
      "\n",
      "Round  10, Average loss 3.226 Test accuracy 94.250\n",
      "selected users: [ 0  1  2  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0478 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round  11, Average loss 1.048 Test accuracy 95.040\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 2.2431 \n",
      "Accuracy: 9347/10000 (93.47%)\n",
      "\n",
      "Round  12, Average loss 2.243 Test accuracy 93.470\n",
      "selected users: [ 0  2  4  5  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6188 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  13, Average loss 2.619 Test accuracy 95.240\n",
      "selected users: [ 0  1  4  5  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2844 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  14, Average loss 2.284 Test accuracy 95.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11]\n",
      "\n",
      "Test set: Average loss: 2.6727 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round  15, Average loss 2.673 Test accuracy 95.130\n",
      "selected users: [ 1  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.1190 \n",
      "Accuracy: 9370/10000 (93.70%)\n",
      "\n",
      "Round  16, Average loss 2.119 Test accuracy 93.700\n",
      "selected users: [ 2  3  4  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3318 \n",
      "Accuracy: 9452/10000 (94.52%)\n",
      "\n",
      "Round  17, Average loss 2.332 Test accuracy 94.520\n",
      "selected users: [ 0  1  3  4  5  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8048 \n",
      "Accuracy: 9335/10000 (93.35%)\n",
      "\n",
      "Round  18, Average loss 1.805 Test accuracy 93.350\n",
      "selected users: [ 2  3  4  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.8650 \n",
      "Accuracy: 9262/10000 (92.62%)\n",
      "\n",
      "Round  19, Average loss 2.865 Test accuracy 92.620\n",
      "selected users: [ 0  2  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9959 \n",
      "Accuracy: 9187/10000 (91.87%)\n",
      "\n",
      "Round  20, Average loss 1.996 Test accuracy 91.870\n",
      "selected users: [ 0  1  3  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7378 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round  21, Average loss 0.738 Test accuracy 93.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6635 \n",
      "Accuracy: 8863/10000 (88.63%)\n",
      "\n",
      "Round  22, Average loss 0.664 Test accuracy 88.630\n",
      "selected users: [ 0  1  2  4  5  6  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1495 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  23, Average loss 0.150 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3091 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  24, Average loss 0.309 Test accuracy 94.920\n",
      "selected users: [ 0  1  2  3  5  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.7280 \n",
      "Accuracy: 9419/10000 (94.19%)\n",
      "\n",
      "Round  25, Average loss 0.728 Test accuracy 94.190\n",
      "selected users: [ 0  2  3  4  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3963 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  26, Average loss 1.396 Test accuracy 94.900\n",
      "selected users: [ 0  2  3  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0542 \n",
      "Accuracy: 9359/10000 (93.59%)\n",
      "\n",
      "Round  27, Average loss 4.054 Test accuracy 93.590\n",
      "selected users: [ 1  2  4  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6912 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round  28, Average loss 1.691 Test accuracy 94.840\n",
      "selected users: [ 1  3  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1182 \n",
      "Accuracy: 9435/10000 (94.35%)\n",
      "\n",
      "Round  29, Average loss 1.118 Test accuracy 94.350\n",
      "(m= 11 )  8 -th Trial!!\n",
      "selected users: [ 0  1  2  3  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  4  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9931 \n",
      "Accuracy: 8199/10000 (81.99%)\n",
      "\n",
      "Round   1, Average loss 1.993 Test accuracy 81.990\n",
      "selected users: [ 0  1  4  5  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1706 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round   2, Average loss 0.171 Test accuracy 95.170\n",
      "selected users: [ 0  1  2  3  4  5  6  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5032 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round   3, Average loss 0.503 Test accuracy 95.070\n",
      "selected users: [ 1  2  3  5  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6986 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round   4, Average loss 0.699 Test accuracy 95.190\n",
      "selected users: [ 0  2  3  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7709 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round   5, Average loss 1.771 Test accuracy 94.900\n",
      "selected users: [ 1  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.1397 \n",
      "Accuracy: 9400/10000 (94.00%)\n",
      "\n",
      "Round   6, Average loss 3.140 Test accuracy 94.000\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 13]\n",
      "\n",
      "Test set: Average loss: 0.8980 \n",
      "Accuracy: 9228/10000 (92.28%)\n",
      "\n",
      "Round   7, Average loss 0.898 Test accuracy 92.280\n",
      "selected users: [ 0  1  2  3  5  6  7  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3886 \n",
      "Accuracy: 9257/10000 (92.57%)\n",
      "\n",
      "Round   8, Average loss 0.389 Test accuracy 92.570\n",
      "selected users: [ 0  1  4  5  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9553 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round   9, Average loss 0.955 Test accuracy 95.050\n",
      "selected users: [ 2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4065 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round  10, Average loss 1.406 Test accuracy 94.550\n",
      "selected users: [ 1  2  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3454 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  11, Average loss 2.345 Test accuracy 94.800\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 4.3688 \n",
      "Accuracy: 9494/10000 (94.94%)\n",
      "\n",
      "Round  12, Average loss 4.369 Test accuracy 94.940\n",
      "selected users: [ 0  1  2  3  4  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.1349 \n",
      "Accuracy: 9491/10000 (94.91%)\n",
      "\n",
      "Round  13, Average loss 3.135 Test accuracy 94.910\n",
      "selected users: [ 0  1  2  4  5  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.5760 \n",
      "Accuracy: 9382/10000 (93.82%)\n",
      "\n",
      "Round  14, Average loss 2.576 Test accuracy 93.820\n",
      "selected users: [ 0  1  3  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9850 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  15, Average loss 0.985 Test accuracy 94.710\n",
      "selected users: [ 0  1  2  4  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.0137 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round  16, Average loss 2.014 Test accuracy 93.980\n",
      "selected users: [ 3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3350 \n",
      "Accuracy: 9028/10000 (90.28%)\n",
      "\n",
      "Round  17, Average loss 0.335 Test accuracy 90.280\n",
      "selected users: [ 1  2  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.0419 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  18, Average loss 1.042 Test accuracy 95.080\n",
      "selected users: [ 0  1  3  5  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4234 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round  19, Average loss 0.423 Test accuracy 95.090\n",
      "selected users: [ 1  2  3  5  6  7  9 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7720 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round  20, Average loss 1.772 Test accuracy 94.680\n",
      "selected users: [ 0  1  2  3  4  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.7026 \n",
      "Accuracy: 9365/10000 (93.65%)\n",
      "\n",
      "Round  21, Average loss 3.703 Test accuracy 93.650\n",
      "selected users: [ 0  1  3  4  5  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8404 \n",
      "Accuracy: 9385/10000 (93.85%)\n",
      "\n",
      "Round  22, Average loss 1.840 Test accuracy 93.850\n",
      "selected users: [ 0  1  3  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8203 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round  23, Average loss 1.820 Test accuracy 94.390\n",
      "selected users: [ 0  1  2  3  5  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1173 \n",
      "Accuracy: 9473/10000 (94.73%)\n",
      "\n",
      "Round  24, Average loss 1.117 Test accuracy 94.730\n",
      "selected users: [ 0  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.3051 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round  25, Average loss 5.305 Test accuracy 94.640\n",
      "selected users: [ 0  1  2  3  4  6  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8164 \n",
      "Accuracy: 9233/10000 (92.33%)\n",
      "\n",
      "Round  26, Average loss 1.816 Test accuracy 92.330\n",
      "selected users: [ 0  2  4  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.9853 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  27, Average loss 2.985 Test accuracy 95.100\n",
      "selected users: [ 0  2  3  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.7666 \n",
      "Accuracy: 9346/10000 (93.46%)\n",
      "\n",
      "Round  28, Average loss 4.767 Test accuracy 93.460\n",
      "selected users: [ 0  2  3  4  5  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 7.7139 \n",
      "Accuracy: 9318/10000 (93.18%)\n",
      "\n",
      "Round  29, Average loss 7.714 Test accuracy 93.180\n",
      "(m= 11 )  9 -th Trial!!\n",
      "selected users: [ 0  1  2  4  5  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1779 \n",
      "Accuracy: 7474/10000 (74.74%)\n",
      "\n",
      "Round   1, Average loss 1.178 Test accuracy 74.740\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1942 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round   2, Average loss 0.194 Test accuracy 94.820\n",
      "selected users: [ 0  1  2  4  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7467 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round   3, Average loss 0.747 Test accuracy 94.620\n",
      "selected users: [ 1  2  3  4  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2509 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round   4, Average loss 1.251 Test accuracy 94.960\n",
      "selected users: [ 1  3  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7310 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round   5, Average loss 1.731 Test accuracy 94.650\n",
      "selected users: [ 1  2  3  4  5  6  7 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7611 \n",
      "Accuracy: 9458/10000 (94.58%)\n",
      "\n",
      "Round   6, Average loss 2.761 Test accuracy 94.580\n",
      "selected users: [ 0  1  2  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0042 \n",
      "Accuracy: 9448/10000 (94.48%)\n",
      "\n",
      "Round   7, Average loss 1.004 Test accuracy 94.480\n",
      "selected users: [ 0  2  4  5  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3239 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round   8, Average loss 2.324 Test accuracy 94.760\n",
      "selected users: [ 0  1  2  3  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.8784 \n",
      "Accuracy: 9489/10000 (94.89%)\n",
      "\n",
      "Round   9, Average loss 0.878 Test accuracy 94.890\n",
      "selected users: [ 0  1  2  4  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3108 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  10, Average loss 1.311 Test accuracy 95.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4584 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  11, Average loss 0.458 Test accuracy 94.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 11 14]\n",
      "\n",
      "Test set: Average loss: 1.4298 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  12, Average loss 1.430 Test accuracy 95.550\n",
      "selected users: [ 0  2  3  4  5  6  7 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.8677 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round  13, Average loss 5.868 Test accuracy 93.930\n",
      "selected users: [ 0  2  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 3.6468 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round  14, Average loss 3.647 Test accuracy 94.540\n",
      "selected users: [ 0  1  2  3  5  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5429 \n",
      "Accuracy: 9423/10000 (94.23%)\n",
      "\n",
      "Round  15, Average loss 1.543 Test accuracy 94.230\n",
      "selected users: [ 0  1  4  5  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.6181 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  16, Average loss 1.618 Test accuracy 95.310\n",
      "selected users: [ 1  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3939 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  17, Average loss 2.394 Test accuracy 95.260\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.5634 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  18, Average loss 2.563 Test accuracy 95.450\n",
      "selected users: [ 1  2  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 3.2640 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  19, Average loss 3.264 Test accuracy 94.960\n",
      "selected users: [ 0  1  4  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.6834 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round  20, Average loss 2.683 Test accuracy 95.040\n",
      "selected users: [ 0  1  3  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6583 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  21, Average loss 1.658 Test accuracy 94.500\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6947 \n",
      "Accuracy: 9319/10000 (93.19%)\n",
      "\n",
      "Round  22, Average loss 1.695 Test accuracy 93.190\n",
      "selected users: [ 1  2  3  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6572 \n",
      "Accuracy: 9228/10000 (92.28%)\n",
      "\n",
      "Round  23, Average loss 0.657 Test accuracy 92.280\n",
      "selected users: [ 0  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.8171 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round  24, Average loss 2.817 Test accuracy 94.540\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0379 \n",
      "Accuracy: 8643/10000 (86.43%)\n",
      "\n",
      "Round  25, Average loss 2.038 Test accuracy 86.430\n",
      "selected users: [ 0  1  3  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4267 \n",
      "Accuracy: 9407/10000 (94.07%)\n",
      "\n",
      "Round  26, Average loss 2.427 Test accuracy 94.070\n",
      "selected users: [ 0  3  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.2383 \n",
      "Accuracy: 8858/10000 (88.58%)\n",
      "\n",
      "Round  27, Average loss 1.238 Test accuracy 88.580\n",
      "selected users: [ 1  3  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6334 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round  28, Average loss 2.633 Test accuracy 93.880\n",
      "selected users: [ 0  1  2  4  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8796 \n",
      "Accuracy: 9416/10000 (94.16%)\n",
      "\n",
      "Round  29, Average loss 1.880 Test accuracy 94.160\n",
      "number of results: 12\n",
      "(m= 12 )  0 -th Trial!!\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2902 \n",
      "Accuracy: 4484/10000 (44.84%)\n",
      "\n",
      "Round   1, Average loss 2.290 Test accuracy 44.840\n",
      "selected users: [ 0  1  2  3  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4817 \n",
      "Accuracy: 8538/10000 (85.38%)\n",
      "\n",
      "Round   2, Average loss 0.482 Test accuracy 85.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 0.1723 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round   3, Average loss 0.172 Test accuracy 94.970\n",
      "selected users: [ 0  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5498 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round   4, Average loss 0.550 Test accuracy 95.030\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1697 \n",
      "Accuracy: 9478/10000 (94.78%)\n",
      "\n",
      "Round   5, Average loss 0.170 Test accuracy 94.780\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3615 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round   6, Average loss 0.361 Test accuracy 95.610\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4087 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round   7, Average loss 0.409 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3717 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round   8, Average loss 0.372 Test accuracy 95.500\n",
      "selected users: [ 0  1  2  5  6  7  8  9 10 11 12 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5041 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round   9, Average loss 0.504 Test accuracy 95.380\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6088 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  10, Average loss 0.609 Test accuracy 95.550\n",
      "selected users: [ 1  2  3  4  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.8064 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  11, Average loss 0.806 Test accuracy 94.620\n",
      "selected users: [ 1  2  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0165 \n",
      "Accuracy: 9494/10000 (94.94%)\n",
      "\n",
      "Round  12, Average loss 1.017 Test accuracy 94.940\n",
      "selected users: [ 0  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6784 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round  13, Average loss 0.678 Test accuracy 93.830\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2573 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round  14, Average loss 0.257 Test accuracy 94.200\n",
      "selected users: [ 2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5089 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  15, Average loss 0.509 Test accuracy 95.760\n",
      "selected users: [ 1  2  3  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9391 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  16, Average loss 0.939 Test accuracy 95.280\n",
      "selected users: [ 1  2  3  4  5  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9264 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  17, Average loss 1.926 Test accuracy 94.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4730 \n",
      "Accuracy: 9368/10000 (93.68%)\n",
      "\n",
      "Round  18, Average loss 2.473 Test accuracy 93.680\n",
      "selected users: [ 0  1  2  3  4  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3233 \n",
      "Accuracy: 9460/10000 (94.60%)\n",
      "\n",
      "Round  19, Average loss 1.323 Test accuracy 94.600\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8194 \n",
      "Accuracy: 9149/10000 (91.49%)\n",
      "\n",
      "Round  20, Average loss 0.819 Test accuracy 91.490\n",
      "selected users: [ 0  1  2  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8973 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  21, Average loss 0.897 Test accuracy 94.800\n",
      "selected users: [ 0  1  3  4  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5839 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round  22, Average loss 0.584 Test accuracy 95.370\n",
      "selected users: [ 0  1  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7657 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  23, Average loss 0.766 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3123 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  24, Average loss 0.312 Test accuracy 95.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0432 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  25, Average loss 1.043 Test accuracy 95.340\n",
      "selected users: [ 2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0764 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round  26, Average loss 1.076 Test accuracy 93.880\n",
      "selected users: [ 0  1  2  4  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1601 \n",
      "Accuracy: 9501/10000 (95.01%)\n",
      "\n",
      "Round  27, Average loss 1.160 Test accuracy 95.010\n",
      "selected users: [ 0  1  2  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5593 \n",
      "Accuracy: 9459/10000 (94.59%)\n",
      "\n",
      "Round  28, Average loss 1.559 Test accuracy 94.590\n",
      "selected users: [ 1  2  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1359 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  29, Average loss 1.136 Test accuracy 94.980\n",
      "(m= 12 )  1 -th Trial!!\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6601 \n",
      "Accuracy: 8378/10000 (83.78%)\n",
      "\n",
      "Round   1, Average loss 1.660 Test accuracy 83.780\n",
      "selected users: [ 0  1  3  4  5  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2020 \n",
      "Accuracy: 9453/10000 (94.53%)\n",
      "\n",
      "Round   2, Average loss 0.202 Test accuracy 94.530\n",
      "selected users: [ 0  1  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2072 \n",
      "Accuracy: 9594/10000 (95.94%)\n",
      "\n",
      "Round   3, Average loss 0.207 Test accuracy 95.940\n",
      "selected users: [ 1  2  3  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7674 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round   4, Average loss 0.767 Test accuracy 95.150\n",
      "selected users: [ 0  2  3  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8871 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round   5, Average loss 1.887 Test accuracy 95.170\n",
      "selected users: [ 0  1  2  3  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4072 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round   6, Average loss 0.407 Test accuracy 94.020\n",
      "selected users: [ 0  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5519 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round   7, Average loss 1.552 Test accuracy 95.000\n",
      "selected users: [ 1  2  3  4  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4650 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round   8, Average loss 1.465 Test accuracy 95.470\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.5430 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round   9, Average loss 1.543 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5480 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round  10, Average loss 1.548 Test accuracy 95.320\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5529 \n",
      "Accuracy: 9435/10000 (94.35%)\n",
      "\n",
      "Round  11, Average loss 1.553 Test accuracy 94.350\n",
      "selected users: [ 0  1  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0961 \n",
      "Accuracy: 9516/10000 (95.16%)\n",
      "\n",
      "Round  12, Average loss 1.096 Test accuracy 95.160\n",
      "selected users: [ 1  2  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0528 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  13, Average loss 1.053 Test accuracy 95.060\n",
      "selected users: [ 0  1  2  4  5  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6749 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round  14, Average loss 0.675 Test accuracy 93.870\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8573 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round  15, Average loss 0.857 Test accuracy 95.370\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5258 \n",
      "Accuracy: 9299/10000 (92.99%)\n",
      "\n",
      "Round  16, Average loss 0.526 Test accuracy 92.990\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5550 \n",
      "Accuracy: 9458/10000 (94.58%)\n",
      "\n",
      "Round  17, Average loss 0.555 Test accuracy 94.580\n",
      "selected users: [ 0  1  2  3  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2012 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  18, Average loss 0.201 Test accuracy 94.650\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1791 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  19, Average loss 1.179 Test accuracy 95.100\n",
      "selected users: [ 0  1  2  3  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3763 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  20, Average loss 0.376 Test accuracy 95.480\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7942 \n",
      "Accuracy: 9327/10000 (93.27%)\n",
      "\n",
      "Round  21, Average loss 1.794 Test accuracy 93.270\n",
      "selected users: [ 0  1  2  3  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3742 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  22, Average loss 0.374 Test accuracy 94.650\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2733 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  23, Average loss 0.273 Test accuracy 94.810\n",
      "selected users: [ 0  1  3  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6831 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round  24, Average loss 0.683 Test accuracy 95.440\n",
      "selected users: [ 1  2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7089 \n",
      "Accuracy: 9473/10000 (94.73%)\n",
      "\n",
      "Round  25, Average loss 1.709 Test accuracy 94.730\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6360 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  26, Average loss 0.636 Test accuracy 94.030\n",
      "selected users: [ 0  1  2  3  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3126 \n",
      "Accuracy: 8307/10000 (83.07%)\n",
      "\n",
      "Round  27, Average loss 1.313 Test accuracy 83.070\n",
      "selected users: [ 0  1  4  5  6  7  8 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5062 \n",
      "Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Round  28, Average loss 0.506 Test accuracy 95.120\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3684 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  29, Average loss 0.368 Test accuracy 95.580\n",
      "(m= 12 )  2 -th Trial!!\n",
      "selected users: [ 1  2  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2206 \n",
      "Accuracy: 7707/10000 (77.07%)\n",
      "\n",
      "Round   1, Average loss 2.221 Test accuracy 77.070\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2459 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round   2, Average loss 0.246 Test accuracy 94.640\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7736 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round   3, Average loss 0.774 Test accuracy 94.330\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2130 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round   4, Average loss 0.213 Test accuracy 95.740\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4466 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round   5, Average loss 0.447 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5295 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round   6, Average loss 0.529 Test accuracy 95.180\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0496 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round   7, Average loss 1.050 Test accuracy 95.500\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8418 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round   8, Average loss 0.842 Test accuracy 95.410\n",
      "selected users: [ 0  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8456 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round   9, Average loss 1.846 Test accuracy 95.170\n",
      "selected users: [ 1  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4153 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  10, Average loss 1.415 Test accuracy 95.200\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8123 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  11, Average loss 0.812 Test accuracy 95.080\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3623 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  12, Average loss 0.362 Test accuracy 95.310\n",
      "selected users: [ 0  1  2  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3607 \n",
      "Accuracy: 9464/10000 (94.64%)\n",
      "\n",
      "Round  13, Average loss 0.361 Test accuracy 94.640\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6804 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  14, Average loss 0.680 Test accuracy 94.800\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3883 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  15, Average loss 0.388 Test accuracy 95.200\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6494 \n",
      "Accuracy: 9346/10000 (93.46%)\n",
      "\n",
      "Round  16, Average loss 0.649 Test accuracy 93.460\n",
      "selected users: [ 0  1  2  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0525 \n",
      "Accuracy: 9442/10000 (94.42%)\n",
      "\n",
      "Round  17, Average loss 1.053 Test accuracy 94.420\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4335 \n",
      "Accuracy: 9483/10000 (94.83%)\n",
      "\n",
      "Round  18, Average loss 0.433 Test accuracy 94.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.5451 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round  19, Average loss 0.545 Test accuracy 95.740\n",
      "selected users: [ 0  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.0674 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  20, Average loss 1.067 Test accuracy 95.080\n",
      "selected users: [ 1  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1719 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round  21, Average loss 1.172 Test accuracy 95.130\n",
      "selected users: [ 0  1  2  3  4  5  6 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8321 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  22, Average loss 1.832 Test accuracy 95.390\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6350 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  23, Average loss 0.635 Test accuracy 95.210\n",
      "selected users: [ 0  1  3  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3984 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  24, Average loss 0.398 Test accuracy 94.620\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5220 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  25, Average loss 2.522 Test accuracy 94.810\n",
      "selected users: [ 0  2  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 5.5951 \n",
      "Accuracy: 9405/10000 (94.05%)\n",
      "\n",
      "Round  26, Average loss 5.595 Test accuracy 94.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6716 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round  27, Average loss 0.672 Test accuracy 93.980\n",
      "selected users: [ 0  1  2  3  4  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3517 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  28, Average loss 1.352 Test accuracy 94.630\n",
      "selected users: [ 0  1  3  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3321 \n",
      "Accuracy: 9326/10000 (93.26%)\n",
      "\n",
      "Round  29, Average loss 0.332 Test accuracy 93.260\n",
      "(m= 12 )  3 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7756 \n",
      "Accuracy: 7644/10000 (76.44%)\n",
      "\n",
      "Round   1, Average loss 1.776 Test accuracy 76.440\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3685 \n",
      "Accuracy: 9457/10000 (94.57%)\n",
      "\n",
      "Round   2, Average loss 0.368 Test accuracy 94.570\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3580 \n",
      "Accuracy: 9485/10000 (94.85%)\n",
      "\n",
      "Round   3, Average loss 0.358 Test accuracy 94.850\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.7288 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round   4, Average loss 0.729 Test accuracy 94.680\n",
      "selected users: [ 0  1  2  3  4  5  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3682 \n",
      "Accuracy: 9202/10000 (92.02%)\n",
      "\n",
      "Round   5, Average loss 1.368 Test accuracy 92.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.2859 \n",
      "Accuracy: 9361/10000 (93.61%)\n",
      "\n",
      "Round   6, Average loss 0.286 Test accuracy 93.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12]\n",
      "\n",
      "Test set: Average loss: 0.4584 \n",
      "Accuracy: 9425/10000 (94.25%)\n",
      "\n",
      "Round   7, Average loss 0.458 Test accuracy 94.250\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4492 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round   8, Average loss 0.449 Test accuracy 94.920\n",
      "selected users: [ 0  1  2  3  4  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3348 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round   9, Average loss 0.335 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2244 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  10, Average loss 0.224 Test accuracy 95.310\n",
      "selected users: [ 0  2  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3875 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  11, Average loss 1.387 Test accuracy 94.760\n",
      "selected users: [ 0  1  2  3  4  5  6 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3500 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  12, Average loss 1.350 Test accuracy 95.380\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9193 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round  13, Average loss 0.919 Test accuracy 94.090\n",
      "selected users: [ 1  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9265 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round  14, Average loss 0.926 Test accuracy 94.670\n",
      "selected users: [ 0  2  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3211 \n",
      "Accuracy: 9516/10000 (95.16%)\n",
      "\n",
      "Round  15, Average loss 1.321 Test accuracy 95.160\n",
      "selected users: [ 0  1  2  3  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4356 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  16, Average loss 0.436 Test accuracy 94.510\n",
      "selected users: [ 0  1  2  4  5  6  7  8 10 11 12 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5659 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round  17, Average loss 0.566 Test accuracy 94.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.8565 \n",
      "Accuracy: 9348/10000 (93.48%)\n",
      "\n",
      "Round  18, Average loss 0.856 Test accuracy 93.480\n",
      "selected users: [ 0  1  2  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6139 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  19, Average loss 0.614 Test accuracy 95.240\n",
      "selected users: [ 1  2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6098 \n",
      "Accuracy: 9415/10000 (94.15%)\n",
      "\n",
      "Round  20, Average loss 1.610 Test accuracy 94.150\n",
      "selected users: [ 0  1  2  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9193 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  21, Average loss 0.919 Test accuracy 94.490\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7222 \n",
      "Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Round  22, Average loss 1.722 Test accuracy 94.720\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1478 \n",
      "Accuracy: 9350/10000 (93.50%)\n",
      "\n",
      "Round  23, Average loss 1.148 Test accuracy 93.500\n",
      "selected users: [ 2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9684 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round  24, Average loss 0.968 Test accuracy 95.040\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1650 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round  25, Average loss 1.165 Test accuracy 94.930\n",
      "selected users: [ 0  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1055 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round  26, Average loss 2.106 Test accuracy 94.820\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3167 \n",
      "Accuracy: 9319/10000 (93.19%)\n",
      "\n",
      "Round  27, Average loss 1.317 Test accuracy 93.190\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5344 \n",
      "Accuracy: 9215/10000 (92.15%)\n",
      "\n",
      "Round  28, Average loss 0.534 Test accuracy 92.150\n",
      "selected users: [ 0  1  2  3  4  5  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9235 \n",
      "Accuracy: 9215/10000 (92.15%)\n",
      "\n",
      "Round  29, Average loss 2.923 Test accuracy 92.150\n",
      "(m= 12 )  4 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2944 \n",
      "Accuracy: 2035/10000 (20.35%)\n",
      "\n",
      "Round   0, Average loss 2.294 Test accuracy 20.350\n",
      "selected users: [ 1  2  3  4  5  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9558 \n",
      "Accuracy: 8776/10000 (87.76%)\n",
      "\n",
      "Round   1, Average loss 0.956 Test accuracy 87.760\n",
      "selected users: [ 1  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1835 \n",
      "Accuracy: 9459/10000 (94.59%)\n",
      "\n",
      "Round   2, Average loss 0.183 Test accuracy 94.590\n",
      "selected users: [ 0  1  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7505 \n",
      "Accuracy: 9307/10000 (93.07%)\n",
      "\n",
      "Round   3, Average loss 0.750 Test accuracy 93.070\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2575 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round   4, Average loss 0.258 Test accuracy 94.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 0.2773 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round   5, Average loss 0.277 Test accuracy 95.460\n",
      "selected users: [ 1  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6367 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round   6, Average loss 0.637 Test accuracy 94.820\n",
      "selected users: [ 0  1  2  3  4  5  6  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3832 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round   7, Average loss 0.383 Test accuracy 95.300\n",
      "selected users: [ 1  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6329 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round   8, Average loss 0.633 Test accuracy 95.190\n",
      "selected users: [ 0  1  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4868 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round   9, Average loss 0.487 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6735 \n",
      "Accuracy: 9410/10000 (94.10%)\n",
      "\n",
      "Round  10, Average loss 0.673 Test accuracy 94.100\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0022 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  11, Average loss 1.002 Test accuracy 95.180\n",
      "selected users: [ 0  1  2  3  4  5  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7621 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  12, Average loss 0.762 Test accuracy 95.780\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.7916 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  13, Average loss 0.792 Test accuracy 95.100\n",
      "selected users: [ 0  2  3  4  5  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.5749 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round  14, Average loss 2.575 Test accuracy 94.750\n",
      "selected users: [ 0  2  3  4  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.6147 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round  15, Average loss 2.615 Test accuracy 94.560\n",
      "selected users: [ 0  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9352 \n",
      "Accuracy: 9426/10000 (94.26%)\n",
      "\n",
      "Round  16, Average loss 2.935 Test accuracy 94.260\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.9314 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round  17, Average loss 0.931 Test accuracy 94.700\n",
      "selected users: [ 0  1  2  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0630 \n",
      "Accuracy: 9474/10000 (94.74%)\n",
      "\n",
      "Round  18, Average loss 1.063 Test accuracy 94.740\n",
      "selected users: [ 0  1  2  3  4  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1519 \n",
      "Accuracy: 9462/10000 (94.62%)\n",
      "\n",
      "Round  19, Average loss 1.152 Test accuracy 94.620\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5992 \n",
      "Accuracy: 9435/10000 (94.35%)\n",
      "\n",
      "Round  20, Average loss 0.599 Test accuracy 94.350\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.8100 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  21, Average loss 1.810 Test accuracy 94.870\n",
      "selected users: [ 0  1  2  3  4  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.5250 \n",
      "Accuracy: 9522/10000 (95.22%)\n",
      "\n",
      "Round  22, Average loss 1.525 Test accuracy 95.220\n",
      "selected users: [ 0  1  2  3  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6970 \n",
      "Accuracy: 8513/10000 (85.13%)\n",
      "\n",
      "Round  23, Average loss 0.697 Test accuracy 85.130\n",
      "selected users: [ 0  2  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4021 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  24, Average loss 0.402 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8413 \n",
      "Accuracy: 9384/10000 (93.84%)\n",
      "\n",
      "Round  25, Average loss 0.841 Test accuracy 93.840\n",
      "selected users: [ 0  2  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0164 \n",
      "Accuracy: 9446/10000 (94.46%)\n",
      "\n",
      "Round  26, Average loss 2.016 Test accuracy 94.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 1.2629 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  27, Average loss 1.263 Test accuracy 95.380\n",
      "selected users: [ 0  1  2  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7837 \n",
      "Accuracy: 9262/10000 (92.62%)\n",
      "\n",
      "Round  28, Average loss 0.784 Test accuracy 92.620\n",
      "selected users: [ 0  1  2  4  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8252 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  29, Average loss 0.825 Test accuracy 95.450\n",
      "(m= 12 )  5 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  2  3  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1717 \n",
      "Accuracy: 7204/10000 (72.04%)\n",
      "\n",
      "Round   1, Average loss 2.172 Test accuracy 72.040\n",
      "selected users: [ 1  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2317 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round   2, Average loss 0.232 Test accuracy 94.770\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 1.0874 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round   3, Average loss 1.087 Test accuracy 95.490\n",
      "selected users: [ 1  2  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6288 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round   4, Average loss 0.629 Test accuracy 94.560\n",
      "selected users: [ 0  2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7816 \n",
      "Accuracy: 9427/10000 (94.27%)\n",
      "\n",
      "Round   5, Average loss 1.782 Test accuracy 94.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 11 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4716 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round   6, Average loss 0.472 Test accuracy 95.430\n",
      "selected users: [ 0  1  2  3  5  6  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2429 \n",
      "Accuracy: 9341/10000 (93.41%)\n",
      "\n",
      "Round   7, Average loss 0.243 Test accuracy 93.410\n",
      "selected users: [ 2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2713 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round   8, Average loss 0.271 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3907 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round   9, Average loss 0.391 Test accuracy 95.040\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3288 \n",
      "Accuracy: 9353/10000 (93.53%)\n",
      "\n",
      "Round  10, Average loss 0.329 Test accuracy 93.530\n",
      "selected users: [ 0  2  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7281 \n",
      "Accuracy: 9495/10000 (94.95%)\n",
      "\n",
      "Round  11, Average loss 0.728 Test accuracy 94.950\n",
      "selected users: [ 0  2  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1809 \n",
      "Accuracy: 9434/10000 (94.34%)\n",
      "\n",
      "Round  12, Average loss 2.181 Test accuracy 94.340\n",
      "selected users: [ 1  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2862 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round  13, Average loss 1.286 Test accuracy 94.450\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3024 \n",
      "Accuracy: 9385/10000 (93.85%)\n",
      "\n",
      "Round  14, Average loss 0.302 Test accuracy 93.850\n",
      "selected users: [ 0  2  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4317 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  15, Average loss 1.432 Test accuracy 95.080\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4199 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round  16, Average loss 1.420 Test accuracy 94.970\n",
      "selected users: [ 0  1  3  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8381 \n",
      "Accuracy: 9408/10000 (94.08%)\n",
      "\n",
      "Round  17, Average loss 0.838 Test accuracy 94.080\n",
      "selected users: [ 1  2  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9804 \n",
      "Accuracy: 9456/10000 (94.56%)\n",
      "\n",
      "Round  18, Average loss 0.980 Test accuracy 94.560\n",
      "selected users: [ 0  1  2  3  5  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2834 \n",
      "Accuracy: 9320/10000 (93.20%)\n",
      "\n",
      "Round  19, Average loss 0.283 Test accuracy 93.200\n",
      "selected users: [ 0  1  2  3  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1507 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round  20, Average loss 0.151 Test accuracy 95.330\n",
      "selected users: [ 0  1  2  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3511 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  21, Average loss 0.351 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6096 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  22, Average loss 0.610 Test accuracy 94.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6782 \n",
      "Accuracy: 9380/10000 (93.80%)\n",
      "\n",
      "Round  23, Average loss 0.678 Test accuracy 93.800\n",
      "selected users: [ 1  2  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4223 \n",
      "Accuracy: 9446/10000 (94.46%)\n",
      "\n",
      "Round  24, Average loss 0.422 Test accuracy 94.460\n",
      "selected users: [ 1  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8693 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  25, Average loss 0.869 Test accuracy 94.990\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5675 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round  26, Average loss 0.567 Test accuracy 95.880\n",
      "selected users: [ 0  1  2  3  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4340 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  27, Average loss 0.434 Test accuracy 94.710\n",
      "selected users: [ 1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9667 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  28, Average loss 0.967 Test accuracy 95.680\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.7253 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  29, Average loss 0.725 Test accuracy 94.790\n",
      "(m= 12 )  6 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3018 \n",
      "Accuracy: 1375/10000 (13.75%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 13.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12]\n",
      "\n",
      "Test set: Average loss: 2.2396 \n",
      "Accuracy: 5193/10000 (51.93%)\n",
      "\n",
      "Round   1, Average loss 2.240 Test accuracy 51.930\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1818 \n",
      "Accuracy: 9453/10000 (94.53%)\n",
      "\n",
      "Round   2, Average loss 0.182 Test accuracy 94.530\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2449 \n",
      "Accuracy: 9466/10000 (94.66%)\n",
      "\n",
      "Round   3, Average loss 0.245 Test accuracy 94.660\n",
      "selected users: [ 0  1  2  3  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3134 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round   4, Average loss 0.313 Test accuracy 95.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9552 \n",
      "Accuracy: 9268/10000 (92.68%)\n",
      "\n",
      "Round   5, Average loss 0.955 Test accuracy 92.680\n",
      "selected users: [ 0  2  3  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6976 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round   6, Average loss 0.698 Test accuracy 95.070\n",
      "selected users: [ 1  2  3  4  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6238 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round   7, Average loss 0.624 Test accuracy 95.570\n",
      "selected users: [ 0  2  3  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9805 \n",
      "Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Round   8, Average loss 0.980 Test accuracy 95.120\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4071 \n",
      "Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Round   9, Average loss 0.407 Test accuracy 93.430\n",
      "selected users: [ 0  1  2  4  5  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5970 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  10, Average loss 0.597 Test accuracy 94.980\n",
      "selected users: [ 0  1  2  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5849 \n",
      "Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Round  11, Average loss 0.585 Test accuracy 95.120\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4772 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  12, Average loss 0.477 Test accuracy 95.280\n",
      "selected users: [ 1  2  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9333 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  13, Average loss 0.933 Test accuracy 95.450\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3128 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round  14, Average loss 0.313 Test accuracy 94.450\n",
      "selected users: [ 0  2  3  4  5  6  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0223 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round  15, Average loss 2.022 Test accuracy 94.090\n",
      "selected users: [ 0  1  3  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6462 \n",
      "Accuracy: 9409/10000 (94.09%)\n",
      "\n",
      "Round  16, Average loss 0.646 Test accuracy 94.090\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.2992 \n",
      "Accuracy: 9096/10000 (90.96%)\n",
      "\n",
      "Round  17, Average loss 0.299 Test accuracy 90.960\n",
      "selected users: [ 0  1  2  3  4  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2760 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round  18, Average loss 0.276 Test accuracy 95.920\n",
      "selected users: [ 0  1  2  3  4  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5800 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  19, Average loss 0.580 Test accuracy 94.980\n",
      "selected users: [ 1  2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3911 \n",
      "Accuracy: 9453/10000 (94.53%)\n",
      "\n",
      "Round  20, Average loss 1.391 Test accuracy 94.530\n",
      "selected users: [ 2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9242 \n",
      "Accuracy: 9307/10000 (93.07%)\n",
      "\n",
      "Round  21, Average loss 0.924 Test accuracy 93.070\n",
      "selected users: [ 0  1  2  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7181 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  22, Average loss 0.718 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 14]\n",
      "\n",
      "Test set: Average loss: 0.8997 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  23, Average loss 0.900 Test accuracy 95.730\n",
      "selected users: [ 1  2  3  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7636 \n",
      "Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Round  24, Average loss 0.764 Test accuracy 95.120\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 11 12 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5654 \n",
      "Accuracy: 9483/10000 (94.83%)\n",
      "\n",
      "Round  25, Average loss 0.565 Test accuracy 94.830\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.4168 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  26, Average loss 0.417 Test accuracy 94.980\n",
      "selected users: [ 1  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0931 \n",
      "Accuracy: 9501/10000 (95.01%)\n",
      "\n",
      "Round  27, Average loss 1.093 Test accuracy 95.010\n",
      "selected users: [ 0  1  2  3  4  5  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0015 \n",
      "Accuracy: 9388/10000 (93.88%)\n",
      "\n",
      "Round  28, Average loss 1.002 Test accuracy 93.880\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4064 \n",
      "Accuracy: 8678/10000 (86.78%)\n",
      "\n",
      "Round  29, Average loss 0.406 Test accuracy 86.780\n",
      "(m= 12 )  7 -th Trial!!\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3006 \n",
      "Accuracy: 2402/10000 (24.02%)\n",
      "\n",
      "Round   1, Average loss 2.301 Test accuracy 24.020\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8495 \n",
      "Accuracy: 8829/10000 (88.29%)\n",
      "\n",
      "Round   2, Average loss 0.850 Test accuracy 88.290\n",
      "selected users: [ 0  1  2  3  5  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4697 \n",
      "Accuracy: 9099/10000 (90.99%)\n",
      "\n",
      "Round   3, Average loss 0.470 Test accuracy 90.990\n",
      "selected users: [ 1  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3311 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round   4, Average loss 0.331 Test accuracy 93.810\n",
      "selected users: [ 0  1  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2296 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   5, Average loss 0.230 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4186 \n",
      "Accuracy: 9370/10000 (93.70%)\n",
      "\n",
      "Round   6, Average loss 0.419 Test accuracy 93.700\n",
      "selected users: [ 0  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6453 \n",
      "Accuracy: 9433/10000 (94.33%)\n",
      "\n",
      "Round   7, Average loss 0.645 Test accuracy 94.330\n",
      "selected users: [ 1  2  3  4  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6179 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round   8, Average loss 0.618 Test accuracy 95.000\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.2167 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round   9, Average loss 0.217 Test accuracy 94.020\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4570 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round  10, Average loss 0.457 Test accuracy 93.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.2547 \n",
      "Accuracy: 9346/10000 (93.46%)\n",
      "\n",
      "Round  11, Average loss 0.255 Test accuracy 93.460\n",
      "selected users: [ 0  1  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6787 \n",
      "Accuracy: 9452/10000 (94.52%)\n",
      "\n",
      "Round  12, Average loss 0.679 Test accuracy 94.520\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4067 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round  13, Average loss 0.407 Test accuracy 95.430\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6155 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  14, Average loss 0.615 Test accuracy 95.080\n",
      "selected users: [ 1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.5787 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  15, Average loss 0.579 Test accuracy 95.210\n",
      "selected users: [ 1  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0345 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round  16, Average loss 1.035 Test accuracy 95.330\n",
      "selected users: [ 0  1  2  3  4  5  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7117 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  17, Average loss 0.712 Test accuracy 94.920\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4009 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  18, Average loss 0.401 Test accuracy 95.100\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.4076 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round  19, Average loss 1.408 Test accuracy 95.030\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6493 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round  20, Average loss 0.649 Test accuracy 95.430\n",
      "selected users: [ 0  1  2  3  4  5  6  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0038 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round  21, Average loss 1.004 Test accuracy 94.820\n",
      "selected users: [ 0  1  3  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7473 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  22, Average loss 0.747 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3968 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round  23, Average loss 0.397 Test accuracy 94.630\n",
      "selected users: [ 0  1  2  3  4  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2717 \n",
      "Accuracy: 9469/10000 (94.69%)\n",
      "\n",
      "Round  24, Average loss 1.272 Test accuracy 94.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.9694 \n",
      "Accuracy: 9332/10000 (93.32%)\n",
      "\n",
      "Round  25, Average loss 0.969 Test accuracy 93.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3132 \n",
      "Accuracy: 9437/10000 (94.37%)\n",
      "\n",
      "Round  26, Average loss 0.313 Test accuracy 94.370\n",
      "selected users: [ 0  1  2  3  4  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6835 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  27, Average loss 0.683 Test accuracy 95.210\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.7854 \n",
      "Accuracy: 9495/10000 (94.95%)\n",
      "\n",
      "Round  28, Average loss 0.785 Test accuracy 94.950\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.9716 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round  29, Average loss 0.972 Test accuracy 95.150\n",
      "(m= 12 )  8 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7495 \n",
      "Accuracy: 9121/10000 (91.21%)\n",
      "\n",
      "Round   1, Average loss 1.750 Test accuracy 91.210\n",
      "selected users: [ 0  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3774 \n",
      "Accuracy: 9459/10000 (94.59%)\n",
      "\n",
      "Round   2, Average loss 0.377 Test accuracy 94.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2065 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round   3, Average loss 0.206 Test accuracy 95.490\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4916 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round   4, Average loss 0.492 Test accuracy 95.560\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.5802 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round   5, Average loss 0.580 Test accuracy 94.920\n",
      "selected users: [ 0  2  3  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3252 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round   6, Average loss 1.325 Test accuracy 95.130\n",
      "selected users: [ 1  2  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9993 \n",
      "Accuracy: 9447/10000 (94.47%)\n",
      "\n",
      "Round   7, Average loss 0.999 Test accuracy 94.470\n",
      "selected users: [ 0  1  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1326 \n",
      "Accuracy: 9469/10000 (94.69%)\n",
      "\n",
      "Round   8, Average loss 1.133 Test accuracy 94.690\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6376 \n",
      "Accuracy: 9447/10000 (94.47%)\n",
      "\n",
      "Round   9, Average loss 0.638 Test accuracy 94.470\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.7642 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  10, Average loss 1.764 Test accuracy 94.500\n",
      "selected users: [ 3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3889 \n",
      "Accuracy: 9220/10000 (92.20%)\n",
      "\n",
      "Round  11, Average loss 0.389 Test accuracy 92.200\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6534 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round  12, Average loss 0.653 Test accuracy 95.170\n",
      "selected users: [ 0  1  2  3  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1786 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  13, Average loss 0.179 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7232 \n",
      "Accuracy: 9382/10000 (93.82%)\n",
      "\n",
      "Round  14, Average loss 0.723 Test accuracy 93.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 14]\n",
      "\n",
      "Test set: Average loss: 0.3655 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round  15, Average loss 0.365 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.7362 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  16, Average loss 0.736 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4814 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  17, Average loss 0.481 Test accuracy 95.360\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7593 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  18, Average loss 0.759 Test accuracy 95.500\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2990 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round  19, Average loss 0.299 Test accuracy 93.960\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3677 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round  20, Average loss 1.368 Test accuracy 95.000\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.9811 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  21, Average loss 2.981 Test accuracy 94.510\n",
      "selected users: [ 0  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.0374 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  22, Average loss 4.037 Test accuracy 94.490\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7050 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  23, Average loss 0.705 Test accuracy 94.490\n",
      "selected users: [ 0  2  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 4.1438 \n",
      "Accuracy: 9379/10000 (93.79%)\n",
      "\n",
      "Round  24, Average loss 4.144 Test accuracy 93.790\n",
      "selected users: [ 0  1  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.7657 \n",
      "Accuracy: 9355/10000 (93.55%)\n",
      "\n",
      "Round  25, Average loss 2.766 Test accuracy 93.550\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.8240 \n",
      "Accuracy: 9275/10000 (92.75%)\n",
      "\n",
      "Round  26, Average loss 1.824 Test accuracy 92.750\n",
      "selected users: [ 0  1  2  3  4  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0583 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  27, Average loss 2.058 Test accuracy 94.710\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9801 \n",
      "Accuracy: 9467/10000 (94.67%)\n",
      "\n",
      "Round  28, Average loss 1.980 Test accuracy 94.670\n",
      "selected users: [ 1  2  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.7593 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round  29, Average loss 1.759 Test accuracy 94.860\n",
      "(m= 12 )  9 -th Trial!!\n",
      "selected users: [ 1  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0843 \n",
      "Accuracy: 7650/10000 (76.50%)\n",
      "\n",
      "Round   1, Average loss 2.084 Test accuracy 76.500\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3264 \n",
      "Accuracy: 9244/10000 (92.44%)\n",
      "\n",
      "Round   2, Average loss 0.326 Test accuracy 92.440\n",
      "selected users: [ 1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2515 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round   3, Average loss 0.251 Test accuracy 94.550\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2460 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round   4, Average loss 0.246 Test accuracy 94.060\n",
      "selected users: [ 0  2  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9690 \n",
      "Accuracy: 9431/10000 (94.31%)\n",
      "\n",
      "Round   5, Average loss 0.969 Test accuracy 94.310\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2711 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round   6, Average loss 0.271 Test accuracy 94.700\n",
      "selected users: [ 0  1  2  4  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4330 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round   7, Average loss 0.433 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6300 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round   8, Average loss 0.630 Test accuracy 95.720\n",
      "selected users: [ 1  2  3  4  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1683 \n",
      "Accuracy: 9495/10000 (94.95%)\n",
      "\n",
      "Round   9, Average loss 1.168 Test accuracy 94.950\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4332 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  10, Average loss 0.433 Test accuracy 94.790\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4424 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  11, Average loss 0.442 Test accuracy 95.380\n",
      "selected users: [ 0  1  2  3  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1993 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  12, Average loss 0.199 Test accuracy 95.650\n",
      "selected users: [ 0  2  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.2095 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  13, Average loss 1.209 Test accuracy 95.140\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7110 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  14, Average loss 0.711 Test accuracy 95.660\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5780 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round  15, Average loss 0.578 Test accuracy 95.630\n",
      "selected users: [ 0  1  3  4  5  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6543 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round  16, Average loss 0.654 Test accuracy 95.400\n",
      "selected users: [ 0  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.1078 \n",
      "Accuracy: 9489/10000 (94.89%)\n",
      "\n",
      "Round  17, Average loss 1.108 Test accuracy 94.890\n",
      "selected users: [ 0  1  2  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4939 \n",
      "Accuracy: 9416/10000 (94.16%)\n",
      "\n",
      "Round  18, Average loss 1.494 Test accuracy 94.160\n",
      "selected users: [ 1  2  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9774 \n",
      "Accuracy: 9313/10000 (93.13%)\n",
      "\n",
      "Round  19, Average loss 0.977 Test accuracy 93.130\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.6613 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round  20, Average loss 1.661 Test accuracy 94.680\n",
      "selected users: [ 0  1  2  3  4  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3818 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  21, Average loss 1.382 Test accuracy 94.760\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.0921 \n",
      "Accuracy: 9369/10000 (93.69%)\n",
      "\n",
      "Round  22, Average loss 2.092 Test accuracy 93.690\n",
      "selected users: [ 1  2  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.4808 \n",
      "Accuracy: 9434/10000 (94.34%)\n",
      "\n",
      "Round  23, Average loss 2.481 Test accuracy 94.340\n",
      "selected users: [ 2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2600 \n",
      "Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Round  24, Average loss 1.260 Test accuracy 94.030\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.6676 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round  25, Average loss 1.668 Test accuracy 94.450\n",
      "selected users: [ 0  1  2  3  4  5  7  8 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.4858 \n",
      "Accuracy: 9041/10000 (90.41%)\n",
      "\n",
      "Round  26, Average loss 1.486 Test accuracy 90.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.3850 \n",
      "Accuracy: 9260/10000 (92.60%)\n",
      "\n",
      "Round  27, Average loss 1.385 Test accuracy 92.600\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.9564 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round  28, Average loss 0.956 Test accuracy 94.770\n",
      "selected users: [ 0  1  2  3  4  5  6  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0166 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  29, Average loss 1.017 Test accuracy 95.770\n",
      "number of results: 13\n",
      "(m= 13 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2422 \n",
      "Accuracy: 3683/10000 (36.83%)\n",
      "\n",
      "Round   1, Average loss 2.242 Test accuracy 36.830\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2051 \n",
      "Accuracy: 3775/10000 (37.75%)\n",
      "\n",
      "Round   2, Average loss 2.205 Test accuracy 37.750\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1988 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round   3, Average loss 0.199 Test accuracy 94.510\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1611 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round   4, Average loss 0.161 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2054 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round   5, Average loss 0.205 Test accuracy 94.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2679 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round   6, Average loss 0.268 Test accuracy 95.520\n",
      "selected users: [ 1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2887 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round   7, Average loss 0.289 Test accuracy 95.380\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9063 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round   8, Average loss 0.906 Test accuracy 94.860\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4309 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round   9, Average loss 0.431 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3806 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  10, Average loss 0.381 Test accuracy 95.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.1632 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round  11, Average loss 0.163 Test accuracy 95.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4001 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  12, Average loss 0.400 Test accuracy 95.290\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3357 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round  13, Average loss 0.336 Test accuracy 95.440\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9503 \n",
      "Accuracy: 9494/10000 (94.94%)\n",
      "\n",
      "Round  14, Average loss 0.950 Test accuracy 94.940\n",
      "selected users: [ 0  1  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3648 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  15, Average loss 0.365 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3895 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  16, Average loss 0.389 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4174 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  17, Average loss 0.417 Test accuracy 95.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5252 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  18, Average loss 0.525 Test accuracy 94.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5217 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  19, Average loss 0.522 Test accuracy 95.140\n",
      "selected users: [ 1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6882 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round  20, Average loss 0.688 Test accuracy 95.370\n",
      "selected users: [ 0  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5602 \n",
      "Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Round  21, Average loss 1.560 Test accuracy 94.710\n",
      "selected users: [ 0  1  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8270 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round  22, Average loss 0.827 Test accuracy 94.450\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6010 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round  23, Average loss 0.601 Test accuracy 95.270\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3079 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round  24, Average loss 0.308 Test accuracy 94.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3858 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  25, Average loss 0.386 Test accuracy 95.280\n",
      "selected users: [ 0  1  2  3  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6324 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round  26, Average loss 0.632 Test accuracy 94.880\n",
      "selected users: [ 0  1  2  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5538 \n",
      "Accuracy: 9522/10000 (95.22%)\n",
      "\n",
      "Round  27, Average loss 0.554 Test accuracy 95.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 0.2063 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  28, Average loss 0.206 Test accuracy 94.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6216 \n",
      "Accuracy: 9431/10000 (94.31%)\n",
      "\n",
      "Round  29, Average loss 0.622 Test accuracy 94.310\n",
      "(m= 13 )  1 -th Trial!!\n",
      "selected users: [ 0  1  2  3  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.2017 \n",
      "Accuracy: 8123/10000 (81.23%)\n",
      "\n",
      "Round   1, Average loss 2.202 Test accuracy 81.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2183 \n",
      "Accuracy: 9362/10000 (93.62%)\n",
      "\n",
      "Round   2, Average loss 0.218 Test accuracy 93.620\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1546 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round   3, Average loss 0.155 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1683 \n",
      "Accuracy: 9491/10000 (94.91%)\n",
      "\n",
      "Round   4, Average loss 0.168 Test accuracy 94.910\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1493 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round   5, Average loss 0.149 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2055 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round   6, Average loss 0.205 Test accuracy 94.990\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1667 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   7, Average loss 0.167 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1486 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round   8, Average loss 0.149 Test accuracy 95.970\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2694 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round   9, Average loss 0.269 Test accuracy 95.240\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2558 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  10, Average loss 0.256 Test accuracy 95.240\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1576 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  11, Average loss 0.158 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1691 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  12, Average loss 0.169 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2889 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round  13, Average loss 0.289 Test accuracy 95.350\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1379 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  14, Average loss 0.138 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3115 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  15, Average loss 0.311 Test accuracy 95.760\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3606 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  16, Average loss 0.361 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3607 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  17, Average loss 0.361 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2069 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  18, Average loss 0.207 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2583 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  19, Average loss 0.258 Test accuracy 95.020\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5731 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  20, Average loss 0.573 Test accuracy 95.360\n",
      "selected users: [ 1  2  3  4  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7614 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  21, Average loss 0.761 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3532 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  22, Average loss 0.353 Test accuracy 95.420\n",
      "selected users: [ 1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8003 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round  23, Average loss 0.800 Test accuracy 95.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3743 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  24, Average loss 0.374 Test accuracy 94.980\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8424 \n",
      "Accuracy: 9476/10000 (94.76%)\n",
      "\n",
      "Round  25, Average loss 0.842 Test accuracy 94.760\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0159 \n",
      "Accuracy: 9449/10000 (94.49%)\n",
      "\n",
      "Round  26, Average loss 1.016 Test accuracy 94.490\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3307 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  27, Average loss 0.331 Test accuracy 94.020\n",
      "selected users: [ 0  1  2  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4685 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  28, Average loss 0.468 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4690 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  29, Average loss 0.469 Test accuracy 94.990\n",
      "(m= 13 )  2 -th Trial!!\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.1768 \n",
      "Accuracy: 8269/10000 (82.69%)\n",
      "\n",
      "Round   1, Average loss 2.177 Test accuracy 82.690\n",
      "selected users: [ 0  1  2  3  4  5  6  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2369 \n",
      "Accuracy: 9460/10000 (94.60%)\n",
      "\n",
      "Round   2, Average loss 0.237 Test accuracy 94.600\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1913 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round   3, Average loss 0.191 Test accuracy 95.090\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.6991 \n",
      "Accuracy: 9491/10000 (94.91%)\n",
      "\n",
      "Round   4, Average loss 0.699 Test accuracy 94.910\n",
      "selected users: [ 0  1  2  3  4  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4907 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round   5, Average loss 0.491 Test accuracy 94.510\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6705 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round   6, Average loss 0.670 Test accuracy 95.440\n",
      "selected users: [ 0  1  2  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6306 \n",
      "Accuracy: 9522/10000 (95.22%)\n",
      "\n",
      "Round   7, Average loss 0.631 Test accuracy 95.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5685 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round   8, Average loss 0.569 Test accuracy 95.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3197 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round   9, Average loss 0.320 Test accuracy 94.900\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4300 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round  10, Average loss 0.430 Test accuracy 95.630\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4573 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  11, Average loss 0.457 Test accuracy 95.510\n",
      "selected users: [ 0  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1832 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  12, Average loss 1.183 Test accuracy 94.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3367 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  13, Average loss 0.337 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5252 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round  14, Average loss 0.525 Test accuracy 95.350\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2268 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round  15, Average loss 0.227 Test accuracy 95.050\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9122 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round  16, Average loss 0.912 Test accuracy 95.130\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3116 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  17, Average loss 0.312 Test accuracy 95.100\n",
      "selected users: [ 0  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1120 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  18, Average loss 1.112 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5789 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  19, Average loss 0.579 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2906 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  20, Average loss 0.291 Test accuracy 94.990\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8751 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  21, Average loss 0.875 Test accuracy 95.240\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6437 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  22, Average loss 0.644 Test accuracy 95.080\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5484 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  23, Average loss 0.548 Test accuracy 95.210\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.6188 \n",
      "Accuracy: 9481/10000 (94.81%)\n",
      "\n",
      "Round  24, Average loss 0.619 Test accuracy 94.810\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3406 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round  25, Average loss 0.341 Test accuracy 94.540\n",
      "selected users: [ 1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7322 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  26, Average loss 0.732 Test accuracy 95.670\n",
      "selected users: [ 0  1  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5656 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  27, Average loss 0.566 Test accuracy 95.180\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3000 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round  28, Average loss 0.300 Test accuracy 94.860\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4816 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  29, Average loss 0.482 Test accuracy 95.200\n",
      "(m= 13 )  3 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9872 \n",
      "Accuracy: 8068/10000 (80.68%)\n",
      "\n",
      "Round   1, Average loss 1.987 Test accuracy 80.680\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2333 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round   2, Average loss 0.233 Test accuracy 94.790\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1672 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round   3, Average loss 0.167 Test accuracy 95.520\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1910 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round   4, Average loss 0.191 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2011 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round   5, Average loss 0.201 Test accuracy 93.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.2092 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round   6, Average loss 0.209 Test accuracy 94.920\n",
      "selected users: [ 0  1  2  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2589 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round   7, Average loss 0.259 Test accuracy 95.640\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7578 \n",
      "Accuracy: 9501/10000 (95.01%)\n",
      "\n",
      "Round   8, Average loss 0.758 Test accuracy 95.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1740 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round   9, Average loss 0.174 Test accuracy 95.320\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1866 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  10, Average loss 0.187 Test accuracy 95.830\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3262 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  11, Average loss 0.326 Test accuracy 95.720\n",
      "selected users: [ 0  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9396 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round  12, Average loss 0.940 Test accuracy 95.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4136 \n",
      "Accuracy: 9438/10000 (94.38%)\n",
      "\n",
      "Round  13, Average loss 0.414 Test accuracy 94.380\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0939 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round  14, Average loss 1.094 Test accuracy 94.550\n",
      "selected users: [ 0  1  2  3  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2285 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  15, Average loss 0.228 Test accuracy 94.870\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3453 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  16, Average loss 0.345 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4206 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round  17, Average loss 0.421 Test accuracy 95.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5607 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  18, Average loss 0.561 Test accuracy 94.870\n",
      "selected users: [ 1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6741 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round  19, Average loss 0.674 Test accuracy 95.050\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4823 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  20, Average loss 0.482 Test accuracy 95.470\n",
      "selected users: [ 0  1  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4449 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round  21, Average loss 0.445 Test accuracy 95.400\n",
      "selected users: [ 0  1  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3937 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  22, Average loss 0.394 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5843 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round  23, Average loss 0.584 Test accuracy 95.520\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 1.1037 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  24, Average loss 1.104 Test accuracy 95.290\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7500 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  25, Average loss 0.750 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5873 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round  26, Average loss 0.587 Test accuracy 95.070\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3272 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  27, Average loss 0.327 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5686 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  28, Average loss 0.569 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6008 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  29, Average loss 0.601 Test accuracy 95.790\n",
      "(m= 13 )  4 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2610 \n",
      "Accuracy: 8023/10000 (80.23%)\n",
      "\n",
      "Round   1, Average loss 2.261 Test accuracy 80.230\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2658 \n",
      "Accuracy: 9324/10000 (93.24%)\n",
      "\n",
      "Round   2, Average loss 0.266 Test accuracy 93.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3289 \n",
      "Accuracy: 9367/10000 (93.67%)\n",
      "\n",
      "Round   3, Average loss 0.329 Test accuracy 93.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1666 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round   4, Average loss 0.167 Test accuracy 94.970\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2994 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round   5, Average loss 0.299 Test accuracy 95.200\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7130 \n",
      "Accuracy: 9406/10000 (94.06%)\n",
      "\n",
      "Round   6, Average loss 0.713 Test accuracy 94.060\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1734 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round   7, Average loss 0.173 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.2404 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round   8, Average loss 0.240 Test accuracy 95.510\n",
      "selected users: [ 1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3975 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round   9, Average loss 0.398 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3201 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  10, Average loss 0.320 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2984 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  11, Average loss 0.298 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4025 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  12, Average loss 0.402 Test accuracy 95.180\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2732 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  13, Average loss 0.273 Test accuracy 95.080\n",
      "selected users: [ 0  1  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2587 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  14, Average loss 0.259 Test accuracy 95.730\n",
      "selected users: [ 0  1  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2706 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  15, Average loss 0.271 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3684 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round  16, Average loss 0.368 Test accuracy 95.200\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3040 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  17, Average loss 0.304 Test accuracy 95.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2215 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round  18, Average loss 0.222 Test accuracy 94.920\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6697 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  19, Average loss 0.670 Test accuracy 95.340\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3622 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  20, Average loss 0.362 Test accuracy 95.380\n",
      "selected users: [ 0  1  2  3  4  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4704 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round  21, Average loss 0.470 Test accuracy 95.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.4975 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  22, Average loss 0.498 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5611 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  23, Average loss 0.561 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5819 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round  24, Average loss 0.582 Test accuracy 95.630\n",
      "selected users: [ 0  1  2  3  4  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5499 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  25, Average loss 0.550 Test accuracy 95.210\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3508 \n",
      "Accuracy: 9458/10000 (94.58%)\n",
      "\n",
      "Round  26, Average loss 0.351 Test accuracy 94.580\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2903 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  27, Average loss 0.290 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4409 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  28, Average loss 0.441 Test accuracy 95.480\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0383 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round  29, Average loss 1.038 Test accuracy 95.170\n",
      "(m= 13 )  5 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1378 \n",
      "Accuracy: 9020/10000 (90.20%)\n",
      "\n",
      "Round   1, Average loss 2.138 Test accuracy 90.200\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2039 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round   2, Average loss 0.204 Test accuracy 95.370\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1717 \n",
      "Accuracy: 9501/10000 (95.01%)\n",
      "\n",
      "Round   3, Average loss 0.172 Test accuracy 95.010\n",
      "selected users: [ 0  1  2  3  4  5  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2187 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round   4, Average loss 0.219 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4283 \n",
      "Accuracy: 9495/10000 (94.95%)\n",
      "\n",
      "Round   5, Average loss 0.428 Test accuracy 94.950\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1509 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round   6, Average loss 0.151 Test accuracy 95.790\n",
      "selected users: [ 0  1  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2812 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round   7, Average loss 0.281 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2336 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round   8, Average loss 0.234 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3503 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round   9, Average loss 0.350 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5420 \n",
      "Accuracy: 9491/10000 (94.91%)\n",
      "\n",
      "Round  10, Average loss 0.542 Test accuracy 94.910\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2941 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  11, Average loss 0.294 Test accuracy 96.030\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3942 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round  12, Average loss 0.394 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.4518 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  13, Average loss 0.452 Test accuracy 95.780\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4398 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round  14, Average loss 0.440 Test accuracy 95.520\n",
      "selected users: [ 0  1  2  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6874 \n",
      "Accuracy: 9445/10000 (94.45%)\n",
      "\n",
      "Round  15, Average loss 0.687 Test accuracy 94.450\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3910 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  16, Average loss 0.391 Test accuracy 95.570\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4021 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round  17, Average loss 0.402 Test accuracy 95.440\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1629 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round  18, Average loss 0.163 Test accuracy 95.090\n",
      "selected users: [ 0  1  2  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4312 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  19, Average loss 0.431 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3485 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  20, Average loss 0.348 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.2836 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  21, Average loss 0.284 Test accuracy 95.100\n",
      "selected users: [ 1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7161 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round  22, Average loss 0.716 Test accuracy 95.620\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5253 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  23, Average loss 0.525 Test accuracy 95.570\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6222 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  24, Average loss 0.622 Test accuracy 95.910\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4315 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  25, Average loss 1.431 Test accuracy 95.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8421 \n",
      "Accuracy: 9516/10000 (95.16%)\n",
      "\n",
      "Round  26, Average loss 0.842 Test accuracy 95.160\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.4605 \n",
      "Accuracy: 9418/10000 (94.18%)\n",
      "\n",
      "Round  27, Average loss 0.460 Test accuracy 94.180\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5621 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round  28, Average loss 0.562 Test accuracy 95.350\n",
      "selected users: [ 1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8249 \n",
      "Accuracy: 9523/10000 (95.23%)\n",
      "\n",
      "Round  29, Average loss 0.825 Test accuracy 95.230\n",
      "(m= 13 )  6 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2658 \n",
      "Accuracy: 7395/10000 (73.95%)\n",
      "\n",
      "Round   1, Average loss 2.266 Test accuracy 73.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3323 \n",
      "Accuracy: 9336/10000 (93.36%)\n",
      "\n",
      "Round   2, Average loss 0.332 Test accuracy 93.360\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2615 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round   3, Average loss 0.262 Test accuracy 94.790\n",
      "selected users: [ 0  1  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1606 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round   4, Average loss 0.161 Test accuracy 95.350\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1889 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round   5, Average loss 0.189 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2076 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round   6, Average loss 0.208 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3041 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round   7, Average loss 0.304 Test accuracy 95.170\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2320 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round   8, Average loss 0.232 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2743 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round   9, Average loss 0.274 Test accuracy 95.450\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.7138 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  10, Average loss 0.714 Test accuracy 94.990\n",
      "selected users: [ 0  1  2  3  4  5  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6178 \n",
      "Accuracy: 9428/10000 (94.28%)\n",
      "\n",
      "Round  11, Average loss 0.618 Test accuracy 94.280\n",
      "selected users: [ 0  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8039 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round  12, Average loss 0.804 Test accuracy 94.770\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9387 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round  13, Average loss 0.939 Test accuracy 94.880\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4642 \n",
      "Accuracy: 9490/10000 (94.90%)\n",
      "\n",
      "Round  14, Average loss 0.464 Test accuracy 94.900\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4319 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  15, Average loss 0.432 Test accuracy 95.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 0.4378 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  16, Average loss 0.438 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5517 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  17, Average loss 0.552 Test accuracy 95.450\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3713 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round  18, Average loss 0.371 Test accuracy 95.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4132 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  19, Average loss 0.413 Test accuracy 95.450\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2468 \n",
      "Accuracy: 9483/10000 (94.83%)\n",
      "\n",
      "Round  20, Average loss 1.247 Test accuracy 94.830\n",
      "selected users: [ 1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7861 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round  21, Average loss 0.786 Test accuracy 95.190\n",
      "selected users: [ 0  1  2  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6357 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  22, Average loss 0.636 Test accuracy 95.060\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.3408 \n",
      "Accuracy: 9491/10000 (94.91%)\n",
      "\n",
      "Round  23, Average loss 1.341 Test accuracy 94.910\n",
      "selected users: [ 0  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8473 \n",
      "Accuracy: 9447/10000 (94.47%)\n",
      "\n",
      "Round  24, Average loss 1.847 Test accuracy 94.470\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8234 \n",
      "Accuracy: 9461/10000 (94.61%)\n",
      "\n",
      "Round  25, Average loss 0.823 Test accuracy 94.610\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4351 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  26, Average loss 0.435 Test accuracy 95.020\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4646 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  27, Average loss 0.465 Test accuracy 95.310\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6276 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  28, Average loss 0.628 Test accuracy 95.180\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4754 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  29, Average loss 0.475 Test accuracy 95.240\n",
      "(m= 13 )  7 -th Trial!!\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0296 \n",
      "Accuracy: 8479/10000 (84.79%)\n",
      "\n",
      "Round   1, Average loss 2.030 Test accuracy 84.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1681 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round   2, Average loss 0.168 Test accuracy 95.050\n",
      "selected users: [ 0  1  2  3  4  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1817 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round   3, Average loss 0.182 Test accuracy 95.330\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7911 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round   4, Average loss 0.791 Test accuracy 94.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5607 \n",
      "Accuracy: 9501/10000 (95.01%)\n",
      "\n",
      "Round   5, Average loss 0.561 Test accuracy 95.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5944 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round   6, Average loss 0.594 Test accuracy 94.650\n",
      "selected users: [ 0  1  2  3  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1877 \n",
      "Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Round   7, Average loss 0.188 Test accuracy 95.000\n",
      "selected users: [ 0  1  2  3  4  5  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4940 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round   8, Average loss 0.494 Test accuracy 94.200\n",
      "selected users: [ 0  1  2  3  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2318 \n",
      "Accuracy: 9389/10000 (93.89%)\n",
      "\n",
      "Round   9, Average loss 0.232 Test accuracy 93.890\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7026 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  10, Average loss 0.703 Test accuracy 94.990\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3986 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  11, Average loss 0.399 Test accuracy 95.460\n",
      "selected users: [ 0  1  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3637 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  12, Average loss 0.364 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3765 \n",
      "Accuracy: 9537/10000 (95.37%)\n",
      "\n",
      "Round  13, Average loss 0.377 Test accuracy 95.370\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3771 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  14, Average loss 0.377 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2437 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  15, Average loss 0.244 Test accuracy 95.450\n",
      "selected users: [ 0  1  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4631 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round  16, Average loss 0.463 Test accuracy 95.350\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2843 \n",
      "Accuracy: 9511/10000 (95.11%)\n",
      "\n",
      "Round  17, Average loss 0.284 Test accuracy 95.110\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3937 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  18, Average loss 0.394 Test accuracy 95.760\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3977 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  19, Average loss 0.398 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2364 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  20, Average loss 0.236 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3185 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  21, Average loss 0.319 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2880 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  22, Average loss 0.288 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2268 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  23, Average loss 0.227 Test accuracy 95.260\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3511 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  24, Average loss 0.351 Test accuracy 95.640\n",
      "selected users: [ 0  1  2  3  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2789 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round  25, Average loss 0.279 Test accuracy 94.930\n",
      "selected users: [ 0  1  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3538 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round  26, Average loss 0.354 Test accuracy 95.620\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1793 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  27, Average loss 0.179 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.3029 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  28, Average loss 0.303 Test accuracy 95.490\n",
      "selected users: [ 0  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2065 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round  29, Average loss 1.207 Test accuracy 95.270\n",
      "(m= 13 )  8 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 2.2924 \n",
      "Accuracy: 1737/10000 (17.37%)\n",
      "\n",
      "Round   0, Average loss 2.292 Test accuracy 17.370\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 14]\n",
      "\n",
      "Test set: Average loss: 2.1344 \n",
      "Accuracy: 6661/10000 (66.61%)\n",
      "\n",
      "Round   1, Average loss 2.134 Test accuracy 66.610\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2896 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round   2, Average loss 0.290 Test accuracy 94.550\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1741 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   3, Average loss 0.174 Test accuracy 95.340\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6341 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round   4, Average loss 0.634 Test accuracy 94.650\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5384 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round   5, Average loss 0.538 Test accuracy 95.270\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2984 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round   6, Average loss 0.298 Test accuracy 95.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3065 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round   7, Average loss 0.307 Test accuracy 95.690\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4208 \n",
      "Accuracy: 9602/10000 (96.02%)\n",
      "\n",
      "Round   8, Average loss 0.421 Test accuracy 96.020\n",
      "selected users: [ 1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5416 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round   9, Average loss 0.542 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4415 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  10, Average loss 0.442 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4007 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  11, Average loss 0.401 Test accuracy 95.380\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9875 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  12, Average loss 0.987 Test accuracy 95.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2409 \n",
      "Accuracy: 9451/10000 (94.51%)\n",
      "\n",
      "Round  13, Average loss 0.241 Test accuracy 94.510\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2769 \n",
      "Accuracy: 9518/10000 (95.18%)\n",
      "\n",
      "Round  14, Average loss 0.277 Test accuracy 95.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3414 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  15, Average loss 0.341 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3868 \n",
      "Accuracy: 9496/10000 (94.96%)\n",
      "\n",
      "Round  16, Average loss 0.387 Test accuracy 94.960\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2507 \n",
      "Accuracy: 9485/10000 (94.85%)\n",
      "\n",
      "Round  17, Average loss 0.251 Test accuracy 94.850\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.5412 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  18, Average loss 0.541 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3295 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  19, Average loss 0.329 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2097 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  20, Average loss 0.210 Test accuracy 95.260\n",
      "selected users: [ 0  1  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2341 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round  21, Average loss 0.234 Test accuracy 95.430\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1532 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round  22, Average loss 0.153 Test accuracy 95.400\n",
      "selected users: [ 0  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8324 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  23, Average loss 0.832 Test accuracy 95.360\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.0289 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  24, Average loss 1.029 Test accuracy 95.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3896 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round  25, Average loss 0.390 Test accuracy 95.170\n",
      "selected users: [ 0  1  2  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5970 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round  26, Average loss 0.597 Test accuracy 95.350\n",
      "selected users: [ 1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7536 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  27, Average loss 0.754 Test accuracy 95.480\n",
      "selected users: [ 2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5708 \n",
      "Accuracy: 9489/10000 (94.89%)\n",
      "\n",
      "Round  28, Average loss 0.571 Test accuracy 94.890\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6042 \n",
      "Accuracy: 9517/10000 (95.17%)\n",
      "\n",
      "Round  29, Average loss 0.604 Test accuracy 95.170\n",
      "(m= 13 )  9 -th Trial!!\n",
      "selected users: [ 0  1  2  3  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8710 \n",
      "Accuracy: 8017/10000 (80.17%)\n",
      "\n",
      "Round   1, Average loss 1.871 Test accuracy 80.170\n",
      "selected users: [ 0  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3795 \n",
      "Accuracy: 9420/10000 (94.20%)\n",
      "\n",
      "Round   2, Average loss 0.379 Test accuracy 94.200\n",
      "selected users: [ 0  1  2  3  4  5  6  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2167 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round   3, Average loss 0.217 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3433 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round   4, Average loss 0.343 Test accuracy 94.920\n",
      "selected users: [ 1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5299 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round   5, Average loss 0.530 Test accuracy 94.790\n",
      "selected users: [ 0  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9504 \n",
      "Accuracy: 9486/10000 (94.86%)\n",
      "\n",
      "Round   6, Average loss 0.950 Test accuracy 94.860\n",
      "selected users: [ 0  1  2  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5730 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round   7, Average loss 0.573 Test accuracy 95.100\n",
      "selected users: [ 0  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.1202 \n",
      "Accuracy: 9477/10000 (94.77%)\n",
      "\n",
      "Round   8, Average loss 1.120 Test accuracy 94.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8014 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round   9, Average loss 0.801 Test accuracy 94.540\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2571 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  10, Average loss 0.257 Test accuracy 95.020\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8514 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  11, Average loss 0.851 Test accuracy 94.870\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4485 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  12, Average loss 0.449 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2280 \n",
      "Accuracy: 9465/10000 (94.65%)\n",
      "\n",
      "Round  13, Average loss 0.228 Test accuracy 94.650\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3387 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round  14, Average loss 0.339 Test accuracy 94.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "\n",
      "Test set: Average loss: 0.2630 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  15, Average loss 0.263 Test accuracy 94.300\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2697 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  16, Average loss 0.270 Test accuracy 95.340\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2942 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  17, Average loss 0.294 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5357 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  18, Average loss 0.536 Test accuracy 95.460\n",
      "selected users: [ 1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8450 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round  19, Average loss 0.845 Test accuracy 95.240\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6951 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round  20, Average loss 0.695 Test accuracy 95.410\n",
      "selected users: [ 0  2  3  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4445 \n",
      "Accuracy: 9441/10000 (94.41%)\n",
      "\n",
      "Round  21, Average loss 1.444 Test accuracy 94.410\n",
      "selected users: [ 0  1  2  3  4  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7647 \n",
      "Accuracy: 9480/10000 (94.80%)\n",
      "\n",
      "Round  22, Average loss 0.765 Test accuracy 94.800\n",
      "selected users: [ 0  1  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5644 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  23, Average loss 0.564 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6455 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  24, Average loss 0.645 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8744 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  25, Average loss 0.874 Test accuracy 94.110\n",
      "selected users: [ 0  1  2  3  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2021 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round  26, Average loss 0.202 Test accuracy 94.840\n",
      "selected users: [ 0  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2115 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round  27, Average loss 1.211 Test accuracy 94.970\n",
      "selected users: [ 0  1  2  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8097 \n",
      "Accuracy: 9460/10000 (94.60%)\n",
      "\n",
      "Round  28, Average loss 0.810 Test accuracy 94.600\n",
      "selected users: [ 0  1  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6516 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  29, Average loss 0.652 Test accuracy 95.310\n",
      "number of results: 14\n",
      "(m= 14 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2320 \n",
      "Accuracy: 5802/10000 (58.02%)\n",
      "\n",
      "Round   1, Average loss 2.232 Test accuracy 58.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3199 \n",
      "Accuracy: 9242/10000 (92.42%)\n",
      "\n",
      "Round   2, Average loss 0.320 Test accuracy 92.420\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1714 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round   3, Average loss 0.171 Test accuracy 94.980\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4284 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round   4, Average loss 0.428 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2277 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round   5, Average loss 0.228 Test accuracy 95.350\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3475 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round   6, Average loss 0.347 Test accuracy 95.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2263 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round   7, Average loss 0.226 Test accuracy 95.640\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1335 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round   8, Average loss 0.133 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1460 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round   9, Average loss 0.146 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1898 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  10, Average loss 0.190 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2921 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  11, Average loss 0.292 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2980 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  12, Average loss 0.298 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2886 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  13, Average loss 0.289 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2791 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round  14, Average loss 0.279 Test accuracy 95.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2250 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  15, Average loss 0.225 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3072 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  16, Average loss 0.307 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2420 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  17, Average loss 0.242 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2597 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  18, Average loss 0.260 Test accuracy 95.560\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4003 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  19, Average loss 0.400 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3150 \n",
      "Accuracy: 9493/10000 (94.93%)\n",
      "\n",
      "Round  20, Average loss 0.315 Test accuracy 94.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2973 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  21, Average loss 0.297 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3018 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  22, Average loss 0.302 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3086 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  23, Average loss 0.309 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2969 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round  24, Average loss 0.297 Test accuracy 94.870\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3007 \n",
      "Accuracy: 9599/10000 (95.99%)\n",
      "\n",
      "Round  25, Average loss 0.301 Test accuracy 95.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2391 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round  26, Average loss 0.239 Test accuracy 95.410\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2426 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  27, Average loss 0.243 Test accuracy 95.640\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2486 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  28, Average loss 0.249 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4070 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  29, Average loss 0.407 Test accuracy 95.710\n",
      "(m= 14 )  1 -th Trial!!\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1066 \n",
      "Accuracy: 8964/10000 (89.64%)\n",
      "\n",
      "Round   1, Average loss 2.107 Test accuracy 89.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1910 \n",
      "Accuracy: 9469/10000 (94.69%)\n",
      "\n",
      "Round   2, Average loss 0.191 Test accuracy 94.690\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1703 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round   3, Average loss 0.170 Test accuracy 94.840\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1999 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round   4, Average loss 0.200 Test accuracy 94.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2007 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round   5, Average loss 0.201 Test accuracy 95.750\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5251 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round   6, Average loss 0.525 Test accuracy 95.100\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2064 \n",
      "Accuracy: 9598/10000 (95.98%)\n",
      "\n",
      "Round   7, Average loss 0.206 Test accuracy 95.980\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2014 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round   8, Average loss 0.201 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1824 \n",
      "Accuracy: 9587/10000 (95.87%)\n",
      "\n",
      "Round   9, Average loss 0.182 Test accuracy 95.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2479 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  10, Average loss 0.248 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2439 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  11, Average loss 0.244 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2144 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  12, Average loss 0.214 Test accuracy 95.730\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1953 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  13, Average loss 0.195 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2121 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round  14, Average loss 0.212 Test accuracy 95.130\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1500 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  15, Average loss 0.150 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1765 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  16, Average loss 0.176 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1294 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  17, Average loss 0.129 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2042 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  18, Average loss 0.204 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1849 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  19, Average loss 0.185 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1593 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  20, Average loss 0.159 Test accuracy 96.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2105 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  21, Average loss 0.211 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2346 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round  22, Average loss 0.235 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1501 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  23, Average loss 0.150 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2260 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round  24, Average loss 0.226 Test accuracy 95.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3389 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  25, Average loss 0.339 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2244 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round  26, Average loss 0.224 Test accuracy 95.320\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2994 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  27, Average loss 0.299 Test accuracy 95.140\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1614 \n",
      "Accuracy: 9614/10000 (96.14%)\n",
      "\n",
      "Round  28, Average loss 0.161 Test accuracy 96.140\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3016 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  29, Average loss 0.302 Test accuracy 95.380\n",
      "(m= 14 )  2 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 1.6459 \n",
      "Accuracy: 9058/10000 (90.58%)\n",
      "\n",
      "Round   1, Average loss 1.646 Test accuracy 90.580\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2204 \n",
      "Accuracy: 9487/10000 (94.87%)\n",
      "\n",
      "Round   2, Average loss 0.220 Test accuracy 94.870\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1555 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round   3, Average loss 0.155 Test accuracy 95.710\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1613 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round   4, Average loss 0.161 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1401 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round   5, Average loss 0.140 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2241 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round   6, Average loss 0.224 Test accuracy 95.860\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4233 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round   7, Average loss 0.423 Test accuracy 95.570\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3146 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round   8, Average loss 0.315 Test accuracy 95.640\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2113 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round   9, Average loss 0.211 Test accuracy 95.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3253 \n",
      "Accuracy: 9523/10000 (95.23%)\n",
      "\n",
      "Round  10, Average loss 0.325 Test accuracy 95.230\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3042 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  11, Average loss 0.304 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2363 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  12, Average loss 0.236 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2465 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  13, Average loss 0.246 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2727 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  14, Average loss 0.273 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4047 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  15, Average loss 0.405 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3687 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  16, Average loss 0.369 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3265 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  17, Average loss 0.327 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3322 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  18, Average loss 0.332 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3663 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round  19, Average loss 0.366 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4976 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  20, Average loss 0.498 Test accuracy 95.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3559 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round  21, Average loss 0.356 Test accuracy 94.840\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5125 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  22, Average loss 0.513 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3354 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  23, Average loss 0.335 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2719 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  24, Average loss 0.272 Test accuracy 95.640\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2550 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  25, Average loss 0.255 Test accuracy 95.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3288 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  26, Average loss 0.329 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3397 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  27, Average loss 0.340 Test accuracy 95.800\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3160 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  28, Average loss 0.316 Test accuracy 95.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.3157 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round  29, Average loss 0.316 Test accuracy 95.040\n",
      "(m= 14 )  3 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 2.2147 \n",
      "Accuracy: 8016/10000 (80.16%)\n",
      "\n",
      "Round   1, Average loss 2.215 Test accuracy 80.160\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5074 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round   2, Average loss 0.507 Test accuracy 94.790\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1501 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round   3, Average loss 0.150 Test accuracy 95.640\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1384 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round   4, Average loss 0.138 Test accuracy 95.700\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2524 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round   5, Average loss 0.252 Test accuracy 95.400\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2054 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round   6, Average loss 0.205 Test accuracy 95.640\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5437 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round   7, Average loss 0.544 Test accuracy 95.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3197 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round   8, Average loss 0.320 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2496 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round   9, Average loss 0.250 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1517 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  10, Average loss 0.152 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1616 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  11, Average loss 0.162 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1908 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  12, Average loss 0.191 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2435 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  13, Average loss 0.244 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1365 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  14, Average loss 0.137 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2523 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round  15, Average loss 0.252 Test accuracy 95.190\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2031 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  16, Average loss 0.203 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1971 \n",
      "Accuracy: 9601/10000 (96.01%)\n",
      "\n",
      "Round  17, Average loss 0.197 Test accuracy 96.010\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1922 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  18, Average loss 0.192 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2215 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  19, Average loss 0.222 Test accuracy 95.710\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3625 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  20, Average loss 0.362 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3305 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  21, Average loss 0.331 Test accuracy 95.480\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8377 \n",
      "Accuracy: 9511/10000 (95.11%)\n",
      "\n",
      "Round  22, Average loss 0.838 Test accuracy 95.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2540 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  23, Average loss 0.254 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2332 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  24, Average loss 0.233 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2939 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  25, Average loss 0.294 Test accuracy 95.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3402 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round  26, Average loss 0.340 Test accuracy 95.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2494 \n",
      "Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Round  27, Average loss 0.249 Test accuracy 94.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2284 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round  28, Average loss 0.228 Test accuracy 95.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2467 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  29, Average loss 0.247 Test accuracy 95.450\n",
      "(m= 14 )  4 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1344 \n",
      "Accuracy: 7764/10000 (77.64%)\n",
      "\n",
      "Round   1, Average loss 2.134 Test accuracy 77.640\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1848 \n",
      "Accuracy: 9492/10000 (94.92%)\n",
      "\n",
      "Round   2, Average loss 0.185 Test accuracy 94.920\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1475 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round   3, Average loss 0.147 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1290 \n",
      "Accuracy: 9610/10000 (96.10%)\n",
      "\n",
      "Round   4, Average loss 0.129 Test accuracy 96.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1511 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round   5, Average loss 0.151 Test accuracy 95.500\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4486 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round   6, Average loss 0.449 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2768 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round   7, Average loss 0.277 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2235 \n",
      "Accuracy: 9601/10000 (96.01%)\n",
      "\n",
      "Round   8, Average loss 0.223 Test accuracy 96.010\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1515 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round   9, Average loss 0.151 Test accuracy 95.570\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1716 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  10, Average loss 0.172 Test accuracy 95.760\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1584 \n",
      "Accuracy: 9604/10000 (96.04%)\n",
      "\n",
      "Round  11, Average loss 0.158 Test accuracy 96.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2493 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round  12, Average loss 0.249 Test accuracy 95.930\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1682 \n",
      "Accuracy: 9601/10000 (96.01%)\n",
      "\n",
      "Round  13, Average loss 0.168 Test accuracy 96.010\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2560 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  14, Average loss 0.256 Test accuracy 95.750\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3924 \n",
      "Accuracy: 9595/10000 (95.95%)\n",
      "\n",
      "Round  15, Average loss 0.392 Test accuracy 95.950\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2535 \n",
      "Accuracy: 9594/10000 (95.94%)\n",
      "\n",
      "Round  16, Average loss 0.253 Test accuracy 95.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2573 \n",
      "Accuracy: 9598/10000 (95.98%)\n",
      "\n",
      "Round  17, Average loss 0.257 Test accuracy 95.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2036 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  18, Average loss 0.204 Test accuracy 95.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2211 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  19, Average loss 0.221 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2853 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  20, Average loss 0.285 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2203 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  21, Average loss 0.220 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2307 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round  22, Average loss 0.231 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3110 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round  23, Average loss 0.311 Test accuracy 95.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3258 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  24, Average loss 0.326 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2836 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round  25, Average loss 0.284 Test accuracy 95.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3652 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  26, Average loss 0.365 Test accuracy 95.670\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.7889 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  27, Average loss 0.789 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3823 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round  28, Average loss 0.382 Test accuracy 95.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3356 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  29, Average loss 0.336 Test accuracy 95.610\n",
      "(m= 14 )  5 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3021 \n",
      "Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "Round   1, Average loss 2.302 Test accuracy 10.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.5060 \n",
      "Accuracy: 9124/10000 (91.24%)\n",
      "\n",
      "Round   2, Average loss 1.506 Test accuracy 91.240\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2792 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   3, Average loss 0.279 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2832 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round   4, Average loss 0.283 Test accuracy 95.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2001 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round   5, Average loss 0.200 Test accuracy 95.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2314 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round   6, Average loss 0.231 Test accuracy 95.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1869 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round   7, Average loss 0.187 Test accuracy 95.730\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2835 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round   8, Average loss 0.284 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1821 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round   9, Average loss 0.182 Test accuracy 95.920\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1560 \n",
      "Accuracy: 9587/10000 (95.87%)\n",
      "\n",
      "Round  10, Average loss 0.156 Test accuracy 95.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2316 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round  11, Average loss 0.232 Test accuracy 95.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2530 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  12, Average loss 0.253 Test accuracy 95.810\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2222 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  13, Average loss 0.222 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2348 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  14, Average loss 0.235 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2886 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round  15, Average loss 0.289 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2553 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  16, Average loss 0.255 Test accuracy 95.670\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3694 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  17, Average loss 0.369 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2820 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  18, Average loss 0.282 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3137 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  19, Average loss 0.314 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2815 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  20, Average loss 0.281 Test accuracy 95.830\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4024 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  21, Average loss 0.402 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2595 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  22, Average loss 0.260 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3271 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  23, Average loss 0.327 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2648 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  24, Average loss 0.265 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4528 \n",
      "Accuracy: 9511/10000 (95.11%)\n",
      "\n",
      "Round  25, Average loss 0.453 Test accuracy 95.110\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3286 \n",
      "Accuracy: 9446/10000 (94.46%)\n",
      "\n",
      "Round  26, Average loss 0.329 Test accuracy 94.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3090 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  27, Average loss 0.309 Test accuracy 95.760\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3092 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round  28, Average loss 0.309 Test accuracy 95.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3301 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round  29, Average loss 0.330 Test accuracy 95.740\n",
      "(m= 14 )  6 -th Trial!!\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2690 \n",
      "Accuracy: 7030/10000 (70.30%)\n",
      "\n",
      "Round   1, Average loss 2.269 Test accuracy 70.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2548 \n",
      "Accuracy: 9463/10000 (94.63%)\n",
      "\n",
      "Round   2, Average loss 0.255 Test accuracy 94.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1933 \n",
      "Accuracy: 9475/10000 (94.75%)\n",
      "\n",
      "Round   3, Average loss 0.193 Test accuracy 94.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1603 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round   4, Average loss 0.160 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1607 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round   5, Average loss 0.161 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2024 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round   6, Average loss 0.202 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1981 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round   7, Average loss 0.198 Test accuracy 95.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1495 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round   8, Average loss 0.149 Test accuracy 95.730\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2658 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round   9, Average loss 0.266 Test accuracy 95.410\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5948 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round  10, Average loss 0.595 Test accuracy 95.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2513 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  11, Average loss 0.251 Test accuracy 95.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2219 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  12, Average loss 0.222 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2536 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  13, Average loss 0.254 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2334 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  14, Average loss 0.233 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1950 \n",
      "Accuracy: 9499/10000 (94.99%)\n",
      "\n",
      "Round  15, Average loss 0.195 Test accuracy 94.990\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5126 \n",
      "Accuracy: 9523/10000 (95.23%)\n",
      "\n",
      "Round  16, Average loss 0.513 Test accuracy 95.230\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2136 \n",
      "Accuracy: 9479/10000 (94.79%)\n",
      "\n",
      "Round  17, Average loss 0.214 Test accuracy 94.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1764 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  18, Average loss 0.176 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1785 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  19, Average loss 0.178 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2772 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  20, Average loss 0.277 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1856 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  21, Average loss 0.186 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1889 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  22, Average loss 0.189 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1524 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round  23, Average loss 0.152 Test accuracy 95.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1802 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round  24, Average loss 0.180 Test accuracy 95.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1694 \n",
      "Accuracy: 9604/10000 (96.04%)\n",
      "\n",
      "Round  25, Average loss 0.169 Test accuracy 96.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2658 \n",
      "Accuracy: 9594/10000 (95.94%)\n",
      "\n",
      "Round  26, Average loss 0.266 Test accuracy 95.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4155 \n",
      "Accuracy: 9514/10000 (95.14%)\n",
      "\n",
      "Round  27, Average loss 0.416 Test accuracy 95.140\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1572 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round  28, Average loss 0.157 Test accuracy 95.090\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2234 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  29, Average loss 0.223 Test accuracy 95.800\n",
      "(m= 14 )  7 -th Trial!!\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8564 \n",
      "Accuracy: 8486/10000 (84.86%)\n",
      "\n",
      "Round   1, Average loss 1.856 Test accuracy 84.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1634 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round   2, Average loss 0.163 Test accuracy 95.620\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5994 \n",
      "Accuracy: 9516/10000 (95.16%)\n",
      "\n",
      "Round   3, Average loss 0.599 Test accuracy 95.160\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9296 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round   4, Average loss 0.930 Test accuracy 94.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4337 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round   5, Average loss 0.434 Test accuracy 95.310\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3120 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round   6, Average loss 0.312 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2712 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round   7, Average loss 0.271 Test accuracy 95.410\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1654 \n",
      "Accuracy: 9504/10000 (95.04%)\n",
      "\n",
      "Round   8, Average loss 0.165 Test accuracy 95.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.2140 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round   9, Average loss 0.214 Test accuracy 95.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2695 \n",
      "Accuracy: 9599/10000 (95.99%)\n",
      "\n",
      "Round  10, Average loss 0.270 Test accuracy 95.990\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2721 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  11, Average loss 0.272 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3013 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  12, Average loss 0.301 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3537 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  13, Average loss 0.354 Test accuracy 95.380\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1697 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  14, Average loss 0.170 Test accuracy 95.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3017 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  15, Average loss 0.302 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3872 \n",
      "Accuracy: 9513/10000 (95.13%)\n",
      "\n",
      "Round  16, Average loss 0.387 Test accuracy 95.130\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3643 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  17, Average loss 0.364 Test accuracy 95.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4464 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  18, Average loss 0.446 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3849 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round  19, Average loss 0.385 Test accuracy 95.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4410 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  20, Average loss 0.441 Test accuracy 95.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5244 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round  21, Average loss 0.524 Test accuracy 95.410\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3067 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  22, Average loss 0.307 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.3860 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  23, Average loss 0.386 Test accuracy 95.310\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4627 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round  24, Average loss 0.463 Test accuracy 95.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3608 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  25, Average loss 0.361 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2937 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  26, Average loss 0.294 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2124 \n",
      "Accuracy: 9427/10000 (94.27%)\n",
      "\n",
      "Round  27, Average loss 0.212 Test accuracy 94.270\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2720 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  28, Average loss 0.272 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3343 \n",
      "Accuracy: 9507/10000 (95.07%)\n",
      "\n",
      "Round  29, Average loss 0.334 Test accuracy 95.070\n",
      "(m= 14 )  8 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3007 \n",
      "Accuracy: 1820/10000 (18.20%)\n",
      "\n",
      "Round   0, Average loss 2.301 Test accuracy 18.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4760 \n",
      "Accuracy: 8804/10000 (88.04%)\n",
      "\n",
      "Round   1, Average loss 1.476 Test accuracy 88.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2400 \n",
      "Accuracy: 9497/10000 (94.97%)\n",
      "\n",
      "Round   2, Average loss 0.240 Test accuracy 94.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2197 \n",
      "Accuracy: 9524/10000 (95.24%)\n",
      "\n",
      "Round   3, Average loss 0.220 Test accuracy 95.240\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1513 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round   4, Average loss 0.151 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1349 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round   5, Average loss 0.135 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1292 \n",
      "Accuracy: 9607/10000 (96.07%)\n",
      "\n",
      "Round   6, Average loss 0.129 Test accuracy 96.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1535 \n",
      "Accuracy: 9602/10000 (96.02%)\n",
      "\n",
      "Round   7, Average loss 0.153 Test accuracy 96.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1491 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round   8, Average loss 0.149 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1377 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round   9, Average loss 0.138 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1293 \n",
      "Accuracy: 9604/10000 (96.04%)\n",
      "\n",
      "Round  10, Average loss 0.129 Test accuracy 96.040\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1435 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round  11, Average loss 0.144 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1526 \n",
      "Accuracy: 9598/10000 (95.98%)\n",
      "\n",
      "Round  12, Average loss 0.153 Test accuracy 95.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1645 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  13, Average loss 0.164 Test accuracy 95.720\n",
      "selected users: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2319 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  14, Average loss 0.232 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1458 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  15, Average loss 0.146 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1558 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round  16, Average loss 0.156 Test accuracy 95.520\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5303 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  17, Average loss 0.530 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2567 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  18, Average loss 0.257 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2699 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  19, Average loss 0.270 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1467 \n",
      "Accuracy: 9541/10000 (95.41%)\n",
      "\n",
      "Round  20, Average loss 0.147 Test accuracy 95.410\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2071 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round  21, Average loss 0.207 Test accuracy 95.840\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2134 \n",
      "Accuracy: 9604/10000 (96.04%)\n",
      "\n",
      "Round  22, Average loss 0.213 Test accuracy 96.040\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2327 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  23, Average loss 0.233 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1451 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  24, Average loss 0.145 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2592 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  25, Average loss 0.259 Test accuracy 95.640\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6556 \n",
      "Accuracy: 9519/10000 (95.19%)\n",
      "\n",
      "Round  26, Average loss 0.656 Test accuracy 95.190\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2778 \n",
      "Accuracy: 9598/10000 (95.98%)\n",
      "\n",
      "Round  27, Average loss 0.278 Test accuracy 95.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2363 \n",
      "Accuracy: 9540/10000 (95.40%)\n",
      "\n",
      "Round  28, Average loss 0.236 Test accuracy 95.400\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3846 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round  29, Average loss 0.385 Test accuracy 95.270\n",
      "(m= 14 )  9 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1663 \n",
      "Accuracy: 7664/10000 (76.64%)\n",
      "\n",
      "Round   1, Average loss 2.166 Test accuracy 76.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.1591 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round   2, Average loss 0.159 Test accuracy 95.210\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1388 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round   3, Average loss 0.139 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "Test set: Average loss: 0.1499 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round   4, Average loss 0.150 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1696 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round   5, Average loss 0.170 Test accuracy 95.550\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5479 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round   6, Average loss 0.548 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2811 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round   7, Average loss 0.281 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2177 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round   8, Average loss 0.218 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1725 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round   9, Average loss 0.173 Test accuracy 95.630\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1985 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  10, Average loss 0.199 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2927 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  11, Average loss 0.293 Test accuracy 95.280\n",
      "selected users: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2955 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  12, Average loss 0.295 Test accuracy 95.570\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6722 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  13, Average loss 0.672 Test accuracy 95.290\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2277 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  14, Average loss 0.228 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2603 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  15, Average loss 0.260 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2493 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  16, Average loss 0.249 Test accuracy 95.280\n",
      "selected users: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2930 \n",
      "Accuracy: 9498/10000 (94.98%)\n",
      "\n",
      "Round  17, Average loss 0.293 Test accuracy 94.980\n",
      "selected users: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1450 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  18, Average loss 0.145 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2042 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  19, Average loss 0.204 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2507 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round  20, Average loss 0.251 Test accuracy 95.520\n",
      "selected users: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2137 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  21, Average loss 0.214 Test accuracy 95.720\n",
      "selected users: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2690 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  22, Average loss 0.269 Test accuracy 96.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2801 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  23, Average loss 0.280 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5286 \n",
      "Accuracy: 9506/10000 (95.06%)\n",
      "\n",
      "Round  24, Average loss 0.529 Test accuracy 95.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.2819 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  25, Average loss 0.282 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3303 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  26, Average loss 0.330 Test accuracy 95.810\n",
      "selected users: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.9150 \n",
      "Accuracy: 9511/10000 (95.11%)\n",
      "\n",
      "Round  27, Average loss 0.915 Test accuracy 95.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14]\n",
      "\n",
      "Test set: Average loss: 0.4137 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  28, Average loss 0.414 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3936 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  29, Average loss 0.394 Test accuracy 95.460\n",
      "number of results: 15\n",
      "(m= 15 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2936 \n",
      "Accuracy: 3884/10000 (38.84%)\n",
      "\n",
      "Round   1, Average loss 2.294 Test accuracy 38.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9321 \n",
      "Accuracy: 8422/10000 (84.22%)\n",
      "\n",
      "Round   2, Average loss 1.932 Test accuracy 84.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2975 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round   3, Average loss 0.298 Test accuracy 95.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2062 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round   4, Average loss 0.206 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1621 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round   5, Average loss 0.162 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1522 \n",
      "Accuracy: 9535/10000 (95.35%)\n",
      "\n",
      "Round   6, Average loss 0.152 Test accuracy 95.350\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1415 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round   7, Average loss 0.141 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1511 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round   8, Average loss 0.151 Test accuracy 95.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1389 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round   9, Average loss 0.139 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1375 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  10, Average loss 0.137 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1453 \n",
      "Accuracy: 9587/10000 (95.87%)\n",
      "\n",
      "Round  11, Average loss 0.145 Test accuracy 95.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1543 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  12, Average loss 0.154 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1551 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  13, Average loss 0.155 Test accuracy 95.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1399 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  14, Average loss 0.140 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1457 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  15, Average loss 0.146 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1454 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  16, Average loss 0.145 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1629 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round  17, Average loss 0.163 Test accuracy 95.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1347 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round  18, Average loss 0.135 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1571 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  19, Average loss 0.157 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1814 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  20, Average loss 0.181 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1532 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  21, Average loss 0.153 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1624 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  22, Average loss 0.162 Test accuracy 95.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1840 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round  23, Average loss 0.184 Test accuracy 95.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1721 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  24, Average loss 0.172 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1637 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  25, Average loss 0.164 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1628 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  26, Average loss 0.163 Test accuracy 95.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1528 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  27, Average loss 0.153 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1614 \n",
      "Accuracy: 9599/10000 (95.99%)\n",
      "\n",
      "Round  28, Average loss 0.161 Test accuracy 95.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1729 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  29, Average loss 0.173 Test accuracy 95.860\n",
      "(m= 15 )  1 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1655 \n",
      "Accuracy: 8673/10000 (86.73%)\n",
      "\n",
      "Round   1, Average loss 2.166 Test accuracy 86.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4365 \n",
      "Accuracy: 9482/10000 (94.82%)\n",
      "\n",
      "Round   2, Average loss 0.437 Test accuracy 94.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2583 \n",
      "Accuracy: 9516/10000 (95.16%)\n",
      "\n",
      "Round   3, Average loss 0.258 Test accuracy 95.160\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1711 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round   4, Average loss 0.171 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1454 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round   5, Average loss 0.145 Test accuracy 95.570\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1451 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round   6, Average loss 0.145 Test accuracy 95.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1473 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round   7, Average loss 0.147 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1357 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round   8, Average loss 0.136 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1635 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round   9, Average loss 0.163 Test accuracy 95.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1396 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  10, Average loss 0.140 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1626 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  11, Average loss 0.163 Test accuracy 95.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1357 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  12, Average loss 0.136 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1437 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  13, Average loss 0.144 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1464 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  14, Average loss 0.146 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1421 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  15, Average loss 0.142 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1456 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  16, Average loss 0.146 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1542 \n",
      "Accuracy: 9511/10000 (95.11%)\n",
      "\n",
      "Round  17, Average loss 0.154 Test accuracy 95.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1377 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round  18, Average loss 0.138 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1448 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  19, Average loss 0.145 Test accuracy 95.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1419 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  20, Average loss 0.142 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1486 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  21, Average loss 0.149 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1451 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  22, Average loss 0.145 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1355 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  23, Average loss 0.135 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1733 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  24, Average loss 0.173 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1916 \n",
      "Accuracy: 9484/10000 (94.84%)\n",
      "\n",
      "Round  25, Average loss 0.192 Test accuracy 94.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1494 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  26, Average loss 0.149 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1326 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round  27, Average loss 0.133 Test accuracy 95.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1544 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round  28, Average loss 0.154 Test accuracy 95.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1433 \n",
      "Accuracy: 9594/10000 (95.94%)\n",
      "\n",
      "Round  29, Average loss 0.143 Test accuracy 95.940\n",
      "(m= 15 )  2 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2987 \n",
      "Accuracy: 3176/10000 (31.76%)\n",
      "\n",
      "Round   0, Average loss 2.299 Test accuracy 31.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2722 \n",
      "Accuracy: 3813/10000 (38.13%)\n",
      "\n",
      "Round   1, Average loss 2.272 Test accuracy 38.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.6512 \n",
      "Accuracy: 9439/10000 (94.39%)\n",
      "\n",
      "Round   2, Average loss 0.651 Test accuracy 94.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2814 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round   3, Average loss 0.281 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1922 \n",
      "Accuracy: 9612/10000 (96.12%)\n",
      "\n",
      "Round   4, Average loss 0.192 Test accuracy 96.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1722 \n",
      "Accuracy: 9595/10000 (95.95%)\n",
      "\n",
      "Round   5, Average loss 0.172 Test accuracy 95.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1445 \n",
      "Accuracy: 9614/10000 (96.14%)\n",
      "\n",
      "Round   6, Average loss 0.145 Test accuracy 96.140\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1457 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round   7, Average loss 0.146 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1466 \n",
      "Accuracy: 9592/10000 (95.92%)\n",
      "\n",
      "Round   8, Average loss 0.147 Test accuracy 95.920\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1327 \n",
      "Accuracy: 9608/10000 (96.08%)\n",
      "\n",
      "Round   9, Average loss 0.133 Test accuracy 96.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1489 \n",
      "Accuracy: 9528/10000 (95.28%)\n",
      "\n",
      "Round  10, Average loss 0.149 Test accuracy 95.280\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1384 \n",
      "Accuracy: 9611/10000 (96.11%)\n",
      "\n",
      "Round  11, Average loss 0.138 Test accuracy 96.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1394 \n",
      "Accuracy: 9584/10000 (95.84%)\n",
      "\n",
      "Round  12, Average loss 0.139 Test accuracy 95.840\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1323 \n",
      "Accuracy: 9618/10000 (96.18%)\n",
      "\n",
      "Round  13, Average loss 0.132 Test accuracy 96.180\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1430 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  14, Average loss 0.143 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1413 \n",
      "Accuracy: 9552/10000 (95.52%)\n",
      "\n",
      "Round  15, Average loss 0.141 Test accuracy 95.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1324 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  16, Average loss 0.132 Test accuracy 96.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1417 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  17, Average loss 0.142 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1431 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  18, Average loss 0.143 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1271 \n",
      "Accuracy: 9615/10000 (96.15%)\n",
      "\n",
      "Round  19, Average loss 0.127 Test accuracy 96.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1381 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  20, Average loss 0.138 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1320 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  21, Average loss 0.132 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1277 \n",
      "Accuracy: 9610/10000 (96.10%)\n",
      "\n",
      "Round  22, Average loss 0.128 Test accuracy 96.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1372 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  23, Average loss 0.137 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1275 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round  24, Average loss 0.127 Test accuracy 95.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1308 \n",
      "Accuracy: 9606/10000 (96.06%)\n",
      "\n",
      "Round  25, Average loss 0.131 Test accuracy 96.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1400 \n",
      "Accuracy: 9562/10000 (95.62%)\n",
      "\n",
      "Round  26, Average loss 0.140 Test accuracy 95.620\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1292 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  27, Average loss 0.129 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1420 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  28, Average loss 0.142 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1382 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round  29, Average loss 0.138 Test accuracy 95.970\n",
      "(m= 15 )  3 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3001 \n",
      "Accuracy: 3080/10000 (30.80%)\n",
      "\n",
      "Round   1, Average loss 2.300 Test accuracy 30.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3052 \n",
      "Accuracy: 246/10000 (2.46%)\n",
      "\n",
      "Round   2, Average loss 2.305 Test accuracy 2.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.8569 \n",
      "Accuracy: 9352/10000 (93.52%)\n",
      "\n",
      "Round   3, Average loss 0.857 Test accuracy 93.520\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2000 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round   4, Average loss 0.200 Test accuracy 95.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1490 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round   5, Average loss 0.149 Test accuracy 95.390\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1468 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round   6, Average loss 0.147 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1493 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round   7, Average loss 0.149 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1546 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round   8, Average loss 0.155 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1659 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round   9, Average loss 0.166 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1454 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  10, Average loss 0.145 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1742 \n",
      "Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Round  11, Average loss 0.174 Test accuracy 95.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1472 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round  12, Average loss 0.147 Test accuracy 95.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1440 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  13, Average loss 0.144 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1510 \n",
      "Accuracy: 9595/10000 (95.95%)\n",
      "\n",
      "Round  14, Average loss 0.151 Test accuracy 95.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1712 \n",
      "Accuracy: 9609/10000 (96.09%)\n",
      "\n",
      "Round  15, Average loss 0.171 Test accuracy 96.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1605 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round  16, Average loss 0.161 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1850 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  17, Average loss 0.185 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1646 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  18, Average loss 0.165 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1511 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  19, Average loss 0.151 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1825 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  20, Average loss 0.183 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1938 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  21, Average loss 0.194 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1609 \n",
      "Accuracy: 9617/10000 (96.17%)\n",
      "\n",
      "Round  22, Average loss 0.161 Test accuracy 96.170\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1789 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  23, Average loss 0.179 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1856 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  24, Average loss 0.186 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2088 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  25, Average loss 0.209 Test accuracy 95.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1837 \n",
      "Accuracy: 9533/10000 (95.33%)\n",
      "\n",
      "Round  26, Average loss 0.184 Test accuracy 95.330\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1893 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round  27, Average loss 0.189 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2157 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  28, Average loss 0.216 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2195 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  29, Average loss 0.219 Test accuracy 95.300\n",
      "(m= 15 )  4 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2352 \n",
      "Accuracy: 8086/10000 (80.86%)\n",
      "\n",
      "Round   1, Average loss 2.235 Test accuracy 80.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2240 \n",
      "Accuracy: 9432/10000 (94.32%)\n",
      "\n",
      "Round   2, Average loss 0.224 Test accuracy 94.320\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1586 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round   3, Average loss 0.159 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1350 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round   4, Average loss 0.135 Test accuracy 95.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1554 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round   5, Average loss 0.155 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1385 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round   6, Average loss 0.138 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1427 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round   7, Average loss 0.143 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1368 \n",
      "Accuracy: 9613/10000 (96.13%)\n",
      "\n",
      "Round   8, Average loss 0.137 Test accuracy 96.130\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1473 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round   9, Average loss 0.147 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1582 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  10, Average loss 0.158 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1350 \n",
      "Accuracy: 9605/10000 (96.05%)\n",
      "\n",
      "Round  11, Average loss 0.135 Test accuracy 96.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1384 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  12, Average loss 0.138 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1458 \n",
      "Accuracy: 9581/10000 (95.81%)\n",
      "\n",
      "Round  13, Average loss 0.146 Test accuracy 95.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1456 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  14, Average loss 0.146 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1951 \n",
      "Accuracy: 9510/10000 (95.10%)\n",
      "\n",
      "Round  15, Average loss 0.195 Test accuracy 95.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1367 \n",
      "Accuracy: 9604/10000 (96.04%)\n",
      "\n",
      "Round  16, Average loss 0.137 Test accuracy 96.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1387 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  17, Average loss 0.139 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1575 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  18, Average loss 0.157 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1677 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  19, Average loss 0.168 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1603 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  20, Average loss 0.160 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1517 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  21, Average loss 0.152 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1468 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  22, Average loss 0.147 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1421 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  23, Average loss 0.142 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1606 \n",
      "Accuracy: 9598/10000 (95.98%)\n",
      "\n",
      "Round  24, Average loss 0.161 Test accuracy 95.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1752 \n",
      "Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Round  25, Average loss 0.175 Test accuracy 95.850\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1841 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  26, Average loss 0.184 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1727 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  27, Average loss 0.173 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2053 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  28, Average loss 0.205 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2065 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round  29, Average loss 0.207 Test accuracy 95.440\n",
      "(m= 15 )  5 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9307 \n",
      "Accuracy: 7287/10000 (72.87%)\n",
      "\n",
      "Round   1, Average loss 1.931 Test accuracy 72.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1999 \n",
      "Accuracy: 9421/10000 (94.21%)\n",
      "\n",
      "Round   2, Average loss 0.200 Test accuracy 94.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1809 \n",
      "Accuracy: 9522/10000 (95.22%)\n",
      "\n",
      "Round   3, Average loss 0.181 Test accuracy 95.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1457 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round   4, Average loss 0.146 Test accuracy 95.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1510 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round   5, Average loss 0.151 Test accuracy 95.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1772 \n",
      "Accuracy: 9547/10000 (95.47%)\n",
      "\n",
      "Round   6, Average loss 0.177 Test accuracy 95.470\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1724 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round   7, Average loss 0.172 Test accuracy 95.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1470 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round   8, Average loss 0.147 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1586 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round   9, Average loss 0.159 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1587 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  10, Average loss 0.159 Test accuracy 95.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1505 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  11, Average loss 0.150 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1488 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  12, Average loss 0.149 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1963 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round  13, Average loss 0.196 Test accuracy 95.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1361 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  14, Average loss 0.136 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1509 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  15, Average loss 0.151 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1332 \n",
      "Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Round  16, Average loss 0.133 Test accuracy 95.900\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1667 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  17, Average loss 0.167 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1628 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  18, Average loss 0.163 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1784 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round  19, Average loss 0.178 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1656 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round  20, Average loss 0.166 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1759 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round  21, Average loss 0.176 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1668 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  22, Average loss 0.167 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1724 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round  23, Average loss 0.172 Test accuracy 95.440\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1523 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  24, Average loss 0.152 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1600 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  25, Average loss 0.160 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1461 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  26, Average loss 0.146 Test accuracy 96.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1830 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  27, Average loss 0.183 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1343 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round  28, Average loss 0.134 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1427 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  29, Average loss 0.143 Test accuracy 95.730\n",
      "(m= 15 )  6 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3008 \n",
      "Accuracy: 2058/10000 (20.58%)\n",
      "\n",
      "Round   0, Average loss 2.301 Test accuracy 20.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.8382 \n",
      "Accuracy: 8963/10000 (89.63%)\n",
      "\n",
      "Round   1, Average loss 1.838 Test accuracy 89.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2535 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   2, Average loss 0.253 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1576 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round   3, Average loss 0.158 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1441 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round   4, Average loss 0.144 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1374 \n",
      "Accuracy: 9609/10000 (96.09%)\n",
      "\n",
      "Round   5, Average loss 0.137 Test accuracy 96.090\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1548 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round   6, Average loss 0.155 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1491 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round   7, Average loss 0.149 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1493 \n",
      "Accuracy: 9548/10000 (95.48%)\n",
      "\n",
      "Round   8, Average loss 0.149 Test accuracy 95.480\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1431 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round   9, Average loss 0.143 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1465 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  10, Average loss 0.146 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1461 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  11, Average loss 0.146 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2098 \n",
      "Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Round  12, Average loss 0.210 Test accuracy 95.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1530 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  13, Average loss 0.153 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1562 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round  14, Average loss 0.156 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1791 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  15, Average loss 0.179 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1818 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  16, Average loss 0.182 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1502 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  17, Average loss 0.150 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1772 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  18, Average loss 0.177 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1399 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  19, Average loss 0.140 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1740 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round  20, Average loss 0.174 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1691 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  21, Average loss 0.169 Test accuracy 95.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1638 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  22, Average loss 0.164 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1616 \n",
      "Accuracy: 9593/10000 (95.93%)\n",
      "\n",
      "Round  23, Average loss 0.162 Test accuracy 95.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1622 \n",
      "Accuracy: 9545/10000 (95.45%)\n",
      "\n",
      "Round  24, Average loss 0.162 Test accuracy 95.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1763 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  25, Average loss 0.176 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1742 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round  26, Average loss 0.174 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1426 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round  27, Average loss 0.143 Test accuracy 95.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1655 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  28, Average loss 0.166 Test accuracy 95.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1567 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  29, Average loss 0.157 Test accuracy 95.680\n",
      "(m= 15 )  7 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2790 \n",
      "Accuracy: 7577/10000 (75.77%)\n",
      "\n",
      "Round   1, Average loss 2.279 Test accuracy 75.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.4260 \n",
      "Accuracy: 9156/10000 (91.56%)\n",
      "\n",
      "Round   2, Average loss 1.426 Test accuracy 91.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5200 \n",
      "Accuracy: 9527/10000 (95.27%)\n",
      "\n",
      "Round   3, Average loss 0.520 Test accuracy 95.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4327 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round   4, Average loss 0.433 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2190 \n",
      "Accuracy: 9549/10000 (95.49%)\n",
      "\n",
      "Round   5, Average loss 0.219 Test accuracy 95.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1717 \n",
      "Accuracy: 9605/10000 (96.05%)\n",
      "\n",
      "Round   6, Average loss 0.172 Test accuracy 96.050\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1712 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round   7, Average loss 0.171 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1659 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round   8, Average loss 0.166 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1817 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round   9, Average loss 0.182 Test accuracy 95.420\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1437 \n",
      "Accuracy: 9572/10000 (95.72%)\n",
      "\n",
      "Round  10, Average loss 0.144 Test accuracy 95.720\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1390 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  11, Average loss 0.139 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1432 \n",
      "Accuracy: 9559/10000 (95.59%)\n",
      "\n",
      "Round  12, Average loss 0.143 Test accuracy 95.590\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1435 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  13, Average loss 0.144 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1316 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  14, Average loss 0.132 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1366 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  15, Average loss 0.137 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1577 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  16, Average loss 0.158 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1257 \n",
      "Accuracy: 9606/10000 (96.06%)\n",
      "\n",
      "Round  17, Average loss 0.126 Test accuracy 96.060\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1376 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  18, Average loss 0.138 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1471 \n",
      "Accuracy: 9576/10000 (95.76%)\n",
      "\n",
      "Round  19, Average loss 0.147 Test accuracy 95.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1662 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  20, Average loss 0.166 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1466 \n",
      "Accuracy: 9587/10000 (95.87%)\n",
      "\n",
      "Round  21, Average loss 0.147 Test accuracy 95.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1690 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  22, Average loss 0.169 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1734 \n",
      "Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Round  23, Average loss 0.173 Test accuracy 95.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1532 \n",
      "Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Round  24, Average loss 0.153 Test accuracy 95.640\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1648 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  25, Average loss 0.165 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1392 \n",
      "Accuracy: 9569/10000 (95.69%)\n",
      "\n",
      "Round  26, Average loss 0.139 Test accuracy 95.690\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1476 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  27, Average loss 0.148 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1810 \n",
      "Accuracy: 9578/10000 (95.78%)\n",
      "\n",
      "Round  28, Average loss 0.181 Test accuracy 95.780\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1694 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  29, Average loss 0.169 Test accuracy 95.680\n",
      "(m= 15 )  8 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2943 \n",
      "Accuracy: 3153/10000 (31.53%)\n",
      "\n",
      "Round   0, Average loss 2.294 Test accuracy 31.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.2051 \n",
      "Accuracy: 9370/10000 (93.70%)\n",
      "\n",
      "Round   1, Average loss 1.205 Test accuracy 93.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5659 \n",
      "Accuracy: 9468/10000 (94.68%)\n",
      "\n",
      "Round   2, Average loss 0.566 Test accuracy 94.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3015 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round   3, Average loss 0.301 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3548 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round   4, Average loss 0.355 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2453 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round   5, Average loss 0.245 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2441 \n",
      "Accuracy: 9520/10000 (95.20%)\n",
      "\n",
      "Round   6, Average loss 0.244 Test accuracy 95.200\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2391 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round   7, Average loss 0.239 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1707 \n",
      "Accuracy: 9575/10000 (95.75%)\n",
      "\n",
      "Round   8, Average loss 0.171 Test accuracy 95.750\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2139 \n",
      "Accuracy: 9588/10000 (95.88%)\n",
      "\n",
      "Round   9, Average loss 0.214 Test accuracy 95.880\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2254 \n",
      "Accuracy: 9571/10000 (95.71%)\n",
      "\n",
      "Round  10, Average loss 0.225 Test accuracy 95.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1848 \n",
      "Accuracy: 9556/10000 (95.56%)\n",
      "\n",
      "Round  11, Average loss 0.185 Test accuracy 95.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1873 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  12, Average loss 0.187 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1596 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  13, Average loss 0.160 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1671 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  14, Average loss 0.167 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1587 \n",
      "Accuracy: 9554/10000 (95.54%)\n",
      "\n",
      "Round  15, Average loss 0.159 Test accuracy 95.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1647 \n",
      "Accuracy: 9579/10000 (95.79%)\n",
      "\n",
      "Round  16, Average loss 0.165 Test accuracy 95.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1658 \n",
      "Accuracy: 9568/10000 (95.68%)\n",
      "\n",
      "Round  17, Average loss 0.166 Test accuracy 95.680\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1754 \n",
      "Accuracy: 9555/10000 (95.55%)\n",
      "\n",
      "Round  18, Average loss 0.175 Test accuracy 95.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1952 \n",
      "Accuracy: 9598/10000 (95.98%)\n",
      "\n",
      "Round  19, Average loss 0.195 Test accuracy 95.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2119 \n",
      "Accuracy: 9596/10000 (95.96%)\n",
      "\n",
      "Round  20, Average loss 0.212 Test accuracy 95.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1884 \n",
      "Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Round  21, Average loss 0.188 Test accuracy 95.430\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1771 \n",
      "Accuracy: 9570/10000 (95.70%)\n",
      "\n",
      "Round  22, Average loss 0.177 Test accuracy 95.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2467 \n",
      "Accuracy: 9591/10000 (95.91%)\n",
      "\n",
      "Round  23, Average loss 0.247 Test accuracy 95.910\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1655 \n",
      "Accuracy: 9611/10000 (96.11%)\n",
      "\n",
      "Round  24, Average loss 0.166 Test accuracy 96.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1404 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round  25, Average loss 0.140 Test accuracy 95.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1524 \n",
      "Accuracy: 9597/10000 (95.97%)\n",
      "\n",
      "Round  26, Average loss 0.152 Test accuracy 95.970\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1669 \n",
      "Accuracy: 9573/10000 (95.73%)\n",
      "\n",
      "Round  27, Average loss 0.167 Test accuracy 95.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1483 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  28, Average loss 0.148 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1852 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  29, Average loss 0.185 Test accuracy 95.420\n",
      "(m= 15 )  9 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2964 \n",
      "Accuracy: 5158/10000 (51.58%)\n",
      "\n",
      "Round   1, Average loss 2.296 Test accuracy 51.580\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4148 \n",
      "Accuracy: 9327/10000 (93.27%)\n",
      "\n",
      "Round   2, Average loss 0.415 Test accuracy 93.270\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2651 \n",
      "Accuracy: 9534/10000 (95.34%)\n",
      "\n",
      "Round   3, Average loss 0.265 Test accuracy 95.340\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1673 \n",
      "Accuracy: 9565/10000 (95.65%)\n",
      "\n",
      "Round   4, Average loss 0.167 Test accuracy 95.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1453 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round   5, Average loss 0.145 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1601 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round   6, Average loss 0.160 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1557 \n",
      "Accuracy: 9595/10000 (95.95%)\n",
      "\n",
      "Round   7, Average loss 0.156 Test accuracy 95.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1609 \n",
      "Accuracy: 9563/10000 (95.63%)\n",
      "\n",
      "Round   8, Average loss 0.161 Test accuracy 95.630\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1775 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round   9, Average loss 0.178 Test accuracy 95.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1575 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  10, Average loss 0.157 Test accuracy 95.460\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1535 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  11, Average loss 0.153 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1996 \n",
      "Accuracy: 9553/10000 (95.53%)\n",
      "\n",
      "Round  12, Average loss 0.200 Test accuracy 95.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1588 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  13, Average loss 0.159 Test accuracy 95.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2076 \n",
      "Accuracy: 9515/10000 (95.15%)\n",
      "\n",
      "Round  14, Average loss 0.208 Test accuracy 95.150\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1824 \n",
      "Accuracy: 9567/10000 (95.67%)\n",
      "\n",
      "Round  15, Average loss 0.182 Test accuracy 95.670\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1884 \n",
      "Accuracy: 9603/10000 (96.03%)\n",
      "\n",
      "Round  16, Average loss 0.188 Test accuracy 96.030\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2260 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round  17, Average loss 0.226 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1577 \n",
      "Accuracy: 9580/10000 (95.80%)\n",
      "\n",
      "Round  18, Average loss 0.158 Test accuracy 95.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1721 \n",
      "Accuracy: 9589/10000 (95.89%)\n",
      "\n",
      "Round  19, Average loss 0.172 Test accuracy 95.890\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2228 \n",
      "Accuracy: 9530/10000 (95.30%)\n",
      "\n",
      "Round  20, Average loss 0.223 Test accuracy 95.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1933 \n",
      "Accuracy: 9560/10000 (95.60%)\n",
      "\n",
      "Round  21, Average loss 0.193 Test accuracy 95.600\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2090 \n",
      "Accuracy: 9531/10000 (95.31%)\n",
      "\n",
      "Round  22, Average loss 0.209 Test accuracy 95.310\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1816 \n",
      "Accuracy: 9536/10000 (95.36%)\n",
      "\n",
      "Round  23, Average loss 0.182 Test accuracy 95.360\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1666 \n",
      "Accuracy: 9551/10000 (95.51%)\n",
      "\n",
      "Round  24, Average loss 0.167 Test accuracy 95.510\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2099 \n",
      "Accuracy: 9525/10000 (95.25%)\n",
      "\n",
      "Round  25, Average loss 0.210 Test accuracy 95.250\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1809 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  26, Average loss 0.181 Test accuracy 95.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1988 \n",
      "Accuracy: 9586/10000 (95.86%)\n",
      "\n",
      "Round  27, Average loss 0.199 Test accuracy 95.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2047 \n",
      "Accuracy: 9582/10000 (95.82%)\n",
      "\n",
      "Round  28, Average loss 0.205 Test accuracy 95.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2103 \n",
      "Accuracy: 9501/10000 (95.01%)\n",
      "\n",
      "Round  29, Average loss 0.210 Test accuracy 95.010\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "# training\n",
    "loss_train_arr = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "net_best = None\n",
    "best_loss = None\n",
    "\n",
    "N_trials = 10\n",
    "N_epochs = 30\n",
    "\n",
    "m_array = np.array(range(4,16))\n",
    "loss_test_arr = np.empty((len(m_array),N_trials,N_epochs))\n",
    "acc_test_arr  = np.empty((len(m_array),N_trials,N_epochs))\n",
    "\n",
    "for m_idx in range(len(m_array)):\n",
    "    m = m_array[m_idx]\n",
    "    print('number of results:',m)\n",
    "    \n",
    "    for trial_idx in range(N_trials):\n",
    "        print('(m=',m,') ',trial_idx,'-th Trial!!')\n",
    "        \n",
    "        net_glob = CNNMnist2(args=args)\n",
    "        net_glob.cuda()\n",
    "        net_glob.train()\n",
    "\n",
    "        # copy weights\n",
    "        w_glob = net_glob.state_dict()\n",
    "\n",
    "        for iter in range(N_epochs): #args.epochs\n",
    "            w_locals, loss_locals = [], []\n",
    "            idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "            idxs_users = np.sort(idxs_users)\n",
    "            print('selected users:',idxs_users)\n",
    "\n",
    "            dec_z_array = []\n",
    "            for idx in idxs_users: #for idx in range(N):\n",
    "        #         print(idx)\n",
    "                local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                w_locals.append(copy.deepcopy(w))\n",
    "                loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "            # update global weights\n",
    "            #w_glob = FedAvg(w_locals)\n",
    "            w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array, dec_z_array)\n",
    "\n",
    "            # copy weight to net_glob\n",
    "            net_glob.load_state_dict(w_glob)\n",
    "\n",
    "            # print loss\n",
    "        #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "        #     loss_train_arr.append(loss_train)\n",
    "\n",
    "            acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "            acc_test_arr[m_idx][trial_idx][iter] = acc_test\n",
    "            loss_test_arr[m_idx][trial_idx][iter] = loss_test\n",
    "            if iter % 1 ==0:\n",
    "                print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "            #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 10, 30)\n",
      "(12, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sel_m=10\n",
    "sel_trial=0\n",
    "\n",
    "plot_acc = np.mean(acc_test_arr, axis=1)\n",
    "print(acc_test_arr.shape)\n",
    "print(plot_acc.shape)\n",
    "\n",
    "plt.plot(plot_acc[0,:],label='m=4')\n",
    "plt.plot(plot_acc[2,:],label='m=6')\n",
    "plt.plot(plot_acc[4,:],label='m=8')\n",
    "plt.plot(plot_acc[6,:],label='m=10')\n",
    "plt.plot(plot_acc[11,:],label='m=15')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Test accuracy(%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(idxs_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
