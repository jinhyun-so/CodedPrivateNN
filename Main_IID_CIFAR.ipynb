{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2\n",
    "from models.Fed import FedAvg\n",
    "from models.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models.test import test_img\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class my_argument:    \n",
    "    epochs = 200    #\"rounds of training\"\n",
    "    num_users = 40  # \"number of users: K\"\n",
    "    frac = 0.5 #\"the fraction of clients: C\"\n",
    "    local_ep=5 #\"the number of local epochs: E\"\n",
    "    local_bs=125 #\"local batch size: B\"\n",
    "    bs=128 #\"test batch size\"\n",
    "    lr=0.001 #\"learning rate\"\n",
    "    momentum=0.5 # \"SGD momentum (default: 0.5)\"\n",
    "    split='user' # \"train-test split type, user or sample\"\n",
    "    weight_decay = 5e-4\n",
    "    opt = 'ADAM'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num=9 #, help='number of each kind of kernel')\n",
    "    kernel_sizes='3,4,5' #  help='comma-separated kernel size to use for convolution')\n",
    "    norm='batch_norm' #, help=\"batch_norm, layer_norm, or None\")\n",
    "    num_filters=32 #, help=\"number of filters for conv nets\")\n",
    "    max_pool='True' #help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    dataset='cifar' #, help=\"name of dataset\")\n",
    "    iid=1\n",
    "    num_classes=10#, help=\"number of classes\")\n",
    "    num_channels=1#, help=\"number of channels of imges\")\n",
    "    gpu=1#, help=\"GPU ID, -1 for CPU\")\n",
    "    stopping_rounds=10#, help='rounds of early stopping')\n",
    "    verbose='False'#, help='verbose print')\n",
    "    seed=1#, help='random seed (default: 1)')\n",
    "    \n",
    "args = my_argument()\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "args.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load dataset and split users\n",
    "if args.dataset == 'mnist':\n",
    "    trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    dataset_train = datasets.MNIST('./data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "    dataset_test = datasets.MNIST('./data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "    # sample users\n",
    "    if args.iid:\n",
    "        dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "elif args.dataset == 'cifar':\n",
    "    trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "    dataset_train = datasets.CIFAR10('./data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "    dataset_test = datasets.CIFAR10('./data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "    if args.iid:\n",
    "        dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        exit('Error: only consider IID setting in CIFAR10')\n",
    "else:\n",
    "    exit('Error: unrecognized dataset')\n",
    "img_size = dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. FedAvg with A=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_layer): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1), #1\n",
    "            nn.ReLU(inplace=True), #2\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #3\n",
    "            nn.ReLU(inplace=True), #4\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), #5\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #6\n",
    "            nn.ReLU(inplace=True), #7\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #8\n",
    "            nn.ReLU(inplace=True), #9\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), #10\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), #11\n",
    "            nn.ReLU(inplace=True), #12\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, padding=0), #13\n",
    "            nn.ReLU(inplace=True), #14\n",
    "            nn.Conv2d(in_channels=64, out_channels=16, kernel_size=1, padding=0), #15\n",
    "            nn.ReLU(inplace=True), #16\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"        \n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "\n",
    "# # build model\n",
    "# if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "#     net_glob = CNNCifar(args=args).to(args.device)\n",
    "# elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "#     net_glob = CNNMnist2(args=args).to(args.device)\n",
    "# elif args.model == 'mlp':\n",
    "#     len_in = 1\n",
    "#     for x in img_size:\n",
    "#         len_in *= x\n",
    "#     net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "# else:\n",
    "#     exit('Error: unrecognized model')\n",
    "    \n",
    "# from models.vgg import *\n",
    "# net_glob = VGG('VGG11')\n",
    "# if args.gpu != -1:\n",
    "#     net_glob = net_glob.cuda()\n",
    "\n",
    "net_glob = CNN()\n",
    "net_glob = net_glob.cuda()\n",
    "print(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0815 \n",
      "Accuracy: 3093/10000 (30.93%)\n",
      "\n",
      "Round   0, Train average loss 2.083 Test accuracy 30.930\n",
      "\n",
      "Test set: Average loss: 1.8290 \n",
      "Accuracy: 3475/10000 (34.75%)\n",
      "\n",
      "Round   1, Train average loss 1.897 Test accuracy 34.750\n",
      "\n",
      "Test set: Average loss: 1.6648 \n",
      "Accuracy: 3963/10000 (39.63%)\n",
      "\n",
      "Round   2, Train average loss 1.731 Test accuracy 39.630\n",
      "\n",
      "Test set: Average loss: 1.5662 \n",
      "Accuracy: 4398/10000 (43.98%)\n",
      "\n",
      "Round   3, Train average loss 1.595 Test accuracy 43.980\n",
      "\n",
      "Test set: Average loss: 1.4983 \n",
      "Accuracy: 4617/10000 (46.17%)\n",
      "\n",
      "Round   4, Train average loss 1.523 Test accuracy 46.170\n",
      "\n",
      "Test set: Average loss: 1.4616 \n",
      "Accuracy: 4781/10000 (47.81%)\n",
      "\n",
      "Round   5, Train average loss 1.421 Test accuracy 47.810\n",
      "\n",
      "Test set: Average loss: 1.4362 \n",
      "Accuracy: 4885/10000 (48.85%)\n",
      "\n",
      "Round   6, Train average loss 1.359 Test accuracy 48.850\n",
      "\n",
      "Test set: Average loss: 1.4181 \n",
      "Accuracy: 4990/10000 (49.90%)\n",
      "\n",
      "Round   7, Train average loss 1.292 Test accuracy 49.900\n",
      "\n",
      "Test set: Average loss: 1.4149 \n",
      "Accuracy: 5130/10000 (51.30%)\n",
      "\n",
      "Round   8, Train average loss 1.249 Test accuracy 51.300\n",
      "\n",
      "Test set: Average loss: 1.4090 \n",
      "Accuracy: 5205/10000 (52.05%)\n",
      "\n",
      "Round   9, Train average loss 1.194 Test accuracy 52.050\n",
      "\n",
      "Test set: Average loss: 1.3788 \n",
      "Accuracy: 5285/10000 (52.85%)\n",
      "\n",
      "Round  10, Train average loss 1.164 Test accuracy 52.850\n",
      "\n",
      "Test set: Average loss: 1.3636 \n",
      "Accuracy: 5368/10000 (53.68%)\n",
      "\n",
      "Round  11, Train average loss 1.108 Test accuracy 53.680\n",
      "\n",
      "Test set: Average loss: 1.3515 \n",
      "Accuracy: 5411/10000 (54.11%)\n",
      "\n",
      "Round  12, Train average loss 1.110 Test accuracy 54.110\n",
      "\n",
      "Test set: Average loss: 1.3542 \n",
      "Accuracy: 5482/10000 (54.82%)\n",
      "\n",
      "Round  13, Train average loss 1.028 Test accuracy 54.820\n",
      "\n",
      "Test set: Average loss: 1.3592 \n",
      "Accuracy: 5535/10000 (55.35%)\n",
      "\n",
      "Round  14, Train average loss 1.001 Test accuracy 55.350\n",
      "\n",
      "Test set: Average loss: 1.3450 \n",
      "Accuracy: 5597/10000 (55.97%)\n",
      "\n",
      "Round  15, Train average loss 1.005 Test accuracy 55.970\n",
      "\n",
      "Test set: Average loss: 1.3555 \n",
      "Accuracy: 5637/10000 (56.37%)\n",
      "\n",
      "Round  16, Train average loss 0.955 Test accuracy 56.370\n",
      "\n",
      "Test set: Average loss: 1.3305 \n",
      "Accuracy: 5644/10000 (56.44%)\n",
      "\n",
      "Round  17, Train average loss 0.943 Test accuracy 56.440\n",
      "\n",
      "Test set: Average loss: 1.3184 \n",
      "Accuracy: 5743/10000 (57.43%)\n",
      "\n",
      "Round  18, Train average loss 0.944 Test accuracy 57.430\n",
      "\n",
      "Test set: Average loss: 1.3567 \n",
      "Accuracy: 5727/10000 (57.27%)\n",
      "\n",
      "Round  19, Train average loss 0.886 Test accuracy 57.270\n",
      "\n",
      "Test set: Average loss: 1.3331 \n",
      "Accuracy: 5780/10000 (57.80%)\n",
      "\n",
      "Round  20, Train average loss 0.878 Test accuracy 57.800\n",
      "\n",
      "Test set: Average loss: 1.3954 \n",
      "Accuracy: 5802/10000 (58.02%)\n",
      "\n",
      "Round  21, Train average loss 0.822 Test accuracy 58.020\n",
      "\n",
      "Test set: Average loss: 1.3558 \n",
      "Accuracy: 5858/10000 (58.58%)\n",
      "\n",
      "Round  22, Train average loss 0.839 Test accuracy 58.580\n",
      "\n",
      "Test set: Average loss: 1.3387 \n",
      "Accuracy: 5866/10000 (58.66%)\n",
      "\n",
      "Round  23, Train average loss 0.824 Test accuracy 58.660\n",
      "\n",
      "Test set: Average loss: 1.4061 \n",
      "Accuracy: 5903/10000 (59.03%)\n",
      "\n",
      "Round  24, Train average loss 0.755 Test accuracy 59.030\n",
      "\n",
      "Test set: Average loss: 1.3798 \n",
      "Accuracy: 5932/10000 (59.32%)\n",
      "\n",
      "Round  25, Train average loss 0.787 Test accuracy 59.320\n",
      "\n",
      "Test set: Average loss: 1.3529 \n",
      "Accuracy: 5977/10000 (59.77%)\n",
      "\n",
      "Round  26, Train average loss 0.779 Test accuracy 59.770\n",
      "\n",
      "Test set: Average loss: 1.3406 \n",
      "Accuracy: 5970/10000 (59.70%)\n",
      "\n",
      "Round  27, Train average loss 0.790 Test accuracy 59.700\n",
      "\n",
      "Test set: Average loss: 1.3489 \n",
      "Accuracy: 6011/10000 (60.11%)\n",
      "\n",
      "Round  28, Train average loss 0.743 Test accuracy 60.110\n",
      "\n",
      "Test set: Average loss: 1.3802 \n",
      "Accuracy: 6070/10000 (60.70%)\n",
      "\n",
      "Round  29, Train average loss 0.725 Test accuracy 60.700\n",
      "\n",
      "Test set: Average loss: 1.3324 \n",
      "Accuracy: 6050/10000 (60.50%)\n",
      "\n",
      "Round  30, Train average loss 0.757 Test accuracy 60.500\n",
      "\n",
      "Test set: Average loss: 1.3878 \n",
      "Accuracy: 6048/10000 (60.48%)\n",
      "\n",
      "Round  31, Train average loss 0.707 Test accuracy 60.480\n",
      "\n",
      "Test set: Average loss: 1.3854 \n",
      "Accuracy: 6070/10000 (60.70%)\n",
      "\n",
      "Round  32, Train average loss 0.681 Test accuracy 60.700\n",
      "\n",
      "Test set: Average loss: 1.3062 \n",
      "Accuracy: 6111/10000 (61.11%)\n",
      "\n",
      "Round  33, Train average loss 0.754 Test accuracy 61.110\n",
      "\n",
      "Test set: Average loss: 1.3439 \n",
      "Accuracy: 6141/10000 (61.41%)\n",
      "\n",
      "Round  34, Train average loss 0.691 Test accuracy 61.410\n",
      "\n",
      "Test set: Average loss: 1.3154 \n",
      "Accuracy: 6196/10000 (61.96%)\n",
      "\n",
      "Round  35, Train average loss 0.714 Test accuracy 61.960\n",
      "\n",
      "Test set: Average loss: 1.3780 \n",
      "Accuracy: 6196/10000 (61.96%)\n",
      "\n",
      "Round  36, Train average loss 0.666 Test accuracy 61.960\n",
      "\n",
      "Test set: Average loss: 1.3297 \n",
      "Accuracy: 6198/10000 (61.98%)\n",
      "\n",
      "Round  37, Train average loss 0.694 Test accuracy 61.980\n",
      "\n",
      "Test set: Average loss: 1.3896 \n",
      "Accuracy: 6163/10000 (61.63%)\n",
      "\n",
      "Round  38, Train average loss 0.649 Test accuracy 61.630\n",
      "\n",
      "Test set: Average loss: 1.3831 \n",
      "Accuracy: 6218/10000 (62.18%)\n",
      "\n",
      "Round  39, Train average loss 0.630 Test accuracy 62.180\n",
      "\n",
      "Test set: Average loss: 1.3830 \n",
      "Accuracy: 6180/10000 (61.80%)\n",
      "\n",
      "Round  40, Train average loss 0.635 Test accuracy 61.800\n",
      "\n",
      "Test set: Average loss: 1.3828 \n",
      "Accuracy: 6240/10000 (62.40%)\n",
      "\n",
      "Round  41, Train average loss 0.630 Test accuracy 62.400\n",
      "\n",
      "Test set: Average loss: 1.3602 \n",
      "Accuracy: 6225/10000 (62.25%)\n",
      "\n",
      "Round  42, Train average loss 0.633 Test accuracy 62.250\n",
      "\n",
      "Test set: Average loss: 1.3714 \n",
      "Accuracy: 6244/10000 (62.44%)\n",
      "\n",
      "Round  43, Train average loss 0.616 Test accuracy 62.440\n",
      "\n",
      "Test set: Average loss: 1.3589 \n",
      "Accuracy: 6294/10000 (62.94%)\n",
      "\n",
      "Round  44, Train average loss 0.616 Test accuracy 62.940\n",
      "\n",
      "Test set: Average loss: 1.3790 \n",
      "Accuracy: 6270/10000 (62.70%)\n",
      "\n",
      "Round  45, Train average loss 0.588 Test accuracy 62.700\n",
      "\n",
      "Test set: Average loss: 1.3625 \n",
      "Accuracy: 6272/10000 (62.72%)\n",
      "\n",
      "Round  46, Train average loss 0.590 Test accuracy 62.720\n",
      "\n",
      "Test set: Average loss: 1.3449 \n",
      "Accuracy: 6309/10000 (63.09%)\n",
      "\n",
      "Round  47, Train average loss 0.626 Test accuracy 63.090\n",
      "\n",
      "Test set: Average loss: 1.3646 \n",
      "Accuracy: 6362/10000 (63.62%)\n",
      "\n",
      "Round  48, Train average loss 0.576 Test accuracy 63.620\n",
      "\n",
      "Test set: Average loss: 1.4287 \n",
      "Accuracy: 6308/10000 (63.08%)\n",
      "\n",
      "Round  49, Train average loss 0.537 Test accuracy 63.080\n"
     ]
    }
   ],
   "source": [
    "net_glob.train()\n",
    "\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()\n",
    "\n",
    "# training\n",
    "loss_train = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "cv_loss, cv_acc = [], []\n",
    "val_loss_pre, counter = 0, 0\n",
    "net_best = None\n",
    "best_loss = None\n",
    "val_acc_list, net_list = [], []\n",
    "\n",
    "for iter in range(50): #args.epochs\n",
    "    w_locals, loss_locals = [], []\n",
    "    m = 10\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    for idx in idxs_users:\n",
    "#         print(idx)\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    \n",
    "    loss_train.append(loss_avg)\n",
    "    \n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "    acc_test_arr.append(acc_test)\n",
    "    loss_test_arr.append(loss_test)\n",
    "    if iter % 1 ==0:\n",
    "        print('Round {:3d}, Train average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "    #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3389 \n",
      "Accuracy: 6364/10000 (63.64%)\n",
      "\n",
      "Round  50, Train average loss 0.614 Test accuracy 63.640\n",
      "\n",
      "Test set: Average loss: 1.3756 \n",
      "Accuracy: 6392/10000 (63.92%)\n",
      "\n",
      "Round  51, Train average loss 0.570 Test accuracy 63.920\n",
      "\n",
      "Test set: Average loss: 1.3593 \n",
      "Accuracy: 6405/10000 (64.05%)\n",
      "\n",
      "Round  52, Train average loss 0.557 Test accuracy 64.050\n",
      "\n",
      "Test set: Average loss: 1.3700 \n",
      "Accuracy: 6436/10000 (64.36%)\n",
      "\n",
      "Round  53, Train average loss 0.568 Test accuracy 64.360\n",
      "\n",
      "Test set: Average loss: 1.3663 \n",
      "Accuracy: 6379/10000 (63.79%)\n",
      "\n",
      "Round  54, Train average loss 0.558 Test accuracy 63.790\n",
      "\n",
      "Test set: Average loss: 1.2891 \n",
      "Accuracy: 6459/10000 (64.59%)\n",
      "\n",
      "Round  55, Train average loss 0.604 Test accuracy 64.590\n",
      "\n",
      "Test set: Average loss: 1.4076 \n",
      "Accuracy: 6462/10000 (64.62%)\n",
      "\n",
      "Round  56, Train average loss 0.493 Test accuracy 64.620\n",
      "\n",
      "Test set: Average loss: 1.3044 \n",
      "Accuracy: 6471/10000 (64.71%)\n",
      "\n",
      "Round  57, Train average loss 0.579 Test accuracy 64.710\n",
      "\n",
      "Test set: Average loss: 1.3466 \n",
      "Accuracy: 6477/10000 (64.77%)\n",
      "\n",
      "Round  58, Train average loss 0.529 Test accuracy 64.770\n",
      "\n",
      "Test set: Average loss: 1.3600 \n",
      "Accuracy: 6499/10000 (64.99%)\n",
      "\n",
      "Round  59, Train average loss 0.523 Test accuracy 64.990\n",
      "\n",
      "Test set: Average loss: 1.3817 \n",
      "Accuracy: 6488/10000 (64.88%)\n",
      "\n",
      "Round  60, Train average loss 0.516 Test accuracy 64.880\n",
      "\n",
      "Test set: Average loss: 1.4114 \n",
      "Accuracy: 6516/10000 (65.16%)\n",
      "\n",
      "Round  61, Train average loss 0.485 Test accuracy 65.160\n",
      "\n",
      "Test set: Average loss: 1.3706 \n",
      "Accuracy: 6511/10000 (65.11%)\n",
      "\n",
      "Round  62, Train average loss 0.502 Test accuracy 65.110\n",
      "\n",
      "Test set: Average loss: 1.3619 \n",
      "Accuracy: 6496/10000 (64.96%)\n",
      "\n",
      "Round  63, Train average loss 0.511 Test accuracy 64.960\n",
      "\n",
      "Test set: Average loss: 1.3692 \n",
      "Accuracy: 6519/10000 (65.19%)\n",
      "\n",
      "Round  64, Train average loss 0.501 Test accuracy 65.190\n",
      "\n",
      "Test set: Average loss: 1.3172 \n",
      "Accuracy: 6598/10000 (65.98%)\n",
      "\n",
      "Round  65, Train average loss 0.535 Test accuracy 65.980\n",
      "\n",
      "Test set: Average loss: 1.3528 \n",
      "Accuracy: 6566/10000 (65.66%)\n",
      "\n",
      "Round  66, Train average loss 0.479 Test accuracy 65.660\n",
      "\n",
      "Test set: Average loss: 1.3254 \n",
      "Accuracy: 6531/10000 (65.31%)\n",
      "\n",
      "Round  67, Train average loss 0.505 Test accuracy 65.310\n",
      "\n",
      "Test set: Average loss: 1.2923 \n",
      "Accuracy: 6597/10000 (65.97%)\n",
      "\n",
      "Round  68, Train average loss 0.525 Test accuracy 65.970\n",
      "\n",
      "Test set: Average loss: 1.3133 \n",
      "Accuracy: 6590/10000 (65.90%)\n",
      "\n",
      "Round  69, Train average loss 0.507 Test accuracy 65.900\n",
      "\n",
      "Test set: Average loss: 1.3278 \n",
      "Accuracy: 6558/10000 (65.58%)\n",
      "\n",
      "Round  70, Train average loss 0.501 Test accuracy 65.580\n",
      "\n",
      "Test set: Average loss: 1.3440 \n",
      "Accuracy: 6575/10000 (65.75%)\n",
      "\n",
      "Round  71, Train average loss 0.477 Test accuracy 65.750\n",
      "\n",
      "Test set: Average loss: 1.3686 \n",
      "Accuracy: 6596/10000 (65.96%)\n",
      "\n",
      "Round  72, Train average loss 0.460 Test accuracy 65.960\n",
      "\n",
      "Test set: Average loss: 1.3247 \n",
      "Accuracy: 6582/10000 (65.82%)\n",
      "\n",
      "Round  73, Train average loss 0.485 Test accuracy 65.820\n",
      "\n",
      "Test set: Average loss: 1.3159 \n",
      "Accuracy: 6603/10000 (66.03%)\n",
      "\n",
      "Round  74, Train average loss 0.478 Test accuracy 66.030\n",
      "\n",
      "Test set: Average loss: 1.3989 \n",
      "Accuracy: 6618/10000 (66.18%)\n",
      "\n",
      "Round  75, Train average loss 0.420 Test accuracy 66.180\n",
      "\n",
      "Test set: Average loss: 1.2941 \n",
      "Accuracy: 6662/10000 (66.62%)\n",
      "\n",
      "Round  76, Train average loss 0.494 Test accuracy 66.620\n",
      "\n",
      "Test set: Average loss: 1.3800 \n",
      "Accuracy: 6656/10000 (66.56%)\n",
      "\n",
      "Round  77, Train average loss 0.408 Test accuracy 66.560\n",
      "\n",
      "Test set: Average loss: 1.3017 \n",
      "Accuracy: 6650/10000 (66.50%)\n",
      "\n",
      "Round  78, Train average loss 0.469 Test accuracy 66.500\n",
      "\n",
      "Test set: Average loss: 1.3227 \n",
      "Accuracy: 6650/10000 (66.50%)\n",
      "\n",
      "Round  79, Train average loss 0.454 Test accuracy 66.500\n",
      "\n",
      "Test set: Average loss: 1.3533 \n",
      "Accuracy: 6668/10000 (66.68%)\n",
      "\n",
      "Round  80, Train average loss 0.421 Test accuracy 66.680\n",
      "\n",
      "Test set: Average loss: 1.3464 \n",
      "Accuracy: 6672/10000 (66.72%)\n",
      "\n",
      "Round  81, Train average loss 0.426 Test accuracy 66.720\n",
      "\n",
      "Test set: Average loss: 1.3337 \n",
      "Accuracy: 6700/10000 (67.00%)\n",
      "\n",
      "Round  82, Train average loss 0.425 Test accuracy 67.000\n",
      "\n",
      "Test set: Average loss: 1.3573 \n",
      "Accuracy: 6714/10000 (67.14%)\n",
      "\n",
      "Round  83, Train average loss 0.416 Test accuracy 67.140\n",
      "\n",
      "Test set: Average loss: 1.3178 \n",
      "Accuracy: 6717/10000 (67.17%)\n",
      "\n",
      "Round  84, Train average loss 0.424 Test accuracy 67.170\n",
      "\n",
      "Test set: Average loss: 1.3223 \n",
      "Accuracy: 6707/10000 (67.07%)\n",
      "\n",
      "Round  85, Train average loss 0.433 Test accuracy 67.070\n",
      "\n",
      "Test set: Average loss: 1.3142 \n",
      "Accuracy: 6700/10000 (67.00%)\n",
      "\n",
      "Round  86, Train average loss 0.432 Test accuracy 67.000\n",
      "\n",
      "Test set: Average loss: 1.2989 \n",
      "Accuracy: 6711/10000 (67.11%)\n",
      "\n",
      "Round  87, Train average loss 0.422 Test accuracy 67.110\n",
      "\n",
      "Test set: Average loss: 1.3430 \n",
      "Accuracy: 6723/10000 (67.23%)\n",
      "\n",
      "Round  88, Train average loss 0.395 Test accuracy 67.230\n",
      "\n",
      "Test set: Average loss: 1.2820 \n",
      "Accuracy: 6780/10000 (67.80%)\n",
      "\n",
      "Round  89, Train average loss 0.435 Test accuracy 67.800\n",
      "\n",
      "Test set: Average loss: 1.3068 \n",
      "Accuracy: 6736/10000 (67.36%)\n",
      "\n",
      "Round  90, Train average loss 0.430 Test accuracy 67.360\n",
      "\n",
      "Test set: Average loss: 1.3305 \n",
      "Accuracy: 6717/10000 (67.17%)\n",
      "\n",
      "Round  91, Train average loss 0.404 Test accuracy 67.170\n",
      "\n",
      "Test set: Average loss: 1.3779 \n",
      "Accuracy: 6758/10000 (67.58%)\n",
      "\n",
      "Round  92, Train average loss 0.369 Test accuracy 67.580\n",
      "\n",
      "Test set: Average loss: 1.3111 \n",
      "Accuracy: 6756/10000 (67.56%)\n",
      "\n",
      "Round  93, Train average loss 0.396 Test accuracy 67.560\n",
      "\n",
      "Test set: Average loss: 1.3206 \n",
      "Accuracy: 6755/10000 (67.55%)\n",
      "\n",
      "Round  94, Train average loss 0.397 Test accuracy 67.550\n",
      "\n",
      "Test set: Average loss: 1.2721 \n",
      "Accuracy: 6790/10000 (67.90%)\n",
      "\n",
      "Round  95, Train average loss 0.427 Test accuracy 67.900\n",
      "\n",
      "Test set: Average loss: 1.3278 \n",
      "Accuracy: 6786/10000 (67.86%)\n",
      "\n",
      "Round  96, Train average loss 0.378 Test accuracy 67.860\n",
      "\n",
      "Test set: Average loss: 1.3219 \n",
      "Accuracy: 6788/10000 (67.88%)\n",
      "\n",
      "Round  97, Train average loss 0.389 Test accuracy 67.880\n",
      "\n",
      "Test set: Average loss: 1.3579 \n",
      "Accuracy: 6750/10000 (67.50%)\n",
      "\n",
      "Round  98, Train average loss 0.358 Test accuracy 67.500\n",
      "\n",
      "Test set: Average loss: 1.2934 \n",
      "Accuracy: 6762/10000 (67.62%)\n",
      "\n",
      "Round  99, Train average loss 0.406 Test accuracy 67.620\n",
      "\n",
      "Test set: Average loss: 1.3494 \n",
      "Accuracy: 6779/10000 (67.79%)\n",
      "\n",
      "Round 100, Train average loss 0.365 Test accuracy 67.790\n",
      "\n",
      "Test set: Average loss: 1.2721 \n",
      "Accuracy: 6771/10000 (67.71%)\n",
      "\n",
      "Round 101, Train average loss 0.418 Test accuracy 67.710\n",
      "\n",
      "Test set: Average loss: 1.2992 \n",
      "Accuracy: 6842/10000 (68.42%)\n",
      "\n",
      "Round 102, Train average loss 0.388 Test accuracy 68.420\n",
      "\n",
      "Test set: Average loss: 1.2840 \n",
      "Accuracy: 6802/10000 (68.02%)\n",
      "\n",
      "Round 103, Train average loss 0.385 Test accuracy 68.020\n",
      "\n",
      "Test set: Average loss: 1.3022 \n",
      "Accuracy: 6808/10000 (68.08%)\n",
      "\n",
      "Round 104, Train average loss 0.373 Test accuracy 68.080\n",
      "\n",
      "Test set: Average loss: 1.3115 \n",
      "Accuracy: 6808/10000 (68.08%)\n",
      "\n",
      "Round 105, Train average loss 0.365 Test accuracy 68.080\n",
      "\n",
      "Test set: Average loss: 1.3345 \n",
      "Accuracy: 6809/10000 (68.09%)\n",
      "\n",
      "Round 106, Train average loss 0.344 Test accuracy 68.090\n",
      "\n",
      "Test set: Average loss: 1.2843 \n",
      "Accuracy: 6820/10000 (68.20%)\n",
      "\n",
      "Round 107, Train average loss 0.376 Test accuracy 68.200\n",
      "\n",
      "Test set: Average loss: 1.2583 \n",
      "Accuracy: 6830/10000 (68.30%)\n",
      "\n",
      "Round 108, Train average loss 0.404 Test accuracy 68.300\n",
      "\n",
      "Test set: Average loss: 1.2804 \n",
      "Accuracy: 6825/10000 (68.25%)\n",
      "\n",
      "Round 109, Train average loss 0.387 Test accuracy 68.250\n",
      "\n",
      "Test set: Average loss: 1.3493 \n",
      "Accuracy: 6817/10000 (68.17%)\n",
      "\n",
      "Round 110, Train average loss 0.326 Test accuracy 68.170\n",
      "\n",
      "Test set: Average loss: 1.3178 \n",
      "Accuracy: 6823/10000 (68.23%)\n",
      "\n",
      "Round 111, Train average loss 0.353 Test accuracy 68.230\n",
      "\n",
      "Test set: Average loss: 1.2997 \n",
      "Accuracy: 6829/10000 (68.29%)\n",
      "\n",
      "Round 112, Train average loss 0.366 Test accuracy 68.290\n",
      "\n",
      "Test set: Average loss: 1.3187 \n",
      "Accuracy: 6879/10000 (68.79%)\n",
      "\n",
      "Round 113, Train average loss 0.344 Test accuracy 68.790\n",
      "\n",
      "Test set: Average loss: 1.2845 \n",
      "Accuracy: 6854/10000 (68.54%)\n",
      "\n",
      "Round 114, Train average loss 0.356 Test accuracy 68.540\n",
      "\n",
      "Test set: Average loss: 1.2677 \n",
      "Accuracy: 6833/10000 (68.33%)\n",
      "\n",
      "Round 115, Train average loss 0.372 Test accuracy 68.330\n",
      "\n",
      "Test set: Average loss: 1.3078 \n",
      "Accuracy: 6830/10000 (68.30%)\n",
      "\n",
      "Round 116, Train average loss 0.335 Test accuracy 68.300\n",
      "\n",
      "Test set: Average loss: 1.3469 \n",
      "Accuracy: 6803/10000 (68.03%)\n",
      "\n",
      "Round 117, Train average loss 0.319 Test accuracy 68.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3045 \n",
      "Accuracy: 6816/10000 (68.16%)\n",
      "\n",
      "Round 118, Train average loss 0.340 Test accuracy 68.160\n",
      "\n",
      "Test set: Average loss: 1.2964 \n",
      "Accuracy: 6851/10000 (68.51%)\n",
      "\n",
      "Round 119, Train average loss 0.354 Test accuracy 68.510\n",
      "\n",
      "Test set: Average loss: 1.2860 \n",
      "Accuracy: 6857/10000 (68.57%)\n",
      "\n",
      "Round 120, Train average loss 0.349 Test accuracy 68.570\n",
      "\n",
      "Test set: Average loss: 1.3749 \n",
      "Accuracy: 6857/10000 (68.57%)\n",
      "\n",
      "Round 121, Train average loss 0.279 Test accuracy 68.570\n",
      "\n",
      "Test set: Average loss: 1.3169 \n",
      "Accuracy: 6858/10000 (68.58%)\n",
      "\n",
      "Round 122, Train average loss 0.334 Test accuracy 68.580\n",
      "\n",
      "Test set: Average loss: 1.2975 \n",
      "Accuracy: 6892/10000 (68.92%)\n",
      "\n",
      "Round 123, Train average loss 0.328 Test accuracy 68.920\n",
      "\n",
      "Test set: Average loss: 1.3093 \n",
      "Accuracy: 6890/10000 (68.90%)\n",
      "\n",
      "Round 124, Train average loss 0.331 Test accuracy 68.900\n",
      "\n",
      "Test set: Average loss: 1.2568 \n",
      "Accuracy: 6880/10000 (68.80%)\n",
      "\n",
      "Round 125, Train average loss 0.374 Test accuracy 68.800\n",
      "\n",
      "Test set: Average loss: 1.2760 \n",
      "Accuracy: 6929/10000 (69.29%)\n",
      "\n",
      "Round 126, Train average loss 0.344 Test accuracy 69.290\n",
      "\n",
      "Test set: Average loss: 1.2306 \n",
      "Accuracy: 6908/10000 (69.08%)\n",
      "\n",
      "Round 127, Train average loss 0.369 Test accuracy 69.080\n",
      "\n",
      "Test set: Average loss: 1.3068 \n",
      "Accuracy: 6906/10000 (69.06%)\n",
      "\n",
      "Round 128, Train average loss 0.305 Test accuracy 69.060\n",
      "\n",
      "Test set: Average loss: 1.2787 \n",
      "Accuracy: 6888/10000 (68.88%)\n",
      "\n",
      "Round 129, Train average loss 0.327 Test accuracy 68.880\n",
      "\n",
      "Test set: Average loss: 1.2884 \n",
      "Accuracy: 6903/10000 (69.03%)\n",
      "\n",
      "Round 130, Train average loss 0.321 Test accuracy 69.030\n",
      "\n",
      "Test set: Average loss: 1.2446 \n",
      "Accuracy: 6946/10000 (69.46%)\n",
      "\n",
      "Round 131, Train average loss 0.354 Test accuracy 69.460\n",
      "\n",
      "Test set: Average loss: 1.2824 \n",
      "Accuracy: 6918/10000 (69.18%)\n",
      "\n",
      "Round 132, Train average loss 0.332 Test accuracy 69.180\n",
      "\n",
      "Test set: Average loss: 1.2997 \n",
      "Accuracy: 6968/10000 (69.68%)\n",
      "\n",
      "Round 133, Train average loss 0.311 Test accuracy 69.680\n",
      "\n",
      "Test set: Average loss: 1.2944 \n",
      "Accuracy: 6912/10000 (69.12%)\n",
      "\n",
      "Round 134, Train average loss 0.305 Test accuracy 69.120\n",
      "\n",
      "Test set: Average loss: 1.3200 \n",
      "Accuracy: 6931/10000 (69.31%)\n",
      "\n",
      "Round 135, Train average loss 0.291 Test accuracy 69.310\n",
      "\n",
      "Test set: Average loss: 1.2665 \n",
      "Accuracy: 6934/10000 (69.34%)\n",
      "\n",
      "Round 136, Train average loss 0.325 Test accuracy 69.340\n",
      "\n",
      "Test set: Average loss: 1.2967 \n",
      "Accuracy: 6935/10000 (69.35%)\n",
      "\n",
      "Round 137, Train average loss 0.304 Test accuracy 69.350\n",
      "\n",
      "Test set: Average loss: 1.3191 \n",
      "Accuracy: 6947/10000 (69.47%)\n",
      "\n",
      "Round 138, Train average loss 0.287 Test accuracy 69.470\n",
      "\n",
      "Test set: Average loss: 1.2984 \n",
      "Accuracy: 6942/10000 (69.42%)\n",
      "\n",
      "Round 139, Train average loss 0.306 Test accuracy 69.420\n",
      "\n",
      "Test set: Average loss: 1.2806 \n",
      "Accuracy: 6936/10000 (69.36%)\n",
      "\n",
      "Round 140, Train average loss 0.307 Test accuracy 69.360\n",
      "\n",
      "Test set: Average loss: 1.3478 \n",
      "Accuracy: 6918/10000 (69.18%)\n",
      "\n",
      "Round 141, Train average loss 0.266 Test accuracy 69.180\n",
      "\n",
      "Test set: Average loss: 1.2910 \n",
      "Accuracy: 6965/10000 (69.65%)\n",
      "\n",
      "Round 142, Train average loss 0.307 Test accuracy 69.650\n",
      "\n",
      "Test set: Average loss: 1.3061 \n",
      "Accuracy: 6940/10000 (69.40%)\n",
      "\n",
      "Round 143, Train average loss 0.287 Test accuracy 69.400\n",
      "\n",
      "Test set: Average loss: 1.2871 \n",
      "Accuracy: 6922/10000 (69.22%)\n",
      "\n",
      "Round 144, Train average loss 0.289 Test accuracy 69.220\n",
      "\n",
      "Test set: Average loss: 1.2762 \n",
      "Accuracy: 6946/10000 (69.46%)\n",
      "\n",
      "Round 145, Train average loss 0.317 Test accuracy 69.460\n",
      "\n",
      "Test set: Average loss: 1.3538 \n",
      "Accuracy: 6947/10000 (69.47%)\n",
      "\n",
      "Round 146, Train average loss 0.267 Test accuracy 69.470\n",
      "\n",
      "Test set: Average loss: 1.2957 \n",
      "Accuracy: 6969/10000 (69.69%)\n",
      "\n",
      "Round 147, Train average loss 0.287 Test accuracy 69.690\n",
      "\n",
      "Test set: Average loss: 1.2896 \n",
      "Accuracy: 6991/10000 (69.91%)\n",
      "\n",
      "Round 148, Train average loss 0.287 Test accuracy 69.910\n",
      "\n",
      "Test set: Average loss: 1.3028 \n",
      "Accuracy: 6976/10000 (69.76%)\n",
      "\n",
      "Round 149, Train average loss 0.269 Test accuracy 69.760\n",
      "\n",
      "Test set: Average loss: 1.2732 \n",
      "Accuracy: 6975/10000 (69.75%)\n",
      "\n",
      "Round 150, Train average loss 0.301 Test accuracy 69.750\n",
      "\n",
      "Test set: Average loss: 1.2570 \n",
      "Accuracy: 6990/10000 (69.90%)\n",
      "\n",
      "Round 151, Train average loss 0.310 Test accuracy 69.900\n",
      "\n",
      "Test set: Average loss: 1.2755 \n",
      "Accuracy: 6987/10000 (69.87%)\n",
      "\n",
      "Round 152, Train average loss 0.300 Test accuracy 69.870\n",
      "\n",
      "Test set: Average loss: 1.2916 \n",
      "Accuracy: 7010/10000 (70.10%)\n",
      "\n",
      "Round 153, Train average loss 0.282 Test accuracy 70.100\n",
      "\n",
      "Test set: Average loss: 1.2890 \n",
      "Accuracy: 6973/10000 (69.73%)\n",
      "\n",
      "Round 154, Train average loss 0.278 Test accuracy 69.730\n",
      "\n",
      "Test set: Average loss: 1.2735 \n",
      "Accuracy: 7015/10000 (70.15%)\n",
      "\n",
      "Round 155, Train average loss 0.277 Test accuracy 70.150\n",
      "\n",
      "Test set: Average loss: 1.2823 \n",
      "Accuracy: 7009/10000 (70.09%)\n",
      "\n",
      "Round 156, Train average loss 0.277 Test accuracy 70.090\n",
      "\n",
      "Test set: Average loss: 1.3035 \n",
      "Accuracy: 6975/10000 (69.75%)\n",
      "\n",
      "Round 157, Train average loss 0.264 Test accuracy 69.750\n",
      "\n",
      "Test set: Average loss: 1.2712 \n",
      "Accuracy: 6997/10000 (69.97%)\n",
      "\n",
      "Round 158, Train average loss 0.286 Test accuracy 69.970\n",
      "\n",
      "Test set: Average loss: 1.3145 \n",
      "Accuracy: 6988/10000 (69.88%)\n",
      "\n",
      "Round 159, Train average loss 0.256 Test accuracy 69.880\n",
      "\n",
      "Test set: Average loss: 1.2953 \n",
      "Accuracy: 6999/10000 (69.99%)\n",
      "\n",
      "Round 160, Train average loss 0.258 Test accuracy 69.990\n",
      "\n",
      "Test set: Average loss: 1.2924 \n",
      "Accuracy: 7010/10000 (70.10%)\n",
      "\n",
      "Round 161, Train average loss 0.262 Test accuracy 70.100\n",
      "\n",
      "Test set: Average loss: 1.2628 \n",
      "Accuracy: 6998/10000 (69.98%)\n",
      "\n",
      "Round 162, Train average loss 0.278 Test accuracy 69.980\n",
      "\n",
      "Test set: Average loss: 1.2700 \n",
      "Accuracy: 7041/10000 (70.41%)\n",
      "\n",
      "Round 163, Train average loss 0.277 Test accuracy 70.410\n",
      "\n",
      "Test set: Average loss: 1.2781 \n",
      "Accuracy: 7050/10000 (70.50%)\n",
      "\n",
      "Round 164, Train average loss 0.262 Test accuracy 70.500\n",
      "\n",
      "Test set: Average loss: 1.2821 \n",
      "Accuracy: 6990/10000 (69.90%)\n",
      "\n",
      "Round 165, Train average loss 0.265 Test accuracy 69.900\n",
      "\n",
      "Test set: Average loss: 1.2783 \n",
      "Accuracy: 7026/10000 (70.26%)\n",
      "\n",
      "Round 166, Train average loss 0.265 Test accuracy 70.260\n",
      "\n",
      "Test set: Average loss: 1.2898 \n",
      "Accuracy: 7000/10000 (70.00%)\n",
      "\n",
      "Round 167, Train average loss 0.256 Test accuracy 70.000\n",
      "\n",
      "Test set: Average loss: 1.3096 \n",
      "Accuracy: 6997/10000 (69.97%)\n",
      "\n",
      "Round 168, Train average loss 0.244 Test accuracy 69.970\n",
      "\n",
      "Test set: Average loss: 1.2653 \n",
      "Accuracy: 7019/10000 (70.19%)\n",
      "\n",
      "Round 169, Train average loss 0.278 Test accuracy 70.190\n",
      "\n",
      "Test set: Average loss: 1.2753 \n",
      "Accuracy: 7038/10000 (70.38%)\n",
      "\n",
      "Round 170, Train average loss 0.262 Test accuracy 70.380\n",
      "\n",
      "Test set: Average loss: 1.2814 \n",
      "Accuracy: 7007/10000 (70.07%)\n",
      "\n",
      "Round 171, Train average loss 0.249 Test accuracy 70.070\n",
      "\n",
      "Test set: Average loss: 1.2868 \n",
      "Accuracy: 7071/10000 (70.71%)\n",
      "\n",
      "Round 172, Train average loss 0.247 Test accuracy 70.710\n",
      "\n",
      "Test set: Average loss: 1.3028 \n",
      "Accuracy: 7031/10000 (70.31%)\n",
      "\n",
      "Round 173, Train average loss 0.238 Test accuracy 70.310\n",
      "\n",
      "Test set: Average loss: 1.3099 \n",
      "Accuracy: 7000/10000 (70.00%)\n",
      "\n",
      "Round 174, Train average loss 0.229 Test accuracy 70.000\n",
      "\n",
      "Test set: Average loss: 1.2892 \n",
      "Accuracy: 6997/10000 (69.97%)\n",
      "\n",
      "Round 175, Train average loss 0.245 Test accuracy 69.970\n",
      "\n",
      "Test set: Average loss: 1.3302 \n",
      "Accuracy: 7020/10000 (70.20%)\n",
      "\n",
      "Round 176, Train average loss 0.223 Test accuracy 70.200\n",
      "\n",
      "Test set: Average loss: 1.2569 \n",
      "Accuracy: 7058/10000 (70.58%)\n",
      "\n",
      "Round 177, Train average loss 0.262 Test accuracy 70.580\n",
      "\n",
      "Test set: Average loss: 1.3047 \n",
      "Accuracy: 7042/10000 (70.42%)\n",
      "\n",
      "Round 178, Train average loss 0.223 Test accuracy 70.420\n",
      "\n",
      "Test set: Average loss: 1.2923 \n",
      "Accuracy: 7036/10000 (70.36%)\n",
      "\n",
      "Round 179, Train average loss 0.237 Test accuracy 70.360\n",
      "\n",
      "Test set: Average loss: 1.2951 \n",
      "Accuracy: 7062/10000 (70.62%)\n",
      "\n",
      "Round 180, Train average loss 0.232 Test accuracy 70.620\n",
      "\n",
      "Test set: Average loss: 1.2869 \n",
      "Accuracy: 7040/10000 (70.40%)\n",
      "\n",
      "Round 181, Train average loss 0.237 Test accuracy 70.400\n",
      "\n",
      "Test set: Average loss: 1.3268 \n",
      "Accuracy: 7043/10000 (70.43%)\n",
      "\n",
      "Round 182, Train average loss 0.218 Test accuracy 70.430\n",
      "\n",
      "Test set: Average loss: 1.2765 \n",
      "Accuracy: 7031/10000 (70.31%)\n",
      "\n",
      "Round 183, Train average loss 0.251 Test accuracy 70.310\n",
      "\n",
      "Test set: Average loss: 1.2952 \n",
      "Accuracy: 7041/10000 (70.41%)\n",
      "\n",
      "Round 184, Train average loss 0.228 Test accuracy 70.410\n",
      "\n",
      "Test set: Average loss: 1.3073 \n",
      "Accuracy: 7027/10000 (70.27%)\n",
      "\n",
      "Round 185, Train average loss 0.221 Test accuracy 70.270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.2633 \n",
      "Accuracy: 7063/10000 (70.63%)\n",
      "\n",
      "Round 186, Train average loss 0.253 Test accuracy 70.630\n",
      "\n",
      "Test set: Average loss: 1.3077 \n",
      "Accuracy: 7076/10000 (70.76%)\n",
      "\n",
      "Round 187, Train average loss 0.221 Test accuracy 70.760\n",
      "\n",
      "Test set: Average loss: 1.3162 \n",
      "Accuracy: 7053/10000 (70.53%)\n",
      "\n",
      "Round 188, Train average loss 0.207 Test accuracy 70.530\n",
      "\n",
      "Test set: Average loss: 1.2954 \n",
      "Accuracy: 7068/10000 (70.68%)\n",
      "\n",
      "Round 189, Train average loss 0.228 Test accuracy 70.680\n",
      "\n",
      "Test set: Average loss: 1.3158 \n",
      "Accuracy: 7061/10000 (70.61%)\n",
      "\n",
      "Round 190, Train average loss 0.214 Test accuracy 70.610\n",
      "\n",
      "Test set: Average loss: 1.2737 \n",
      "Accuracy: 7067/10000 (70.67%)\n",
      "\n",
      "Round 191, Train average loss 0.241 Test accuracy 70.670\n",
      "\n",
      "Test set: Average loss: 1.2685 \n",
      "Accuracy: 7071/10000 (70.71%)\n",
      "\n",
      "Round 192, Train average loss 0.236 Test accuracy 70.710\n",
      "\n",
      "Test set: Average loss: 1.3232 \n",
      "Accuracy: 7078/10000 (70.78%)\n",
      "\n",
      "Round 193, Train average loss 0.203 Test accuracy 70.780\n",
      "\n",
      "Test set: Average loss: 1.3191 \n",
      "Accuracy: 7075/10000 (70.75%)\n",
      "\n",
      "Round 194, Train average loss 0.202 Test accuracy 70.750\n",
      "\n",
      "Test set: Average loss: 1.2656 \n",
      "Accuracy: 7080/10000 (70.80%)\n",
      "\n",
      "Round 195, Train average loss 0.238 Test accuracy 70.800\n",
      "\n",
      "Test set: Average loss: 1.3127 \n",
      "Accuracy: 7082/10000 (70.82%)\n",
      "\n",
      "Round 196, Train average loss 0.208 Test accuracy 70.820\n",
      "\n",
      "Test set: Average loss: 1.2872 \n",
      "Accuracy: 7068/10000 (70.68%)\n",
      "\n",
      "Round 197, Train average loss 0.213 Test accuracy 70.680\n",
      "\n",
      "Test set: Average loss: 1.2815 \n",
      "Accuracy: 7079/10000 (70.79%)\n",
      "\n",
      "Round 198, Train average loss 0.220 Test accuracy 70.790\n",
      "\n",
      "Test set: Average loss: 1.3379 \n",
      "Accuracy: 7091/10000 (70.91%)\n",
      "\n",
      "Round 199, Train average loss 0.186 Test accuracy 70.910\n"
     ]
    }
   ],
   "source": [
    "for iter in range(50,200): #args.epochs\n",
    "    w_locals, loss_locals = [], []\n",
    "    m = 10\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    for idx in idxs_users:\n",
    "#         print(idx)\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    \n",
    "    loss_train.append(loss_avg)\n",
    "    \n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "    acc_test_arr.append(acc_test)\n",
    "    loss_test_arr.append(loss_test)\n",
    "    if iter % 1 ==0:\n",
    "        print('Round {:3d}, Train average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "    #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3088 \n",
      "Accuracy: 7116/10000 (71.16%)\n",
      "\n",
      "Round 200, Train average loss 0.212 Test accuracy 71.160\n",
      "\n",
      "Test set: Average loss: 1.3023 \n",
      "Accuracy: 7119/10000 (71.19%)\n",
      "\n",
      "Round 201, Train average loss 0.204 Test accuracy 71.190\n",
      "\n",
      "Test set: Average loss: 1.2728 \n",
      "Accuracy: 7086/10000 (70.86%)\n",
      "\n",
      "Round 202, Train average loss 0.236 Test accuracy 70.860\n",
      "\n",
      "Test set: Average loss: 1.3167 \n",
      "Accuracy: 7088/10000 (70.88%)\n",
      "\n",
      "Round 203, Train average loss 0.197 Test accuracy 70.880\n",
      "\n",
      "Test set: Average loss: 1.2959 \n",
      "Accuracy: 7095/10000 (70.95%)\n",
      "\n",
      "Round 204, Train average loss 0.199 Test accuracy 70.950\n",
      "\n",
      "Test set: Average loss: 1.3104 \n",
      "Accuracy: 7069/10000 (70.69%)\n",
      "\n",
      "Round 205, Train average loss 0.203 Test accuracy 70.690\n",
      "\n",
      "Test set: Average loss: 1.2944 \n",
      "Accuracy: 7110/10000 (71.10%)\n",
      "\n",
      "Round 206, Train average loss 0.202 Test accuracy 71.100\n",
      "\n",
      "Test set: Average loss: 1.2725 \n",
      "Accuracy: 7100/10000 (71.00%)\n",
      "\n",
      "Round 207, Train average loss 0.227 Test accuracy 71.000\n",
      "\n",
      "Test set: Average loss: 1.3074 \n",
      "Accuracy: 7132/10000 (71.32%)\n",
      "\n",
      "Round 208, Train average loss 0.201 Test accuracy 71.320\n",
      "\n",
      "Test set: Average loss: 1.2961 \n",
      "Accuracy: 7127/10000 (71.27%)\n",
      "\n",
      "Round 209, Train average loss 0.206 Test accuracy 71.270\n",
      "\n",
      "Test set: Average loss: 1.2914 \n",
      "Accuracy: 7124/10000 (71.24%)\n",
      "\n",
      "Round 210, Train average loss 0.207 Test accuracy 71.240\n",
      "\n",
      "Test set: Average loss: 1.3126 \n",
      "Accuracy: 7118/10000 (71.18%)\n",
      "\n",
      "Round 211, Train average loss 0.197 Test accuracy 71.180\n",
      "\n",
      "Test set: Average loss: 1.2729 \n",
      "Accuracy: 7088/10000 (70.88%)\n",
      "\n",
      "Round 212, Train average loss 0.214 Test accuracy 70.880\n",
      "\n",
      "Test set: Average loss: 1.3112 \n",
      "Accuracy: 7105/10000 (71.05%)\n",
      "\n",
      "Round 213, Train average loss 0.190 Test accuracy 71.050\n",
      "\n",
      "Test set: Average loss: 1.2744 \n",
      "Accuracy: 7120/10000 (71.20%)\n",
      "\n",
      "Round 214, Train average loss 0.205 Test accuracy 71.200\n",
      "\n",
      "Test set: Average loss: 1.2832 \n",
      "Accuracy: 7111/10000 (71.11%)\n",
      "\n",
      "Round 215, Train average loss 0.202 Test accuracy 71.110\n",
      "\n",
      "Test set: Average loss: 1.3286 \n",
      "Accuracy: 7136/10000 (71.36%)\n",
      "\n",
      "Round 216, Train average loss 0.179 Test accuracy 71.360\n",
      "\n",
      "Test set: Average loss: 1.3094 \n",
      "Accuracy: 7098/10000 (70.98%)\n",
      "\n",
      "Round 217, Train average loss 0.183 Test accuracy 70.980\n",
      "\n",
      "Test set: Average loss: 1.3075 \n",
      "Accuracy: 7076/10000 (70.76%)\n",
      "\n",
      "Round 218, Train average loss 0.196 Test accuracy 70.760\n",
      "\n",
      "Test set: Average loss: 1.2684 \n",
      "Accuracy: 7113/10000 (71.13%)\n",
      "\n",
      "Round 219, Train average loss 0.208 Test accuracy 71.130\n",
      "\n",
      "Test set: Average loss: 1.2758 \n",
      "Accuracy: 7126/10000 (71.26%)\n",
      "\n",
      "Round 220, Train average loss 0.220 Test accuracy 71.260\n",
      "\n",
      "Test set: Average loss: 1.3137 \n",
      "Accuracy: 7138/10000 (71.38%)\n",
      "\n",
      "Round 221, Train average loss 0.182 Test accuracy 71.380\n",
      "\n",
      "Test set: Average loss: 1.3507 \n",
      "Accuracy: 7105/10000 (71.05%)\n",
      "\n",
      "Round 222, Train average loss 0.165 Test accuracy 71.050\n",
      "\n",
      "Test set: Average loss: 1.2754 \n",
      "Accuracy: 7110/10000 (71.10%)\n",
      "\n",
      "Round 223, Train average loss 0.204 Test accuracy 71.100\n",
      "\n",
      "Test set: Average loss: 1.2919 \n",
      "Accuracy: 7102/10000 (71.02%)\n",
      "\n",
      "Round 224, Train average loss 0.204 Test accuracy 71.020\n",
      "\n",
      "Test set: Average loss: 1.2759 \n",
      "Accuracy: 7146/10000 (71.46%)\n",
      "\n",
      "Round 225, Train average loss 0.208 Test accuracy 71.460\n",
      "\n",
      "Test set: Average loss: 1.2964 \n",
      "Accuracy: 7119/10000 (71.19%)\n",
      "\n",
      "Round 226, Train average loss 0.188 Test accuracy 71.190\n",
      "\n",
      "Test set: Average loss: 1.3310 \n",
      "Accuracy: 7133/10000 (71.33%)\n",
      "\n",
      "Round 227, Train average loss 0.169 Test accuracy 71.330\n",
      "\n",
      "Test set: Average loss: 1.3342 \n",
      "Accuracy: 7122/10000 (71.22%)\n",
      "\n",
      "Round 228, Train average loss 0.165 Test accuracy 71.220\n",
      "\n",
      "Test set: Average loss: 1.3474 \n",
      "Accuracy: 7134/10000 (71.34%)\n",
      "\n",
      "Round 229, Train average loss 0.168 Test accuracy 71.340\n",
      "\n",
      "Test set: Average loss: 1.3388 \n",
      "Accuracy: 7134/10000 (71.34%)\n",
      "\n",
      "Round 230, Train average loss 0.171 Test accuracy 71.340\n",
      "\n",
      "Test set: Average loss: 1.3124 \n",
      "Accuracy: 7148/10000 (71.48%)\n",
      "\n",
      "Round 231, Train average loss 0.189 Test accuracy 71.480\n",
      "\n",
      "Test set: Average loss: 1.3055 \n",
      "Accuracy: 7123/10000 (71.23%)\n",
      "\n",
      "Round 232, Train average loss 0.187 Test accuracy 71.230\n",
      "\n",
      "Test set: Average loss: 1.3041 \n",
      "Accuracy: 7102/10000 (71.02%)\n",
      "\n",
      "Round 233, Train average loss 0.190 Test accuracy 71.020\n",
      "\n",
      "Test set: Average loss: 1.2925 \n",
      "Accuracy: 7105/10000 (71.05%)\n",
      "\n",
      "Round 234, Train average loss 0.185 Test accuracy 71.050\n",
      "\n",
      "Test set: Average loss: 1.2954 \n",
      "Accuracy: 7137/10000 (71.37%)\n",
      "\n",
      "Round 235, Train average loss 0.191 Test accuracy 71.370\n",
      "\n",
      "Test set: Average loss: 1.3173 \n",
      "Accuracy: 7130/10000 (71.30%)\n",
      "\n",
      "Round 236, Train average loss 0.169 Test accuracy 71.300\n",
      "\n",
      "Test set: Average loss: 1.3136 \n",
      "Accuracy: 7132/10000 (71.32%)\n",
      "\n",
      "Round 237, Train average loss 0.183 Test accuracy 71.320\n",
      "\n",
      "Test set: Average loss: 1.3044 \n",
      "Accuracy: 7115/10000 (71.15%)\n",
      "\n",
      "Round 238, Train average loss 0.183 Test accuracy 71.150\n",
      "\n",
      "Test set: Average loss: 1.3264 \n",
      "Accuracy: 7129/10000 (71.29%)\n",
      "\n",
      "Round 239, Train average loss 0.172 Test accuracy 71.290\n",
      "\n",
      "Test set: Average loss: 1.2701 \n",
      "Accuracy: 7140/10000 (71.40%)\n",
      "\n",
      "Round 240, Train average loss 0.199 Test accuracy 71.400\n",
      "\n",
      "Test set: Average loss: 1.2713 \n",
      "Accuracy: 7143/10000 (71.43%)\n",
      "\n",
      "Round 241, Train average loss 0.192 Test accuracy 71.430\n",
      "\n",
      "Test set: Average loss: 1.2935 \n",
      "Accuracy: 7170/10000 (71.70%)\n",
      "\n",
      "Round 242, Train average loss 0.177 Test accuracy 71.700\n",
      "\n",
      "Test set: Average loss: 1.3225 \n",
      "Accuracy: 7116/10000 (71.16%)\n",
      "\n",
      "Round 243, Train average loss 0.161 Test accuracy 71.160\n",
      "\n",
      "Test set: Average loss: 1.2560 \n",
      "Accuracy: 7140/10000 (71.40%)\n",
      "\n",
      "Round 244, Train average loss 0.197 Test accuracy 71.400\n",
      "\n",
      "Test set: Average loss: 1.2998 \n",
      "Accuracy: 7145/10000 (71.45%)\n",
      "\n",
      "Round 245, Train average loss 0.177 Test accuracy 71.450\n",
      "\n",
      "Test set: Average loss: 1.3275 \n",
      "Accuracy: 7132/10000 (71.32%)\n",
      "\n",
      "Round 246, Train average loss 0.166 Test accuracy 71.320\n",
      "\n",
      "Test set: Average loss: 1.3048 \n",
      "Accuracy: 7161/10000 (71.61%)\n",
      "\n",
      "Round 247, Train average loss 0.167 Test accuracy 71.610\n",
      "\n",
      "Test set: Average loss: 1.3010 \n",
      "Accuracy: 7132/10000 (71.32%)\n",
      "\n",
      "Round 248, Train average loss 0.173 Test accuracy 71.320\n",
      "\n",
      "Test set: Average loss: 1.2956 \n",
      "Accuracy: 7153/10000 (71.53%)\n",
      "\n",
      "Round 249, Train average loss 0.185 Test accuracy 71.530\n",
      "\n",
      "Test set: Average loss: 1.3105 \n",
      "Accuracy: 7159/10000 (71.59%)\n",
      "\n",
      "Round 250, Train average loss 0.159 Test accuracy 71.590\n",
      "\n",
      "Test set: Average loss: 1.3123 \n",
      "Accuracy: 7159/10000 (71.59%)\n",
      "\n",
      "Round 251, Train average loss 0.162 Test accuracy 71.590\n",
      "\n",
      "Test set: Average loss: 1.3172 \n",
      "Accuracy: 7152/10000 (71.52%)\n",
      "\n",
      "Round 252, Train average loss 0.167 Test accuracy 71.520\n",
      "\n",
      "Test set: Average loss: 1.2964 \n",
      "Accuracy: 7117/10000 (71.17%)\n",
      "\n",
      "Round 253, Train average loss 0.182 Test accuracy 71.170\n",
      "\n",
      "Test set: Average loss: 1.3132 \n",
      "Accuracy: 7151/10000 (71.51%)\n",
      "\n",
      "Round 254, Train average loss 0.161 Test accuracy 71.510\n",
      "\n",
      "Test set: Average loss: 1.2949 \n",
      "Accuracy: 7139/10000 (71.39%)\n",
      "\n",
      "Round 255, Train average loss 0.178 Test accuracy 71.390\n",
      "\n",
      "Test set: Average loss: 1.3030 \n",
      "Accuracy: 7148/10000 (71.48%)\n",
      "\n",
      "Round 256, Train average loss 0.164 Test accuracy 71.480\n",
      "\n",
      "Test set: Average loss: 1.2822 \n",
      "Accuracy: 7144/10000 (71.44%)\n",
      "\n",
      "Round 257, Train average loss 0.183 Test accuracy 71.440\n",
      "\n",
      "Test set: Average loss: 1.3109 \n",
      "Accuracy: 7147/10000 (71.47%)\n",
      "\n",
      "Round 258, Train average loss 0.159 Test accuracy 71.470\n",
      "\n",
      "Test set: Average loss: 1.2815 \n",
      "Accuracy: 7183/10000 (71.83%)\n",
      "\n",
      "Round 259, Train average loss 0.177 Test accuracy 71.830\n",
      "\n",
      "Test set: Average loss: 1.3354 \n",
      "Accuracy: 7176/10000 (71.76%)\n",
      "\n",
      "Round 260, Train average loss 0.157 Test accuracy 71.760\n",
      "\n",
      "Test set: Average loss: 1.2706 \n",
      "Accuracy: 7180/10000 (71.80%)\n",
      "\n",
      "Round 261, Train average loss 0.191 Test accuracy 71.800\n",
      "\n",
      "Test set: Average loss: 1.2972 \n",
      "Accuracy: 7166/10000 (71.66%)\n",
      "\n",
      "Round 262, Train average loss 0.166 Test accuracy 71.660\n",
      "\n",
      "Test set: Average loss: 1.2983 \n",
      "Accuracy: 7172/10000 (71.72%)\n",
      "\n",
      "Round 263, Train average loss 0.160 Test accuracy 71.720\n",
      "\n",
      "Test set: Average loss: 1.3028 \n",
      "Accuracy: 7173/10000 (71.73%)\n",
      "\n",
      "Round 264, Train average loss 0.164 Test accuracy 71.730\n",
      "\n",
      "Test set: Average loss: 1.3049 \n",
      "Accuracy: 7180/10000 (71.80%)\n",
      "\n",
      "Round 265, Train average loss 0.159 Test accuracy 71.800\n",
      "\n",
      "Test set: Average loss: 1.3001 \n",
      "Accuracy: 7169/10000 (71.69%)\n",
      "\n",
      "Round 266, Train average loss 0.167 Test accuracy 71.690\n",
      "\n",
      "Test set: Average loss: 1.3388 \n",
      "Accuracy: 7139/10000 (71.39%)\n",
      "\n",
      "Round 267, Train average loss 0.143 Test accuracy 71.390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3274 \n",
      "Accuracy: 7127/10000 (71.27%)\n",
      "\n",
      "Round 268, Train average loss 0.155 Test accuracy 71.270\n",
      "\n",
      "Test set: Average loss: 1.3133 \n",
      "Accuracy: 7144/10000 (71.44%)\n",
      "\n",
      "Round 269, Train average loss 0.164 Test accuracy 71.440\n",
      "\n",
      "Test set: Average loss: 1.3466 \n",
      "Accuracy: 7168/10000 (71.68%)\n",
      "\n",
      "Round 270, Train average loss 0.143 Test accuracy 71.680\n",
      "\n",
      "Test set: Average loss: 1.3613 \n",
      "Accuracy: 7133/10000 (71.33%)\n",
      "\n",
      "Round 271, Train average loss 0.143 Test accuracy 71.330\n",
      "\n",
      "Test set: Average loss: 1.3576 \n",
      "Accuracy: 7105/10000 (71.05%)\n",
      "\n",
      "Round 272, Train average loss 0.139 Test accuracy 71.050\n",
      "\n",
      "Test set: Average loss: 1.2837 \n",
      "Accuracy: 7204/10000 (72.04%)\n",
      "\n",
      "Round 273, Train average loss 0.169 Test accuracy 72.040\n",
      "\n",
      "Test set: Average loss: 1.3434 \n",
      "Accuracy: 7152/10000 (71.52%)\n",
      "\n",
      "Round 274, Train average loss 0.142 Test accuracy 71.520\n",
      "\n",
      "Test set: Average loss: 1.3245 \n",
      "Accuracy: 7161/10000 (71.61%)\n",
      "\n",
      "Round 275, Train average loss 0.155 Test accuracy 71.610\n",
      "\n",
      "Test set: Average loss: 1.2842 \n",
      "Accuracy: 7184/10000 (71.84%)\n",
      "\n",
      "Round 276, Train average loss 0.174 Test accuracy 71.840\n",
      "\n",
      "Test set: Average loss: 1.3064 \n",
      "Accuracy: 7170/10000 (71.70%)\n",
      "\n",
      "Round 277, Train average loss 0.151 Test accuracy 71.700\n",
      "\n",
      "Test set: Average loss: 1.3174 \n",
      "Accuracy: 7196/10000 (71.96%)\n",
      "\n",
      "Round 278, Train average loss 0.146 Test accuracy 71.960\n",
      "\n",
      "Test set: Average loss: 1.3393 \n",
      "Accuracy: 7141/10000 (71.41%)\n",
      "\n",
      "Round 279, Train average loss 0.139 Test accuracy 71.410\n",
      "\n",
      "Test set: Average loss: 1.3265 \n",
      "Accuracy: 7152/10000 (71.52%)\n",
      "\n",
      "Round 280, Train average loss 0.148 Test accuracy 71.520\n",
      "\n",
      "Test set: Average loss: 1.3697 \n",
      "Accuracy: 7159/10000 (71.59%)\n",
      "\n",
      "Round 281, Train average loss 0.135 Test accuracy 71.590\n",
      "\n",
      "Test set: Average loss: 1.3210 \n",
      "Accuracy: 7162/10000 (71.62%)\n",
      "\n",
      "Round 282, Train average loss 0.146 Test accuracy 71.620\n",
      "\n",
      "Test set: Average loss: 1.3337 \n",
      "Accuracy: 7150/10000 (71.50%)\n",
      "\n",
      "Round 283, Train average loss 0.156 Test accuracy 71.500\n",
      "\n",
      "Test set: Average loss: 1.3120 \n",
      "Accuracy: 7174/10000 (71.74%)\n",
      "\n",
      "Round 284, Train average loss 0.156 Test accuracy 71.740\n",
      "\n",
      "Test set: Average loss: 1.3074 \n",
      "Accuracy: 7184/10000 (71.84%)\n",
      "\n",
      "Round 285, Train average loss 0.148 Test accuracy 71.840\n",
      "\n",
      "Test set: Average loss: 1.3740 \n",
      "Accuracy: 7161/10000 (71.61%)\n",
      "\n",
      "Round 286, Train average loss 0.125 Test accuracy 71.610\n",
      "\n",
      "Test set: Average loss: 1.3519 \n",
      "Accuracy: 7139/10000 (71.39%)\n",
      "\n",
      "Round 287, Train average loss 0.139 Test accuracy 71.390\n",
      "\n",
      "Test set: Average loss: 1.3547 \n",
      "Accuracy: 7141/10000 (71.41%)\n",
      "\n",
      "Round 288, Train average loss 0.141 Test accuracy 71.410\n",
      "\n",
      "Test set: Average loss: 1.3552 \n",
      "Accuracy: 7161/10000 (71.61%)\n",
      "\n",
      "Round 289, Train average loss 0.139 Test accuracy 71.610\n",
      "\n",
      "Test set: Average loss: 1.3648 \n",
      "Accuracy: 7129/10000 (71.29%)\n",
      "\n",
      "Round 290, Train average loss 0.137 Test accuracy 71.290\n",
      "\n",
      "Test set: Average loss: 1.3445 \n",
      "Accuracy: 7163/10000 (71.63%)\n",
      "\n",
      "Round 291, Train average loss 0.150 Test accuracy 71.630\n",
      "\n",
      "Test set: Average loss: 1.3712 \n",
      "Accuracy: 7146/10000 (71.46%)\n",
      "\n",
      "Round 292, Train average loss 0.133 Test accuracy 71.460\n",
      "\n",
      "Test set: Average loss: 1.3871 \n",
      "Accuracy: 7168/10000 (71.68%)\n",
      "\n",
      "Round 293, Train average loss 0.120 Test accuracy 71.680\n",
      "\n",
      "Test set: Average loss: 1.3414 \n",
      "Accuracy: 7154/10000 (71.54%)\n",
      "\n",
      "Round 294, Train average loss 0.147 Test accuracy 71.540\n",
      "\n",
      "Test set: Average loss: 1.3541 \n",
      "Accuracy: 7129/10000 (71.29%)\n",
      "\n",
      "Round 295, Train average loss 0.142 Test accuracy 71.290\n",
      "\n",
      "Test set: Average loss: 1.3731 \n",
      "Accuracy: 7108/10000 (71.08%)\n",
      "\n",
      "Round 296, Train average loss 0.126 Test accuracy 71.080\n",
      "\n",
      "Test set: Average loss: 1.3670 \n",
      "Accuracy: 7093/10000 (70.93%)\n",
      "\n",
      "Round 297, Train average loss 0.138 Test accuracy 70.930\n",
      "\n",
      "Test set: Average loss: 1.4034 \n",
      "Accuracy: 7108/10000 (71.08%)\n",
      "\n",
      "Round 298, Train average loss 0.117 Test accuracy 71.080\n",
      "\n",
      "Test set: Average loss: 1.3259 \n",
      "Accuracy: 7149/10000 (71.49%)\n",
      "\n",
      "Round 299, Train average loss 0.153 Test accuracy 71.490\n"
     ]
    }
   ],
   "source": [
    "for iter in range(200,300): #args.epochs\n",
    "    w_locals, loss_locals = [], []\n",
    "    m = 10\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    for idx in idxs_users:\n",
    "#         print(idx)\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    \n",
    "    loss_train.append(loss_avg)\n",
    "    \n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "    acc_test_arr.append(acc_test)\n",
    "    loss_test_arr.append(loss_test)\n",
    "    if iter % 1 ==0:\n",
    "        print('Round {:3d}, Train average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "    #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3627 \n",
      "Accuracy: 7150/10000 (71.50%)\n",
      "\n",
      "Round 300, Train average loss 0.133 Test accuracy 71.500\n",
      "\n",
      "Test set: Average loss: 1.3454 \n",
      "Accuracy: 7145/10000 (71.45%)\n",
      "\n",
      "Round 301, Train average loss 0.143 Test accuracy 71.450\n",
      "\n",
      "Test set: Average loss: 1.3609 \n",
      "Accuracy: 7142/10000 (71.42%)\n",
      "\n",
      "Round 302, Train average loss 0.143 Test accuracy 71.420\n",
      "\n",
      "Test set: Average loss: 1.3654 \n",
      "Accuracy: 7111/10000 (71.11%)\n",
      "\n",
      "Round 303, Train average loss 0.134 Test accuracy 71.110\n",
      "\n",
      "Test set: Average loss: 1.3542 \n",
      "Accuracy: 7104/10000 (71.04%)\n",
      "\n",
      "Round 304, Train average loss 0.136 Test accuracy 71.040\n",
      "\n",
      "Test set: Average loss: 1.3807 \n",
      "Accuracy: 7132/10000 (71.32%)\n",
      "\n",
      "Round 305, Train average loss 0.121 Test accuracy 71.320\n",
      "\n",
      "Test set: Average loss: 1.3899 \n",
      "Accuracy: 7108/10000 (71.08%)\n",
      "\n",
      "Round 306, Train average loss 0.121 Test accuracy 71.080\n",
      "\n",
      "Test set: Average loss: 1.3463 \n",
      "Accuracy: 7166/10000 (71.66%)\n",
      "\n",
      "Round 307, Train average loss 0.155 Test accuracy 71.660\n",
      "\n",
      "Test set: Average loss: 1.3406 \n",
      "Accuracy: 7177/10000 (71.77%)\n",
      "\n",
      "Round 308, Train average loss 0.149 Test accuracy 71.770\n",
      "\n",
      "Test set: Average loss: 1.3661 \n",
      "Accuracy: 7151/10000 (71.51%)\n",
      "\n",
      "Round 309, Train average loss 0.127 Test accuracy 71.510\n",
      "\n",
      "Test set: Average loss: 1.3587 \n",
      "Accuracy: 7125/10000 (71.25%)\n",
      "\n",
      "Round 310, Train average loss 0.139 Test accuracy 71.250\n",
      "\n",
      "Test set: Average loss: 1.3874 \n",
      "Accuracy: 7146/10000 (71.46%)\n",
      "\n",
      "Round 311, Train average loss 0.125 Test accuracy 71.460\n",
      "\n",
      "Test set: Average loss: 1.3693 \n",
      "Accuracy: 7140/10000 (71.40%)\n",
      "\n",
      "Round 312, Train average loss 0.127 Test accuracy 71.400\n",
      "\n",
      "Test set: Average loss: 1.3313 \n",
      "Accuracy: 7160/10000 (71.60%)\n",
      "\n",
      "Round 313, Train average loss 0.151 Test accuracy 71.600\n",
      "\n",
      "Test set: Average loss: 1.3386 \n",
      "Accuracy: 7147/10000 (71.47%)\n",
      "\n",
      "Round 314, Train average loss 0.149 Test accuracy 71.470\n",
      "\n",
      "Test set: Average loss: 1.3284 \n",
      "Accuracy: 7174/10000 (71.74%)\n",
      "\n",
      "Round 315, Train average loss 0.142 Test accuracy 71.740\n",
      "\n",
      "Test set: Average loss: 1.3279 \n",
      "Accuracy: 7180/10000 (71.80%)\n",
      "\n",
      "Round 316, Train average loss 0.147 Test accuracy 71.800\n",
      "\n",
      "Test set: Average loss: 1.3602 \n",
      "Accuracy: 7163/10000 (71.63%)\n",
      "\n",
      "Round 317, Train average loss 0.124 Test accuracy 71.630\n",
      "\n",
      "Test set: Average loss: 1.3204 \n",
      "Accuracy: 7175/10000 (71.75%)\n",
      "\n",
      "Round 318, Train average loss 0.143 Test accuracy 71.750\n",
      "\n",
      "Test set: Average loss: 1.3327 \n",
      "Accuracy: 7160/10000 (71.60%)\n",
      "\n",
      "Round 319, Train average loss 0.144 Test accuracy 71.600\n",
      "\n",
      "Test set: Average loss: 1.3466 \n",
      "Accuracy: 7192/10000 (71.92%)\n",
      "\n",
      "Round 320, Train average loss 0.132 Test accuracy 71.920\n",
      "\n",
      "Test set: Average loss: 1.3585 \n",
      "Accuracy: 7158/10000 (71.58%)\n",
      "\n",
      "Round 321, Train average loss 0.123 Test accuracy 71.580\n",
      "\n",
      "Test set: Average loss: 1.3540 \n",
      "Accuracy: 7174/10000 (71.74%)\n",
      "\n",
      "Round 322, Train average loss 0.132 Test accuracy 71.740\n",
      "\n",
      "Test set: Average loss: 1.3365 \n",
      "Accuracy: 7163/10000 (71.63%)\n",
      "\n",
      "Round 323, Train average loss 0.138 Test accuracy 71.630\n",
      "\n",
      "Test set: Average loss: 1.3663 \n",
      "Accuracy: 7175/10000 (71.75%)\n",
      "\n",
      "Round 324, Train average loss 0.131 Test accuracy 71.750\n",
      "\n",
      "Test set: Average loss: 1.3393 \n",
      "Accuracy: 7168/10000 (71.68%)\n",
      "\n",
      "Round 325, Train average loss 0.132 Test accuracy 71.680\n",
      "\n",
      "Test set: Average loss: 1.3361 \n",
      "Accuracy: 7189/10000 (71.89%)\n",
      "\n",
      "Round 326, Train average loss 0.136 Test accuracy 71.890\n",
      "\n",
      "Test set: Average loss: 1.3687 \n",
      "Accuracy: 7194/10000 (71.94%)\n",
      "\n",
      "Round 327, Train average loss 0.119 Test accuracy 71.940\n",
      "\n",
      "Test set: Average loss: 1.3299 \n",
      "Accuracy: 7186/10000 (71.86%)\n",
      "\n",
      "Round 328, Train average loss 0.137 Test accuracy 71.860\n",
      "\n",
      "Test set: Average loss: 1.3252 \n",
      "Accuracy: 7191/10000 (71.91%)\n",
      "\n",
      "Round 329, Train average loss 0.141 Test accuracy 71.910\n",
      "\n",
      "Test set: Average loss: 1.3327 \n",
      "Accuracy: 7190/10000 (71.90%)\n",
      "\n",
      "Round 330, Train average loss 0.128 Test accuracy 71.900\n",
      "\n",
      "Test set: Average loss: 1.3551 \n",
      "Accuracy: 7202/10000 (72.02%)\n",
      "\n",
      "Round 331, Train average loss 0.127 Test accuracy 72.020\n",
      "\n",
      "Test set: Average loss: 1.3460 \n",
      "Accuracy: 7202/10000 (72.02%)\n",
      "\n",
      "Round 332, Train average loss 0.122 Test accuracy 72.020\n",
      "\n",
      "Test set: Average loss: 1.3637 \n",
      "Accuracy: 7213/10000 (72.13%)\n",
      "\n",
      "Round 333, Train average loss 0.123 Test accuracy 72.130\n",
      "\n",
      "Test set: Average loss: 1.3553 \n",
      "Accuracy: 7216/10000 (72.16%)\n",
      "\n",
      "Round 334, Train average loss 0.124 Test accuracy 72.160\n",
      "\n",
      "Test set: Average loss: 1.3766 \n",
      "Accuracy: 7165/10000 (71.65%)\n",
      "\n",
      "Round 335, Train average loss 0.129 Test accuracy 71.650\n",
      "\n",
      "Test set: Average loss: 1.3869 \n",
      "Accuracy: 7174/10000 (71.74%)\n",
      "\n",
      "Round 336, Train average loss 0.116 Test accuracy 71.740\n",
      "\n",
      "Test set: Average loss: 1.3828 \n",
      "Accuracy: 7181/10000 (71.81%)\n",
      "\n",
      "Round 337, Train average loss 0.114 Test accuracy 71.810\n",
      "\n",
      "Test set: Average loss: 1.3685 \n",
      "Accuracy: 7202/10000 (72.02%)\n",
      "\n",
      "Round 338, Train average loss 0.131 Test accuracy 72.020\n",
      "\n",
      "Test set: Average loss: 1.3831 \n",
      "Accuracy: 7185/10000 (71.85%)\n",
      "\n",
      "Round 339, Train average loss 0.116 Test accuracy 71.850\n",
      "\n",
      "Test set: Average loss: 1.3307 \n",
      "Accuracy: 7203/10000 (72.03%)\n",
      "\n",
      "Round 340, Train average loss 0.140 Test accuracy 72.030\n",
      "\n",
      "Test set: Average loss: 1.3612 \n",
      "Accuracy: 7191/10000 (71.91%)\n",
      "\n",
      "Round 341, Train average loss 0.122 Test accuracy 71.910\n",
      "\n",
      "Test set: Average loss: 1.3348 \n",
      "Accuracy: 7184/10000 (71.84%)\n",
      "\n",
      "Round 342, Train average loss 0.140 Test accuracy 71.840\n",
      "\n",
      "Test set: Average loss: 1.3550 \n",
      "Accuracy: 7193/10000 (71.93%)\n",
      "\n",
      "Round 343, Train average loss 0.123 Test accuracy 71.930\n",
      "\n",
      "Test set: Average loss: 1.3552 \n",
      "Accuracy: 7165/10000 (71.65%)\n",
      "\n",
      "Round 344, Train average loss 0.127 Test accuracy 71.650\n",
      "\n",
      "Test set: Average loss: 1.3363 \n",
      "Accuracy: 7171/10000 (71.71%)\n",
      "\n",
      "Round 345, Train average loss 0.131 Test accuracy 71.710\n",
      "\n",
      "Test set: Average loss: 1.3711 \n",
      "Accuracy: 7177/10000 (71.77%)\n",
      "\n",
      "Round 346, Train average loss 0.112 Test accuracy 71.770\n",
      "\n",
      "Test set: Average loss: 1.3752 \n",
      "Accuracy: 7182/10000 (71.82%)\n",
      "\n",
      "Round 347, Train average loss 0.120 Test accuracy 71.820\n",
      "\n",
      "Test set: Average loss: 1.3383 \n",
      "Accuracy: 7210/10000 (72.10%)\n",
      "\n",
      "Round 348, Train average loss 0.132 Test accuracy 72.100\n",
      "\n",
      "Test set: Average loss: 1.3400 \n",
      "Accuracy: 7204/10000 (72.04%)\n",
      "\n",
      "Round 349, Train average loss 0.130 Test accuracy 72.040\n",
      "\n",
      "Test set: Average loss: 1.3698 \n",
      "Accuracy: 7216/10000 (72.16%)\n",
      "\n",
      "Round 350, Train average loss 0.114 Test accuracy 72.160\n",
      "\n",
      "Test set: Average loss: 1.3515 \n",
      "Accuracy: 7203/10000 (72.03%)\n",
      "\n",
      "Round 351, Train average loss 0.122 Test accuracy 72.030\n",
      "\n",
      "Test set: Average loss: 1.3806 \n",
      "Accuracy: 7217/10000 (72.17%)\n",
      "\n",
      "Round 352, Train average loss 0.111 Test accuracy 72.170\n",
      "\n",
      "Test set: Average loss: 1.3782 \n",
      "Accuracy: 7193/10000 (71.93%)\n",
      "\n",
      "Round 353, Train average loss 0.116 Test accuracy 71.930\n",
      "\n",
      "Test set: Average loss: 1.3585 \n",
      "Accuracy: 7199/10000 (71.99%)\n",
      "\n",
      "Round 354, Train average loss 0.126 Test accuracy 71.990\n",
      "\n",
      "Test set: Average loss: 1.3569 \n",
      "Accuracy: 7199/10000 (71.99%)\n",
      "\n",
      "Round 355, Train average loss 0.115 Test accuracy 71.990\n",
      "\n",
      "Test set: Average loss: 1.3750 \n",
      "Accuracy: 7162/10000 (71.62%)\n",
      "\n",
      "Round 356, Train average loss 0.106 Test accuracy 71.620\n",
      "\n",
      "Test set: Average loss: 1.3381 \n",
      "Accuracy: 7186/10000 (71.86%)\n",
      "\n",
      "Round 357, Train average loss 0.128 Test accuracy 71.860\n",
      "\n",
      "Test set: Average loss: 1.4029 \n",
      "Accuracy: 7180/10000 (71.80%)\n",
      "\n",
      "Round 358, Train average loss 0.100 Test accuracy 71.800\n",
      "\n",
      "Test set: Average loss: 1.3872 \n",
      "Accuracy: 7142/10000 (71.42%)\n",
      "\n",
      "Round 359, Train average loss 0.114 Test accuracy 71.420\n",
      "\n",
      "Test set: Average loss: 1.3755 \n",
      "Accuracy: 7193/10000 (71.93%)\n",
      "\n",
      "Round 360, Train average loss 0.117 Test accuracy 71.930\n",
      "\n",
      "Test set: Average loss: 1.3713 \n",
      "Accuracy: 7179/10000 (71.79%)\n",
      "\n",
      "Round 361, Train average loss 0.119 Test accuracy 71.790\n",
      "\n",
      "Test set: Average loss: 1.4019 \n",
      "Accuracy: 7207/10000 (72.07%)\n",
      "\n",
      "Round 362, Train average loss 0.105 Test accuracy 72.070\n",
      "\n",
      "Test set: Average loss: 1.3639 \n",
      "Accuracy: 7206/10000 (72.06%)\n",
      "\n",
      "Round 363, Train average loss 0.125 Test accuracy 72.060\n",
      "\n",
      "Test set: Average loss: 1.3751 \n",
      "Accuracy: 7216/10000 (72.16%)\n",
      "\n",
      "Round 364, Train average loss 0.118 Test accuracy 72.160\n",
      "\n",
      "Test set: Average loss: 1.3417 \n",
      "Accuracy: 7190/10000 (71.90%)\n",
      "\n",
      "Round 365, Train average loss 0.126 Test accuracy 71.900\n",
      "\n",
      "Test set: Average loss: 1.3815 \n",
      "Accuracy: 7159/10000 (71.59%)\n",
      "\n",
      "Round 366, Train average loss 0.113 Test accuracy 71.590\n",
      "\n",
      "Test set: Average loss: 1.4152 \n",
      "Accuracy: 7176/10000 (71.76%)\n",
      "\n",
      "Round 367, Train average loss 0.101 Test accuracy 71.760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3790 \n",
      "Accuracy: 7171/10000 (71.71%)\n",
      "\n",
      "Round 368, Train average loss 0.119 Test accuracy 71.710\n",
      "\n",
      "Test set: Average loss: 1.3644 \n",
      "Accuracy: 7190/10000 (71.90%)\n",
      "\n",
      "Round 369, Train average loss 0.117 Test accuracy 71.900\n",
      "\n",
      "Test set: Average loss: 1.3469 \n",
      "Accuracy: 7199/10000 (71.99%)\n",
      "\n",
      "Round 370, Train average loss 0.124 Test accuracy 71.990\n",
      "\n",
      "Test set: Average loss: 1.4068 \n",
      "Accuracy: 7186/10000 (71.86%)\n",
      "\n",
      "Round 371, Train average loss 0.099 Test accuracy 71.860\n",
      "\n",
      "Test set: Average loss: 1.3857 \n",
      "Accuracy: 7182/10000 (71.82%)\n",
      "\n",
      "Round 372, Train average loss 0.112 Test accuracy 71.820\n",
      "\n",
      "Test set: Average loss: 1.4104 \n",
      "Accuracy: 7171/10000 (71.71%)\n",
      "\n",
      "Round 373, Train average loss 0.107 Test accuracy 71.710\n",
      "\n",
      "Test set: Average loss: 1.3718 \n",
      "Accuracy: 7176/10000 (71.76%)\n",
      "\n",
      "Round 374, Train average loss 0.115 Test accuracy 71.760\n",
      "\n",
      "Test set: Average loss: 1.4082 \n",
      "Accuracy: 7196/10000 (71.96%)\n",
      "\n",
      "Round 375, Train average loss 0.100 Test accuracy 71.960\n",
      "\n",
      "Test set: Average loss: 1.4097 \n",
      "Accuracy: 7184/10000 (71.84%)\n",
      "\n",
      "Round 376, Train average loss 0.107 Test accuracy 71.840\n",
      "\n",
      "Test set: Average loss: 1.3943 \n",
      "Accuracy: 7173/10000 (71.73%)\n",
      "\n",
      "Round 377, Train average loss 0.108 Test accuracy 71.730\n",
      "\n",
      "Test set: Average loss: 1.3891 \n",
      "Accuracy: 7182/10000 (71.82%)\n",
      "\n",
      "Round 378, Train average loss 0.114 Test accuracy 71.820\n",
      "\n",
      "Test set: Average loss: 1.4160 \n",
      "Accuracy: 7194/10000 (71.94%)\n",
      "\n",
      "Round 379, Train average loss 0.096 Test accuracy 71.940\n",
      "\n",
      "Test set: Average loss: 1.3810 \n",
      "Accuracy: 7174/10000 (71.74%)\n",
      "\n",
      "Round 380, Train average loss 0.112 Test accuracy 71.740\n",
      "\n",
      "Test set: Average loss: 1.3482 \n",
      "Accuracy: 7180/10000 (71.80%)\n",
      "\n",
      "Round 381, Train average loss 0.124 Test accuracy 71.800\n",
      "\n",
      "Test set: Average loss: 1.3968 \n",
      "Accuracy: 7181/10000 (71.81%)\n",
      "\n",
      "Round 382, Train average loss 0.105 Test accuracy 71.810\n",
      "\n",
      "Test set: Average loss: 1.3661 \n",
      "Accuracy: 7163/10000 (71.63%)\n",
      "\n",
      "Round 383, Train average loss 0.124 Test accuracy 71.630\n",
      "\n",
      "Test set: Average loss: 1.3900 \n",
      "Accuracy: 7203/10000 (72.03%)\n",
      "\n",
      "Round 384, Train average loss 0.105 Test accuracy 72.030\n",
      "\n",
      "Test set: Average loss: 1.3674 \n",
      "Accuracy: 7191/10000 (71.91%)\n",
      "\n",
      "Round 385, Train average loss 0.122 Test accuracy 71.910\n",
      "\n",
      "Test set: Average loss: 1.3879 \n",
      "Accuracy: 7223/10000 (72.23%)\n",
      "\n",
      "Round 386, Train average loss 0.120 Test accuracy 72.230\n",
      "\n",
      "Test set: Average loss: 1.3570 \n",
      "Accuracy: 7226/10000 (72.26%)\n",
      "\n",
      "Round 387, Train average loss 0.116 Test accuracy 72.260\n",
      "\n",
      "Test set: Average loss: 1.3971 \n",
      "Accuracy: 7221/10000 (72.21%)\n",
      "\n",
      "Round 388, Train average loss 0.106 Test accuracy 72.210\n",
      "\n",
      "Test set: Average loss: 1.3720 \n",
      "Accuracy: 7217/10000 (72.17%)\n",
      "\n",
      "Round 389, Train average loss 0.113 Test accuracy 72.170\n",
      "\n",
      "Test set: Average loss: 1.3694 \n",
      "Accuracy: 7231/10000 (72.31%)\n",
      "\n",
      "Round 390, Train average loss 0.110 Test accuracy 72.310\n",
      "\n",
      "Test set: Average loss: 1.3742 \n",
      "Accuracy: 7195/10000 (71.95%)\n",
      "\n",
      "Round 391, Train average loss 0.105 Test accuracy 71.950\n",
      "\n",
      "Test set: Average loss: 1.3620 \n",
      "Accuracy: 7191/10000 (71.91%)\n",
      "\n",
      "Round 392, Train average loss 0.113 Test accuracy 71.910\n",
      "\n",
      "Test set: Average loss: 1.3757 \n",
      "Accuracy: 7184/10000 (71.84%)\n",
      "\n",
      "Round 393, Train average loss 0.106 Test accuracy 71.840\n",
      "\n",
      "Test set: Average loss: 1.4116 \n",
      "Accuracy: 7233/10000 (72.33%)\n",
      "\n",
      "Round 394, Train average loss 0.101 Test accuracy 72.330\n",
      "\n",
      "Test set: Average loss: 1.4098 \n",
      "Accuracy: 7158/10000 (71.58%)\n",
      "\n",
      "Round 395, Train average loss 0.101 Test accuracy 71.580\n",
      "\n",
      "Test set: Average loss: 1.4187 \n",
      "Accuracy: 7190/10000 (71.90%)\n",
      "\n",
      "Round 396, Train average loss 0.098 Test accuracy 71.900\n",
      "\n",
      "Test set: Average loss: 1.4413 \n",
      "Accuracy: 7215/10000 (72.15%)\n",
      "\n",
      "Round 397, Train average loss 0.094 Test accuracy 72.150\n",
      "\n",
      "Test set: Average loss: 1.3526 \n",
      "Accuracy: 7197/10000 (71.97%)\n",
      "\n",
      "Round 398, Train average loss 0.126 Test accuracy 71.970\n",
      "\n",
      "Test set: Average loss: 1.3978 \n",
      "Accuracy: 7201/10000 (72.01%)\n",
      "\n",
      "Round 399, Train average loss 0.102 Test accuracy 72.010\n",
      "\n",
      "Test set: Average loss: 1.4119 \n",
      "Accuracy: 7233/10000 (72.33%)\n",
      "\n",
      "Round 400, Train average loss 0.101 Test accuracy 72.330\n",
      "\n",
      "Test set: Average loss: 1.3977 \n",
      "Accuracy: 7196/10000 (71.96%)\n",
      "\n",
      "Round 401, Train average loss 0.111 Test accuracy 71.960\n",
      "\n",
      "Test set: Average loss: 1.4339 \n",
      "Accuracy: 7181/10000 (71.81%)\n",
      "\n",
      "Round 402, Train average loss 0.094 Test accuracy 71.810\n",
      "\n",
      "Test set: Average loss: 1.4039 \n",
      "Accuracy: 7192/10000 (71.92%)\n",
      "\n",
      "Round 403, Train average loss 0.104 Test accuracy 71.920\n",
      "\n",
      "Test set: Average loss: 1.3837 \n",
      "Accuracy: 7189/10000 (71.89%)\n",
      "\n",
      "Round 404, Train average loss 0.112 Test accuracy 71.890\n",
      "\n",
      "Test set: Average loss: 1.4180 \n",
      "Accuracy: 7177/10000 (71.77%)\n",
      "\n",
      "Round 405, Train average loss 0.095 Test accuracy 71.770\n",
      "\n",
      "Test set: Average loss: 1.4110 \n",
      "Accuracy: 7201/10000 (72.01%)\n",
      "\n",
      "Round 406, Train average loss 0.107 Test accuracy 72.010\n",
      "\n",
      "Test set: Average loss: 1.4089 \n",
      "Accuracy: 7212/10000 (72.12%)\n",
      "\n",
      "Round 407, Train average loss 0.099 Test accuracy 72.120\n",
      "\n",
      "Test set: Average loss: 1.4370 \n",
      "Accuracy: 7177/10000 (71.77%)\n",
      "\n",
      "Round 408, Train average loss 0.096 Test accuracy 71.770\n",
      "\n",
      "Test set: Average loss: 1.4224 \n",
      "Accuracy: 7175/10000 (71.75%)\n",
      "\n",
      "Round 409, Train average loss 0.100 Test accuracy 71.750\n",
      "\n",
      "Test set: Average loss: 1.4139 \n",
      "Accuracy: 7204/10000 (72.04%)\n",
      "\n",
      "Round 410, Train average loss 0.104 Test accuracy 72.040\n",
      "\n",
      "Test set: Average loss: 1.4399 \n",
      "Accuracy: 7198/10000 (71.98%)\n",
      "\n",
      "Round 411, Train average loss 0.092 Test accuracy 71.980\n",
      "\n",
      "Test set: Average loss: 1.3975 \n",
      "Accuracy: 7205/10000 (72.05%)\n",
      "\n",
      "Round 412, Train average loss 0.105 Test accuracy 72.050\n",
      "\n",
      "Test set: Average loss: 1.4374 \n",
      "Accuracy: 7173/10000 (71.73%)\n",
      "\n",
      "Round 413, Train average loss 0.092 Test accuracy 71.730\n",
      "\n",
      "Test set: Average loss: 1.4269 \n",
      "Accuracy: 7217/10000 (72.17%)\n",
      "\n",
      "Round 414, Train average loss 0.102 Test accuracy 72.170\n",
      "\n",
      "Test set: Average loss: 1.4171 \n",
      "Accuracy: 7193/10000 (71.93%)\n",
      "\n",
      "Round 415, Train average loss 0.094 Test accuracy 71.930\n",
      "\n",
      "Test set: Average loss: 1.3881 \n",
      "Accuracy: 7201/10000 (72.01%)\n",
      "\n",
      "Round 416, Train average loss 0.108 Test accuracy 72.010\n",
      "\n",
      "Test set: Average loss: 1.4099 \n",
      "Accuracy: 7203/10000 (72.03%)\n",
      "\n",
      "Round 417, Train average loss 0.099 Test accuracy 72.030\n",
      "\n",
      "Test set: Average loss: 1.4225 \n",
      "Accuracy: 7213/10000 (72.13%)\n",
      "\n",
      "Round 418, Train average loss 0.097 Test accuracy 72.130\n",
      "\n",
      "Test set: Average loss: 1.4008 \n",
      "Accuracy: 7209/10000 (72.09%)\n",
      "\n",
      "Round 419, Train average loss 0.098 Test accuracy 72.090\n",
      "\n",
      "Test set: Average loss: 1.3920 \n",
      "Accuracy: 7215/10000 (72.15%)\n",
      "\n",
      "Round 420, Train average loss 0.106 Test accuracy 72.150\n",
      "\n",
      "Test set: Average loss: 1.4342 \n",
      "Accuracy: 7200/10000 (72.00%)\n",
      "\n",
      "Round 421, Train average loss 0.095 Test accuracy 72.000\n",
      "\n",
      "Test set: Average loss: 1.4549 \n",
      "Accuracy: 7174/10000 (71.74%)\n",
      "\n",
      "Round 422, Train average loss 0.088 Test accuracy 71.740\n",
      "\n",
      "Test set: Average loss: 1.4484 \n",
      "Accuracy: 7203/10000 (72.03%)\n",
      "\n",
      "Round 423, Train average loss 0.098 Test accuracy 72.030\n",
      "\n",
      "Test set: Average loss: 1.4799 \n",
      "Accuracy: 7213/10000 (72.13%)\n",
      "\n",
      "Round 424, Train average loss 0.082 Test accuracy 72.130\n",
      "\n",
      "Test set: Average loss: 1.4447 \n",
      "Accuracy: 7201/10000 (72.01%)\n",
      "\n",
      "Round 425, Train average loss 0.098 Test accuracy 72.010\n",
      "\n",
      "Test set: Average loss: 1.4330 \n",
      "Accuracy: 7220/10000 (72.20%)\n",
      "\n",
      "Round 426, Train average loss 0.102 Test accuracy 72.200\n",
      "\n",
      "Test set: Average loss: 1.4077 \n",
      "Accuracy: 7208/10000 (72.08%)\n",
      "\n",
      "Round 427, Train average loss 0.105 Test accuracy 72.080\n",
      "\n",
      "Test set: Average loss: 1.4081 \n",
      "Accuracy: 7198/10000 (71.98%)\n",
      "\n",
      "Round 428, Train average loss 0.101 Test accuracy 71.980\n",
      "\n",
      "Test set: Average loss: 1.4559 \n",
      "Accuracy: 7200/10000 (72.00%)\n",
      "\n",
      "Round 429, Train average loss 0.082 Test accuracy 72.000\n",
      "\n",
      "Test set: Average loss: 1.4373 \n",
      "Accuracy: 7188/10000 (71.88%)\n",
      "\n",
      "Round 430, Train average loss 0.094 Test accuracy 71.880\n",
      "\n",
      "Test set: Average loss: 1.4139 \n",
      "Accuracy: 7204/10000 (72.04%)\n",
      "\n",
      "Round 431, Train average loss 0.108 Test accuracy 72.040\n",
      "\n",
      "Test set: Average loss: 1.4061 \n",
      "Accuracy: 7209/10000 (72.09%)\n",
      "\n",
      "Round 432, Train average loss 0.095 Test accuracy 72.090\n",
      "\n",
      "Test set: Average loss: 1.4370 \n",
      "Accuracy: 7211/10000 (72.11%)\n",
      "\n",
      "Round 433, Train average loss 0.096 Test accuracy 72.110\n",
      "\n",
      "Test set: Average loss: 1.4208 \n",
      "Accuracy: 7208/10000 (72.08%)\n",
      "\n",
      "Round 434, Train average loss 0.102 Test accuracy 72.080\n",
      "\n",
      "Test set: Average loss: 1.4002 \n",
      "Accuracy: 7229/10000 (72.29%)\n",
      "\n",
      "Round 435, Train average loss 0.102 Test accuracy 72.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4639 \n",
      "Accuracy: 7190/10000 (71.90%)\n",
      "\n",
      "Round 436, Train average loss 0.078 Test accuracy 71.900\n",
      "\n",
      "Test set: Average loss: 1.4257 \n",
      "Accuracy: 7221/10000 (72.21%)\n",
      "\n",
      "Round 437, Train average loss 0.099 Test accuracy 72.210\n",
      "\n",
      "Test set: Average loss: 1.4374 \n",
      "Accuracy: 7209/10000 (72.09%)\n",
      "\n",
      "Round 438, Train average loss 0.090 Test accuracy 72.090\n",
      "\n",
      "Test set: Average loss: 1.4505 \n",
      "Accuracy: 7197/10000 (71.97%)\n",
      "\n",
      "Round 439, Train average loss 0.090 Test accuracy 71.970\n",
      "\n",
      "Test set: Average loss: 1.4333 \n",
      "Accuracy: 7223/10000 (72.23%)\n",
      "\n",
      "Round 440, Train average loss 0.096 Test accuracy 72.230\n",
      "\n",
      "Test set: Average loss: 1.4332 \n",
      "Accuracy: 7207/10000 (72.07%)\n",
      "\n",
      "Round 441, Train average loss 0.095 Test accuracy 72.070\n",
      "\n",
      "Test set: Average loss: 1.4339 \n",
      "Accuracy: 7218/10000 (72.18%)\n",
      "\n",
      "Round 442, Train average loss 0.097 Test accuracy 72.180\n",
      "\n",
      "Test set: Average loss: 1.4398 \n",
      "Accuracy: 7182/10000 (71.82%)\n",
      "\n",
      "Round 443, Train average loss 0.094 Test accuracy 71.820\n",
      "\n",
      "Test set: Average loss: 1.4432 \n",
      "Accuracy: 7231/10000 (72.31%)\n",
      "\n",
      "Round 444, Train average loss 0.087 Test accuracy 72.310\n",
      "\n",
      "Test set: Average loss: 1.3914 \n",
      "Accuracy: 7165/10000 (71.65%)\n",
      "\n",
      "Round 445, Train average loss 0.101 Test accuracy 71.650\n",
      "\n",
      "Test set: Average loss: 1.4222 \n",
      "Accuracy: 7220/10000 (72.20%)\n",
      "\n",
      "Round 446, Train average loss 0.092 Test accuracy 72.200\n",
      "\n",
      "Test set: Average loss: 1.4010 \n",
      "Accuracy: 7216/10000 (72.16%)\n",
      "\n",
      "Round 447, Train average loss 0.105 Test accuracy 72.160\n",
      "\n",
      "Test set: Average loss: 1.4278 \n",
      "Accuracy: 7220/10000 (72.20%)\n",
      "\n",
      "Round 448, Train average loss 0.090 Test accuracy 72.200\n",
      "\n",
      "Test set: Average loss: 1.4253 \n",
      "Accuracy: 7202/10000 (72.02%)\n",
      "\n",
      "Round 449, Train average loss 0.096 Test accuracy 72.020\n",
      "\n",
      "Test set: Average loss: 1.4798 \n",
      "Accuracy: 7198/10000 (71.98%)\n",
      "\n",
      "Round 450, Train average loss 0.079 Test accuracy 71.980\n",
      "\n",
      "Test set: Average loss: 1.4422 \n",
      "Accuracy: 7195/10000 (71.95%)\n",
      "\n",
      "Round 451, Train average loss 0.093 Test accuracy 71.950\n",
      "\n",
      "Test set: Average loss: 1.4390 \n",
      "Accuracy: 7225/10000 (72.25%)\n",
      "\n",
      "Round 452, Train average loss 0.091 Test accuracy 72.250\n",
      "\n",
      "Test set: Average loss: 1.4408 \n",
      "Accuracy: 7210/10000 (72.10%)\n",
      "\n",
      "Round 453, Train average loss 0.095 Test accuracy 72.100\n",
      "\n",
      "Test set: Average loss: 1.4310 \n",
      "Accuracy: 7220/10000 (72.20%)\n",
      "\n",
      "Round 454, Train average loss 0.100 Test accuracy 72.200\n",
      "\n",
      "Test set: Average loss: 1.4451 \n",
      "Accuracy: 7216/10000 (72.16%)\n",
      "\n",
      "Round 455, Train average loss 0.093 Test accuracy 72.160\n",
      "\n",
      "Test set: Average loss: 1.4379 \n",
      "Accuracy: 7200/10000 (72.00%)\n",
      "\n",
      "Round 456, Train average loss 0.099 Test accuracy 72.000\n",
      "\n",
      "Test set: Average loss: 1.4597 \n",
      "Accuracy: 7213/10000 (72.13%)\n",
      "\n",
      "Round 457, Train average loss 0.091 Test accuracy 72.130\n",
      "\n",
      "Test set: Average loss: 1.4086 \n",
      "Accuracy: 7255/10000 (72.55%)\n",
      "\n",
      "Round 458, Train average loss 0.098 Test accuracy 72.550\n",
      "\n",
      "Test set: Average loss: 1.4507 \n",
      "Accuracy: 7190/10000 (71.90%)\n",
      "\n",
      "Round 459, Train average loss 0.086 Test accuracy 71.900\n",
      "\n",
      "Test set: Average loss: 1.4351 \n",
      "Accuracy: 7227/10000 (72.27%)\n",
      "\n",
      "Round 460, Train average loss 0.096 Test accuracy 72.270\n",
      "\n",
      "Test set: Average loss: 1.4453 \n",
      "Accuracy: 7241/10000 (72.41%)\n",
      "\n",
      "Round 461, Train average loss 0.092 Test accuracy 72.410\n",
      "\n",
      "Test set: Average loss: 1.4372 \n",
      "Accuracy: 7209/10000 (72.09%)\n",
      "\n",
      "Round 462, Train average loss 0.094 Test accuracy 72.090\n",
      "\n",
      "Test set: Average loss: 1.4293 \n",
      "Accuracy: 7196/10000 (71.96%)\n",
      "\n",
      "Round 463, Train average loss 0.093 Test accuracy 71.960\n",
      "\n",
      "Test set: Average loss: 1.4484 \n",
      "Accuracy: 7198/10000 (71.98%)\n",
      "\n",
      "Round 464, Train average loss 0.086 Test accuracy 71.980\n",
      "\n",
      "Test set: Average loss: 1.4667 \n",
      "Accuracy: 7213/10000 (72.13%)\n",
      "\n",
      "Round 465, Train average loss 0.087 Test accuracy 72.130\n",
      "\n",
      "Test set: Average loss: 1.4631 \n",
      "Accuracy: 7206/10000 (72.06%)\n",
      "\n",
      "Round 466, Train average loss 0.086 Test accuracy 72.060\n",
      "\n",
      "Test set: Average loss: 1.4678 \n",
      "Accuracy: 7187/10000 (71.87%)\n",
      "\n",
      "Round 467, Train average loss 0.091 Test accuracy 71.870\n",
      "\n",
      "Test set: Average loss: 1.4433 \n",
      "Accuracy: 7219/10000 (72.19%)\n",
      "\n",
      "Round 468, Train average loss 0.092 Test accuracy 72.190\n",
      "\n",
      "Test set: Average loss: 1.4621 \n",
      "Accuracy: 7223/10000 (72.23%)\n",
      "\n",
      "Round 469, Train average loss 0.090 Test accuracy 72.230\n",
      "\n",
      "Test set: Average loss: 1.4601 \n",
      "Accuracy: 7179/10000 (71.79%)\n",
      "\n",
      "Round 470, Train average loss 0.086 Test accuracy 71.790\n",
      "\n",
      "Test set: Average loss: 1.4607 \n",
      "Accuracy: 7199/10000 (71.99%)\n",
      "\n",
      "Round 471, Train average loss 0.081 Test accuracy 71.990\n",
      "\n",
      "Test set: Average loss: 1.4860 \n",
      "Accuracy: 7187/10000 (71.87%)\n",
      "\n",
      "Round 472, Train average loss 0.076 Test accuracy 71.870\n",
      "\n",
      "Test set: Average loss: 1.4609 \n",
      "Accuracy: 7170/10000 (71.70%)\n",
      "\n",
      "Round 473, Train average loss 0.086 Test accuracy 71.700\n",
      "\n",
      "Test set: Average loss: 1.4518 \n",
      "Accuracy: 7200/10000 (72.00%)\n",
      "\n",
      "Round 474, Train average loss 0.091 Test accuracy 72.000\n",
      "\n",
      "Test set: Average loss: 1.4648 \n",
      "Accuracy: 7207/10000 (72.07%)\n",
      "\n",
      "Round 475, Train average loss 0.089 Test accuracy 72.070\n",
      "\n",
      "Test set: Average loss: 1.4257 \n",
      "Accuracy: 7227/10000 (72.27%)\n",
      "\n",
      "Round 476, Train average loss 0.097 Test accuracy 72.270\n",
      "\n",
      "Test set: Average loss: 1.4397 \n",
      "Accuracy: 7214/10000 (72.14%)\n",
      "\n",
      "Round 477, Train average loss 0.090 Test accuracy 72.140\n",
      "\n",
      "Test set: Average loss: 1.4869 \n",
      "Accuracy: 7204/10000 (72.04%)\n",
      "\n",
      "Round 478, Train average loss 0.076 Test accuracy 72.040\n",
      "\n",
      "Test set: Average loss: 1.4717 \n",
      "Accuracy: 7216/10000 (72.16%)\n",
      "\n",
      "Round 479, Train average loss 0.082 Test accuracy 72.160\n",
      "\n",
      "Test set: Average loss: 1.4765 \n",
      "Accuracy: 7207/10000 (72.07%)\n",
      "\n",
      "Round 480, Train average loss 0.084 Test accuracy 72.070\n",
      "\n",
      "Test set: Average loss: 1.4674 \n",
      "Accuracy: 7207/10000 (72.07%)\n",
      "\n",
      "Round 481, Train average loss 0.090 Test accuracy 72.070\n",
      "\n",
      "Test set: Average loss: 1.4766 \n",
      "Accuracy: 7210/10000 (72.10%)\n",
      "\n",
      "Round 482, Train average loss 0.083 Test accuracy 72.100\n",
      "\n",
      "Test set: Average loss: 1.4641 \n",
      "Accuracy: 7221/10000 (72.21%)\n",
      "\n",
      "Round 483, Train average loss 0.087 Test accuracy 72.210\n",
      "\n",
      "Test set: Average loss: 1.4625 \n",
      "Accuracy: 7200/10000 (72.00%)\n",
      "\n",
      "Round 484, Train average loss 0.085 Test accuracy 72.000\n",
      "\n",
      "Test set: Average loss: 1.4622 \n",
      "Accuracy: 7195/10000 (71.95%)\n",
      "\n",
      "Round 485, Train average loss 0.084 Test accuracy 71.950\n",
      "\n",
      "Test set: Average loss: 1.4635 \n",
      "Accuracy: 7207/10000 (72.07%)\n",
      "\n",
      "Round 486, Train average loss 0.083 Test accuracy 72.070\n",
      "\n",
      "Test set: Average loss: 1.4246 \n",
      "Accuracy: 7235/10000 (72.35%)\n",
      "\n",
      "Round 487, Train average loss 0.095 Test accuracy 72.350\n",
      "\n",
      "Test set: Average loss: 1.4885 \n",
      "Accuracy: 7226/10000 (72.26%)\n",
      "\n",
      "Round 488, Train average loss 0.079 Test accuracy 72.260\n",
      "\n",
      "Test set: Average loss: 1.4568 \n",
      "Accuracy: 7212/10000 (72.12%)\n",
      "\n",
      "Round 489, Train average loss 0.086 Test accuracy 72.120\n",
      "\n",
      "Test set: Average loss: 1.4654 \n",
      "Accuracy: 7272/10000 (72.72%)\n",
      "\n",
      "Round 490, Train average loss 0.084 Test accuracy 72.720\n",
      "\n",
      "Test set: Average loss: 1.4445 \n",
      "Accuracy: 7232/10000 (72.32%)\n",
      "\n",
      "Round 491, Train average loss 0.086 Test accuracy 72.320\n",
      "\n",
      "Test set: Average loss: 1.4561 \n",
      "Accuracy: 7237/10000 (72.37%)\n",
      "\n",
      "Round 492, Train average loss 0.083 Test accuracy 72.370\n",
      "\n",
      "Test set: Average loss: 1.4697 \n",
      "Accuracy: 7210/10000 (72.10%)\n",
      "\n",
      "Round 493, Train average loss 0.084 Test accuracy 72.100\n",
      "\n",
      "Test set: Average loss: 1.4392 \n",
      "Accuracy: 7190/10000 (71.90%)\n",
      "\n",
      "Round 494, Train average loss 0.091 Test accuracy 71.900\n",
      "\n",
      "Test set: Average loss: 1.4840 \n",
      "Accuracy: 7174/10000 (71.74%)\n",
      "\n",
      "Round 495, Train average loss 0.079 Test accuracy 71.740\n",
      "\n",
      "Test set: Average loss: 1.4607 \n",
      "Accuracy: 7227/10000 (72.27%)\n",
      "\n",
      "Round 496, Train average loss 0.085 Test accuracy 72.270\n",
      "\n",
      "Test set: Average loss: 1.5001 \n",
      "Accuracy: 7216/10000 (72.16%)\n",
      "\n",
      "Round 497, Train average loss 0.075 Test accuracy 72.160\n",
      "\n",
      "Test set: Average loss: 1.4926 \n",
      "Accuracy: 7213/10000 (72.13%)\n",
      "\n",
      "Round 498, Train average loss 0.080 Test accuracy 72.130\n",
      "\n",
      "Test set: Average loss: 1.5067 \n",
      "Accuracy: 7232/10000 (72.32%)\n",
      "\n",
      "Round 499, Train average loss 0.076 Test accuracy 72.320\n"
     ]
    }
   ],
   "source": [
    "for iter in range(300,500): #args.epochs\n",
    "    w_locals, loss_locals = [], []\n",
    "    m = 10\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    for idx in idxs_users:\n",
    "#         print(idx)\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    \n",
    "    loss_train.append(loss_avg)\n",
    "    \n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "    acc_test_arr.append(acc_test)\n",
    "    loss_test_arr.append(loss_test)\n",
    "    if iter % 1 ==0:\n",
    "        print('Round {:3d}, Train average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_avg,acc_test))\n",
    "    #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_test_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './results_CIFAR/FedAvg_N40_m10_A0_'\n",
    "outfile = open(filename,'wb')\n",
    "\n",
    "pickle.dump(acc_test_arr,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
