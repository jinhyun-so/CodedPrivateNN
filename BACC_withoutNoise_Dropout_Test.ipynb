{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "size of X: (60000, 784)\n",
      "size of Y: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "import math\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2\n",
    "from models.Fed import FedAvg\n",
    "from models.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models.test import test_img\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2, CNNMnist3\n",
    "from models.Fed import FedAvg\n",
    "from models.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models.test import test_img\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils.functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "\n",
    "class my_argument:    \n",
    "    epochs = 200    #\"rounds of training\"\n",
    "    num_users = 15  # \"number of users: N\"\n",
    "    num_partition = 6 # \"number of users: K\"\n",
    "    frac = 0.5 #\"the fraction of clients: C\"\n",
    "    local_ep = 1 #\"the number of local epochs: E\"\n",
    "    local_bs = 200 #\"local batch size: B\"\n",
    "    bs=200 #\"test batch size\"\n",
    "    lr=0.01 #\"learning rate\"\n",
    "    momentum=0.5 # \"SGD momentum (default: 0.5)\"\n",
    "    split='user' # \"train-test split type, user or sample\"\n",
    "    opt='ADAM'\n",
    "    loss='Custom' # 'Custom' or 'Default'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num=9 #, help='number of each kind of kernel')\n",
    "    kernel_sizes='3,4,5' #  help='comma-separated kernel size to use for convolution')\n",
    "    norm='None' #, help=\"batch_norm, layer_norm, or None\")\n",
    "    num_filters=32 #, help=\"number of filters for conv nets\")\n",
    "    max_pool='True' #help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    dataset='mnist' #, help=\"name of dataset\")\n",
    "    iid=1\n",
    "    num_classes=10#, help=\"number of classes\")\n",
    "    num_channels=1#, help=\"number of channels of imges\")\n",
    "    gpu=1#, help=\"GPU ID, -1 for CPU\")\n",
    "    stopping_rounds=10#, help='rounds of early stopping')\n",
    "    verbose='False'#, help='verbose print')\n",
    "    seed=1#, help='random seed (default: 1)')\n",
    "    \n",
    "args = my_argument()\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "# load dataset and split users\n",
    "trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "\n",
    "dict_users = mnist_iid(dataset_train, args.num_partition)\n",
    "\n",
    "encoding_input_array_np = np.empty((len(dataset_train),28*28))\n",
    "encoding_label_array_np = np.empty((len(dataset_train),args.num_classes))\n",
    "print(\"size of X:\" ,encoding_input_array_np.shape)\n",
    "print(\"size of Y:\" ,encoding_label_array_np.shape)\n",
    "\n",
    "Size_submatrices = int(60000/args.num_partition)\n",
    "\n",
    "for i in range(args.num_partition):\n",
    "    \n",
    "    stt_pos = i*Size_submatrices\n",
    "    end_pos = (i+1)*Size_submatrices\n",
    "#     print(i,stt_pos,end_pos)\n",
    "    Temp_train = DataLoader(DatasetSplit(dataset_train, dict_users[i]), batch_size=Size_submatrices, shuffle=True)\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(Temp_train):\n",
    "        \n",
    "        images_np = images.detach().cpu().numpy()\n",
    "        encoding_input_array_np[stt_pos:end_pos,:] = np.reshape(images_np, (Size_submatrices,28*28))\n",
    "#         print(encoding_input_array_np[stt_pos:end_pos,:].shape)\n",
    "\n",
    "        onehot_labels = torch.nn.functional.one_hot(labels,num_classes=args.num_classes)\n",
    "        labels_np = onehot_labels.detach().cpu().numpy()\n",
    "#         print(labels_np.shape)\n",
    "        encoding_label_array_np[stt_pos:end_pos,:] = labels_np\n",
    "\n",
    "\n",
    "# print(labels_np[0:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "z_array: [ 1.00000000e+00  8.66025404e-01  5.00000000e-01  6.12323400e-17\n",
      " -5.00000000e-01 -8.66025404e-01]\n",
      "@BACC_Enc: N,K,T, m_i= 6 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 6 6 0 10000 \n",
      "\n",
      "(T, sigma)= 0 1 )  0 -th Trial!!\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3025 \n",
      "Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Round   3, Average loss 2.303 Test accuracy 10.280\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2.2646 \n",
      "Accuracy: 3651/10000 (36.51%)\n",
      "\n",
      "Round   4, Average loss 2.265 Test accuracy 36.510\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 1.4479 \n",
      "Accuracy: 7978/10000 (79.78%)\n",
      "\n",
      "Round   5, Average loss 1.448 Test accuracy 79.780\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.8814 \n",
      "Accuracy: 9273/10000 (92.73%)\n",
      "\n",
      "Round   6, Average loss 0.881 Test accuracy 92.730\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.7758 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round   7, Average loss 0.776 Test accuracy 93.760\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.6274 \n",
      "Accuracy: 9426/10000 (94.26%)\n",
      "\n",
      "Round   8, Average loss 0.627 Test accuracy 94.260\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.6237 \n",
      "Accuracy: 9460/10000 (94.60%)\n",
      "\n",
      "Round   9, Average loss 0.624 Test accuracy 94.600\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5690 \n",
      "Accuracy: 9470/10000 (94.70%)\n",
      "\n",
      "Round  10, Average loss 0.569 Test accuracy 94.700\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5729 \n",
      "Accuracy: 9488/10000 (94.88%)\n",
      "\n",
      "Round  11, Average loss 0.573 Test accuracy 94.880\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5418 \n",
      "Accuracy: 9494/10000 (94.94%)\n",
      "\n",
      "Round  12, Average loss 0.542 Test accuracy 94.940\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5221 \n",
      "Accuracy: 9502/10000 (95.02%)\n",
      "\n",
      "Round  13, Average loss 0.522 Test accuracy 95.020\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5161 \n",
      "Accuracy: 9505/10000 (95.05%)\n",
      "\n",
      "Round  14, Average loss 0.516 Test accuracy 95.050\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5139 \n",
      "Accuracy: 9521/10000 (95.21%)\n",
      "\n",
      "Round  15, Average loss 0.514 Test accuracy 95.210\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5593 \n",
      "Accuracy: 9511/10000 (95.11%)\n",
      "\n",
      "Round  16, Average loss 0.559 Test accuracy 95.110\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5484 \n",
      "Accuracy: 9509/10000 (95.09%)\n",
      "\n",
      "Round  17, Average loss 0.548 Test accuracy 95.090\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5088 \n",
      "Accuracy: 9532/10000 (95.32%)\n",
      "\n",
      "Round  18, Average loss 0.509 Test accuracy 95.320\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5085 \n",
      "Accuracy: 9544/10000 (95.44%)\n",
      "\n",
      "Round  19, Average loss 0.509 Test accuracy 95.440\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5262 \n",
      "Accuracy: 9529/10000 (95.29%)\n",
      "\n",
      "Round  20, Average loss 0.526 Test accuracy 95.290\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5627 \n",
      "Accuracy: 9538/10000 (95.38%)\n",
      "\n",
      "Round  21, Average loss 0.563 Test accuracy 95.380\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5102 \n",
      "Accuracy: 9539/10000 (95.39%)\n",
      "\n",
      "Round  22, Average loss 0.510 Test accuracy 95.390\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5264 \n",
      "Accuracy: 9542/10000 (95.42%)\n",
      "\n",
      "Round  23, Average loss 0.526 Test accuracy 95.420\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.4918 \n",
      "Accuracy: 9574/10000 (95.74%)\n",
      "\n",
      "Round  24, Average loss 0.492 Test accuracy 95.740\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5001 \n",
      "Accuracy: 9550/10000 (95.50%)\n",
      "\n",
      "Round  25, Average loss 0.500 Test accuracy 95.500\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.4880 \n",
      "Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Round  26, Average loss 0.488 Test accuracy 95.660\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5196 \n",
      "Accuracy: 9583/10000 (95.83%)\n",
      "\n",
      "Round  27, Average loss 0.520 Test accuracy 95.830\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5106 \n",
      "Accuracy: 9557/10000 (95.57%)\n",
      "\n",
      "Round  28, Average loss 0.511 Test accuracy 95.570\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 0.5228 \n",
      "Accuracy: 9546/10000 (95.46%)\n",
      "\n",
      "Round  29, Average loss 0.523 Test accuracy 95.460\n",
      "1\n",
      "z_array: [ 1.          0.9781476   0.91354546  0.80901699  0.66913061  0.5\n",
      "  0.30901699  0.10452846 -0.10452846 -0.30901699 -0.5        -0.66913061\n",
      " -0.80901699 -0.91354546 -0.9781476 ]\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 15 6 0 10000 \n",
      "\n",
      "(T, sigma)= 0 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3021 \n",
      "Accuracy: 1980/10000 (19.80%)\n",
      "\n",
      "Round   1, Average loss 2.302 Test accuracy 19.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2965 \n",
      "Accuracy: 2099/10000 (20.99%)\n",
      "\n",
      "Round   2, Average loss 2.297 Test accuracy 20.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2780 \n",
      "Accuracy: 2453/10000 (24.53%)\n",
      "\n",
      "Round   3, Average loss 2.278 Test accuracy 24.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.2086 \n",
      "Accuracy: 5210/10000 (52.10%)\n",
      "\n",
      "Round   4, Average loss 2.209 Test accuracy 52.100\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.1420 \n",
      "Accuracy: 8670/10000 (86.70%)\n",
      "\n",
      "Round   5, Average loss 2.142 Test accuracy 86.700\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0582 \n",
      "Accuracy: 9311/10000 (93.11%)\n",
      "\n",
      "Round   6, Average loss 2.058 Test accuracy 93.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0683 \n",
      "Accuracy: 9382/10000 (93.82%)\n",
      "\n",
      "Round   7, Average loss 2.068 Test accuracy 93.820\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9919 \n",
      "Accuracy: 9383/10000 (93.83%)\n",
      "\n",
      "Round   8, Average loss 1.992 Test accuracy 93.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0075 \n",
      "Accuracy: 9412/10000 (94.12%)\n",
      "\n",
      "Round   9, Average loss 2.008 Test accuracy 94.120\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0327 \n",
      "Accuracy: 9430/10000 (94.30%)\n",
      "\n",
      "Round  10, Average loss 2.033 Test accuracy 94.300\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9970 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  11, Average loss 1.997 Test accuracy 93.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9810 \n",
      "Accuracy: 9399/10000 (93.99%)\n",
      "\n",
      "Round  12, Average loss 1.981 Test accuracy 93.990\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9940 \n",
      "Accuracy: 9361/10000 (93.61%)\n",
      "\n",
      "Round  13, Average loss 1.994 Test accuracy 93.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9649 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  14, Average loss 1.965 Test accuracy 94.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0142 \n",
      "Accuracy: 9400/10000 (94.00%)\n",
      "\n",
      "Round  15, Average loss 2.014 Test accuracy 94.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9650 \n",
      "Accuracy: 9394/10000 (93.94%)\n",
      "\n",
      "Round  16, Average loss 1.965 Test accuracy 93.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9876 \n",
      "Accuracy: 9386/10000 (93.86%)\n",
      "\n",
      "Round  17, Average loss 1.988 Test accuracy 93.860\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9837 \n",
      "Accuracy: 9371/10000 (93.71%)\n",
      "\n",
      "Round  18, Average loss 1.984 Test accuracy 93.710\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9916 \n",
      "Accuracy: 9395/10000 (93.95%)\n",
      "\n",
      "Round  19, Average loss 1.992 Test accuracy 93.950\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0030 \n",
      "Accuracy: 9407/10000 (94.07%)\n",
      "\n",
      "Round  20, Average loss 2.003 Test accuracy 94.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9509 \n",
      "Accuracy: 9387/10000 (93.87%)\n",
      "\n",
      "Round  21, Average loss 1.951 Test accuracy 93.870\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9977 \n",
      "Accuracy: 9421/10000 (94.21%)\n",
      "\n",
      "Round  22, Average loss 1.998 Test accuracy 94.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9841 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  23, Average loss 1.984 Test accuracy 93.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9957 \n",
      "Accuracy: 9407/10000 (94.07%)\n",
      "\n",
      "Round  24, Average loss 1.996 Test accuracy 94.070\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9856 \n",
      "Accuracy: 9411/10000 (94.11%)\n",
      "\n",
      "Round  25, Average loss 1.986 Test accuracy 94.110\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9805 \n",
      "Accuracy: 9353/10000 (93.53%)\n",
      "\n",
      "Round  26, Average loss 1.981 Test accuracy 93.530\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0023 \n",
      "Accuracy: 9454/10000 (94.54%)\n",
      "\n",
      "Round  27, Average loss 2.002 Test accuracy 94.540\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 1.9805 \n",
      "Accuracy: 9366/10000 (93.66%)\n",
      "\n",
      "Round  28, Average loss 1.980 Test accuracy 93.660\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0180 \n",
      "Accuracy: 9413/10000 (94.13%)\n",
      "\n",
      "Round  29, Average loss 2.018 Test accuracy 94.130\n"
     ]
    }
   ],
   "source": [
    "from models.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist1, CNNMnist2, CNNMnist3\n",
    "\n",
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec, FedAvg_with_LCC_Dec\n",
    "\n",
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "K = 6\n",
    "T = 0\n",
    "sigma = 1\n",
    "Noise_Alloc = []\n",
    "\n",
    "Signal_Alloc = []\n",
    "for i in range(K+T):\n",
    "    if i not in Noise_Alloc:\n",
    "        Signal_Alloc.append(i)\n",
    "\n",
    "\n",
    "j_array = np.array(range(K+T))\n",
    "alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "# alpha_array = np.array([-5.87785252e-01, 5.87785252e-01])\n",
    "# print(\"alpha_array: \",alpha_array,'\\n')\n",
    "\n",
    "B = 0.5\n",
    "\n",
    "\n",
    "N_array = [6,15]\n",
    "alloc_case = 3\n",
    "B_array = [0.5]\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "\n",
    "\n",
    "loss_test_arr_v0_0 = np.zeros((len(N_array),len(B_array),N_trials,N_epochs))\n",
    "acc_test_arr_v0_0  = np.zeros((len(N_array),len(B_array),N_trials,N_epochs))\n",
    "\n",
    "for N_idx in range(len(N_array)):\n",
    "    \n",
    "    N = N_array[N_idx]\n",
    "    \n",
    "    \n",
    "           \n",
    "        \n",
    "    # print(\"alpha_array: \",alpha_array,'\\n')\n",
    "    \n",
    "    \n",
    "    for B_idx in range(len(B_array)):\n",
    "        \n",
    "        B = B_array[B_idx]\n",
    "        z_array = []\n",
    "#         while(len(z_array)<N):\n",
    "#             z_tmp = np.random.uniform(-1,1,1)\n",
    "#             MIS_tmp = MutualInformationSecurity(alpha_array[Signal_Alloc], alpha_array[Noise_Alloc],[z_tmp], 1,sigma)\n",
    "#             if MIS_tmp < B and MIS_tmp > 0.1:\n",
    "#                 z_array.append(z_tmp[0])\n",
    "#         \n",
    "#         z_array = np.sort(z_array)\n",
    "        print(N_idx)\n",
    "        i_array = np.array(range(N))\n",
    "        z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "#         if N==2:\n",
    "#             z_array = np.array([-0.88, 0.88])\n",
    "#         elif N ==4:\n",
    "#             z_array = np.array([-0.88, -0.25, 0.25, 0.88])\n",
    "#         elif N ==5:\n",
    "#             z_array = np.array([-0.88, -0.25, -0.2, 0.25, 0.88])\n",
    "#         elif N ==6:\n",
    "#             z_array = np.array([-0.94, -0.88, -0.25, 0.25, 0.88, 0.94])\n",
    "#         elif N ==7:\n",
    "#             z_array = np.array([-0.94, -0.88, -0.25, 0, 0.25, 0.88, 0.94])\n",
    "#         else:\n",
    "#             z_array = np.array([-0.94, -0.88, -0.25, -0.2, 0.2, 0.25, 0.88, 0.94])\n",
    "\n",
    "            \n",
    "        print('z_array:',z_array)        \n",
    "        \n",
    "        _Noise_label = np.ones((30000*T,10)) * 0.1\n",
    "\n",
    "        X_tilde,a,b = BACC_Enc_Data_v3(encoding_input_array_np, N, K, T, sigma, alpha_array, z_array, _Noise_Alloc = Noise_Alloc, _is_LCC=False) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "        y_tilde,a,b = BACC_Enc_Data_v3(encoding_label_array_np, N, K, T, sigma, alpha_array, z_array, _Noise_Alloc = Noise_Alloc, _Noise = _Noise_label, is_predefined_noise=True, _is_LCC=False) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "\n",
    "        m = N # m is the number of received result @ master\n",
    "    #     print('number of results:',m)\n",
    "\n",
    "        for trial_idx in range(N_trials):\n",
    "            print('(T, sigma)=',T,sigma,') ',trial_idx,'-th Trial!!')\n",
    "\n",
    "            net_glob = CNNMnist1(args=args)\n",
    "            net_glob.cuda()\n",
    "            net_glob.train()\n",
    "\n",
    "            # copy weights\n",
    "            w_glob = net_glob.state_dict()\n",
    "\n",
    "            for iter in range(N_epochs): #args.epochs\n",
    "                w_locals, loss_locals = [], []\n",
    "                idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "                idxs_users = np.sort(idxs_users)\n",
    "                print('selected users:',idxs_users)\n",
    "                \n",
    "#                 coded_net = BACC_Enc_Model_withNoise_v3(net_glob.cuda(), N, K, T, 0, alpha_array, z_array, _Noise_Alloc=Noise_Alloc, _is_LCC=False)\n",
    "\n",
    "                dec_z_array = []\n",
    "                for idx in idxs_users: #for idx in range(N):\n",
    "            #         print(idx)\n",
    "                    local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "#                     w, loss = local.train(net=copy.deepcopy(coded_net[idx]).cuda())\n",
    "                    w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                    w_locals.append(copy.deepcopy(w))\n",
    "                    loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                    dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "                # update global weights\n",
    "                \n",
    "                w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "#                 w_glob = FedAvg_with_LCC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "                # copy weight to net_glob\n",
    "                net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                # print loss\n",
    "            #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "            #     loss_train_arr.append(loss_train)\n",
    "\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                acc_test_arr_v0_0[N_idx][B_idx][trial_idx][iter] = acc_test\n",
    "                loss_test_arr_v0_0[N_idx][B_idx][trial_idx][iter] = loss_test\n",
    "                if iter % 1 ==0:\n",
    "                    print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "                #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "z_array: [ 1.00000000e+00  8.66025404e-01  5.00000000e-01  6.12323400e-17\n",
      " -5.00000000e-01 -8.66025404e-01]\n",
      "@BACC_Enc: N,K,T, m_i= 6 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 6 6 0 10000 \n",
      "\n",
      "(T, sigma)= 0 1 )  0 -th Trial!!\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2.3023 \n",
      "Accuracy: 1115/10000 (11.15%)\n",
      "\n",
      "Round   0, Average loss 2.302 Test accuracy 11.150\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2.7549 \n",
      "Accuracy: 7688/10000 (76.88%)\n",
      "\n",
      "Round   1, Average loss 2.755 Test accuracy 76.880\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 25.4866 \n",
      "Accuracy: 7437/10000 (74.37%)\n",
      "\n",
      "Round   2, Average loss 25.487 Test accuracy 74.370\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 34.5410 \n",
      "Accuracy: 8590/10000 (85.90%)\n",
      "\n",
      "Round   3, Average loss 34.541 Test accuracy 85.900\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 96.0410 \n",
      "Accuracy: 8472/10000 (84.72%)\n",
      "\n",
      "Round   4, Average loss 96.041 Test accuracy 84.720\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 199.3244 \n",
      "Accuracy: 8633/10000 (86.33%)\n",
      "\n",
      "Round   5, Average loss 199.324 Test accuracy 86.330\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 371.0632 \n",
      "Accuracy: 8728/10000 (87.28%)\n",
      "\n",
      "Round   6, Average loss 371.063 Test accuracy 87.280\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 619.2230 \n",
      "Accuracy: 8763/10000 (87.63%)\n",
      "\n",
      "Round   7, Average loss 619.223 Test accuracy 87.630\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 992.2753 \n",
      "Accuracy: 8781/10000 (87.81%)\n",
      "\n",
      "Round   8, Average loss 992.275 Test accuracy 87.810\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 1462.8777 \n",
      "Accuracy: 8807/10000 (88.07%)\n",
      "\n",
      "Round   9, Average loss 1462.878 Test accuracy 88.070\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2112.5221 \n",
      "Accuracy: 8772/10000 (87.72%)\n",
      "\n",
      "Round  10, Average loss 2112.522 Test accuracy 87.720\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 2925.1933 \n",
      "Accuracy: 8701/10000 (87.01%)\n",
      "\n",
      "Round  11, Average loss 2925.193 Test accuracy 87.010\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 4059.1258 \n",
      "Accuracy: 8549/10000 (85.49%)\n",
      "\n",
      "Round  12, Average loss 4059.126 Test accuracy 85.490\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 5265.5942 \n",
      "Accuracy: 8540/10000 (85.40%)\n",
      "\n",
      "Round  13, Average loss 5265.594 Test accuracy 85.400\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 6547.4685 \n",
      "Accuracy: 8556/10000 (85.56%)\n",
      "\n",
      "Round  14, Average loss 6547.469 Test accuracy 85.560\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 8011.4331 \n",
      "Accuracy: 8565/10000 (85.65%)\n",
      "\n",
      "Round  15, Average loss 8011.433 Test accuracy 85.650\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 9561.5549 \n",
      "Accuracy: 8606/10000 (86.06%)\n",
      "\n",
      "Round  16, Average loss 9561.555 Test accuracy 86.060\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 11437.2330 \n",
      "Accuracy: 8608/10000 (86.08%)\n",
      "\n",
      "Round  17, Average loss 11437.233 Test accuracy 86.080\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 13437.5381 \n",
      "Accuracy: 8633/10000 (86.33%)\n",
      "\n",
      "Round  18, Average loss 13437.538 Test accuracy 86.330\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 15602.9166 \n",
      "Accuracy: 8645/10000 (86.45%)\n",
      "\n",
      "Round  19, Average loss 15602.917 Test accuracy 86.450\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 18013.4008 \n",
      "Accuracy: 8664/10000 (86.64%)\n",
      "\n",
      "Round  20, Average loss 18013.401 Test accuracy 86.640\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 20530.3243 \n",
      "Accuracy: 8691/10000 (86.91%)\n",
      "\n",
      "Round  21, Average loss 20530.324 Test accuracy 86.910\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 23440.4860 \n",
      "Accuracy: 8717/10000 (87.17%)\n",
      "\n",
      "Round  22, Average loss 23440.486 Test accuracy 87.170\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 26558.2366 \n",
      "Accuracy: 8730/10000 (87.30%)\n",
      "\n",
      "Round  23, Average loss 26558.237 Test accuracy 87.300\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 29987.6146 \n",
      "Accuracy: 8711/10000 (87.11%)\n",
      "\n",
      "Round  24, Average loss 29987.615 Test accuracy 87.110\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 33374.9439 \n",
      "Accuracy: 8715/10000 (87.15%)\n",
      "\n",
      "Round  25, Average loss 33374.944 Test accuracy 87.150\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 36910.6553 \n",
      "Accuracy: 8755/10000 (87.55%)\n",
      "\n",
      "Round  26, Average loss 36910.655 Test accuracy 87.550\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 41077.5963 \n",
      "Accuracy: 8760/10000 (87.60%)\n",
      "\n",
      "Round  27, Average loss 41077.596 Test accuracy 87.600\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 45182.5131 \n",
      "Accuracy: 8770/10000 (87.70%)\n",
      "\n",
      "Round  28, Average loss 45182.513 Test accuracy 87.700\n",
      "selected users: [0 1 2 3 4 5]\n",
      "\n",
      "Test set: Average loss: 49602.0348 \n",
      "Accuracy: 8777/10000 (87.77%)\n",
      "\n",
      "Round  29, Average loss 49602.035 Test accuracy 87.770\n",
      "1\n",
      "z_array: [ 1.          0.93969262  0.76604444  0.5         0.17364818 -0.17364818\n",
      " -0.5        -0.76604444 -0.93969262]\n",
      "@BACC_Enc: N,K,T, m_i= 9 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 9 6 0 10000 \n",
      "\n",
      "(T, sigma)= 0 1 )  0 -th Trial!!\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 2.1078 \n",
      "Accuracy: 3915/10000 (39.15%)\n",
      "\n",
      "Round   0, Average loss 2.108 Test accuracy 39.150\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 0.7339 \n",
      "Accuracy: 8706/10000 (87.06%)\n",
      "\n",
      "Round   1, Average loss 0.734 Test accuracy 87.060\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 1.8633 \n",
      "Accuracy: 8003/10000 (80.03%)\n",
      "\n",
      "Round   2, Average loss 1.863 Test accuracy 80.030\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 1.2992 \n",
      "Accuracy: 8905/10000 (89.05%)\n",
      "\n",
      "Round   3, Average loss 1.299 Test accuracy 89.050\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 3.6861 \n",
      "Accuracy: 8026/10000 (80.26%)\n",
      "\n",
      "Round   4, Average loss 3.686 Test accuracy 80.260\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 7.2488 \n",
      "Accuracy: 7578/10000 (75.78%)\n",
      "\n",
      "Round   5, Average loss 7.249 Test accuracy 75.780\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 7.0878 \n",
      "Accuracy: 7894/10000 (78.94%)\n",
      "\n",
      "Round   6, Average loss 7.088 Test accuracy 78.940\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 12.3905 \n",
      "Accuracy: 7395/10000 (73.95%)\n",
      "\n",
      "Round   7, Average loss 12.390 Test accuracy 73.950\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 8.3151 \n",
      "Accuracy: 8169/10000 (81.69%)\n",
      "\n",
      "Round   8, Average loss 8.315 Test accuracy 81.690\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 28.2216 \n",
      "Accuracy: 6798/10000 (67.98%)\n",
      "\n",
      "Round   9, Average loss 28.222 Test accuracy 67.980\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 10.1433 \n",
      "Accuracy: 8345/10000 (83.45%)\n",
      "\n",
      "Round  10, Average loss 10.143 Test accuracy 83.450\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 24.6387 \n",
      "Accuracy: 7294/10000 (72.94%)\n",
      "\n",
      "Round  11, Average loss 24.639 Test accuracy 72.940\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 14.5654 \n",
      "Accuracy: 8085/10000 (80.85%)\n",
      "\n",
      "Round  12, Average loss 14.565 Test accuracy 80.850\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 27.9788 \n",
      "Accuracy: 7407/10000 (74.07%)\n",
      "\n",
      "Round  13, Average loss 27.979 Test accuracy 74.070\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 16.8243 \n",
      "Accuracy: 8087/10000 (80.87%)\n",
      "\n",
      "Round  14, Average loss 16.824 Test accuracy 80.870\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 45.4145 \n",
      "Accuracy: 6919/10000 (69.19%)\n",
      "\n",
      "Round  15, Average loss 45.414 Test accuracy 69.190\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 19.5137 \n",
      "Accuracy: 8095/10000 (80.95%)\n",
      "\n",
      "Round  16, Average loss 19.514 Test accuracy 80.950\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 46.4409 \n",
      "Accuracy: 7141/10000 (71.41%)\n",
      "\n",
      "Round  17, Average loss 46.441 Test accuracy 71.410\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 25.6081 \n",
      "Accuracy: 7941/10000 (79.41%)\n",
      "\n",
      "Round  18, Average loss 25.608 Test accuracy 79.410\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 43.0283 \n",
      "Accuracy: 7357/10000 (73.57%)\n",
      "\n",
      "Round  19, Average loss 43.028 Test accuracy 73.570\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 36.4380 \n",
      "Accuracy: 7691/10000 (76.91%)\n",
      "\n",
      "Round  20, Average loss 36.438 Test accuracy 76.910\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 43.6339 \n",
      "Accuracy: 7466/10000 (74.66%)\n",
      "\n",
      "Round  21, Average loss 43.634 Test accuracy 74.660\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 49.6264 \n",
      "Accuracy: 7499/10000 (74.99%)\n",
      "\n",
      "Round  22, Average loss 49.626 Test accuracy 74.990\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 40.9937 \n",
      "Accuracy: 7552/10000 (75.52%)\n",
      "\n",
      "Round  23, Average loss 40.994 Test accuracy 75.520\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 43.1204 \n",
      "Accuracy: 7575/10000 (75.75%)\n",
      "\n",
      "Round  24, Average loss 43.120 Test accuracy 75.750\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 43.8685 \n",
      "Accuracy: 7536/10000 (75.36%)\n",
      "\n",
      "Round  25, Average loss 43.868 Test accuracy 75.360\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 55.5360 \n",
      "Accuracy: 7223/10000 (72.23%)\n",
      "\n",
      "Round  26, Average loss 55.536 Test accuracy 72.230\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 35.1130 \n",
      "Accuracy: 8032/10000 (80.32%)\n",
      "\n",
      "Round  27, Average loss 35.113 Test accuracy 80.320\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 56.1270 \n",
      "Accuracy: 7325/10000 (73.25%)\n",
      "\n",
      "Round  28, Average loss 56.127 Test accuracy 73.250\n",
      "selected users: [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Test set: Average loss: 39.6153 \n",
      "Accuracy: 7887/10000 (78.87%)\n",
      "\n",
      "Round  29, Average loss 39.615 Test accuracy 78.870\n",
      "2\n",
      "z_array: [ 1.00000000e+00  9.65925826e-01  8.66025404e-01  7.07106781e-01\n",
      "  5.00000000e-01  2.58819045e-01  6.12323400e-17 -2.58819045e-01\n",
      " -5.00000000e-01 -7.07106781e-01 -8.66025404e-01 -9.65925826e-01]\n",
      "@BACC_Enc: N,K,T, m_i= 12 6 0 10000 \n",
      "\n",
      "@BACC_Enc: N,K,T, m_i= 12 6 0 10000 \n",
      "\n",
      "(T, sigma)= 0 1 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: nan \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss nan Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: nan \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   1, Average loss nan Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: nan \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   2, Average loss nan Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: nan \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   3, Average loss nan Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "Test set: Average loss: nan \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   4, Average loss nan Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b595a663c666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m#     loss_train_arr.append(loss_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0macc_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_glob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[0macc_test_arr_v0_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mB_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mloss_test_arr_v0_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mB_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Jinhyun_DESKTOP\\06.Github\\CodedPrivateNN\\models\\test.py\u001b[0m in \u001b[0;36mtest_img\u001b[1;34m(net_g, datatest, args)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatatest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec, FedAvg_with_LCC_Dec\n",
    "\n",
    "from utils.functions import *\n",
    "import math\n",
    "\n",
    "K = 6\n",
    "T = 0\n",
    "sigma = 1\n",
    "Noise_Alloc = []\n",
    "\n",
    "Signal_Alloc = []\n",
    "for i in range(K+T):\n",
    "    if i not in Noise_Alloc:\n",
    "        Signal_Alloc.append(i)\n",
    "\n",
    "\n",
    "j_array = np.array(range(K+T))\n",
    "alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "# alpha_array = np.array([-5.87785252e-01, 5.87785252e-01])\n",
    "# print(\"alpha_array: \",alpha_array,'\\n')\n",
    "\n",
    "B = 0.5\n",
    "\n",
    "\n",
    "N_array = [6,15]\n",
    "alloc_case = 3\n",
    "B_array = [0.5]\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "\n",
    "\n",
    "loss_test_arr_v0_1 = np.zeros((len(N_array),len(B_array),N_trials,N_epochs))\n",
    "acc_test_arr_v0_1  = np.zeros((len(N_array),len(B_array),N_trials,N_epochs))\n",
    "\n",
    "for N_idx in range(len(N_array)):\n",
    "    \n",
    "    N = N_array[N_idx]\n",
    "    \n",
    "    \n",
    "           \n",
    "        \n",
    "    # print(\"alpha_array: \",alpha_array,'\\n')\n",
    "    \n",
    "    \n",
    "    for B_idx in range(len(B_array)):\n",
    "        \n",
    "        B = B_array[B_idx]\n",
    "        z_array = []\n",
    "#         while(len(z_array)<N):\n",
    "#             z_tmp = np.random.uniform(-1,1,1)\n",
    "#             MIS_tmp = MutualInformationSecurity(alpha_array[Signal_Alloc], alpha_array[Noise_Alloc],[z_tmp], 1,sigma)\n",
    "#             if MIS_tmp < B and MIS_tmp > 0.1:\n",
    "#                 z_array.append(z_tmp[0])\n",
    "#         \n",
    "#         z_array = np.sort(z_array)\n",
    "        print(N_idx)\n",
    "        i_array = np.array(range(N))\n",
    "        z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "#         if N==2:\n",
    "#             z_array = np.array([-0.88, 0.88])\n",
    "#         elif N ==4:\n",
    "#             z_array = np.array([-0.88, -0.25, 0.25, 0.88])\n",
    "#         elif N ==5:\n",
    "#             z_array = np.array([-0.88, -0.25, -0.2, 0.25, 0.88])\n",
    "#         elif N ==6:\n",
    "#             z_array = np.array([-0.94, -0.88, -0.25, 0.25, 0.88, 0.94])\n",
    "#         elif N ==7:\n",
    "#             z_array = np.array([-0.94, -0.88, -0.25, 0, 0.25, 0.88, 0.94])\n",
    "#         else:\n",
    "#             z_array = np.array([-0.94, -0.88, -0.25, -0.2, 0.2, 0.25, 0.88, 0.94])\n",
    "\n",
    "            \n",
    "        print('z_array:',z_array)        \n",
    "        \n",
    "        _Noise_label = np.ones((30000*T,10)) * 0.1\n",
    "\n",
    "        X_tilde,a,b = BACC_Enc_Data_v3(encoding_input_array_np, N, K, T, sigma, alpha_array, z_array, _Noise_Alloc = Noise_Alloc, _is_LCC=False) #BACC_Enc(encoding_input_array_np, alpha_array, z_array)\n",
    "        y_tilde,a,b = BACC_Enc_Data_v3(encoding_label_array_np, N, K, T, sigma, alpha_array, z_array, _Noise_Alloc = Noise_Alloc, _Noise = _Noise_label, is_predefined_noise=True, _is_LCC=False) #BACC_Enc(encoding_label_array_np, alpha_array, z_array)\n",
    "\n",
    "        m = N # m is the number of received result @ master\n",
    "    #     print('number of results:',m)\n",
    "\n",
    "        for trial_idx in range(N_trials):\n",
    "            print('(T, sigma)=',T,sigma,') ',trial_idx,'-th Trial!!')\n",
    "\n",
    "            net_glob = CNNMnist2(args=args)\n",
    "            net_glob.cuda()\n",
    "            net_glob.train()\n",
    "\n",
    "            # copy weights\n",
    "            w_glob = net_glob.state_dict()\n",
    "\n",
    "            for iter in range(N_epochs): #args.epochs\n",
    "                w_locals, loss_locals = [], []\n",
    "                idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "                idxs_users = np.sort(idxs_users)\n",
    "                print('selected users:',idxs_users)\n",
    "                \n",
    "#                 coded_net = BACC_Enc_Model_withNoise_v3(net_glob.cuda(), N, K, T, 0, alpha_array, z_array, _Noise_Alloc=Noise_Alloc, _is_LCC=False)\n",
    "\n",
    "                dec_z_array = []\n",
    "                for idx in idxs_users: #for idx in range(N):\n",
    "            #         print(idx)\n",
    "                    local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "#                     w, loss = local.train(net=copy.deepcopy(coded_net[idx]).cuda())\n",
    "                    w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                    w_locals.append(copy.deepcopy(w))\n",
    "                    loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                    dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "                # update global weights\n",
    "                \n",
    "                w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "#                 w_glob = FedAvg_with_LCC_Dec(w_locals, alpha_array[Signal_Alloc], dec_z_array)\n",
    "\n",
    "                # copy weight to net_glob\n",
    "                net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                # print loss\n",
    "            #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "            #     loss_train_arr.append(loss_train)\n",
    "\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                acc_test_arr_v0_1[N_idx][B_idx][trial_idx][iter] = acc_test\n",
    "                loss_test_arr_v0_1[N_idx][B_idx][trial_idx][iter] = loss_test\n",
    "                if iter % 1 ==0:\n",
    "                    print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "                #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96592583  0.70710678  0.25881905 -0.25881905 -0.70710678 -0.96592583]\n",
      "[ 1.          0.9781476   0.91354546  0.80901699  0.66913061  0.5\n",
      "  0.30901699  0.10452846 -0.10452846 -0.30901699 -0.5        -0.66913061\n",
      " -0.80901699 -0.91354546 -0.9781476 ]\n"
     ]
    }
   ],
   "source": [
    "j_array = np.array(range(K+T))\n",
    "alpha_array = np.cos((2*j_array+1)*math.pi/(2*(K+T))) #np.cos((2*j_array+1)*math.pi/(2*K))\n",
    "\n",
    "i_array = np.array(range(N))\n",
    "z_array = np.cos(i_array*2*math.pi/N/2) # np.cos(i_array*2*math.pi/N/2)\n",
    "\n",
    "print(alpha_array)\n",
    "print(z_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of results: 15\n",
      "(m= 15 )  0 -th Trial!!\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.3026 \n",
      "Accuracy: 980/10000 (9.80%)\n",
      "\n",
      "Round   0, Average loss 2.303 Test accuracy 9.800\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 2.0779 \n",
      "Accuracy: 5473/10000 (54.73%)\n",
      "\n",
      "Round   1, Average loss 2.078 Test accuracy 54.730\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2006 \n",
      "Accuracy: 9508/10000 (95.08%)\n",
      "\n",
      "Round   2, Average loss 0.201 Test accuracy 95.080\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2194 \n",
      "Accuracy: 9455/10000 (94.55%)\n",
      "\n",
      "Round   3, Average loss 0.219 Test accuracy 94.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2028 \n",
      "Accuracy: 9398/10000 (93.98%)\n",
      "\n",
      "Round   4, Average loss 0.203 Test accuracy 93.980\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3108 \n",
      "Accuracy: 9179/10000 (91.79%)\n",
      "\n",
      "Round   5, Average loss 0.311 Test accuracy 91.790\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2371 \n",
      "Accuracy: 9356/10000 (93.56%)\n",
      "\n",
      "Round   6, Average loss 0.237 Test accuracy 93.560\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2015 \n",
      "Accuracy: 9376/10000 (93.76%)\n",
      "\n",
      "Round   7, Average loss 0.202 Test accuracy 93.760\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2364 \n",
      "Accuracy: 9393/10000 (93.93%)\n",
      "\n",
      "Round   8, Average loss 0.236 Test accuracy 93.930\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3125 \n",
      "Accuracy: 9194/10000 (91.94%)\n",
      "\n",
      "Round   9, Average loss 0.313 Test accuracy 91.940\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2392 \n",
      "Accuracy: 9381/10000 (93.81%)\n",
      "\n",
      "Round  10, Average loss 0.239 Test accuracy 93.810\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1585 \n",
      "Accuracy: 9561/10000 (95.61%)\n",
      "\n",
      "Round  11, Average loss 0.159 Test accuracy 95.610\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2478 \n",
      "Accuracy: 9355/10000 (93.55%)\n",
      "\n",
      "Round  12, Average loss 0.248 Test accuracy 93.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1575 \n",
      "Accuracy: 9577/10000 (95.77%)\n",
      "\n",
      "Round  13, Average loss 0.158 Test accuracy 95.770\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2235 \n",
      "Accuracy: 9321/10000 (93.21%)\n",
      "\n",
      "Round  14, Average loss 0.223 Test accuracy 93.210\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1928 \n",
      "Accuracy: 9402/10000 (94.02%)\n",
      "\n",
      "Round  15, Average loss 0.193 Test accuracy 94.020\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1778 \n",
      "Accuracy: 9450/10000 (94.50%)\n",
      "\n",
      "Round  16, Average loss 0.178 Test accuracy 94.500\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2301 \n",
      "Accuracy: 9304/10000 (93.04%)\n",
      "\n",
      "Round  17, Average loss 0.230 Test accuracy 93.040\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4779 \n",
      "Accuracy: 8545/10000 (85.45%)\n",
      "\n",
      "Round  18, Average loss 0.478 Test accuracy 85.450\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2336 \n",
      "Accuracy: 9400/10000 (94.00%)\n",
      "\n",
      "Round  19, Average loss 0.234 Test accuracy 94.000\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3016 \n",
      "Accuracy: 9074/10000 (90.74%)\n",
      "\n",
      "Round  20, Average loss 0.302 Test accuracy 90.740\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3117 \n",
      "Accuracy: 9283/10000 (92.83%)\n",
      "\n",
      "Round  21, Average loss 0.312 Test accuracy 92.830\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3515 \n",
      "Accuracy: 8922/10000 (89.22%)\n",
      "\n",
      "Round  22, Average loss 0.351 Test accuracy 89.220\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2119 \n",
      "Accuracy: 9365/10000 (93.65%)\n",
      "\n",
      "Round  23, Average loss 0.212 Test accuracy 93.650\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.4889 \n",
      "Accuracy: 8355/10000 (83.55%)\n",
      "\n",
      "Round  24, Average loss 0.489 Test accuracy 83.550\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2113 \n",
      "Accuracy: 9326/10000 (93.26%)\n",
      "\n",
      "Round  25, Average loss 0.211 Test accuracy 93.260\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.3478 \n",
      "Accuracy: 9096/10000 (90.96%)\n",
      "\n",
      "Round  26, Average loss 0.348 Test accuracy 90.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.2200 \n",
      "Accuracy: 9396/10000 (93.96%)\n",
      "\n",
      "Round  27, Average loss 0.220 Test accuracy 93.960\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.5112 \n",
      "Accuracy: 8749/10000 (87.49%)\n",
      "\n",
      "Round  28, Average loss 0.511 Test accuracy 87.490\n",
      "selected users: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Test set: Average loss: 0.1649 \n",
      "Accuracy: 9503/10000 (95.03%)\n",
      "\n",
      "Round  29, Average loss 0.165 Test accuracy 95.030\n"
     ]
    }
   ],
   "source": [
    "from models.Update import LocalUpdate_with_BACC\n",
    "from models.Fed import FedAvg_with_BACC_Dec\n",
    "\n",
    "# training\n",
    "loss_train_arr = []\n",
    "loss_test_arr = []\n",
    "acc_test_arr = []\n",
    "net_best = None\n",
    "best_loss = None\n",
    "\n",
    "N_trials = 1\n",
    "N_epochs = 30\n",
    "\n",
    "# m_array = np.array(range(4,16)) # m is the number of received result @ master\n",
    "m_array = np.array([15]) # m is the number of received result @ master\n",
    "loss_test_arr = np.empty((len(m_array),N_trials,N_epochs))\n",
    "acc_test_arr  = np.empty((len(m_array),N_trials,N_epochs))\n",
    "\n",
    "for m_idx in range(len(m_array)):   \n",
    "    \n",
    "    m = m_array[m_idx] # m is the number of received result @ master\n",
    "    print('number of results:',m)\n",
    "    \n",
    "    for trial_idx in range(N_trials):\n",
    "        print('(m=',m,') ',trial_idx,'-th Trial!!')\n",
    "        \n",
    "        net_glob = CNNMnist2(args=args)\n",
    "        net_glob.cuda()\n",
    "        net_glob.train()\n",
    "\n",
    "        # copy weights\n",
    "        w_glob = net_glob.state_dict()\n",
    "\n",
    "        for iter in range(N_epochs): #args.epochs\n",
    "            w_locals, loss_locals = [], []\n",
    "            idxs_users = np.random.choice(range(N), m, replace=False)\n",
    "            idxs_users = np.sort(idxs_users)\n",
    "            print('selected users:',idxs_users)\n",
    "\n",
    "            dec_z_array = []\n",
    "            for idx in idxs_users: #for idx in range(N):\n",
    "        #         print(idx)\n",
    "                local = LocalUpdate_with_BACC(args=args, dataset=X_tilde[idx,:,:], label=y_tilde[idx,:,:])\n",
    "                w, loss = local.train(net=copy.deepcopy(net_glob).cuda())\n",
    "                w_locals.append(copy.deepcopy(w))\n",
    "                loss_locals.append(copy.deepcopy(loss))\n",
    "\n",
    "                dec_z_array.append(z_array[idx])\n",
    "\n",
    "\n",
    "            # update global weights\n",
    "            #w_glob = FedAvg(w_locals)\n",
    "            w_glob = FedAvg_with_BACC_Dec(w_locals, alpha_array, dec_z_array)\n",
    "\n",
    "            # copy weight to net_glob\n",
    "            net_glob.load_state_dict(w_glob)\n",
    "\n",
    "            # print loss\n",
    "        #     acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "\n",
    "        #     loss_train_arr.append(loss_train)\n",
    "\n",
    "            acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "            acc_test_arr[m_idx][trial_idx][iter] = acc_test\n",
    "            loss_test_arr[m_idx][trial_idx][iter] = loss_test\n",
    "            if iter % 1 ==0:\n",
    "                print('Round {:3d}, Average loss {:.3f} Test accuracy {:.3f}'.format(iter, loss_test, acc_test))\n",
    "            #print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
